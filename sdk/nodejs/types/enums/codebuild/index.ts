// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***


export const FleetComputeConfigurationmachineType = {
    General: "GENERAL",
    Nvme: "NVME",
} as const;

/**
 * The machine type of the instance type included in your fleet.
 */
export type FleetComputeConfigurationmachineType = (typeof FleetComputeConfigurationmachineType)[keyof typeof FleetComputeConfigurationmachineType];

export const FleetComputeType = {
    BuildGeneral1Small: "BUILD_GENERAL1_SMALL",
    BuildGeneral1Medium: "BUILD_GENERAL1_MEDIUM",
    BuildGeneral1Large: "BUILD_GENERAL1_LARGE",
    BuildGeneral1Xlarge: "BUILD_GENERAL1_XLARGE",
    BuildGeneral12xlarge: "BUILD_GENERAL1_2XLARGE",
    AttributeBasedCompute: "ATTRIBUTE_BASED_COMPUTE",
    CustomInstanceType: "CUSTOM_INSTANCE_TYPE",
} as const;

/**
 * Information about the compute resources the compute fleet uses. Available values include:
 *
 * - `ATTRIBUTE_BASED_COMPUTE` : Specify the amount of vCPUs, memory, disk space, and the type of machine.
 *
 * > If you use `ATTRIBUTE_BASED_COMPUTE` , you must define your attributes by using `computeConfiguration` . AWS CodeBuild will select the cheapest instance that satisfies your specified attributes. For more information, see [Reserved capacity environment types](https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-compute-types.html#environment-reserved-capacity.types) in the *AWS CodeBuild User Guide* .
 * - `BUILD_GENERAL1_SMALL` : Use up to 4 GiB memory and 2 vCPUs for builds.
 * - `BUILD_GENERAL1_MEDIUM` : Use up to 8 GiB memory and 4 vCPUs for builds.
 * - `BUILD_GENERAL1_LARGE` : Use up to 16 GiB memory and 8 vCPUs for builds, depending on your environment type.
 * - `BUILD_GENERAL1_XLARGE` : Use up to 72 GiB memory and 36 vCPUs for builds, depending on your environment type.
 * - `BUILD_GENERAL1_2XLARGE` : Use up to 144 GiB memory, 72 vCPUs, and 824 GB of SSD storage for builds. This compute type supports Docker images up to 100 GB uncompressed.
 * - `BUILD_LAMBDA_1GB` : Use up to 1 GiB memory for builds. Only available for environment type `LINUX_LAMBDA_CONTAINER` and `ARM_LAMBDA_CONTAINER` .
 * - `BUILD_LAMBDA_2GB` : Use up to 2 GiB memory for builds. Only available for environment type `LINUX_LAMBDA_CONTAINER` and `ARM_LAMBDA_CONTAINER` .
 * - `BUILD_LAMBDA_4GB` : Use up to 4 GiB memory for builds. Only available for environment type `LINUX_LAMBDA_CONTAINER` and `ARM_LAMBDA_CONTAINER` .
 * - `BUILD_LAMBDA_8GB` : Use up to 8 GiB memory for builds. Only available for environment type `LINUX_LAMBDA_CONTAINER` and `ARM_LAMBDA_CONTAINER` .
 * - `BUILD_LAMBDA_10GB` : Use up to 10 GiB memory for builds. Only available for environment type `LINUX_LAMBDA_CONTAINER` and `ARM_LAMBDA_CONTAINER` .
 *
 * If you use `BUILD_GENERAL1_SMALL` :
 *
 * - For environment type `LINUX_CONTAINER` , you can use up to 4 GiB memory and 2 vCPUs for builds.
 * - For environment type `LINUX_GPU_CONTAINER` , you can use up to 16 GiB memory, 4 vCPUs, and 1 NVIDIA A10G Tensor Core GPU for builds.
 * - For environment type `ARM_CONTAINER` , you can use up to 4 GiB memory and 2 vCPUs on ARM-based processors for builds.
 *
 * If you use `BUILD_GENERAL1_LARGE` :
 *
 * - For environment type `LINUX_CONTAINER` , you can use up to 16 GiB memory and 8 vCPUs for builds.
 * - For environment type `LINUX_GPU_CONTAINER` , you can use up to 255 GiB memory, 32 vCPUs, and 4 NVIDIA Tesla V100 GPUs for builds.
 * - For environment type `ARM_CONTAINER` , you can use up to 16 GiB memory and 8 vCPUs on ARM-based processors for builds.
 *
 * For more information, see [On-demand environment types](https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-compute-types.html#environment.types) in the *AWS CodeBuild User Guide.*
 */
export type FleetComputeType = (typeof FleetComputeType)[keyof typeof FleetComputeType];

export const FleetEnvironmentType = {
    WindowsServer2019Container: "WINDOWS_SERVER_2019_CONTAINER",
    WindowsServer2022Container: "WINDOWS_SERVER_2022_CONTAINER",
    LinuxContainer: "LINUX_CONTAINER",
    LinuxGpuContainer: "LINUX_GPU_CONTAINER",
    ArmContainer: "ARM_CONTAINER",
    MacArm: "MAC_ARM",
    LinuxEc2: "LINUX_EC2",
    ArmEc2: "ARM_EC2",
    WindowsEc2: "WINDOWS_EC2",
} as const;

/**
 * The environment type of the compute fleet.
 *
 * - The environment type `ARM_CONTAINER` is available only in regions US East (N. Virginia), US East (Ohio), US West (Oregon), EU (Ireland), Asia Pacific (Mumbai), Asia Pacific (Tokyo), Asia Pacific (Singapore), Asia Pacific (Sydney), EU (Frankfurt), and South America (São Paulo).
 * - The environment type `ARM_EC2` is available only in regions US East (N. Virginia), US East (Ohio), US West (Oregon), EU (Ireland), EU (Frankfurt), Asia Pacific (Tokyo), Asia Pacific (Singapore), Asia Pacific (Sydney), South America (São Paulo), and Asia Pacific (Mumbai).
 * - The environment type `LINUX_CONTAINER` is available only in regions US East (N. Virginia), US East (Ohio), US West (Oregon), EU (Ireland), EU (Frankfurt), Asia Pacific (Tokyo), Asia Pacific (Singapore), Asia Pacific (Sydney), South America (São Paulo), and Asia Pacific (Mumbai).
 * - The environment type `LINUX_EC2` is available only in regions US East (N. Virginia), US East (Ohio), US West (Oregon), EU (Ireland), EU (Frankfurt), Asia Pacific (Tokyo), Asia Pacific (Singapore), Asia Pacific (Sydney), South America (São Paulo), and Asia Pacific (Mumbai).
 * - The environment type `LINUX_GPU_CONTAINER` is available only in regions US East (N. Virginia), US East (Ohio), US West (Oregon), EU (Ireland), EU (Frankfurt), Asia Pacific (Tokyo), and Asia Pacific (Sydney).
 * - The environment type `MAC_ARM` is available only in regions US East (Ohio), US East (N. Virginia), US West (Oregon), Europe (Frankfurt), and Asia Pacific (Sydney).
 * - The environment type `WINDOWS_EC2` is available only in regions US East (N. Virginia), US East (Ohio), US West (Oregon), EU (Ireland), EU (Frankfurt), Asia Pacific (Tokyo), Asia Pacific (Singapore), Asia Pacific (Sydney), South America (São Paulo), and Asia Pacific (Mumbai).
 * - The environment type `WINDOWS_SERVER_2019_CONTAINER` is available only in regions US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Sydney), Asia Pacific (Tokyo), Asia Pacific (Mumbai) and EU (Ireland).
 * - The environment type `WINDOWS_SERVER_2022_CONTAINER` is available only in regions US East (N. Virginia), US East (Ohio), US West (Oregon), EU (Ireland), EU (Frankfurt), Asia Pacific (Sydney), Asia Pacific (Singapore), Asia Pacific (Tokyo), South America (São Paulo) and Asia Pacific (Mumbai).
 *
 * For more information, see [Build environment compute types](https://docs.aws.amazon.com//codebuild/latest/userguide/build-env-ref-compute-types.html) in the *AWS CodeBuild user guide* .
 */
export type FleetEnvironmentType = (typeof FleetEnvironmentType)[keyof typeof FleetEnvironmentType];

export const FleetOverflowBehavior = {
    Queue: "QUEUE",
    OnDemand: "ON_DEMAND",
} as const;

/**
 * The compute fleet overflow behavior.
 *
 * - For overflow behavior `QUEUE` , your overflow builds need to wait on the existing fleet instance to become available.
 * - For overflow behavior `ON_DEMAND` , your overflow builds run on CodeBuild on-demand.
 *
 * > If you choose to set your overflow behavior to on-demand while creating a VPC-connected fleet, make sure that you add the required VPC permissions to your project service role. For more information, see [Example policy statement to allow CodeBuild access to AWS services required to create a VPC network interface](https://docs.aws.amazon.com/codebuild/latest/userguide/auth-and-access-control-iam-identity-based-access-control.html#customer-managed-policies-example-create-vpc-network-interface) .
 */
export type FleetOverflowBehavior = (typeof FleetOverflowBehavior)[keyof typeof FleetOverflowBehavior];

export const FleetProxyConfigurationDefaultBehavior = {
    AllowAll: "ALLOW_ALL",
    DenyAll: "DENY_ALL",
} as const;

/**
 * The default behavior of outgoing traffic.
 */
export type FleetProxyConfigurationDefaultBehavior = (typeof FleetProxyConfigurationDefaultBehavior)[keyof typeof FleetProxyConfigurationDefaultBehavior];

export const FleetProxyRuleEffect = {
    Allow: "ALLOW",
    Deny: "DENY",
} as const;

/**
 * The behavior of the proxy rule.
 */
export type FleetProxyRuleEffect = (typeof FleetProxyRuleEffect)[keyof typeof FleetProxyRuleEffect];

export const FleetProxyRuleType = {
    Domain: "DOMAIN",
    Ip: "IP",
} as const;

/**
 * The type of proxy rule.
 */
export type FleetProxyRuleType = (typeof FleetProxyRuleType)[keyof typeof FleetProxyRuleType];

export const FleetScalingConfigurationInputScalingType = {
    TargetTrackingScaling: "TARGET_TRACKING_SCALING",
} as const;

/**
 * The scaling type for a compute fleet.
 */
export type FleetScalingConfigurationInputScalingType = (typeof FleetScalingConfigurationInputScalingType)[keyof typeof FleetScalingConfigurationInputScalingType];

export const FleetTargetTrackingScalingConfigurationMetricType = {
    FleetUtilizationRate: "FLEET_UTILIZATION_RATE",
} as const;

/**
 * The metric type to determine auto-scaling.
 */
export type FleetTargetTrackingScalingConfigurationMetricType = (typeof FleetTargetTrackingScalingConfigurationMetricType)[keyof typeof FleetTargetTrackingScalingConfigurationMetricType];
