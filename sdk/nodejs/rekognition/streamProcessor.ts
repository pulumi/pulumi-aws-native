// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../types/input";
import * as outputs from "../types/output";
import * as enums from "../types/enums";
import * as utilities from "../utilities";

/**
 * The AWS::Rekognition::StreamProcessor type is used to create an Amazon Rekognition StreamProcessor that you can use to analyze streaming videos.
 */
export class StreamProcessor extends pulumi.CustomResource {
    /**
     * Get an existing StreamProcessor resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, opts?: pulumi.CustomResourceOptions): StreamProcessor {
        return new StreamProcessor(name, undefined as any, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'aws-native:rekognition:StreamProcessor';

    /**
     * Returns true if the given object is an instance of StreamProcessor.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is StreamProcessor {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === StreamProcessor.__pulumiType;
    }

    /**
     * Amazon Resource Name for the newly created stream processor.
     */
    public /*out*/ readonly arn!: pulumi.Output<string>;
    /**
     * The BoundingBoxRegionsOfInterest specifies an array of bounding boxes of interest in the video frames to analyze, as part of connected home feature. If an object is partially in a region of interest, Rekognition will tag it as detected if the overlap of the object with the region-of-interest is greater than 20%.
     */
    public readonly boundingBoxRegionsOfInterest!: pulumi.Output<outputs.rekognition.StreamProcessorBoundingBox[] | undefined>;
    /**
     * Connected home settings to use on a streaming video. Defining the settings is required in the request parameter for `CreateStreamProcessor` . Including this setting in the CreateStreamProcessor request lets you use the stream processor for connected home features. You can then select what you want the stream processor to detect, such as people or pets.
     *
     * When the stream processor has started, one notification is sent for each object class specified. For example, if packages and pets are selected, one SNS notification is published the first time a package is detected and one SNS notification is published the first time a pet is detected. An end-of-session summary is also published. For more information, see the ConnectedHome section of [StreamProcessorSettings](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_StreamProcessorSettings) .
     */
    public readonly connectedHomeSettings!: pulumi.Output<outputs.rekognition.StreamProcessorConnectedHomeSettings | undefined>;
    /**
     * Allows you to opt in or opt out to share data with Rekognition to improve model performance. You can choose this option at the account level or on a per-stream basis. Note that if you opt out at the account level, this setting is ignored on individual streams. For more information, see [StreamProcessorDataSharingPreference](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_StreamProcessorDataSharingPreference) .
     */
    public readonly dataSharingPreference!: pulumi.Output<outputs.rekognition.StreamProcessorDataSharingPreference | undefined>;
    /**
     * The input parameters used to recognize faces in a streaming video analyzed by a Amazon Rekognition stream processor. `FaceSearchSettings` is a request parameter for [CreateStreamProcessor](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_CreateStreamProcessor) . For more information, see [FaceSearchSettings](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_FaceSearchSettings) .
     */
    public readonly faceSearchSettings!: pulumi.Output<outputs.rekognition.StreamProcessorFaceSearchSettings | undefined>;
    /**
     * Amazon Rekognition Video Stream Processor take as input a Kinesis video stream (Input) and a Kinesis data stream (Output). This is the Amazon Kinesis Data Streams instance to which the Amazon Rekognition stream processor streams the analysis results. This must be created within the constraints specified at [KinesisDataStream](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_KinesisDataStream) .
     */
    public readonly kinesisDataStream!: pulumi.Output<outputs.rekognition.StreamProcessorKinesisDataStream | undefined>;
    /**
     * The Kinesis video stream that provides the source of the streaming video for an Amazon Rekognition Video stream processor. For more information, see [KinesisVideoStream](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_KinesisVideoStream) .
     */
    public readonly kinesisVideoStream!: pulumi.Output<outputs.rekognition.StreamProcessorKinesisVideoStream>;
    /**
     * The KMS key that is used by Rekognition to encrypt any intermediate customer metadata and store in the customer's S3 bucket.
     */
    public readonly kmsKeyId!: pulumi.Output<string | undefined>;
    /**
     * Name of the stream processor. It's an identifier you assign to the stream processor. You can use it to manage the stream processor.
     */
    public readonly name!: pulumi.Output<string | undefined>;
    /**
     * The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the object detection results and completion status of a video analysis operation. Amazon Rekognition publishes a notification the first time an object of interest or a person is detected in the video stream. Amazon Rekognition also publishes an an end-of-session notification with a summary when the stream processing session is complete. For more information, see [StreamProcessorNotificationChannel](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_StreamProcessorNotificationChannel) .
     */
    public readonly notificationChannel!: pulumi.Output<outputs.rekognition.StreamProcessorNotificationChannel | undefined>;
    /**
     * The PolygonRegionsOfInterest specifies a set of polygon areas of interest in the video frames to analyze, as part of connected home feature. Each polygon is in turn, an ordered list of Point
     */
    public readonly polygonRegionsOfInterest!: pulumi.Output<outputs.rekognition.StreamProcessorPoint[][] | undefined>;
    /**
     * ARN of the IAM role that allows access to the stream processor, and provides Rekognition read permissions for KVS stream and write permissions to S3 bucket and SNS topic.
     */
    public readonly roleArn!: pulumi.Output<string>;
    /**
     * The Amazon S3 bucket location to which Amazon Rekognition publishes the detailed inference results of a video analysis operation. These results include the name of the stream processor resource, the session ID of the stream processing session, and labeled timestamps and bounding boxes for detected labels. For more information, see [S3Destination](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_S3Destination) .
     */
    public readonly s3Destination!: pulumi.Output<outputs.rekognition.StreamProcessorS3Destination | undefined>;
    /**
     * Current status of the stream processor.
     */
    public /*out*/ readonly status!: pulumi.Output<string>;
    /**
     * Detailed status message about the stream processor.
     */
    public /*out*/ readonly statusMessage!: pulumi.Output<string>;
    /**
     * An array of key-value pairs to apply to this resource.
     */
    public readonly tags!: pulumi.Output<outputs.Tag[] | undefined>;

    /**
     * Create a StreamProcessor resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    constructor(name: string, args: StreamProcessorArgs, opts?: pulumi.CustomResourceOptions) {
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (!opts.id) {
            if ((!args || args.kinesisVideoStream === undefined) && !opts.urn) {
                throw new Error("Missing required property 'kinesisVideoStream'");
            }
            if ((!args || args.roleArn === undefined) && !opts.urn) {
                throw new Error("Missing required property 'roleArn'");
            }
            resourceInputs["boundingBoxRegionsOfInterest"] = args ? args.boundingBoxRegionsOfInterest : undefined;
            resourceInputs["connectedHomeSettings"] = args ? args.connectedHomeSettings : undefined;
            resourceInputs["dataSharingPreference"] = args ? args.dataSharingPreference : undefined;
            resourceInputs["faceSearchSettings"] = args ? args.faceSearchSettings : undefined;
            resourceInputs["kinesisDataStream"] = args ? args.kinesisDataStream : undefined;
            resourceInputs["kinesisVideoStream"] = args ? args.kinesisVideoStream : undefined;
            resourceInputs["kmsKeyId"] = args ? args.kmsKeyId : undefined;
            resourceInputs["name"] = args ? args.name : undefined;
            resourceInputs["notificationChannel"] = args ? args.notificationChannel : undefined;
            resourceInputs["polygonRegionsOfInterest"] = args ? args.polygonRegionsOfInterest : undefined;
            resourceInputs["roleArn"] = args ? args.roleArn : undefined;
            resourceInputs["s3Destination"] = args ? args.s3Destination : undefined;
            resourceInputs["tags"] = args ? args.tags : undefined;
            resourceInputs["arn"] = undefined /*out*/;
            resourceInputs["status"] = undefined /*out*/;
            resourceInputs["statusMessage"] = undefined /*out*/;
        } else {
            resourceInputs["arn"] = undefined /*out*/;
            resourceInputs["boundingBoxRegionsOfInterest"] = undefined /*out*/;
            resourceInputs["connectedHomeSettings"] = undefined /*out*/;
            resourceInputs["dataSharingPreference"] = undefined /*out*/;
            resourceInputs["faceSearchSettings"] = undefined /*out*/;
            resourceInputs["kinesisDataStream"] = undefined /*out*/;
            resourceInputs["kinesisVideoStream"] = undefined /*out*/;
            resourceInputs["kmsKeyId"] = undefined /*out*/;
            resourceInputs["name"] = undefined /*out*/;
            resourceInputs["notificationChannel"] = undefined /*out*/;
            resourceInputs["polygonRegionsOfInterest"] = undefined /*out*/;
            resourceInputs["roleArn"] = undefined /*out*/;
            resourceInputs["s3Destination"] = undefined /*out*/;
            resourceInputs["status"] = undefined /*out*/;
            resourceInputs["statusMessage"] = undefined /*out*/;
            resourceInputs["tags"] = undefined /*out*/;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        const replaceOnChanges = { replaceOnChanges: ["boundingBoxRegionsOfInterest[*]", "connectedHomeSettings", "dataSharingPreference", "faceSearchSettings", "kinesisDataStream", "kinesisVideoStream", "kmsKeyId", "name", "notificationChannel", "polygonRegionsOfInterest[*]", "roleArn", "s3Destination"] };
        opts = pulumi.mergeOptions(opts, replaceOnChanges);
        super(StreamProcessor.__pulumiType, name, resourceInputs, opts);
    }
}

/**
 * The set of arguments for constructing a StreamProcessor resource.
 */
export interface StreamProcessorArgs {
    /**
     * The BoundingBoxRegionsOfInterest specifies an array of bounding boxes of interest in the video frames to analyze, as part of connected home feature. If an object is partially in a region of interest, Rekognition will tag it as detected if the overlap of the object with the region-of-interest is greater than 20%.
     */
    boundingBoxRegionsOfInterest?: pulumi.Input<pulumi.Input<inputs.rekognition.StreamProcessorBoundingBoxArgs>[]>;
    /**
     * Connected home settings to use on a streaming video. Defining the settings is required in the request parameter for `CreateStreamProcessor` . Including this setting in the CreateStreamProcessor request lets you use the stream processor for connected home features. You can then select what you want the stream processor to detect, such as people or pets.
     *
     * When the stream processor has started, one notification is sent for each object class specified. For example, if packages and pets are selected, one SNS notification is published the first time a package is detected and one SNS notification is published the first time a pet is detected. An end-of-session summary is also published. For more information, see the ConnectedHome section of [StreamProcessorSettings](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_StreamProcessorSettings) .
     */
    connectedHomeSettings?: pulumi.Input<inputs.rekognition.StreamProcessorConnectedHomeSettingsArgs>;
    /**
     * Allows you to opt in or opt out to share data with Rekognition to improve model performance. You can choose this option at the account level or on a per-stream basis. Note that if you opt out at the account level, this setting is ignored on individual streams. For more information, see [StreamProcessorDataSharingPreference](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_StreamProcessorDataSharingPreference) .
     */
    dataSharingPreference?: pulumi.Input<inputs.rekognition.StreamProcessorDataSharingPreferenceArgs>;
    /**
     * The input parameters used to recognize faces in a streaming video analyzed by a Amazon Rekognition stream processor. `FaceSearchSettings` is a request parameter for [CreateStreamProcessor](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_CreateStreamProcessor) . For more information, see [FaceSearchSettings](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_FaceSearchSettings) .
     */
    faceSearchSettings?: pulumi.Input<inputs.rekognition.StreamProcessorFaceSearchSettingsArgs>;
    /**
     * Amazon Rekognition Video Stream Processor take as input a Kinesis video stream (Input) and a Kinesis data stream (Output). This is the Amazon Kinesis Data Streams instance to which the Amazon Rekognition stream processor streams the analysis results. This must be created within the constraints specified at [KinesisDataStream](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_KinesisDataStream) .
     */
    kinesisDataStream?: pulumi.Input<inputs.rekognition.StreamProcessorKinesisDataStreamArgs>;
    /**
     * The Kinesis video stream that provides the source of the streaming video for an Amazon Rekognition Video stream processor. For more information, see [KinesisVideoStream](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_KinesisVideoStream) .
     */
    kinesisVideoStream: pulumi.Input<inputs.rekognition.StreamProcessorKinesisVideoStreamArgs>;
    /**
     * The KMS key that is used by Rekognition to encrypt any intermediate customer metadata and store in the customer's S3 bucket.
     */
    kmsKeyId?: pulumi.Input<string>;
    /**
     * Name of the stream processor. It's an identifier you assign to the stream processor. You can use it to manage the stream processor.
     */
    name?: pulumi.Input<string>;
    /**
     * The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the object detection results and completion status of a video analysis operation. Amazon Rekognition publishes a notification the first time an object of interest or a person is detected in the video stream. Amazon Rekognition also publishes an an end-of-session notification with a summary when the stream processing session is complete. For more information, see [StreamProcessorNotificationChannel](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_StreamProcessorNotificationChannel) .
     */
    notificationChannel?: pulumi.Input<inputs.rekognition.StreamProcessorNotificationChannelArgs>;
    /**
     * The PolygonRegionsOfInterest specifies a set of polygon areas of interest in the video frames to analyze, as part of connected home feature. Each polygon is in turn, an ordered list of Point
     */
    polygonRegionsOfInterest?: pulumi.Input<pulumi.Input<pulumi.Input<inputs.rekognition.StreamProcessorPointArgs>[]>[]>;
    /**
     * ARN of the IAM role that allows access to the stream processor, and provides Rekognition read permissions for KVS stream and write permissions to S3 bucket and SNS topic.
     */
    roleArn: pulumi.Input<string>;
    /**
     * The Amazon S3 bucket location to which Amazon Rekognition publishes the detailed inference results of a video analysis operation. These results include the name of the stream processor resource, the session ID of the stream processing session, and labeled timestamps and bounding boxes for detected labels. For more information, see [S3Destination](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_S3Destination) .
     */
    s3Destination?: pulumi.Input<inputs.rekognition.StreamProcessorS3DestinationArgs>;
    /**
     * An array of key-value pairs to apply to this resource.
     */
    tags?: pulumi.Input<pulumi.Input<inputs.TagArgs>[]>;
}
