# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import copy
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from .. import _utilities
from . import outputs
from ._inputs import *

__all__ = ['JobArgs', 'Job']

@pulumi.input_type
class JobArgs:
    def __init__(__self__, *,
                 command: pulumi.Input['JobCommandArgs'],
                 role: pulumi.Input[str],
                 allocated_capacity: Optional[pulumi.Input[float]] = None,
                 connections: Optional[pulumi.Input['JobConnectionsListArgs']] = None,
                 default_arguments: Optional[Any] = None,
                 description: Optional[pulumi.Input[str]] = None,
                 execution_class: Optional[pulumi.Input[str]] = None,
                 execution_property: Optional[pulumi.Input['JobExecutionPropertyArgs']] = None,
                 glue_version: Optional[pulumi.Input[str]] = None,
                 job_mode: Optional[pulumi.Input[str]] = None,
                 log_uri: Optional[pulumi.Input[str]] = None,
                 maintenance_window: Optional[pulumi.Input[str]] = None,
                 max_capacity: Optional[pulumi.Input[float]] = None,
                 max_retries: Optional[pulumi.Input[float]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 non_overridable_arguments: Optional[Any] = None,
                 notification_property: Optional[pulumi.Input['JobNotificationPropertyArgs']] = None,
                 number_of_workers: Optional[pulumi.Input[int]] = None,
                 security_configuration: Optional[pulumi.Input[str]] = None,
                 tags: Optional[Any] = None,
                 timeout: Optional[pulumi.Input[int]] = None,
                 worker_type: Optional[pulumi.Input[str]] = None):
        """
        The set of arguments for constructing a Job resource.
        :param pulumi.Input['JobCommandArgs'] command: The code that executes a job.
        :param pulumi.Input[str] role: The name or Amazon Resource Name (ARN) of the IAM role associated with this job.
        :param pulumi.Input[float] allocated_capacity: This parameter is no longer supported. Use `MaxCapacity` instead.
               
               The number of capacity units that are allocated to this job.
        :param pulumi.Input['JobConnectionsListArgs'] connections: The connections used for this job.
        :param Any default_arguments: The default arguments for this job, specified as name-value pairs.
               
               You can specify arguments here that your own job-execution script consumes, in addition to arguments that AWS Glue itself consumes.
               
               For information about how to specify and consume your own job arguments, see [Calling AWS Glue APIs in Python](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-calling.html) in the *AWS Glue Developer Guide* .
               
               For information about the key-value pairs that AWS Glue consumes to set up your job, see [Special Parameters Used by AWS Glue](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html) in the *AWS Glue Developer Guide* .
               
               Search the [CloudFormation User Guide](https://docs.aws.amazon.com/cloudformation/) for `AWS::Glue::Job` for more information about the expected schema for this property.
        :param pulumi.Input[str] description: A description of the job.
        :param pulumi.Input[str] execution_class: Indicates whether the job is run with a standard or flexible execution class. The standard execution class is ideal for time-sensitive workloads that require fast job startup and dedicated resources.
               
               The flexible execution class is appropriate for time-insensitive jobs whose start and completion times may vary.
               
               Only jobs with AWS Glue version 3.0 and above and command type `glueetl` will be allowed to set `ExecutionClass` to `FLEX` . The flexible execution class is available for Spark jobs.
        :param pulumi.Input['JobExecutionPropertyArgs'] execution_property: The maximum number of concurrent runs that are allowed for this job.
        :param pulumi.Input[str] glue_version: Glue version determines the versions of Apache Spark and Python that AWS Glue supports. The Python version indicates the version supported for jobs of type Spark.
               
               For more information about the available AWS Glue versions and corresponding Spark and Python versions, see [Glue version](https://docs.aws.amazon.com/glue/latest/dg/add-job.html) in the developer guide.
               
               Jobs that are created without specifying a Glue version default to the latest Glue version available.
        :param pulumi.Input[str] job_mode: A mode that describes how a job was created. Valid values are:
               
               - `SCRIPT` - The job was created using the AWS Glue Studio script editor.
               - `VISUAL` - The job was created using the AWS Glue Studio visual editor.
               - `NOTEBOOK` - The job was created using an interactive sessions notebook.
               
               When the `JobMode` field is missing or null, `SCRIPT` is assigned as the default value.
        :param pulumi.Input[str] log_uri: This field is reserved for future use.
        :param pulumi.Input[str] maintenance_window: This field specifies a day of the week and hour for a maintenance window for streaming jobs. AWS Glue periodically performs maintenance activities. During these maintenance windows, AWS Glue will need to restart your streaming jobs.
               
               AWS Glue will restart the job within 3 hours of the specified maintenance window. For instance, if you set up the maintenance window for Monday at 10:00AM GMT, your jobs will be restarted between 10:00AM GMT to 1:00PM GMT.
        :param pulumi.Input[float] max_capacity: The number of AWS Glue data processing units (DPUs) that can be allocated when this job runs. A DPU is a relative measure of processing power that consists of 4 vCPUs of compute capacity and 16 GB of memory.
               
               Do not set `Max Capacity` if using `WorkerType` and `NumberOfWorkers` .
               
               The value that can be allocated for `MaxCapacity` depends on whether you are running a Python shell job or an Apache Spark ETL job:
               
               - When you specify a Python shell job ( `JobCommand.Name` ="pythonshell"), you can allocate either 0.0625 or 1 DPU. The default is 0.0625 DPU.
               - When you specify an Apache Spark ETL job ( `JobCommand.Name` ="glueetl"), you can allocate from 2 to 100 DPUs. The default is 10 DPUs. This job type cannot have a fractional DPU allocation.
        :param pulumi.Input[float] max_retries: The maximum number of times to retry this job after a JobRun fails.
        :param pulumi.Input[str] name: The name you assign to this job definition.
        :param Any non_overridable_arguments: Non-overridable arguments for this job, specified as name-value pairs.
               
               Search the [CloudFormation User Guide](https://docs.aws.amazon.com/cloudformation/) for `AWS::Glue::Job` for more information about the expected schema for this property.
        :param pulumi.Input['JobNotificationPropertyArgs'] notification_property: Specifies configuration properties of a notification.
        :param pulumi.Input[int] number_of_workers: The number of workers of a defined `workerType` that are allocated when a job runs.
               
               The maximum number of workers you can define are 299 for `G.1X` , and 149 for `G.2X` .
        :param pulumi.Input[str] security_configuration: The name of the `SecurityConfiguration` structure to be used with this job.
        :param Any tags: The tags to use with this job.
               
               Search the [CloudFormation User Guide](https://docs.aws.amazon.com/cloudformation/) for `AWS::Glue::Job` for more information about the expected schema for this property.
        :param pulumi.Input[int] timeout: The job timeout in minutes. This is the maximum time that a job run can consume resources before it is terminated and enters TIMEOUT status. The default is 2,880 minutes (48 hours).
        :param pulumi.Input[str] worker_type: The type of predefined worker that is allocated when a job runs. Accepts a value of G.1X, G.2X, G.4X, G.8X or G.025X for Spark jobs. Accepts the value Z.2X for Ray jobs.
               
               - For the `G.1X` worker type, each worker maps to 1 DPU (4 vCPUs, 16 GB of memory) with 84GB disk (approximately 34GB free), and provides 1 executor per worker. We recommend this worker type for workloads such as data transforms, joins, and queries, to offers a scalable and cost effective way to run most jobs.
               - For the `G.2X` worker type, each worker maps to 2 DPU (8 vCPUs, 32 GB of memory) with 128GB disk (approximately 77GB free), and provides 1 executor per worker. We recommend this worker type for workloads such as data transforms, joins, and queries, to offers a scalable and cost effective way to run most jobs.
               - For the `G.4X` worker type, each worker maps to 4 DPU (16 vCPUs, 64 GB of memory) with 256GB disk (approximately 235GB free), and provides 1 executor per worker. We recommend this worker type for jobs whose workloads contain your most demanding transforms, aggregations, joins, and queries. This worker type is available only for AWS Glue version 3.0 or later Spark ETL jobs in the following AWS Regions: US East (Ohio), US East (N. Virginia), US West (Oregon), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (Ireland), and Europe (Stockholm).
               - For the `G.8X` worker type, each worker maps to 8 DPU (32 vCPUs, 128 GB of memory) with 512GB disk (approximately 487GB free), and provides 1 executor per worker. We recommend this worker type for jobs whose workloads contain your most demanding transforms, aggregations, joins, and queries. This worker type is available only for AWS Glue version 3.0 or later Spark ETL jobs, in the same AWS Regions as supported for the `G.4X` worker type.
               - For the `G.025X` worker type, each worker maps to 0.25 DPU (2 vCPUs, 4 GB of memory) with 84GB disk (approximately 34GB free), and provides 1 executor per worker. We recommend this worker type for low volume streaming jobs. This worker type is only available for AWS Glue version 3.0 streaming jobs.
               - For the `Z.2X` worker type, each worker maps to 2 M-DPU (8vCPUs, 64 GB of memory) with 128 GB disk (approximately 120GB free), and provides up to 8 Ray workers based on the autoscaler.
        """
        pulumi.set(__self__, "command", command)
        pulumi.set(__self__, "role", role)
        if allocated_capacity is not None:
            pulumi.set(__self__, "allocated_capacity", allocated_capacity)
        if connections is not None:
            pulumi.set(__self__, "connections", connections)
        if default_arguments is not None:
            pulumi.set(__self__, "default_arguments", default_arguments)
        if description is not None:
            pulumi.set(__self__, "description", description)
        if execution_class is not None:
            pulumi.set(__self__, "execution_class", execution_class)
        if execution_property is not None:
            pulumi.set(__self__, "execution_property", execution_property)
        if glue_version is not None:
            pulumi.set(__self__, "glue_version", glue_version)
        if job_mode is not None:
            pulumi.set(__self__, "job_mode", job_mode)
        if log_uri is not None:
            pulumi.set(__self__, "log_uri", log_uri)
        if maintenance_window is not None:
            pulumi.set(__self__, "maintenance_window", maintenance_window)
        if max_capacity is not None:
            pulumi.set(__self__, "max_capacity", max_capacity)
        if max_retries is not None:
            pulumi.set(__self__, "max_retries", max_retries)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if non_overridable_arguments is not None:
            pulumi.set(__self__, "non_overridable_arguments", non_overridable_arguments)
        if notification_property is not None:
            pulumi.set(__self__, "notification_property", notification_property)
        if number_of_workers is not None:
            pulumi.set(__self__, "number_of_workers", number_of_workers)
        if security_configuration is not None:
            pulumi.set(__self__, "security_configuration", security_configuration)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if timeout is not None:
            pulumi.set(__self__, "timeout", timeout)
        if worker_type is not None:
            pulumi.set(__self__, "worker_type", worker_type)

    @property
    @pulumi.getter
    def command(self) -> pulumi.Input['JobCommandArgs']:
        """
        The code that executes a job.
        """
        return pulumi.get(self, "command")

    @command.setter
    def command(self, value: pulumi.Input['JobCommandArgs']):
        pulumi.set(self, "command", value)

    @property
    @pulumi.getter
    def role(self) -> pulumi.Input[str]:
        """
        The name or Amazon Resource Name (ARN) of the IAM role associated with this job.
        """
        return pulumi.get(self, "role")

    @role.setter
    def role(self, value: pulumi.Input[str]):
        pulumi.set(self, "role", value)

    @property
    @pulumi.getter(name="allocatedCapacity")
    def allocated_capacity(self) -> Optional[pulumi.Input[float]]:
        """
        This parameter is no longer supported. Use `MaxCapacity` instead.

        The number of capacity units that are allocated to this job.
        """
        return pulumi.get(self, "allocated_capacity")

    @allocated_capacity.setter
    def allocated_capacity(self, value: Optional[pulumi.Input[float]]):
        pulumi.set(self, "allocated_capacity", value)

    @property
    @pulumi.getter
    def connections(self) -> Optional[pulumi.Input['JobConnectionsListArgs']]:
        """
        The connections used for this job.
        """
        return pulumi.get(self, "connections")

    @connections.setter
    def connections(self, value: Optional[pulumi.Input['JobConnectionsListArgs']]):
        pulumi.set(self, "connections", value)

    @property
    @pulumi.getter(name="defaultArguments")
    def default_arguments(self) -> Optional[Any]:
        """
        The default arguments for this job, specified as name-value pairs.

        You can specify arguments here that your own job-execution script consumes, in addition to arguments that AWS Glue itself consumes.

        For information about how to specify and consume your own job arguments, see [Calling AWS Glue APIs in Python](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-calling.html) in the *AWS Glue Developer Guide* .

        For information about the key-value pairs that AWS Glue consumes to set up your job, see [Special Parameters Used by AWS Glue](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html) in the *AWS Glue Developer Guide* .

        Search the [CloudFormation User Guide](https://docs.aws.amazon.com/cloudformation/) for `AWS::Glue::Job` for more information about the expected schema for this property.
        """
        return pulumi.get(self, "default_arguments")

    @default_arguments.setter
    def default_arguments(self, value: Optional[Any]):
        pulumi.set(self, "default_arguments", value)

    @property
    @pulumi.getter
    def description(self) -> Optional[pulumi.Input[str]]:
        """
        A description of the job.
        """
        return pulumi.get(self, "description")

    @description.setter
    def description(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "description", value)

    @property
    @pulumi.getter(name="executionClass")
    def execution_class(self) -> Optional[pulumi.Input[str]]:
        """
        Indicates whether the job is run with a standard or flexible execution class. The standard execution class is ideal for time-sensitive workloads that require fast job startup and dedicated resources.

        The flexible execution class is appropriate for time-insensitive jobs whose start and completion times may vary.

        Only jobs with AWS Glue version 3.0 and above and command type `glueetl` will be allowed to set `ExecutionClass` to `FLEX` . The flexible execution class is available for Spark jobs.
        """
        return pulumi.get(self, "execution_class")

    @execution_class.setter
    def execution_class(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "execution_class", value)

    @property
    @pulumi.getter(name="executionProperty")
    def execution_property(self) -> Optional[pulumi.Input['JobExecutionPropertyArgs']]:
        """
        The maximum number of concurrent runs that are allowed for this job.
        """
        return pulumi.get(self, "execution_property")

    @execution_property.setter
    def execution_property(self, value: Optional[pulumi.Input['JobExecutionPropertyArgs']]):
        pulumi.set(self, "execution_property", value)

    @property
    @pulumi.getter(name="glueVersion")
    def glue_version(self) -> Optional[pulumi.Input[str]]:
        """
        Glue version determines the versions of Apache Spark and Python that AWS Glue supports. The Python version indicates the version supported for jobs of type Spark.

        For more information about the available AWS Glue versions and corresponding Spark and Python versions, see [Glue version](https://docs.aws.amazon.com/glue/latest/dg/add-job.html) in the developer guide.

        Jobs that are created without specifying a Glue version default to the latest Glue version available.
        """
        return pulumi.get(self, "glue_version")

    @glue_version.setter
    def glue_version(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "glue_version", value)

    @property
    @pulumi.getter(name="jobMode")
    def job_mode(self) -> Optional[pulumi.Input[str]]:
        """
        A mode that describes how a job was created. Valid values are:

        - `SCRIPT` - The job was created using the AWS Glue Studio script editor.
        - `VISUAL` - The job was created using the AWS Glue Studio visual editor.
        - `NOTEBOOK` - The job was created using an interactive sessions notebook.

        When the `JobMode` field is missing or null, `SCRIPT` is assigned as the default value.
        """
        return pulumi.get(self, "job_mode")

    @job_mode.setter
    def job_mode(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "job_mode", value)

    @property
    @pulumi.getter(name="logUri")
    def log_uri(self) -> Optional[pulumi.Input[str]]:
        """
        This field is reserved for future use.
        """
        return pulumi.get(self, "log_uri")

    @log_uri.setter
    def log_uri(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "log_uri", value)

    @property
    @pulumi.getter(name="maintenanceWindow")
    def maintenance_window(self) -> Optional[pulumi.Input[str]]:
        """
        This field specifies a day of the week and hour for a maintenance window for streaming jobs. AWS Glue periodically performs maintenance activities. During these maintenance windows, AWS Glue will need to restart your streaming jobs.

        AWS Glue will restart the job within 3 hours of the specified maintenance window. For instance, if you set up the maintenance window for Monday at 10:00AM GMT, your jobs will be restarted between 10:00AM GMT to 1:00PM GMT.
        """
        return pulumi.get(self, "maintenance_window")

    @maintenance_window.setter
    def maintenance_window(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "maintenance_window", value)

    @property
    @pulumi.getter(name="maxCapacity")
    def max_capacity(self) -> Optional[pulumi.Input[float]]:
        """
        The number of AWS Glue data processing units (DPUs) that can be allocated when this job runs. A DPU is a relative measure of processing power that consists of 4 vCPUs of compute capacity and 16 GB of memory.

        Do not set `Max Capacity` if using `WorkerType` and `NumberOfWorkers` .

        The value that can be allocated for `MaxCapacity` depends on whether you are running a Python shell job or an Apache Spark ETL job:

        - When you specify a Python shell job ( `JobCommand.Name` ="pythonshell"), you can allocate either 0.0625 or 1 DPU. The default is 0.0625 DPU.
        - When you specify an Apache Spark ETL job ( `JobCommand.Name` ="glueetl"), you can allocate from 2 to 100 DPUs. The default is 10 DPUs. This job type cannot have a fractional DPU allocation.
        """
        return pulumi.get(self, "max_capacity")

    @max_capacity.setter
    def max_capacity(self, value: Optional[pulumi.Input[float]]):
        pulumi.set(self, "max_capacity", value)

    @property
    @pulumi.getter(name="maxRetries")
    def max_retries(self) -> Optional[pulumi.Input[float]]:
        """
        The maximum number of times to retry this job after a JobRun fails.
        """
        return pulumi.get(self, "max_retries")

    @max_retries.setter
    def max_retries(self, value: Optional[pulumi.Input[float]]):
        pulumi.set(self, "max_retries", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[str]]:
        """
        The name you assign to this job definition.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter(name="nonOverridableArguments")
    def non_overridable_arguments(self) -> Optional[Any]:
        """
        Non-overridable arguments for this job, specified as name-value pairs.

        Search the [CloudFormation User Guide](https://docs.aws.amazon.com/cloudformation/) for `AWS::Glue::Job` for more information about the expected schema for this property.
        """
        return pulumi.get(self, "non_overridable_arguments")

    @non_overridable_arguments.setter
    def non_overridable_arguments(self, value: Optional[Any]):
        pulumi.set(self, "non_overridable_arguments", value)

    @property
    @pulumi.getter(name="notificationProperty")
    def notification_property(self) -> Optional[pulumi.Input['JobNotificationPropertyArgs']]:
        """
        Specifies configuration properties of a notification.
        """
        return pulumi.get(self, "notification_property")

    @notification_property.setter
    def notification_property(self, value: Optional[pulumi.Input['JobNotificationPropertyArgs']]):
        pulumi.set(self, "notification_property", value)

    @property
    @pulumi.getter(name="numberOfWorkers")
    def number_of_workers(self) -> Optional[pulumi.Input[int]]:
        """
        The number of workers of a defined `workerType` that are allocated when a job runs.

        The maximum number of workers you can define are 299 for `G.1X` , and 149 for `G.2X` .
        """
        return pulumi.get(self, "number_of_workers")

    @number_of_workers.setter
    def number_of_workers(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "number_of_workers", value)

    @property
    @pulumi.getter(name="securityConfiguration")
    def security_configuration(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the `SecurityConfiguration` structure to be used with this job.
        """
        return pulumi.get(self, "security_configuration")

    @security_configuration.setter
    def security_configuration(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "security_configuration", value)

    @property
    @pulumi.getter
    def tags(self) -> Optional[Any]:
        """
        The tags to use with this job.

        Search the [CloudFormation User Guide](https://docs.aws.amazon.com/cloudformation/) for `AWS::Glue::Job` for more information about the expected schema for this property.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[Any]):
        pulumi.set(self, "tags", value)

    @property
    @pulumi.getter
    def timeout(self) -> Optional[pulumi.Input[int]]:
        """
        The job timeout in minutes. This is the maximum time that a job run can consume resources before it is terminated and enters TIMEOUT status. The default is 2,880 minutes (48 hours).
        """
        return pulumi.get(self, "timeout")

    @timeout.setter
    def timeout(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "timeout", value)

    @property
    @pulumi.getter(name="workerType")
    def worker_type(self) -> Optional[pulumi.Input[str]]:
        """
        The type of predefined worker that is allocated when a job runs. Accepts a value of G.1X, G.2X, G.4X, G.8X or G.025X for Spark jobs. Accepts the value Z.2X for Ray jobs.

        - For the `G.1X` worker type, each worker maps to 1 DPU (4 vCPUs, 16 GB of memory) with 84GB disk (approximately 34GB free), and provides 1 executor per worker. We recommend this worker type for workloads such as data transforms, joins, and queries, to offers a scalable and cost effective way to run most jobs.
        - For the `G.2X` worker type, each worker maps to 2 DPU (8 vCPUs, 32 GB of memory) with 128GB disk (approximately 77GB free), and provides 1 executor per worker. We recommend this worker type for workloads such as data transforms, joins, and queries, to offers a scalable and cost effective way to run most jobs.
        - For the `G.4X` worker type, each worker maps to 4 DPU (16 vCPUs, 64 GB of memory) with 256GB disk (approximately 235GB free), and provides 1 executor per worker. We recommend this worker type for jobs whose workloads contain your most demanding transforms, aggregations, joins, and queries. This worker type is available only for AWS Glue version 3.0 or later Spark ETL jobs in the following AWS Regions: US East (Ohio), US East (N. Virginia), US West (Oregon), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (Ireland), and Europe (Stockholm).
        - For the `G.8X` worker type, each worker maps to 8 DPU (32 vCPUs, 128 GB of memory) with 512GB disk (approximately 487GB free), and provides 1 executor per worker. We recommend this worker type for jobs whose workloads contain your most demanding transforms, aggregations, joins, and queries. This worker type is available only for AWS Glue version 3.0 or later Spark ETL jobs, in the same AWS Regions as supported for the `G.4X` worker type.
        - For the `G.025X` worker type, each worker maps to 0.25 DPU (2 vCPUs, 4 GB of memory) with 84GB disk (approximately 34GB free), and provides 1 executor per worker. We recommend this worker type for low volume streaming jobs. This worker type is only available for AWS Glue version 3.0 streaming jobs.
        - For the `Z.2X` worker type, each worker maps to 2 M-DPU (8vCPUs, 64 GB of memory) with 128 GB disk (approximately 120GB free), and provides up to 8 Ray workers based on the autoscaler.
        """
        return pulumi.get(self, "worker_type")

    @worker_type.setter
    def worker_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "worker_type", value)


class Job(pulumi.CustomResource):
    @overload
    def __init__(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 allocated_capacity: Optional[pulumi.Input[float]] = None,
                 command: Optional[pulumi.Input[Union['JobCommandArgs', 'JobCommandArgsDict']]] = None,
                 connections: Optional[pulumi.Input[Union['JobConnectionsListArgs', 'JobConnectionsListArgsDict']]] = None,
                 default_arguments: Optional[Any] = None,
                 description: Optional[pulumi.Input[str]] = None,
                 execution_class: Optional[pulumi.Input[str]] = None,
                 execution_property: Optional[pulumi.Input[Union['JobExecutionPropertyArgs', 'JobExecutionPropertyArgsDict']]] = None,
                 glue_version: Optional[pulumi.Input[str]] = None,
                 job_mode: Optional[pulumi.Input[str]] = None,
                 log_uri: Optional[pulumi.Input[str]] = None,
                 maintenance_window: Optional[pulumi.Input[str]] = None,
                 max_capacity: Optional[pulumi.Input[float]] = None,
                 max_retries: Optional[pulumi.Input[float]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 non_overridable_arguments: Optional[Any] = None,
                 notification_property: Optional[pulumi.Input[Union['JobNotificationPropertyArgs', 'JobNotificationPropertyArgsDict']]] = None,
                 number_of_workers: Optional[pulumi.Input[int]] = None,
                 role: Optional[pulumi.Input[str]] = None,
                 security_configuration: Optional[pulumi.Input[str]] = None,
                 tags: Optional[Any] = None,
                 timeout: Optional[pulumi.Input[int]] = None,
                 worker_type: Optional[pulumi.Input[str]] = None,
                 __props__=None):
        """
        Resource Type definition for AWS::Glue::Job

        :param str resource_name: The name of the resource.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[float] allocated_capacity: This parameter is no longer supported. Use `MaxCapacity` instead.
               
               The number of capacity units that are allocated to this job.
        :param pulumi.Input[Union['JobCommandArgs', 'JobCommandArgsDict']] command: The code that executes a job.
        :param pulumi.Input[Union['JobConnectionsListArgs', 'JobConnectionsListArgsDict']] connections: The connections used for this job.
        :param Any default_arguments: The default arguments for this job, specified as name-value pairs.
               
               You can specify arguments here that your own job-execution script consumes, in addition to arguments that AWS Glue itself consumes.
               
               For information about how to specify and consume your own job arguments, see [Calling AWS Glue APIs in Python](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-calling.html) in the *AWS Glue Developer Guide* .
               
               For information about the key-value pairs that AWS Glue consumes to set up your job, see [Special Parameters Used by AWS Glue](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html) in the *AWS Glue Developer Guide* .
               
               Search the [CloudFormation User Guide](https://docs.aws.amazon.com/cloudformation/) for `AWS::Glue::Job` for more information about the expected schema for this property.
        :param pulumi.Input[str] description: A description of the job.
        :param pulumi.Input[str] execution_class: Indicates whether the job is run with a standard or flexible execution class. The standard execution class is ideal for time-sensitive workloads that require fast job startup and dedicated resources.
               
               The flexible execution class is appropriate for time-insensitive jobs whose start and completion times may vary.
               
               Only jobs with AWS Glue version 3.0 and above and command type `glueetl` will be allowed to set `ExecutionClass` to `FLEX` . The flexible execution class is available for Spark jobs.
        :param pulumi.Input[Union['JobExecutionPropertyArgs', 'JobExecutionPropertyArgsDict']] execution_property: The maximum number of concurrent runs that are allowed for this job.
        :param pulumi.Input[str] glue_version: Glue version determines the versions of Apache Spark and Python that AWS Glue supports. The Python version indicates the version supported for jobs of type Spark.
               
               For more information about the available AWS Glue versions and corresponding Spark and Python versions, see [Glue version](https://docs.aws.amazon.com/glue/latest/dg/add-job.html) in the developer guide.
               
               Jobs that are created without specifying a Glue version default to the latest Glue version available.
        :param pulumi.Input[str] job_mode: A mode that describes how a job was created. Valid values are:
               
               - `SCRIPT` - The job was created using the AWS Glue Studio script editor.
               - `VISUAL` - The job was created using the AWS Glue Studio visual editor.
               - `NOTEBOOK` - The job was created using an interactive sessions notebook.
               
               When the `JobMode` field is missing or null, `SCRIPT` is assigned as the default value.
        :param pulumi.Input[str] log_uri: This field is reserved for future use.
        :param pulumi.Input[str] maintenance_window: This field specifies a day of the week and hour for a maintenance window for streaming jobs. AWS Glue periodically performs maintenance activities. During these maintenance windows, AWS Glue will need to restart your streaming jobs.
               
               AWS Glue will restart the job within 3 hours of the specified maintenance window. For instance, if you set up the maintenance window for Monday at 10:00AM GMT, your jobs will be restarted between 10:00AM GMT to 1:00PM GMT.
        :param pulumi.Input[float] max_capacity: The number of AWS Glue data processing units (DPUs) that can be allocated when this job runs. A DPU is a relative measure of processing power that consists of 4 vCPUs of compute capacity and 16 GB of memory.
               
               Do not set `Max Capacity` if using `WorkerType` and `NumberOfWorkers` .
               
               The value that can be allocated for `MaxCapacity` depends on whether you are running a Python shell job or an Apache Spark ETL job:
               
               - When you specify a Python shell job ( `JobCommand.Name` ="pythonshell"), you can allocate either 0.0625 or 1 DPU. The default is 0.0625 DPU.
               - When you specify an Apache Spark ETL job ( `JobCommand.Name` ="glueetl"), you can allocate from 2 to 100 DPUs. The default is 10 DPUs. This job type cannot have a fractional DPU allocation.
        :param pulumi.Input[float] max_retries: The maximum number of times to retry this job after a JobRun fails.
        :param pulumi.Input[str] name: The name you assign to this job definition.
        :param Any non_overridable_arguments: Non-overridable arguments for this job, specified as name-value pairs.
               
               Search the [CloudFormation User Guide](https://docs.aws.amazon.com/cloudformation/) for `AWS::Glue::Job` for more information about the expected schema for this property.
        :param pulumi.Input[Union['JobNotificationPropertyArgs', 'JobNotificationPropertyArgsDict']] notification_property: Specifies configuration properties of a notification.
        :param pulumi.Input[int] number_of_workers: The number of workers of a defined `workerType` that are allocated when a job runs.
               
               The maximum number of workers you can define are 299 for `G.1X` , and 149 for `G.2X` .
        :param pulumi.Input[str] role: The name or Amazon Resource Name (ARN) of the IAM role associated with this job.
        :param pulumi.Input[str] security_configuration: The name of the `SecurityConfiguration` structure to be used with this job.
        :param Any tags: The tags to use with this job.
               
               Search the [CloudFormation User Guide](https://docs.aws.amazon.com/cloudformation/) for `AWS::Glue::Job` for more information about the expected schema for this property.
        :param pulumi.Input[int] timeout: The job timeout in minutes. This is the maximum time that a job run can consume resources before it is terminated and enters TIMEOUT status. The default is 2,880 minutes (48 hours).
        :param pulumi.Input[str] worker_type: The type of predefined worker that is allocated when a job runs. Accepts a value of G.1X, G.2X, G.4X, G.8X or G.025X for Spark jobs. Accepts the value Z.2X for Ray jobs.
               
               - For the `G.1X` worker type, each worker maps to 1 DPU (4 vCPUs, 16 GB of memory) with 84GB disk (approximately 34GB free), and provides 1 executor per worker. We recommend this worker type for workloads such as data transforms, joins, and queries, to offers a scalable and cost effective way to run most jobs.
               - For the `G.2X` worker type, each worker maps to 2 DPU (8 vCPUs, 32 GB of memory) with 128GB disk (approximately 77GB free), and provides 1 executor per worker. We recommend this worker type for workloads such as data transforms, joins, and queries, to offers a scalable and cost effective way to run most jobs.
               - For the `G.4X` worker type, each worker maps to 4 DPU (16 vCPUs, 64 GB of memory) with 256GB disk (approximately 235GB free), and provides 1 executor per worker. We recommend this worker type for jobs whose workloads contain your most demanding transforms, aggregations, joins, and queries. This worker type is available only for AWS Glue version 3.0 or later Spark ETL jobs in the following AWS Regions: US East (Ohio), US East (N. Virginia), US West (Oregon), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (Ireland), and Europe (Stockholm).
               - For the `G.8X` worker type, each worker maps to 8 DPU (32 vCPUs, 128 GB of memory) with 512GB disk (approximately 487GB free), and provides 1 executor per worker. We recommend this worker type for jobs whose workloads contain your most demanding transforms, aggregations, joins, and queries. This worker type is available only for AWS Glue version 3.0 or later Spark ETL jobs, in the same AWS Regions as supported for the `G.4X` worker type.
               - For the `G.025X` worker type, each worker maps to 0.25 DPU (2 vCPUs, 4 GB of memory) with 84GB disk (approximately 34GB free), and provides 1 executor per worker. We recommend this worker type for low volume streaming jobs. This worker type is only available for AWS Glue version 3.0 streaming jobs.
               - For the `Z.2X` worker type, each worker maps to 2 M-DPU (8vCPUs, 64 GB of memory) with 128 GB disk (approximately 120GB free), and provides up to 8 Ray workers based on the autoscaler.
        """
        ...
    @overload
    def __init__(__self__,
                 resource_name: str,
                 args: JobArgs,
                 opts: Optional[pulumi.ResourceOptions] = None):
        """
        Resource Type definition for AWS::Glue::Job

        :param str resource_name: The name of the resource.
        :param JobArgs args: The arguments to use to populate this resource's properties.
        :param pulumi.ResourceOptions opts: Options for the resource.
        """
        ...
    def __init__(__self__, resource_name: str, *args, **kwargs):
        resource_args, opts = _utilities.get_resource_args_opts(JobArgs, pulumi.ResourceOptions, *args, **kwargs)
        if resource_args is not None:
            __self__._internal_init(resource_name, opts, **resource_args.__dict__)
        else:
            __self__._internal_init(resource_name, *args, **kwargs)

    def _internal_init(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 allocated_capacity: Optional[pulumi.Input[float]] = None,
                 command: Optional[pulumi.Input[Union['JobCommandArgs', 'JobCommandArgsDict']]] = None,
                 connections: Optional[pulumi.Input[Union['JobConnectionsListArgs', 'JobConnectionsListArgsDict']]] = None,
                 default_arguments: Optional[Any] = None,
                 description: Optional[pulumi.Input[str]] = None,
                 execution_class: Optional[pulumi.Input[str]] = None,
                 execution_property: Optional[pulumi.Input[Union['JobExecutionPropertyArgs', 'JobExecutionPropertyArgsDict']]] = None,
                 glue_version: Optional[pulumi.Input[str]] = None,
                 job_mode: Optional[pulumi.Input[str]] = None,
                 log_uri: Optional[pulumi.Input[str]] = None,
                 maintenance_window: Optional[pulumi.Input[str]] = None,
                 max_capacity: Optional[pulumi.Input[float]] = None,
                 max_retries: Optional[pulumi.Input[float]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 non_overridable_arguments: Optional[Any] = None,
                 notification_property: Optional[pulumi.Input[Union['JobNotificationPropertyArgs', 'JobNotificationPropertyArgsDict']]] = None,
                 number_of_workers: Optional[pulumi.Input[int]] = None,
                 role: Optional[pulumi.Input[str]] = None,
                 security_configuration: Optional[pulumi.Input[str]] = None,
                 tags: Optional[Any] = None,
                 timeout: Optional[pulumi.Input[int]] = None,
                 worker_type: Optional[pulumi.Input[str]] = None,
                 __props__=None):
        opts = pulumi.ResourceOptions.merge(_utilities.get_resource_opts_defaults(), opts)
        if not isinstance(opts, pulumi.ResourceOptions):
            raise TypeError('Expected resource options to be a ResourceOptions instance')
        if opts.id is None:
            if __props__ is not None:
                raise TypeError('__props__ is only valid when passed in combination with a valid opts.id to get an existing resource')
            __props__ = JobArgs.__new__(JobArgs)

            __props__.__dict__["allocated_capacity"] = allocated_capacity
            if command is None and not opts.urn:
                raise TypeError("Missing required property 'command'")
            __props__.__dict__["command"] = command
            __props__.__dict__["connections"] = connections
            __props__.__dict__["default_arguments"] = default_arguments
            __props__.__dict__["description"] = description
            __props__.__dict__["execution_class"] = execution_class
            __props__.__dict__["execution_property"] = execution_property
            __props__.__dict__["glue_version"] = glue_version
            __props__.__dict__["job_mode"] = job_mode
            __props__.__dict__["log_uri"] = log_uri
            __props__.__dict__["maintenance_window"] = maintenance_window
            __props__.__dict__["max_capacity"] = max_capacity
            __props__.__dict__["max_retries"] = max_retries
            __props__.__dict__["name"] = name
            __props__.__dict__["non_overridable_arguments"] = non_overridable_arguments
            __props__.__dict__["notification_property"] = notification_property
            __props__.__dict__["number_of_workers"] = number_of_workers
            if role is None and not opts.urn:
                raise TypeError("Missing required property 'role'")
            __props__.__dict__["role"] = role
            __props__.__dict__["security_configuration"] = security_configuration
            __props__.__dict__["tags"] = tags
            __props__.__dict__["timeout"] = timeout
            __props__.__dict__["worker_type"] = worker_type
            __props__.__dict__["aws_id"] = None
        replace_on_changes = pulumi.ResourceOptions(replace_on_changes=["name"])
        opts = pulumi.ResourceOptions.merge(opts, replace_on_changes)
        super(Job, __self__).__init__(
            'aws-native:glue:Job',
            resource_name,
            __props__,
            opts)

    @staticmethod
    def get(resource_name: str,
            id: pulumi.Input[str],
            opts: Optional[pulumi.ResourceOptions] = None) -> 'Job':
        """
        Get an existing Job resource's state with the given name, id, and optional extra
        properties used to qualify the lookup.

        :param str resource_name: The unique name of the resulting resource.
        :param pulumi.Input[str] id: The unique provider ID of the resource to lookup.
        :param pulumi.ResourceOptions opts: Options for the resource.
        """
        opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))

        __props__ = JobArgs.__new__(JobArgs)

        __props__.__dict__["allocated_capacity"] = None
        __props__.__dict__["aws_id"] = None
        __props__.__dict__["command"] = None
        __props__.__dict__["connections"] = None
        __props__.__dict__["default_arguments"] = None
        __props__.__dict__["description"] = None
        __props__.__dict__["execution_class"] = None
        __props__.__dict__["execution_property"] = None
        __props__.__dict__["glue_version"] = None
        __props__.__dict__["job_mode"] = None
        __props__.__dict__["log_uri"] = None
        __props__.__dict__["maintenance_window"] = None
        __props__.__dict__["max_capacity"] = None
        __props__.__dict__["max_retries"] = None
        __props__.__dict__["name"] = None
        __props__.__dict__["non_overridable_arguments"] = None
        __props__.__dict__["notification_property"] = None
        __props__.__dict__["number_of_workers"] = None
        __props__.__dict__["role"] = None
        __props__.__dict__["security_configuration"] = None
        __props__.__dict__["tags"] = None
        __props__.__dict__["timeout"] = None
        __props__.__dict__["worker_type"] = None
        return Job(resource_name, opts=opts, __props__=__props__)

    @property
    @pulumi.getter(name="allocatedCapacity")
    def allocated_capacity(self) -> pulumi.Output[Optional[float]]:
        """
        This parameter is no longer supported. Use `MaxCapacity` instead.

        The number of capacity units that are allocated to this job.
        """
        return pulumi.get(self, "allocated_capacity")

    @property
    @pulumi.getter(name="awsId")
    def aws_id(self) -> pulumi.Output[str]:
        """
        The ID of this job run.
        """
        return pulumi.get(self, "aws_id")

    @property
    @pulumi.getter
    def command(self) -> pulumi.Output['outputs.JobCommand']:
        """
        The code that executes a job.
        """
        return pulumi.get(self, "command")

    @property
    @pulumi.getter
    def connections(self) -> pulumi.Output[Optional['outputs.JobConnectionsList']]:
        """
        The connections used for this job.
        """
        return pulumi.get(self, "connections")

    @property
    @pulumi.getter(name="defaultArguments")
    def default_arguments(self) -> pulumi.Output[Optional[Any]]:
        """
        The default arguments for this job, specified as name-value pairs.

        You can specify arguments here that your own job-execution script consumes, in addition to arguments that AWS Glue itself consumes.

        For information about how to specify and consume your own job arguments, see [Calling AWS Glue APIs in Python](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-calling.html) in the *AWS Glue Developer Guide* .

        For information about the key-value pairs that AWS Glue consumes to set up your job, see [Special Parameters Used by AWS Glue](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html) in the *AWS Glue Developer Guide* .

        Search the [CloudFormation User Guide](https://docs.aws.amazon.com/cloudformation/) for `AWS::Glue::Job` for more information about the expected schema for this property.
        """
        return pulumi.get(self, "default_arguments")

    @property
    @pulumi.getter
    def description(self) -> pulumi.Output[Optional[str]]:
        """
        A description of the job.
        """
        return pulumi.get(self, "description")

    @property
    @pulumi.getter(name="executionClass")
    def execution_class(self) -> pulumi.Output[Optional[str]]:
        """
        Indicates whether the job is run with a standard or flexible execution class. The standard execution class is ideal for time-sensitive workloads that require fast job startup and dedicated resources.

        The flexible execution class is appropriate for time-insensitive jobs whose start and completion times may vary.

        Only jobs with AWS Glue version 3.0 and above and command type `glueetl` will be allowed to set `ExecutionClass` to `FLEX` . The flexible execution class is available for Spark jobs.
        """
        return pulumi.get(self, "execution_class")

    @property
    @pulumi.getter(name="executionProperty")
    def execution_property(self) -> pulumi.Output[Optional['outputs.JobExecutionProperty']]:
        """
        The maximum number of concurrent runs that are allowed for this job.
        """
        return pulumi.get(self, "execution_property")

    @property
    @pulumi.getter(name="glueVersion")
    def glue_version(self) -> pulumi.Output[Optional[str]]:
        """
        Glue version determines the versions of Apache Spark and Python that AWS Glue supports. The Python version indicates the version supported for jobs of type Spark.

        For more information about the available AWS Glue versions and corresponding Spark and Python versions, see [Glue version](https://docs.aws.amazon.com/glue/latest/dg/add-job.html) in the developer guide.

        Jobs that are created without specifying a Glue version default to the latest Glue version available.
        """
        return pulumi.get(self, "glue_version")

    @property
    @pulumi.getter(name="jobMode")
    def job_mode(self) -> pulumi.Output[Optional[str]]:
        """
        A mode that describes how a job was created. Valid values are:

        - `SCRIPT` - The job was created using the AWS Glue Studio script editor.
        - `VISUAL` - The job was created using the AWS Glue Studio visual editor.
        - `NOTEBOOK` - The job was created using an interactive sessions notebook.

        When the `JobMode` field is missing or null, `SCRIPT` is assigned as the default value.
        """
        return pulumi.get(self, "job_mode")

    @property
    @pulumi.getter(name="logUri")
    def log_uri(self) -> pulumi.Output[Optional[str]]:
        """
        This field is reserved for future use.
        """
        return pulumi.get(self, "log_uri")

    @property
    @pulumi.getter(name="maintenanceWindow")
    def maintenance_window(self) -> pulumi.Output[Optional[str]]:
        """
        This field specifies a day of the week and hour for a maintenance window for streaming jobs. AWS Glue periodically performs maintenance activities. During these maintenance windows, AWS Glue will need to restart your streaming jobs.

        AWS Glue will restart the job within 3 hours of the specified maintenance window. For instance, if you set up the maintenance window for Monday at 10:00AM GMT, your jobs will be restarted between 10:00AM GMT to 1:00PM GMT.
        """
        return pulumi.get(self, "maintenance_window")

    @property
    @pulumi.getter(name="maxCapacity")
    def max_capacity(self) -> pulumi.Output[Optional[float]]:
        """
        The number of AWS Glue data processing units (DPUs) that can be allocated when this job runs. A DPU is a relative measure of processing power that consists of 4 vCPUs of compute capacity and 16 GB of memory.

        Do not set `Max Capacity` if using `WorkerType` and `NumberOfWorkers` .

        The value that can be allocated for `MaxCapacity` depends on whether you are running a Python shell job or an Apache Spark ETL job:

        - When you specify a Python shell job ( `JobCommand.Name` ="pythonshell"), you can allocate either 0.0625 or 1 DPU. The default is 0.0625 DPU.
        - When you specify an Apache Spark ETL job ( `JobCommand.Name` ="glueetl"), you can allocate from 2 to 100 DPUs. The default is 10 DPUs. This job type cannot have a fractional DPU allocation.
        """
        return pulumi.get(self, "max_capacity")

    @property
    @pulumi.getter(name="maxRetries")
    def max_retries(self) -> pulumi.Output[Optional[float]]:
        """
        The maximum number of times to retry this job after a JobRun fails.
        """
        return pulumi.get(self, "max_retries")

    @property
    @pulumi.getter
    def name(self) -> pulumi.Output[Optional[str]]:
        """
        The name you assign to this job definition.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="nonOverridableArguments")
    def non_overridable_arguments(self) -> pulumi.Output[Optional[Any]]:
        """
        Non-overridable arguments for this job, specified as name-value pairs.

        Search the [CloudFormation User Guide](https://docs.aws.amazon.com/cloudformation/) for `AWS::Glue::Job` for more information about the expected schema for this property.
        """
        return pulumi.get(self, "non_overridable_arguments")

    @property
    @pulumi.getter(name="notificationProperty")
    def notification_property(self) -> pulumi.Output[Optional['outputs.JobNotificationProperty']]:
        """
        Specifies configuration properties of a notification.
        """
        return pulumi.get(self, "notification_property")

    @property
    @pulumi.getter(name="numberOfWorkers")
    def number_of_workers(self) -> pulumi.Output[Optional[int]]:
        """
        The number of workers of a defined `workerType` that are allocated when a job runs.

        The maximum number of workers you can define are 299 for `G.1X` , and 149 for `G.2X` .
        """
        return pulumi.get(self, "number_of_workers")

    @property
    @pulumi.getter
    def role(self) -> pulumi.Output[str]:
        """
        The name or Amazon Resource Name (ARN) of the IAM role associated with this job.
        """
        return pulumi.get(self, "role")

    @property
    @pulumi.getter(name="securityConfiguration")
    def security_configuration(self) -> pulumi.Output[Optional[str]]:
        """
        The name of the `SecurityConfiguration` structure to be used with this job.
        """
        return pulumi.get(self, "security_configuration")

    @property
    @pulumi.getter
    def tags(self) -> pulumi.Output[Optional[Any]]:
        """
        The tags to use with this job.

        Search the [CloudFormation User Guide](https://docs.aws.amazon.com/cloudformation/) for `AWS::Glue::Job` for more information about the expected schema for this property.
        """
        return pulumi.get(self, "tags")

    @property
    @pulumi.getter
    def timeout(self) -> pulumi.Output[Optional[int]]:
        """
        The job timeout in minutes. This is the maximum time that a job run can consume resources before it is terminated and enters TIMEOUT status. The default is 2,880 minutes (48 hours).
        """
        return pulumi.get(self, "timeout")

    @property
    @pulumi.getter(name="workerType")
    def worker_type(self) -> pulumi.Output[Optional[str]]:
        """
        The type of predefined worker that is allocated when a job runs. Accepts a value of G.1X, G.2X, G.4X, G.8X or G.025X for Spark jobs. Accepts the value Z.2X for Ray jobs.

        - For the `G.1X` worker type, each worker maps to 1 DPU (4 vCPUs, 16 GB of memory) with 84GB disk (approximately 34GB free), and provides 1 executor per worker. We recommend this worker type for workloads such as data transforms, joins, and queries, to offers a scalable and cost effective way to run most jobs.
        - For the `G.2X` worker type, each worker maps to 2 DPU (8 vCPUs, 32 GB of memory) with 128GB disk (approximately 77GB free), and provides 1 executor per worker. We recommend this worker type for workloads such as data transforms, joins, and queries, to offers a scalable and cost effective way to run most jobs.
        - For the `G.4X` worker type, each worker maps to 4 DPU (16 vCPUs, 64 GB of memory) with 256GB disk (approximately 235GB free), and provides 1 executor per worker. We recommend this worker type for jobs whose workloads contain your most demanding transforms, aggregations, joins, and queries. This worker type is available only for AWS Glue version 3.0 or later Spark ETL jobs in the following AWS Regions: US East (Ohio), US East (N. Virginia), US West (Oregon), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (Ireland), and Europe (Stockholm).
        - For the `G.8X` worker type, each worker maps to 8 DPU (32 vCPUs, 128 GB of memory) with 512GB disk (approximately 487GB free), and provides 1 executor per worker. We recommend this worker type for jobs whose workloads contain your most demanding transforms, aggregations, joins, and queries. This worker type is available only for AWS Glue version 3.0 or later Spark ETL jobs, in the same AWS Regions as supported for the `G.4X` worker type.
        - For the `G.025X` worker type, each worker maps to 0.25 DPU (2 vCPUs, 4 GB of memory) with 84GB disk (approximately 34GB free), and provides 1 executor per worker. We recommend this worker type for low volume streaming jobs. This worker type is only available for AWS Glue version 3.0 streaming jobs.
        - For the `Z.2X` worker type, each worker maps to 2 M-DPU (8vCPUs, 64 GB of memory) with 128 GB disk (approximately 120GB free), and provides up to 8 Ray workers based on the autoscaler.
        """
        return pulumi.get(self, "worker_type")

