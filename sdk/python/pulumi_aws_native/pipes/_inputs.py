# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import copy
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from .. import _utilities
from ._enums import *

__all__ = [
    'PipeAwsVpcConfigurationArgs',
    'PipeAwsVpcConfigurationArgsDict',
    'PipeBatchArrayPropertiesArgs',
    'PipeBatchArrayPropertiesArgsDict',
    'PipeBatchContainerOverridesArgs',
    'PipeBatchContainerOverridesArgsDict',
    'PipeBatchEnvironmentVariableArgs',
    'PipeBatchEnvironmentVariableArgsDict',
    'PipeBatchJobDependencyArgs',
    'PipeBatchJobDependencyArgsDict',
    'PipeBatchResourceRequirementArgs',
    'PipeBatchResourceRequirementArgsDict',
    'PipeBatchRetryStrategyArgs',
    'PipeBatchRetryStrategyArgsDict',
    'PipeCapacityProviderStrategyItemArgs',
    'PipeCapacityProviderStrategyItemArgsDict',
    'PipeCloudwatchLogsLogDestinationArgs',
    'PipeCloudwatchLogsLogDestinationArgsDict',
    'PipeDeadLetterConfigArgs',
    'PipeDeadLetterConfigArgsDict',
    'PipeDimensionMappingArgs',
    'PipeDimensionMappingArgsDict',
    'PipeEcsContainerOverrideArgs',
    'PipeEcsContainerOverrideArgsDict',
    'PipeEcsEnvironmentFileArgs',
    'PipeEcsEnvironmentFileArgsDict',
    'PipeEcsEnvironmentVariableArgs',
    'PipeEcsEnvironmentVariableArgsDict',
    'PipeEcsEphemeralStorageArgs',
    'PipeEcsEphemeralStorageArgsDict',
    'PipeEcsInferenceAcceleratorOverrideArgs',
    'PipeEcsInferenceAcceleratorOverrideArgsDict',
    'PipeEcsResourceRequirementArgs',
    'PipeEcsResourceRequirementArgsDict',
    'PipeEcsTaskOverrideArgs',
    'PipeEcsTaskOverrideArgsDict',
    'PipeEnrichmentHttpParametersArgs',
    'PipeEnrichmentHttpParametersArgsDict',
    'PipeEnrichmentParametersArgs',
    'PipeEnrichmentParametersArgsDict',
    'PipeFilterCriteriaArgs',
    'PipeFilterCriteriaArgsDict',
    'PipeFilterArgs',
    'PipeFilterArgsDict',
    'PipeFirehoseLogDestinationArgs',
    'PipeFirehoseLogDestinationArgsDict',
    'PipeLogConfigurationArgs',
    'PipeLogConfigurationArgsDict',
    'PipeMqBrokerAccessCredentialsPropertiesArgs',
    'PipeMqBrokerAccessCredentialsPropertiesArgsDict',
    'PipeMskAccessCredentials0PropertiesArgs',
    'PipeMskAccessCredentials0PropertiesArgsDict',
    'PipeMskAccessCredentials1PropertiesArgs',
    'PipeMskAccessCredentials1PropertiesArgsDict',
    'PipeMultiMeasureAttributeMappingArgs',
    'PipeMultiMeasureAttributeMappingArgsDict',
    'PipeMultiMeasureMappingArgs',
    'PipeMultiMeasureMappingArgsDict',
    'PipeNetworkConfigurationArgs',
    'PipeNetworkConfigurationArgsDict',
    'PipePlacementConstraintArgs',
    'PipePlacementConstraintArgsDict',
    'PipePlacementStrategyArgs',
    'PipePlacementStrategyArgsDict',
    'PipeS3LogDestinationArgs',
    'PipeS3LogDestinationArgsDict',
    'PipeSageMakerPipelineParameterArgs',
    'PipeSageMakerPipelineParameterArgsDict',
    'PipeSelfManagedKafkaAccessConfigurationCredentials0PropertiesArgs',
    'PipeSelfManagedKafkaAccessConfigurationCredentials0PropertiesArgsDict',
    'PipeSelfManagedKafkaAccessConfigurationCredentials1PropertiesArgs',
    'PipeSelfManagedKafkaAccessConfigurationCredentials1PropertiesArgsDict',
    'PipeSelfManagedKafkaAccessConfigurationCredentials2PropertiesArgs',
    'PipeSelfManagedKafkaAccessConfigurationCredentials2PropertiesArgsDict',
    'PipeSelfManagedKafkaAccessConfigurationCredentials3PropertiesArgs',
    'PipeSelfManagedKafkaAccessConfigurationCredentials3PropertiesArgsDict',
    'PipeSelfManagedKafkaAccessConfigurationVpcArgs',
    'PipeSelfManagedKafkaAccessConfigurationVpcArgsDict',
    'PipeSingleMeasureMappingArgs',
    'PipeSingleMeasureMappingArgsDict',
    'PipeSourceActiveMqBrokerParametersArgs',
    'PipeSourceActiveMqBrokerParametersArgsDict',
    'PipeSourceDynamoDbStreamParametersArgs',
    'PipeSourceDynamoDbStreamParametersArgsDict',
    'PipeSourceKinesisStreamParametersArgs',
    'PipeSourceKinesisStreamParametersArgsDict',
    'PipeSourceManagedStreamingKafkaParametersArgs',
    'PipeSourceManagedStreamingKafkaParametersArgsDict',
    'PipeSourceParametersArgs',
    'PipeSourceParametersArgsDict',
    'PipeSourceRabbitMqBrokerParametersArgs',
    'PipeSourceRabbitMqBrokerParametersArgsDict',
    'PipeSourceSelfManagedKafkaParametersArgs',
    'PipeSourceSelfManagedKafkaParametersArgsDict',
    'PipeSourceSqsQueueParametersArgs',
    'PipeSourceSqsQueueParametersArgsDict',
    'PipeTagArgs',
    'PipeTagArgsDict',
    'PipeTargetBatchJobParametersArgs',
    'PipeTargetBatchJobParametersArgsDict',
    'PipeTargetCloudWatchLogsParametersArgs',
    'PipeTargetCloudWatchLogsParametersArgsDict',
    'PipeTargetEcsTaskParametersArgs',
    'PipeTargetEcsTaskParametersArgsDict',
    'PipeTargetEventBridgeEventBusParametersArgs',
    'PipeTargetEventBridgeEventBusParametersArgsDict',
    'PipeTargetHttpParametersArgs',
    'PipeTargetHttpParametersArgsDict',
    'PipeTargetKinesisStreamParametersArgs',
    'PipeTargetKinesisStreamParametersArgsDict',
    'PipeTargetLambdaFunctionParametersArgs',
    'PipeTargetLambdaFunctionParametersArgsDict',
    'PipeTargetParametersArgs',
    'PipeTargetParametersArgsDict',
    'PipeTargetRedshiftDataParametersArgs',
    'PipeTargetRedshiftDataParametersArgsDict',
    'PipeTargetSageMakerPipelineParametersArgs',
    'PipeTargetSageMakerPipelineParametersArgsDict',
    'PipeTargetSqsQueueParametersArgs',
    'PipeTargetSqsQueueParametersArgsDict',
    'PipeTargetStateMachineParametersArgs',
    'PipeTargetStateMachineParametersArgsDict',
    'PipeTargetTimestreamParametersArgs',
    'PipeTargetTimestreamParametersArgsDict',
]

MYPY = False

if not MYPY:
    class PipeAwsVpcConfigurationArgsDict(TypedDict):
        subnets: pulumi.Input[Sequence[pulumi.Input[str]]]
        """
        Specifies the subnets associated with the task. These subnets must all be in the same VPC. You can specify as many as 16 subnets.
        """
        assign_public_ip: NotRequired[pulumi.Input['PipeAssignPublicIp']]
        """
        Specifies whether the task's elastic network interface receives a public IP address. You can specify `ENABLED` only when `LaunchType` in `EcsParameters` is set to `FARGATE` .
        """
        security_groups: NotRequired[pulumi.Input[Sequence[pulumi.Input[str]]]]
        """
        Specifies the security groups associated with the task. These security groups must all be in the same VPC. You can specify as many as five security groups. If you do not specify a security group, the default security group for the VPC is used.
        """
elif False:
    PipeAwsVpcConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeAwsVpcConfigurationArgs:
    def __init__(__self__, *,
                 subnets: pulumi.Input[Sequence[pulumi.Input[str]]],
                 assign_public_ip: Optional[pulumi.Input['PipeAssignPublicIp']] = None,
                 security_groups: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] subnets: Specifies the subnets associated with the task. These subnets must all be in the same VPC. You can specify as many as 16 subnets.
        :param pulumi.Input['PipeAssignPublicIp'] assign_public_ip: Specifies whether the task's elastic network interface receives a public IP address. You can specify `ENABLED` only when `LaunchType` in `EcsParameters` is set to `FARGATE` .
        :param pulumi.Input[Sequence[pulumi.Input[str]]] security_groups: Specifies the security groups associated with the task. These security groups must all be in the same VPC. You can specify as many as five security groups. If you do not specify a security group, the default security group for the VPC is used.
        """
        pulumi.set(__self__, "subnets", subnets)
        if assign_public_ip is not None:
            pulumi.set(__self__, "assign_public_ip", assign_public_ip)
        if security_groups is not None:
            pulumi.set(__self__, "security_groups", security_groups)

    @property
    @pulumi.getter
    def subnets(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        Specifies the subnets associated with the task. These subnets must all be in the same VPC. You can specify as many as 16 subnets.
        """
        return pulumi.get(self, "subnets")

    @subnets.setter
    def subnets(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "subnets", value)

    @property
    @pulumi.getter(name="assignPublicIp")
    def assign_public_ip(self) -> Optional[pulumi.Input['PipeAssignPublicIp']]:
        """
        Specifies whether the task's elastic network interface receives a public IP address. You can specify `ENABLED` only when `LaunchType` in `EcsParameters` is set to `FARGATE` .
        """
        return pulumi.get(self, "assign_public_ip")

    @assign_public_ip.setter
    def assign_public_ip(self, value: Optional[pulumi.Input['PipeAssignPublicIp']]):
        pulumi.set(self, "assign_public_ip", value)

    @property
    @pulumi.getter(name="securityGroups")
    def security_groups(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Specifies the security groups associated with the task. These security groups must all be in the same VPC. You can specify as many as five security groups. If you do not specify a security group, the default security group for the VPC is used.
        """
        return pulumi.get(self, "security_groups")

    @security_groups.setter
    def security_groups(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "security_groups", value)


if not MYPY:
    class PipeBatchArrayPropertiesArgsDict(TypedDict):
        size: NotRequired[pulumi.Input[int]]
        """
        The size of the array, if this is an array batch job.
        """
elif False:
    PipeBatchArrayPropertiesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeBatchArrayPropertiesArgs:
    def __init__(__self__, *,
                 size: Optional[pulumi.Input[int]] = None):
        """
        :param pulumi.Input[int] size: The size of the array, if this is an array batch job.
        """
        if size is not None:
            pulumi.set(__self__, "size", size)

    @property
    @pulumi.getter
    def size(self) -> Optional[pulumi.Input[int]]:
        """
        The size of the array, if this is an array batch job.
        """
        return pulumi.get(self, "size")

    @size.setter
    def size(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "size", value)


if not MYPY:
    class PipeBatchContainerOverridesArgsDict(TypedDict):
        command: NotRequired[pulumi.Input[Sequence[pulumi.Input[str]]]]
        """
        The command to send to the container that overrides the default command from the Docker image or the task definition.
        """
        environment: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipeBatchEnvironmentVariableArgsDict']]]]
        """
        The environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition.

        > Environment variables cannot start with " `AWS Batch` ". This naming convention is reserved for variables that AWS Batch sets.
        """
        instance_type: NotRequired[pulumi.Input[str]]
        """
        The instance type to use for a multi-node parallel job.

        > This parameter isn't applicable to single-node container jobs or jobs that run on Fargate resources, and shouldn't be provided.
        """
        resource_requirements: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipeBatchResourceRequirementArgsDict']]]]
        """
        The type and amount of resources to assign to a container. This overrides the settings in the job definition. The supported resources include `GPU` , `MEMORY` , and `VCPU` .
        """
elif False:
    PipeBatchContainerOverridesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeBatchContainerOverridesArgs:
    def __init__(__self__, *,
                 command: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 environment: Optional[pulumi.Input[Sequence[pulumi.Input['PipeBatchEnvironmentVariableArgs']]]] = None,
                 instance_type: Optional[pulumi.Input[str]] = None,
                 resource_requirements: Optional[pulumi.Input[Sequence[pulumi.Input['PipeBatchResourceRequirementArgs']]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] command: The command to send to the container that overrides the default command from the Docker image or the task definition.
        :param pulumi.Input[Sequence[pulumi.Input['PipeBatchEnvironmentVariableArgs']]] environment: The environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition.
               
               > Environment variables cannot start with " `AWS Batch` ". This naming convention is reserved for variables that AWS Batch sets.
        :param pulumi.Input[str] instance_type: The instance type to use for a multi-node parallel job.
               
               > This parameter isn't applicable to single-node container jobs or jobs that run on Fargate resources, and shouldn't be provided.
        :param pulumi.Input[Sequence[pulumi.Input['PipeBatchResourceRequirementArgs']]] resource_requirements: The type and amount of resources to assign to a container. This overrides the settings in the job definition. The supported resources include `GPU` , `MEMORY` , and `VCPU` .
        """
        if command is not None:
            pulumi.set(__self__, "command", command)
        if environment is not None:
            pulumi.set(__self__, "environment", environment)
        if instance_type is not None:
            pulumi.set(__self__, "instance_type", instance_type)
        if resource_requirements is not None:
            pulumi.set(__self__, "resource_requirements", resource_requirements)

    @property
    @pulumi.getter
    def command(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        The command to send to the container that overrides the default command from the Docker image or the task definition.
        """
        return pulumi.get(self, "command")

    @command.setter
    def command(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "command", value)

    @property
    @pulumi.getter
    def environment(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipeBatchEnvironmentVariableArgs']]]]:
        """
        The environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition.

        > Environment variables cannot start with " `AWS Batch` ". This naming convention is reserved for variables that AWS Batch sets.
        """
        return pulumi.get(self, "environment")

    @environment.setter
    def environment(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipeBatchEnvironmentVariableArgs']]]]):
        pulumi.set(self, "environment", value)

    @property
    @pulumi.getter(name="instanceType")
    def instance_type(self) -> Optional[pulumi.Input[str]]:
        """
        The instance type to use for a multi-node parallel job.

        > This parameter isn't applicable to single-node container jobs or jobs that run on Fargate resources, and shouldn't be provided.
        """
        return pulumi.get(self, "instance_type")

    @instance_type.setter
    def instance_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "instance_type", value)

    @property
    @pulumi.getter(name="resourceRequirements")
    def resource_requirements(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipeBatchResourceRequirementArgs']]]]:
        """
        The type and amount of resources to assign to a container. This overrides the settings in the job definition. The supported resources include `GPU` , `MEMORY` , and `VCPU` .
        """
        return pulumi.get(self, "resource_requirements")

    @resource_requirements.setter
    def resource_requirements(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipeBatchResourceRequirementArgs']]]]):
        pulumi.set(self, "resource_requirements", value)


if not MYPY:
    class PipeBatchEnvironmentVariableArgsDict(TypedDict):
        name: NotRequired[pulumi.Input[str]]
        """
        The name of the key-value pair. For environment variables, this is the name of the environment variable.
        """
        value: NotRequired[pulumi.Input[str]]
        """
        The value of the key-value pair. For environment variables, this is the value of the environment variable.
        """
elif False:
    PipeBatchEnvironmentVariableArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeBatchEnvironmentVariableArgs:
    def __init__(__self__, *,
                 name: Optional[pulumi.Input[str]] = None,
                 value: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] name: The name of the key-value pair. For environment variables, this is the name of the environment variable.
        :param pulumi.Input[str] value: The value of the key-value pair. For environment variables, this is the value of the environment variable.
        """
        if name is not None:
            pulumi.set(__self__, "name", name)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the key-value pair. For environment variables, this is the name of the environment variable.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter
    def value(self) -> Optional[pulumi.Input[str]]:
        """
        The value of the key-value pair. For environment variables, this is the value of the environment variable.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "value", value)


if not MYPY:
    class PipeBatchJobDependencyArgsDict(TypedDict):
        job_id: NotRequired[pulumi.Input[str]]
        """
        The job ID of the AWS Batch job that's associated with this dependency.
        """
        type: NotRequired[pulumi.Input['PipeBatchJobDependencyType']]
        """
        The type of the job dependency.
        """
elif False:
    PipeBatchJobDependencyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeBatchJobDependencyArgs:
    def __init__(__self__, *,
                 job_id: Optional[pulumi.Input[str]] = None,
                 type: Optional[pulumi.Input['PipeBatchJobDependencyType']] = None):
        """
        :param pulumi.Input[str] job_id: The job ID of the AWS Batch job that's associated with this dependency.
        :param pulumi.Input['PipeBatchJobDependencyType'] type: The type of the job dependency.
        """
        if job_id is not None:
            pulumi.set(__self__, "job_id", job_id)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter(name="jobId")
    def job_id(self) -> Optional[pulumi.Input[str]]:
        """
        The job ID of the AWS Batch job that's associated with this dependency.
        """
        return pulumi.get(self, "job_id")

    @job_id.setter
    def job_id(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "job_id", value)

    @property
    @pulumi.getter
    def type(self) -> Optional[pulumi.Input['PipeBatchJobDependencyType']]:
        """
        The type of the job dependency.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: Optional[pulumi.Input['PipeBatchJobDependencyType']]):
        pulumi.set(self, "type", value)


if not MYPY:
    class PipeBatchResourceRequirementArgsDict(TypedDict):
        type: pulumi.Input['PipeBatchResourceRequirementType']
        """
        The type of resource to assign to a container. The supported resources include `GPU` , `MEMORY` , and `VCPU` .
        """
        value: pulumi.Input[str]
        """
        The quantity of the specified resource to reserve for the container. The values vary based on the `type` specified.

        - **type="GPU"** - The number of physical GPUs to reserve for the container. Make sure that the number of GPUs reserved for all containers in a job doesn't exceed the number of available GPUs on the compute resource that the job is launched on.

        > GPUs aren't available for jobs that are running on Fargate resources.
        - **type="MEMORY"** - The memory hard limit (in MiB) present to the container. This parameter is supported for jobs that are running on EC2 resources. If your container attempts to exceed the memory specified, the container is terminated. This parameter maps to `Memory` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/#create-a-container) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/) and the `--memory` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/) . You must specify at least 4 MiB of memory for a job. This is required but can be specified in several places for multi-node parallel (MNP) jobs. It must be specified for each node at least once. This parameter maps to `Memory` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/#create-a-container) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/) and the `--memory` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/) .

        > If you're trying to maximize your resource utilization by providing your jobs as much memory as possible for a particular instance type, see [Memory management](https://docs.aws.amazon.com/batch/latest/userguide/memory-management.html) in the *AWS Batch User Guide* . 

        For jobs that are running on Fargate resources, then `value` is the hard limit (in MiB), and must match one of the supported values and the `VCPU` values must be one of the values supported for that memory value.

        - **value = 512** - `VCPU` = 0.25
        - **value = 1024** - `VCPU` = 0.25 or 0.5
        - **value = 2048** - `VCPU` = 0.25, 0.5, or 1
        - **value = 3072** - `VCPU` = 0.5, or 1
        - **value = 4096** - `VCPU` = 0.5, 1, or 2
        - **value = 5120, 6144, or 7168** - `VCPU` = 1 or 2
        - **value = 8192** - `VCPU` = 1, 2, 4, or 8
        - **value = 9216, 10240, 11264, 12288, 13312, 14336, or 15360** - `VCPU` = 2 or 4
        - **value = 16384** - `VCPU` = 2, 4, or 8
        - **value = 17408, 18432, 19456, 21504, 22528, 23552, 25600, 26624, 27648, 29696, or 30720** - `VCPU` = 4
        - **value = 20480, 24576, or 28672** - `VCPU` = 4 or 8
        - **value = 36864, 45056, 53248, or 61440** - `VCPU` = 8
        - **value = 32768, 40960, 49152, or 57344** - `VCPU` = 8 or 16
        - **value = 65536, 73728, 81920, 90112, 98304, 106496, 114688, or 122880** - `VCPU` = 16
        - **type="VCPU"** - The number of vCPUs reserved for the container. This parameter maps to `CpuShares` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/#create-a-container) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/) and the `--cpu-shares` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/) . Each vCPU is equivalent to 1,024 CPU shares. For EC2 resources, you must specify at least one vCPU. This is required but can be specified in several places; it must be specified for each node at least once.

        The default for the Fargate On-Demand vCPU resource count quota is 6 vCPUs. For more information about Fargate quotas, see [AWS Fargate quotas](https://docs.aws.amazon.com/general/latest/gr/ecs-service.html#service-quotas-fargate) in the *AWS General Reference* .

        For jobs that are running on Fargate resources, then `value` must match one of the supported values and the `MEMORY` values must be one of the values supported for that `VCPU` value. The supported values are 0.25, 0.5, 1, 2, 4, 8, and 16

        - **value = 0.25** - `MEMORY` = 512, 1024, or 2048
        - **value = 0.5** - `MEMORY` = 1024, 2048, 3072, or 4096
        - **value = 1** - `MEMORY` = 2048, 3072, 4096, 5120, 6144, 7168, or 8192
        - **value = 2** - `MEMORY` = 4096, 5120, 6144, 7168, 8192, 9216, 10240, 11264, 12288, 13312, 14336, 15360, or 16384
        - **value = 4** - `MEMORY` = 8192, 9216, 10240, 11264, 12288, 13312, 14336, 15360, 16384, 17408, 18432, 19456, 20480, 21504, 22528, 23552, 24576, 25600, 26624, 27648, 28672, 29696, or 30720
        - **value = 8** - `MEMORY` = 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056, 49152, 53248, 57344, or 61440
        - **value = 16** - `MEMORY` = 32768, 40960, 49152, 57344, 65536, 73728, 81920, 90112, 98304, 106496, 114688, or 122880
        """
elif False:
    PipeBatchResourceRequirementArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeBatchResourceRequirementArgs:
    def __init__(__self__, *,
                 type: pulumi.Input['PipeBatchResourceRequirementType'],
                 value: pulumi.Input[str]):
        """
        :param pulumi.Input['PipeBatchResourceRequirementType'] type: The type of resource to assign to a container. The supported resources include `GPU` , `MEMORY` , and `VCPU` .
        :param pulumi.Input[str] value: The quantity of the specified resource to reserve for the container. The values vary based on the `type` specified.
               
               - **type="GPU"** - The number of physical GPUs to reserve for the container. Make sure that the number of GPUs reserved for all containers in a job doesn't exceed the number of available GPUs on the compute resource that the job is launched on.
               
               > GPUs aren't available for jobs that are running on Fargate resources.
               - **type="MEMORY"** - The memory hard limit (in MiB) present to the container. This parameter is supported for jobs that are running on EC2 resources. If your container attempts to exceed the memory specified, the container is terminated. This parameter maps to `Memory` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/#create-a-container) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/) and the `--memory` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/) . You must specify at least 4 MiB of memory for a job. This is required but can be specified in several places for multi-node parallel (MNP) jobs. It must be specified for each node at least once. This parameter maps to `Memory` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/#create-a-container) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/) and the `--memory` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/) .
               
               > If you're trying to maximize your resource utilization by providing your jobs as much memory as possible for a particular instance type, see [Memory management](https://docs.aws.amazon.com/batch/latest/userguide/memory-management.html) in the *AWS Batch User Guide* . 
               
               For jobs that are running on Fargate resources, then `value` is the hard limit (in MiB), and must match one of the supported values and the `VCPU` values must be one of the values supported for that memory value.
               
               - **value = 512** - `VCPU` = 0.25
               - **value = 1024** - `VCPU` = 0.25 or 0.5
               - **value = 2048** - `VCPU` = 0.25, 0.5, or 1
               - **value = 3072** - `VCPU` = 0.5, or 1
               - **value = 4096** - `VCPU` = 0.5, 1, or 2
               - **value = 5120, 6144, or 7168** - `VCPU` = 1 or 2
               - **value = 8192** - `VCPU` = 1, 2, 4, or 8
               - **value = 9216, 10240, 11264, 12288, 13312, 14336, or 15360** - `VCPU` = 2 or 4
               - **value = 16384** - `VCPU` = 2, 4, or 8
               - **value = 17408, 18432, 19456, 21504, 22528, 23552, 25600, 26624, 27648, 29696, or 30720** - `VCPU` = 4
               - **value = 20480, 24576, or 28672** - `VCPU` = 4 or 8
               - **value = 36864, 45056, 53248, or 61440** - `VCPU` = 8
               - **value = 32768, 40960, 49152, or 57344** - `VCPU` = 8 or 16
               - **value = 65536, 73728, 81920, 90112, 98304, 106496, 114688, or 122880** - `VCPU` = 16
               - **type="VCPU"** - The number of vCPUs reserved for the container. This parameter maps to `CpuShares` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/#create-a-container) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/) and the `--cpu-shares` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/) . Each vCPU is equivalent to 1,024 CPU shares. For EC2 resources, you must specify at least one vCPU. This is required but can be specified in several places; it must be specified for each node at least once.
               
               The default for the Fargate On-Demand vCPU resource count quota is 6 vCPUs. For more information about Fargate quotas, see [AWS Fargate quotas](https://docs.aws.amazon.com/general/latest/gr/ecs-service.html#service-quotas-fargate) in the *AWS General Reference* .
               
               For jobs that are running on Fargate resources, then `value` must match one of the supported values and the `MEMORY` values must be one of the values supported for that `VCPU` value. The supported values are 0.25, 0.5, 1, 2, 4, 8, and 16
               
               - **value = 0.25** - `MEMORY` = 512, 1024, or 2048
               - **value = 0.5** - `MEMORY` = 1024, 2048, 3072, or 4096
               - **value = 1** - `MEMORY` = 2048, 3072, 4096, 5120, 6144, 7168, or 8192
               - **value = 2** - `MEMORY` = 4096, 5120, 6144, 7168, 8192, 9216, 10240, 11264, 12288, 13312, 14336, 15360, or 16384
               - **value = 4** - `MEMORY` = 8192, 9216, 10240, 11264, 12288, 13312, 14336, 15360, 16384, 17408, 18432, 19456, 20480, 21504, 22528, 23552, 24576, 25600, 26624, 27648, 28672, 29696, or 30720
               - **value = 8** - `MEMORY` = 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056, 49152, 53248, 57344, or 61440
               - **value = 16** - `MEMORY` = 32768, 40960, 49152, 57344, 65536, 73728, 81920, 90112, 98304, 106496, 114688, or 122880
        """
        pulumi.set(__self__, "type", type)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input['PipeBatchResourceRequirementType']:
        """
        The type of resource to assign to a container. The supported resources include `GPU` , `MEMORY` , and `VCPU` .
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input['PipeBatchResourceRequirementType']):
        pulumi.set(self, "type", value)

    @property
    @pulumi.getter
    def value(self) -> pulumi.Input[str]:
        """
        The quantity of the specified resource to reserve for the container. The values vary based on the `type` specified.

        - **type="GPU"** - The number of physical GPUs to reserve for the container. Make sure that the number of GPUs reserved for all containers in a job doesn't exceed the number of available GPUs on the compute resource that the job is launched on.

        > GPUs aren't available for jobs that are running on Fargate resources.
        - **type="MEMORY"** - The memory hard limit (in MiB) present to the container. This parameter is supported for jobs that are running on EC2 resources. If your container attempts to exceed the memory specified, the container is terminated. This parameter maps to `Memory` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/#create-a-container) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/) and the `--memory` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/) . You must specify at least 4 MiB of memory for a job. This is required but can be specified in several places for multi-node parallel (MNP) jobs. It must be specified for each node at least once. This parameter maps to `Memory` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/#create-a-container) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/) and the `--memory` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/) .

        > If you're trying to maximize your resource utilization by providing your jobs as much memory as possible for a particular instance type, see [Memory management](https://docs.aws.amazon.com/batch/latest/userguide/memory-management.html) in the *AWS Batch User Guide* . 

        For jobs that are running on Fargate resources, then `value` is the hard limit (in MiB), and must match one of the supported values and the `VCPU` values must be one of the values supported for that memory value.

        - **value = 512** - `VCPU` = 0.25
        - **value = 1024** - `VCPU` = 0.25 or 0.5
        - **value = 2048** - `VCPU` = 0.25, 0.5, or 1
        - **value = 3072** - `VCPU` = 0.5, or 1
        - **value = 4096** - `VCPU` = 0.5, 1, or 2
        - **value = 5120, 6144, or 7168** - `VCPU` = 1 or 2
        - **value = 8192** - `VCPU` = 1, 2, 4, or 8
        - **value = 9216, 10240, 11264, 12288, 13312, 14336, or 15360** - `VCPU` = 2 or 4
        - **value = 16384** - `VCPU` = 2, 4, or 8
        - **value = 17408, 18432, 19456, 21504, 22528, 23552, 25600, 26624, 27648, 29696, or 30720** - `VCPU` = 4
        - **value = 20480, 24576, or 28672** - `VCPU` = 4 or 8
        - **value = 36864, 45056, 53248, or 61440** - `VCPU` = 8
        - **value = 32768, 40960, 49152, or 57344** - `VCPU` = 8 or 16
        - **value = 65536, 73728, 81920, 90112, 98304, 106496, 114688, or 122880** - `VCPU` = 16
        - **type="VCPU"** - The number of vCPUs reserved for the container. This parameter maps to `CpuShares` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/#create-a-container) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.23/) and the `--cpu-shares` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/) . Each vCPU is equivalent to 1,024 CPU shares. For EC2 resources, you must specify at least one vCPU. This is required but can be specified in several places; it must be specified for each node at least once.

        The default for the Fargate On-Demand vCPU resource count quota is 6 vCPUs. For more information about Fargate quotas, see [AWS Fargate quotas](https://docs.aws.amazon.com/general/latest/gr/ecs-service.html#service-quotas-fargate) in the *AWS General Reference* .

        For jobs that are running on Fargate resources, then `value` must match one of the supported values and the `MEMORY` values must be one of the values supported for that `VCPU` value. The supported values are 0.25, 0.5, 1, 2, 4, 8, and 16

        - **value = 0.25** - `MEMORY` = 512, 1024, or 2048
        - **value = 0.5** - `MEMORY` = 1024, 2048, 3072, or 4096
        - **value = 1** - `MEMORY` = 2048, 3072, 4096, 5120, 6144, 7168, or 8192
        - **value = 2** - `MEMORY` = 4096, 5120, 6144, 7168, 8192, 9216, 10240, 11264, 12288, 13312, 14336, 15360, or 16384
        - **value = 4** - `MEMORY` = 8192, 9216, 10240, 11264, 12288, 13312, 14336, 15360, 16384, 17408, 18432, 19456, 20480, 21504, 22528, 23552, 24576, 25600, 26624, 27648, 28672, 29696, or 30720
        - **value = 8** - `MEMORY` = 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056, 49152, 53248, 57344, or 61440
        - **value = 16** - `MEMORY` = 32768, 40960, 49152, 57344, 65536, 73728, 81920, 90112, 98304, 106496, 114688, or 122880
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: pulumi.Input[str]):
        pulumi.set(self, "value", value)


if not MYPY:
    class PipeBatchRetryStrategyArgsDict(TypedDict):
        attempts: NotRequired[pulumi.Input[int]]
        """
        The number of times to move a job to the `RUNNABLE` status. If the value of `attempts` is greater than one, the job is retried on failure the same number of attempts as the value.
        """
elif False:
    PipeBatchRetryStrategyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeBatchRetryStrategyArgs:
    def __init__(__self__, *,
                 attempts: Optional[pulumi.Input[int]] = None):
        """
        :param pulumi.Input[int] attempts: The number of times to move a job to the `RUNNABLE` status. If the value of `attempts` is greater than one, the job is retried on failure the same number of attempts as the value.
        """
        if attempts is not None:
            pulumi.set(__self__, "attempts", attempts)

    @property
    @pulumi.getter
    def attempts(self) -> Optional[pulumi.Input[int]]:
        """
        The number of times to move a job to the `RUNNABLE` status. If the value of `attempts` is greater than one, the job is retried on failure the same number of attempts as the value.
        """
        return pulumi.get(self, "attempts")

    @attempts.setter
    def attempts(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "attempts", value)


if not MYPY:
    class PipeCapacityProviderStrategyItemArgsDict(TypedDict):
        capacity_provider: pulumi.Input[str]
        """
        The short name of the capacity provider.
        """
        base: NotRequired[pulumi.Input[int]]
        """
        The base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.
        """
        weight: NotRequired[pulumi.Input[int]]
        """
        The weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.
        """
elif False:
    PipeCapacityProviderStrategyItemArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeCapacityProviderStrategyItemArgs:
    def __init__(__self__, *,
                 capacity_provider: pulumi.Input[str],
                 base: Optional[pulumi.Input[int]] = None,
                 weight: Optional[pulumi.Input[int]] = None):
        """
        :param pulumi.Input[str] capacity_provider: The short name of the capacity provider.
        :param pulumi.Input[int] base: The base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.
        :param pulumi.Input[int] weight: The weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.
        """
        pulumi.set(__self__, "capacity_provider", capacity_provider)
        if base is not None:
            pulumi.set(__self__, "base", base)
        if weight is not None:
            pulumi.set(__self__, "weight", weight)

    @property
    @pulumi.getter(name="capacityProvider")
    def capacity_provider(self) -> pulumi.Input[str]:
        """
        The short name of the capacity provider.
        """
        return pulumi.get(self, "capacity_provider")

    @capacity_provider.setter
    def capacity_provider(self, value: pulumi.Input[str]):
        pulumi.set(self, "capacity_provider", value)

    @property
    @pulumi.getter
    def base(self) -> Optional[pulumi.Input[int]]:
        """
        The base value designates how many tasks, at a minimum, to run on the specified capacity provider. Only one capacity provider in a capacity provider strategy can have a base defined. If no value is specified, the default value of 0 is used.
        """
        return pulumi.get(self, "base")

    @base.setter
    def base(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "base", value)

    @property
    @pulumi.getter
    def weight(self) -> Optional[pulumi.Input[int]]:
        """
        The weight value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The weight value is taken into consideration after the base value, if defined, is satisfied.
        """
        return pulumi.get(self, "weight")

    @weight.setter
    def weight(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "weight", value)


if not MYPY:
    class PipeCloudwatchLogsLogDestinationArgsDict(TypedDict):
        log_group_arn: NotRequired[pulumi.Input[str]]
        """
        The AWS Resource Name (ARN) for the CloudWatch log group to which EventBridge sends the log records.
        """
elif False:
    PipeCloudwatchLogsLogDestinationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeCloudwatchLogsLogDestinationArgs:
    def __init__(__self__, *,
                 log_group_arn: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] log_group_arn: The AWS Resource Name (ARN) for the CloudWatch log group to which EventBridge sends the log records.
        """
        if log_group_arn is not None:
            pulumi.set(__self__, "log_group_arn", log_group_arn)

    @property
    @pulumi.getter(name="logGroupArn")
    def log_group_arn(self) -> Optional[pulumi.Input[str]]:
        """
        The AWS Resource Name (ARN) for the CloudWatch log group to which EventBridge sends the log records.
        """
        return pulumi.get(self, "log_group_arn")

    @log_group_arn.setter
    def log_group_arn(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "log_group_arn", value)


if not MYPY:
    class PipeDeadLetterConfigArgsDict(TypedDict):
        arn: NotRequired[pulumi.Input[str]]
        """
        The ARN of the specified target for the dead-letter queue.

        For Amazon Kinesis stream and Amazon DynamoDB stream sources, specify either an Amazon SNS topic or Amazon SQS queue ARN.
        """
elif False:
    PipeDeadLetterConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeDeadLetterConfigArgs:
    def __init__(__self__, *,
                 arn: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] arn: The ARN of the specified target for the dead-letter queue.
               
               For Amazon Kinesis stream and Amazon DynamoDB stream sources, specify either an Amazon SNS topic or Amazon SQS queue ARN.
        """
        if arn is not None:
            pulumi.set(__self__, "arn", arn)

    @property
    @pulumi.getter
    def arn(self) -> Optional[pulumi.Input[str]]:
        """
        The ARN of the specified target for the dead-letter queue.

        For Amazon Kinesis stream and Amazon DynamoDB stream sources, specify either an Amazon SNS topic or Amazon SQS queue ARN.
        """
        return pulumi.get(self, "arn")

    @arn.setter
    def arn(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "arn", value)


if not MYPY:
    class PipeDimensionMappingArgsDict(TypedDict):
        dimension_name: pulumi.Input[str]
        """
        The metadata attributes of the time series. For example, the name and Availability Zone of an Amazon EC2 instance or the name of the manufacturer of a wind turbine are dimensions.
        """
        dimension_value: pulumi.Input[str]
        """
        Dynamic path to the dimension value in the source event.
        """
        dimension_value_type: pulumi.Input['PipeDimensionValueType']
        """
        The data type of the dimension for the time-series data.
        """
elif False:
    PipeDimensionMappingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeDimensionMappingArgs:
    def __init__(__self__, *,
                 dimension_name: pulumi.Input[str],
                 dimension_value: pulumi.Input[str],
                 dimension_value_type: pulumi.Input['PipeDimensionValueType']):
        """
        :param pulumi.Input[str] dimension_name: The metadata attributes of the time series. For example, the name and Availability Zone of an Amazon EC2 instance or the name of the manufacturer of a wind turbine are dimensions.
        :param pulumi.Input[str] dimension_value: Dynamic path to the dimension value in the source event.
        :param pulumi.Input['PipeDimensionValueType'] dimension_value_type: The data type of the dimension for the time-series data.
        """
        pulumi.set(__self__, "dimension_name", dimension_name)
        pulumi.set(__self__, "dimension_value", dimension_value)
        pulumi.set(__self__, "dimension_value_type", dimension_value_type)

    @property
    @pulumi.getter(name="dimensionName")
    def dimension_name(self) -> pulumi.Input[str]:
        """
        The metadata attributes of the time series. For example, the name and Availability Zone of an Amazon EC2 instance or the name of the manufacturer of a wind turbine are dimensions.
        """
        return pulumi.get(self, "dimension_name")

    @dimension_name.setter
    def dimension_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "dimension_name", value)

    @property
    @pulumi.getter(name="dimensionValue")
    def dimension_value(self) -> pulumi.Input[str]:
        """
        Dynamic path to the dimension value in the source event.
        """
        return pulumi.get(self, "dimension_value")

    @dimension_value.setter
    def dimension_value(self, value: pulumi.Input[str]):
        pulumi.set(self, "dimension_value", value)

    @property
    @pulumi.getter(name="dimensionValueType")
    def dimension_value_type(self) -> pulumi.Input['PipeDimensionValueType']:
        """
        The data type of the dimension for the time-series data.
        """
        return pulumi.get(self, "dimension_value_type")

    @dimension_value_type.setter
    def dimension_value_type(self, value: pulumi.Input['PipeDimensionValueType']):
        pulumi.set(self, "dimension_value_type", value)


if not MYPY:
    class PipeEcsContainerOverrideArgsDict(TypedDict):
        command: NotRequired[pulumi.Input[Sequence[pulumi.Input[str]]]]
        """
        The command to send to the container that overrides the default command from the Docker image or the task definition. You must also specify a container name.
        """
        cpu: NotRequired[pulumi.Input[int]]
        """
        The number of `cpu` units reserved for the container, instead of the default value from the task definition. You must also specify a container name.
        """
        environment: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipeEcsEnvironmentVariableArgsDict']]]]
        """
        The environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition. You must also specify a container name.
        """
        environment_files: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipeEcsEnvironmentFileArgsDict']]]]
        """
        A list of files containing the environment variables to pass to a container, instead of the value from the container definition.
        """
        memory: NotRequired[pulumi.Input[int]]
        """
        The hard limit (in MiB) of memory to present to the container, instead of the default value from the task definition. If your container attempts to exceed the memory specified here, the container is killed. You must also specify a container name.
        """
        memory_reservation: NotRequired[pulumi.Input[int]]
        """
        The soft limit (in MiB) of memory to reserve for the container, instead of the default value from the task definition. You must also specify a container name.
        """
        name: NotRequired[pulumi.Input[str]]
        """
        The name of the container that receives the override. This parameter is required if any override is specified.
        """
        resource_requirements: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipeEcsResourceRequirementArgsDict']]]]
        """
        The type and amount of a resource to assign to a container, instead of the default value from the task definition. The only supported resource is a GPU.
        """
elif False:
    PipeEcsContainerOverrideArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeEcsContainerOverrideArgs:
    def __init__(__self__, *,
                 command: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 cpu: Optional[pulumi.Input[int]] = None,
                 environment: Optional[pulumi.Input[Sequence[pulumi.Input['PipeEcsEnvironmentVariableArgs']]]] = None,
                 environment_files: Optional[pulumi.Input[Sequence[pulumi.Input['PipeEcsEnvironmentFileArgs']]]] = None,
                 memory: Optional[pulumi.Input[int]] = None,
                 memory_reservation: Optional[pulumi.Input[int]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 resource_requirements: Optional[pulumi.Input[Sequence[pulumi.Input['PipeEcsResourceRequirementArgs']]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] command: The command to send to the container that overrides the default command from the Docker image or the task definition. You must also specify a container name.
        :param pulumi.Input[int] cpu: The number of `cpu` units reserved for the container, instead of the default value from the task definition. You must also specify a container name.
        :param pulumi.Input[Sequence[pulumi.Input['PipeEcsEnvironmentVariableArgs']]] environment: The environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition. You must also specify a container name.
        :param pulumi.Input[Sequence[pulumi.Input['PipeEcsEnvironmentFileArgs']]] environment_files: A list of files containing the environment variables to pass to a container, instead of the value from the container definition.
        :param pulumi.Input[int] memory: The hard limit (in MiB) of memory to present to the container, instead of the default value from the task definition. If your container attempts to exceed the memory specified here, the container is killed. You must also specify a container name.
        :param pulumi.Input[int] memory_reservation: The soft limit (in MiB) of memory to reserve for the container, instead of the default value from the task definition. You must also specify a container name.
        :param pulumi.Input[str] name: The name of the container that receives the override. This parameter is required if any override is specified.
        :param pulumi.Input[Sequence[pulumi.Input['PipeEcsResourceRequirementArgs']]] resource_requirements: The type and amount of a resource to assign to a container, instead of the default value from the task definition. The only supported resource is a GPU.
        """
        if command is not None:
            pulumi.set(__self__, "command", command)
        if cpu is not None:
            pulumi.set(__self__, "cpu", cpu)
        if environment is not None:
            pulumi.set(__self__, "environment", environment)
        if environment_files is not None:
            pulumi.set(__self__, "environment_files", environment_files)
        if memory is not None:
            pulumi.set(__self__, "memory", memory)
        if memory_reservation is not None:
            pulumi.set(__self__, "memory_reservation", memory_reservation)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if resource_requirements is not None:
            pulumi.set(__self__, "resource_requirements", resource_requirements)

    @property
    @pulumi.getter
    def command(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        The command to send to the container that overrides the default command from the Docker image or the task definition. You must also specify a container name.
        """
        return pulumi.get(self, "command")

    @command.setter
    def command(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "command", value)

    @property
    @pulumi.getter
    def cpu(self) -> Optional[pulumi.Input[int]]:
        """
        The number of `cpu` units reserved for the container, instead of the default value from the task definition. You must also specify a container name.
        """
        return pulumi.get(self, "cpu")

    @cpu.setter
    def cpu(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "cpu", value)

    @property
    @pulumi.getter
    def environment(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipeEcsEnvironmentVariableArgs']]]]:
        """
        The environment variables to send to the container. You can add new environment variables, which are added to the container at launch, or you can override the existing environment variables from the Docker image or the task definition. You must also specify a container name.
        """
        return pulumi.get(self, "environment")

    @environment.setter
    def environment(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipeEcsEnvironmentVariableArgs']]]]):
        pulumi.set(self, "environment", value)

    @property
    @pulumi.getter(name="environmentFiles")
    def environment_files(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipeEcsEnvironmentFileArgs']]]]:
        """
        A list of files containing the environment variables to pass to a container, instead of the value from the container definition.
        """
        return pulumi.get(self, "environment_files")

    @environment_files.setter
    def environment_files(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipeEcsEnvironmentFileArgs']]]]):
        pulumi.set(self, "environment_files", value)

    @property
    @pulumi.getter
    def memory(self) -> Optional[pulumi.Input[int]]:
        """
        The hard limit (in MiB) of memory to present to the container, instead of the default value from the task definition. If your container attempts to exceed the memory specified here, the container is killed. You must also specify a container name.
        """
        return pulumi.get(self, "memory")

    @memory.setter
    def memory(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "memory", value)

    @property
    @pulumi.getter(name="memoryReservation")
    def memory_reservation(self) -> Optional[pulumi.Input[int]]:
        """
        The soft limit (in MiB) of memory to reserve for the container, instead of the default value from the task definition. You must also specify a container name.
        """
        return pulumi.get(self, "memory_reservation")

    @memory_reservation.setter
    def memory_reservation(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "memory_reservation", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the container that receives the override. This parameter is required if any override is specified.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter(name="resourceRequirements")
    def resource_requirements(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipeEcsResourceRequirementArgs']]]]:
        """
        The type and amount of a resource to assign to a container, instead of the default value from the task definition. The only supported resource is a GPU.
        """
        return pulumi.get(self, "resource_requirements")

    @resource_requirements.setter
    def resource_requirements(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipeEcsResourceRequirementArgs']]]]):
        pulumi.set(self, "resource_requirements", value)


if not MYPY:
    class PipeEcsEnvironmentFileArgsDict(TypedDict):
        type: pulumi.Input['PipeEcsEnvironmentFileType']
        """
        The file type to use. The only supported value is `s3` .
        """
        value: pulumi.Input[str]
        """
        The Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.
        """
elif False:
    PipeEcsEnvironmentFileArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeEcsEnvironmentFileArgs:
    def __init__(__self__, *,
                 type: pulumi.Input['PipeEcsEnvironmentFileType'],
                 value: pulumi.Input[str]):
        """
        :param pulumi.Input['PipeEcsEnvironmentFileType'] type: The file type to use. The only supported value is `s3` .
        :param pulumi.Input[str] value: The Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.
        """
        pulumi.set(__self__, "type", type)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input['PipeEcsEnvironmentFileType']:
        """
        The file type to use. The only supported value is `s3` .
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input['PipeEcsEnvironmentFileType']):
        pulumi.set(self, "type", value)

    @property
    @pulumi.getter
    def value(self) -> pulumi.Input[str]:
        """
        The Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: pulumi.Input[str]):
        pulumi.set(self, "value", value)


if not MYPY:
    class PipeEcsEnvironmentVariableArgsDict(TypedDict):
        name: NotRequired[pulumi.Input[str]]
        """
        The name of the key-value pair. For environment variables, this is the name of the environment variable.
        """
        value: NotRequired[pulumi.Input[str]]
        """
        The value of the key-value pair. For environment variables, this is the value of the environment variable.
        """
elif False:
    PipeEcsEnvironmentVariableArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeEcsEnvironmentVariableArgs:
    def __init__(__self__, *,
                 name: Optional[pulumi.Input[str]] = None,
                 value: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] name: The name of the key-value pair. For environment variables, this is the name of the environment variable.
        :param pulumi.Input[str] value: The value of the key-value pair. For environment variables, this is the value of the environment variable.
        """
        if name is not None:
            pulumi.set(__self__, "name", name)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the key-value pair. For environment variables, this is the name of the environment variable.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter
    def value(self) -> Optional[pulumi.Input[str]]:
        """
        The value of the key-value pair. For environment variables, this is the value of the environment variable.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "value", value)


if not MYPY:
    class PipeEcsEphemeralStorageArgsDict(TypedDict):
        size_in_gi_b: pulumi.Input[int]
        """
        The total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is `21` GiB and the maximum supported value is `200` GiB.
        """
elif False:
    PipeEcsEphemeralStorageArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeEcsEphemeralStorageArgs:
    def __init__(__self__, *,
                 size_in_gi_b: pulumi.Input[int]):
        """
        :param pulumi.Input[int] size_in_gi_b: The total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is `21` GiB and the maximum supported value is `200` GiB.
        """
        pulumi.set(__self__, "size_in_gi_b", size_in_gi_b)

    @property
    @pulumi.getter(name="sizeInGiB")
    def size_in_gi_b(self) -> pulumi.Input[int]:
        """
        The total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is `21` GiB and the maximum supported value is `200` GiB.
        """
        return pulumi.get(self, "size_in_gi_b")

    @size_in_gi_b.setter
    def size_in_gi_b(self, value: pulumi.Input[int]):
        pulumi.set(self, "size_in_gi_b", value)


if not MYPY:
    class PipeEcsInferenceAcceleratorOverrideArgsDict(TypedDict):
        device_name: NotRequired[pulumi.Input[str]]
        """
        The Elastic Inference accelerator device name to override for the task. This parameter must match a `deviceName` specified in the task definition.
        """
        device_type: NotRequired[pulumi.Input[str]]
        """
        The Elastic Inference accelerator type to use.
        """
elif False:
    PipeEcsInferenceAcceleratorOverrideArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeEcsInferenceAcceleratorOverrideArgs:
    def __init__(__self__, *,
                 device_name: Optional[pulumi.Input[str]] = None,
                 device_type: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] device_name: The Elastic Inference accelerator device name to override for the task. This parameter must match a `deviceName` specified in the task definition.
        :param pulumi.Input[str] device_type: The Elastic Inference accelerator type to use.
        """
        if device_name is not None:
            pulumi.set(__self__, "device_name", device_name)
        if device_type is not None:
            pulumi.set(__self__, "device_type", device_type)

    @property
    @pulumi.getter(name="deviceName")
    def device_name(self) -> Optional[pulumi.Input[str]]:
        """
        The Elastic Inference accelerator device name to override for the task. This parameter must match a `deviceName` specified in the task definition.
        """
        return pulumi.get(self, "device_name")

    @device_name.setter
    def device_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "device_name", value)

    @property
    @pulumi.getter(name="deviceType")
    def device_type(self) -> Optional[pulumi.Input[str]]:
        """
        The Elastic Inference accelerator type to use.
        """
        return pulumi.get(self, "device_type")

    @device_type.setter
    def device_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "device_type", value)


if not MYPY:
    class PipeEcsResourceRequirementArgsDict(TypedDict):
        type: pulumi.Input['PipeEcsResourceRequirementType']
        """
        The type of resource to assign to a container. The supported values are `GPU` or `InferenceAccelerator` .
        """
        value: pulumi.Input[str]
        """
        The value for the specified resource type.

        If the `GPU` type is used, the value is the number of physical `GPUs` the Amazon ECS container agent reserves for the container. The number of GPUs that's reserved for all containers in a task can't exceed the number of available GPUs on the container instance that the task is launched on.

        If the `InferenceAccelerator` type is used, the `value` matches the `deviceName` for an InferenceAccelerator specified in a task definition.
        """
elif False:
    PipeEcsResourceRequirementArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeEcsResourceRequirementArgs:
    def __init__(__self__, *,
                 type: pulumi.Input['PipeEcsResourceRequirementType'],
                 value: pulumi.Input[str]):
        """
        :param pulumi.Input['PipeEcsResourceRequirementType'] type: The type of resource to assign to a container. The supported values are `GPU` or `InferenceAccelerator` .
        :param pulumi.Input[str] value: The value for the specified resource type.
               
               If the `GPU` type is used, the value is the number of physical `GPUs` the Amazon ECS container agent reserves for the container. The number of GPUs that's reserved for all containers in a task can't exceed the number of available GPUs on the container instance that the task is launched on.
               
               If the `InferenceAccelerator` type is used, the `value` matches the `deviceName` for an InferenceAccelerator specified in a task definition.
        """
        pulumi.set(__self__, "type", type)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input['PipeEcsResourceRequirementType']:
        """
        The type of resource to assign to a container. The supported values are `GPU` or `InferenceAccelerator` .
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input['PipeEcsResourceRequirementType']):
        pulumi.set(self, "type", value)

    @property
    @pulumi.getter
    def value(self) -> pulumi.Input[str]:
        """
        The value for the specified resource type.

        If the `GPU` type is used, the value is the number of physical `GPUs` the Amazon ECS container agent reserves for the container. The number of GPUs that's reserved for all containers in a task can't exceed the number of available GPUs on the container instance that the task is launched on.

        If the `InferenceAccelerator` type is used, the `value` matches the `deviceName` for an InferenceAccelerator specified in a task definition.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: pulumi.Input[str]):
        pulumi.set(self, "value", value)


if not MYPY:
    class PipeEcsTaskOverrideArgsDict(TypedDict):
        container_overrides: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipeEcsContainerOverrideArgsDict']]]]
        """
        One or more container overrides that are sent to a task.
        """
        cpu: NotRequired[pulumi.Input[str]]
        """
        The cpu override for the task.
        """
        ephemeral_storage: NotRequired[pulumi.Input['PipeEcsEphemeralStorageArgsDict']]
        """
        The ephemeral storage setting override for the task.

        > This parameter is only supported for tasks hosted on Fargate that use the following platform versions:
        > 
        > - Linux platform version `1.4.0` or later.
        > - Windows platform version `1.0.0` or later.
        """
        execution_role_arn: NotRequired[pulumi.Input[str]]
        """
        The Amazon Resource Name (ARN) of the task execution IAM role override for the task. For more information, see [Amazon ECS task execution IAM role](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_execution_IAM_role.html) in the *Amazon Elastic Container Service Developer Guide* .
        """
        inference_accelerator_overrides: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipeEcsInferenceAcceleratorOverrideArgsDict']]]]
        """
        The Elastic Inference accelerator override for the task.
        """
        memory: NotRequired[pulumi.Input[str]]
        """
        The memory override for the task.
        """
        task_role_arn: NotRequired[pulumi.Input[str]]
        """
        The Amazon Resource Name (ARN) of the IAM role that containers in this task can assume. All containers in this task are granted the permissions that are specified in this role. For more information, see [IAM Role for Tasks](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html) in the *Amazon Elastic Container Service Developer Guide* .
        """
elif False:
    PipeEcsTaskOverrideArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeEcsTaskOverrideArgs:
    def __init__(__self__, *,
                 container_overrides: Optional[pulumi.Input[Sequence[pulumi.Input['PipeEcsContainerOverrideArgs']]]] = None,
                 cpu: Optional[pulumi.Input[str]] = None,
                 ephemeral_storage: Optional[pulumi.Input['PipeEcsEphemeralStorageArgs']] = None,
                 execution_role_arn: Optional[pulumi.Input[str]] = None,
                 inference_accelerator_overrides: Optional[pulumi.Input[Sequence[pulumi.Input['PipeEcsInferenceAcceleratorOverrideArgs']]]] = None,
                 memory: Optional[pulumi.Input[str]] = None,
                 task_role_arn: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input['PipeEcsContainerOverrideArgs']]] container_overrides: One or more container overrides that are sent to a task.
        :param pulumi.Input[str] cpu: The cpu override for the task.
        :param pulumi.Input['PipeEcsEphemeralStorageArgs'] ephemeral_storage: The ephemeral storage setting override for the task.
               
               > This parameter is only supported for tasks hosted on Fargate that use the following platform versions:
               > 
               > - Linux platform version `1.4.0` or later.
               > - Windows platform version `1.0.0` or later.
        :param pulumi.Input[str] execution_role_arn: The Amazon Resource Name (ARN) of the task execution IAM role override for the task. For more information, see [Amazon ECS task execution IAM role](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_execution_IAM_role.html) in the *Amazon Elastic Container Service Developer Guide* .
        :param pulumi.Input[Sequence[pulumi.Input['PipeEcsInferenceAcceleratorOverrideArgs']]] inference_accelerator_overrides: The Elastic Inference accelerator override for the task.
        :param pulumi.Input[str] memory: The memory override for the task.
        :param pulumi.Input[str] task_role_arn: The Amazon Resource Name (ARN) of the IAM role that containers in this task can assume. All containers in this task are granted the permissions that are specified in this role. For more information, see [IAM Role for Tasks](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html) in the *Amazon Elastic Container Service Developer Guide* .
        """
        if container_overrides is not None:
            pulumi.set(__self__, "container_overrides", container_overrides)
        if cpu is not None:
            pulumi.set(__self__, "cpu", cpu)
        if ephemeral_storage is not None:
            pulumi.set(__self__, "ephemeral_storage", ephemeral_storage)
        if execution_role_arn is not None:
            pulumi.set(__self__, "execution_role_arn", execution_role_arn)
        if inference_accelerator_overrides is not None:
            pulumi.set(__self__, "inference_accelerator_overrides", inference_accelerator_overrides)
        if memory is not None:
            pulumi.set(__self__, "memory", memory)
        if task_role_arn is not None:
            pulumi.set(__self__, "task_role_arn", task_role_arn)

    @property
    @pulumi.getter(name="containerOverrides")
    def container_overrides(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipeEcsContainerOverrideArgs']]]]:
        """
        One or more container overrides that are sent to a task.
        """
        return pulumi.get(self, "container_overrides")

    @container_overrides.setter
    def container_overrides(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipeEcsContainerOverrideArgs']]]]):
        pulumi.set(self, "container_overrides", value)

    @property
    @pulumi.getter
    def cpu(self) -> Optional[pulumi.Input[str]]:
        """
        The cpu override for the task.
        """
        return pulumi.get(self, "cpu")

    @cpu.setter
    def cpu(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "cpu", value)

    @property
    @pulumi.getter(name="ephemeralStorage")
    def ephemeral_storage(self) -> Optional[pulumi.Input['PipeEcsEphemeralStorageArgs']]:
        """
        The ephemeral storage setting override for the task.

        > This parameter is only supported for tasks hosted on Fargate that use the following platform versions:
        > 
        > - Linux platform version `1.4.0` or later.
        > - Windows platform version `1.0.0` or later.
        """
        return pulumi.get(self, "ephemeral_storage")

    @ephemeral_storage.setter
    def ephemeral_storage(self, value: Optional[pulumi.Input['PipeEcsEphemeralStorageArgs']]):
        pulumi.set(self, "ephemeral_storage", value)

    @property
    @pulumi.getter(name="executionRoleArn")
    def execution_role_arn(self) -> Optional[pulumi.Input[str]]:
        """
        The Amazon Resource Name (ARN) of the task execution IAM role override for the task. For more information, see [Amazon ECS task execution IAM role](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_execution_IAM_role.html) in the *Amazon Elastic Container Service Developer Guide* .
        """
        return pulumi.get(self, "execution_role_arn")

    @execution_role_arn.setter
    def execution_role_arn(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "execution_role_arn", value)

    @property
    @pulumi.getter(name="inferenceAcceleratorOverrides")
    def inference_accelerator_overrides(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipeEcsInferenceAcceleratorOverrideArgs']]]]:
        """
        The Elastic Inference accelerator override for the task.
        """
        return pulumi.get(self, "inference_accelerator_overrides")

    @inference_accelerator_overrides.setter
    def inference_accelerator_overrides(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipeEcsInferenceAcceleratorOverrideArgs']]]]):
        pulumi.set(self, "inference_accelerator_overrides", value)

    @property
    @pulumi.getter
    def memory(self) -> Optional[pulumi.Input[str]]:
        """
        The memory override for the task.
        """
        return pulumi.get(self, "memory")

    @memory.setter
    def memory(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "memory", value)

    @property
    @pulumi.getter(name="taskRoleArn")
    def task_role_arn(self) -> Optional[pulumi.Input[str]]:
        """
        The Amazon Resource Name (ARN) of the IAM role that containers in this task can assume. All containers in this task are granted the permissions that are specified in this role. For more information, see [IAM Role for Tasks](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html) in the *Amazon Elastic Container Service Developer Guide* .
        """
        return pulumi.get(self, "task_role_arn")

    @task_role_arn.setter
    def task_role_arn(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "task_role_arn", value)


if not MYPY:
    class PipeEnrichmentHttpParametersArgsDict(TypedDict):
        header_parameters: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[str]]]]
        """
        The headers that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.
        """
        path_parameter_values: NotRequired[pulumi.Input[Sequence[pulumi.Input[str]]]]
        """
        The path parameter values to be used to populate API Gateway REST API or EventBridge ApiDestination path wildcards ("*").
        """
        query_string_parameters: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[str]]]]
        """
        The query string keys/values that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.
        """
elif False:
    PipeEnrichmentHttpParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeEnrichmentHttpParametersArgs:
    def __init__(__self__, *,
                 header_parameters: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 path_parameter_values: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 query_string_parameters: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None):
        """
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] header_parameters: The headers that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] path_parameter_values: The path parameter values to be used to populate API Gateway REST API or EventBridge ApiDestination path wildcards ("*").
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] query_string_parameters: The query string keys/values that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.
        """
        if header_parameters is not None:
            pulumi.set(__self__, "header_parameters", header_parameters)
        if path_parameter_values is not None:
            pulumi.set(__self__, "path_parameter_values", path_parameter_values)
        if query_string_parameters is not None:
            pulumi.set(__self__, "query_string_parameters", query_string_parameters)

    @property
    @pulumi.getter(name="headerParameters")
    def header_parameters(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        The headers that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.
        """
        return pulumi.get(self, "header_parameters")

    @header_parameters.setter
    def header_parameters(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "header_parameters", value)

    @property
    @pulumi.getter(name="pathParameterValues")
    def path_parameter_values(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        The path parameter values to be used to populate API Gateway REST API or EventBridge ApiDestination path wildcards ("*").
        """
        return pulumi.get(self, "path_parameter_values")

    @path_parameter_values.setter
    def path_parameter_values(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "path_parameter_values", value)

    @property
    @pulumi.getter(name="queryStringParameters")
    def query_string_parameters(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        The query string keys/values that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.
        """
        return pulumi.get(self, "query_string_parameters")

    @query_string_parameters.setter
    def query_string_parameters(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "query_string_parameters", value)


if not MYPY:
    class PipeEnrichmentParametersArgsDict(TypedDict):
        http_parameters: NotRequired[pulumi.Input['PipeEnrichmentHttpParametersArgsDict']]
        """
        Contains the HTTP parameters to use when the target is a API Gateway REST endpoint or EventBridge ApiDestination.

        If you specify an API Gateway REST API or EventBridge ApiDestination as a target, you can use this parameter to specify headers, path parameters, and query string keys/values as part of your target invoking request. If you're using ApiDestinations, the corresponding Connection can also have these values configured. In case of any conflicting keys, values from the Connection take precedence.
        """
        input_template: NotRequired[pulumi.Input[str]]
        """
        Valid JSON text passed to the enrichment. In this case, nothing from the event itself is passed to the enrichment. For more information, see [The JavaScript Object Notation (JSON) Data Interchange Format](https://docs.aws.amazon.com/http://www.rfc-editor.org/rfc/rfc7159.txt) .

        To remove an input template, specify an empty string.
        """
elif False:
    PipeEnrichmentParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeEnrichmentParametersArgs:
    def __init__(__self__, *,
                 http_parameters: Optional[pulumi.Input['PipeEnrichmentHttpParametersArgs']] = None,
                 input_template: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input['PipeEnrichmentHttpParametersArgs'] http_parameters: Contains the HTTP parameters to use when the target is a API Gateway REST endpoint or EventBridge ApiDestination.
               
               If you specify an API Gateway REST API or EventBridge ApiDestination as a target, you can use this parameter to specify headers, path parameters, and query string keys/values as part of your target invoking request. If you're using ApiDestinations, the corresponding Connection can also have these values configured. In case of any conflicting keys, values from the Connection take precedence.
        :param pulumi.Input[str] input_template: Valid JSON text passed to the enrichment. In this case, nothing from the event itself is passed to the enrichment. For more information, see [The JavaScript Object Notation (JSON) Data Interchange Format](https://docs.aws.amazon.com/http://www.rfc-editor.org/rfc/rfc7159.txt) .
               
               To remove an input template, specify an empty string.
        """
        if http_parameters is not None:
            pulumi.set(__self__, "http_parameters", http_parameters)
        if input_template is not None:
            pulumi.set(__self__, "input_template", input_template)

    @property
    @pulumi.getter(name="httpParameters")
    def http_parameters(self) -> Optional[pulumi.Input['PipeEnrichmentHttpParametersArgs']]:
        """
        Contains the HTTP parameters to use when the target is a API Gateway REST endpoint or EventBridge ApiDestination.

        If you specify an API Gateway REST API or EventBridge ApiDestination as a target, you can use this parameter to specify headers, path parameters, and query string keys/values as part of your target invoking request. If you're using ApiDestinations, the corresponding Connection can also have these values configured. In case of any conflicting keys, values from the Connection take precedence.
        """
        return pulumi.get(self, "http_parameters")

    @http_parameters.setter
    def http_parameters(self, value: Optional[pulumi.Input['PipeEnrichmentHttpParametersArgs']]):
        pulumi.set(self, "http_parameters", value)

    @property
    @pulumi.getter(name="inputTemplate")
    def input_template(self) -> Optional[pulumi.Input[str]]:
        """
        Valid JSON text passed to the enrichment. In this case, nothing from the event itself is passed to the enrichment. For more information, see [The JavaScript Object Notation (JSON) Data Interchange Format](https://docs.aws.amazon.com/http://www.rfc-editor.org/rfc/rfc7159.txt) .

        To remove an input template, specify an empty string.
        """
        return pulumi.get(self, "input_template")

    @input_template.setter
    def input_template(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "input_template", value)


if not MYPY:
    class PipeFilterCriteriaArgsDict(TypedDict):
        filters: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipeFilterArgsDict']]]]
        """
        The event patterns.
        """
elif False:
    PipeFilterCriteriaArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeFilterCriteriaArgs:
    def __init__(__self__, *,
                 filters: Optional[pulumi.Input[Sequence[pulumi.Input['PipeFilterArgs']]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input['PipeFilterArgs']]] filters: The event patterns.
        """
        if filters is not None:
            pulumi.set(__self__, "filters", filters)

    @property
    @pulumi.getter
    def filters(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipeFilterArgs']]]]:
        """
        The event patterns.
        """
        return pulumi.get(self, "filters")

    @filters.setter
    def filters(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipeFilterArgs']]]]):
        pulumi.set(self, "filters", value)


if not MYPY:
    class PipeFilterArgsDict(TypedDict):
        pattern: NotRequired[pulumi.Input[str]]
        """
        The event pattern.
        """
elif False:
    PipeFilterArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeFilterArgs:
    def __init__(__self__, *,
                 pattern: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] pattern: The event pattern.
        """
        if pattern is not None:
            pulumi.set(__self__, "pattern", pattern)

    @property
    @pulumi.getter
    def pattern(self) -> Optional[pulumi.Input[str]]:
        """
        The event pattern.
        """
        return pulumi.get(self, "pattern")

    @pattern.setter
    def pattern(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "pattern", value)


if not MYPY:
    class PipeFirehoseLogDestinationArgsDict(TypedDict):
        delivery_stream_arn: NotRequired[pulumi.Input[str]]
        """
        The Amazon Resource Name (ARN) of the Firehose delivery stream to which EventBridge delivers the pipe log records.
        """
elif False:
    PipeFirehoseLogDestinationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeFirehoseLogDestinationArgs:
    def __init__(__self__, *,
                 delivery_stream_arn: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] delivery_stream_arn: The Amazon Resource Name (ARN) of the Firehose delivery stream to which EventBridge delivers the pipe log records.
        """
        if delivery_stream_arn is not None:
            pulumi.set(__self__, "delivery_stream_arn", delivery_stream_arn)

    @property
    @pulumi.getter(name="deliveryStreamArn")
    def delivery_stream_arn(self) -> Optional[pulumi.Input[str]]:
        """
        The Amazon Resource Name (ARN) of the Firehose delivery stream to which EventBridge delivers the pipe log records.
        """
        return pulumi.get(self, "delivery_stream_arn")

    @delivery_stream_arn.setter
    def delivery_stream_arn(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "delivery_stream_arn", value)


if not MYPY:
    class PipeLogConfigurationArgsDict(TypedDict):
        cloudwatch_logs_log_destination: NotRequired[pulumi.Input['PipeCloudwatchLogsLogDestinationArgsDict']]
        """
        The logging configuration settings for the pipe.
        """
        firehose_log_destination: NotRequired[pulumi.Input['PipeFirehoseLogDestinationArgsDict']]
        """
        The Amazon Data Firehose logging configuration settings for the pipe.
        """
        include_execution_data: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipeIncludeExecutionDataOption']]]]
        """
        Whether the execution data (specifically, the `payload` , `awsRequest` , and `awsResponse` fields) is included in the log messages for this pipe.

        This applies to all log destinations for the pipe.

        For more information, see [Including execution data in logs](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-logs.html#eb-pipes-logs-execution-data) in the *Amazon EventBridge User Guide* .

        *Allowed values:* `ALL`
        """
        level: NotRequired[pulumi.Input['PipeLogLevel']]
        """
        The level of logging detail to include. This applies to all log destinations for the pipe.
        """
        s3_log_destination: NotRequired[pulumi.Input['PipeS3LogDestinationArgsDict']]
        """
        The Amazon S3 logging configuration settings for the pipe.
        """
elif False:
    PipeLogConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeLogConfigurationArgs:
    def __init__(__self__, *,
                 cloudwatch_logs_log_destination: Optional[pulumi.Input['PipeCloudwatchLogsLogDestinationArgs']] = None,
                 firehose_log_destination: Optional[pulumi.Input['PipeFirehoseLogDestinationArgs']] = None,
                 include_execution_data: Optional[pulumi.Input[Sequence[pulumi.Input['PipeIncludeExecutionDataOption']]]] = None,
                 level: Optional[pulumi.Input['PipeLogLevel']] = None,
                 s3_log_destination: Optional[pulumi.Input['PipeS3LogDestinationArgs']] = None):
        """
        :param pulumi.Input['PipeCloudwatchLogsLogDestinationArgs'] cloudwatch_logs_log_destination: The logging configuration settings for the pipe.
        :param pulumi.Input['PipeFirehoseLogDestinationArgs'] firehose_log_destination: The Amazon Data Firehose logging configuration settings for the pipe.
        :param pulumi.Input[Sequence[pulumi.Input['PipeIncludeExecutionDataOption']]] include_execution_data: Whether the execution data (specifically, the `payload` , `awsRequest` , and `awsResponse` fields) is included in the log messages for this pipe.
               
               This applies to all log destinations for the pipe.
               
               For more information, see [Including execution data in logs](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-logs.html#eb-pipes-logs-execution-data) in the *Amazon EventBridge User Guide* .
               
               *Allowed values:* `ALL`
        :param pulumi.Input['PipeLogLevel'] level: The level of logging detail to include. This applies to all log destinations for the pipe.
        :param pulumi.Input['PipeS3LogDestinationArgs'] s3_log_destination: The Amazon S3 logging configuration settings for the pipe.
        """
        if cloudwatch_logs_log_destination is not None:
            pulumi.set(__self__, "cloudwatch_logs_log_destination", cloudwatch_logs_log_destination)
        if firehose_log_destination is not None:
            pulumi.set(__self__, "firehose_log_destination", firehose_log_destination)
        if include_execution_data is not None:
            pulumi.set(__self__, "include_execution_data", include_execution_data)
        if level is not None:
            pulumi.set(__self__, "level", level)
        if s3_log_destination is not None:
            pulumi.set(__self__, "s3_log_destination", s3_log_destination)

    @property
    @pulumi.getter(name="cloudwatchLogsLogDestination")
    def cloudwatch_logs_log_destination(self) -> Optional[pulumi.Input['PipeCloudwatchLogsLogDestinationArgs']]:
        """
        The logging configuration settings for the pipe.
        """
        return pulumi.get(self, "cloudwatch_logs_log_destination")

    @cloudwatch_logs_log_destination.setter
    def cloudwatch_logs_log_destination(self, value: Optional[pulumi.Input['PipeCloudwatchLogsLogDestinationArgs']]):
        pulumi.set(self, "cloudwatch_logs_log_destination", value)

    @property
    @pulumi.getter(name="firehoseLogDestination")
    def firehose_log_destination(self) -> Optional[pulumi.Input['PipeFirehoseLogDestinationArgs']]:
        """
        The Amazon Data Firehose logging configuration settings for the pipe.
        """
        return pulumi.get(self, "firehose_log_destination")

    @firehose_log_destination.setter
    def firehose_log_destination(self, value: Optional[pulumi.Input['PipeFirehoseLogDestinationArgs']]):
        pulumi.set(self, "firehose_log_destination", value)

    @property
    @pulumi.getter(name="includeExecutionData")
    def include_execution_data(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipeIncludeExecutionDataOption']]]]:
        """
        Whether the execution data (specifically, the `payload` , `awsRequest` , and `awsResponse` fields) is included in the log messages for this pipe.

        This applies to all log destinations for the pipe.

        For more information, see [Including execution data in logs](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-logs.html#eb-pipes-logs-execution-data) in the *Amazon EventBridge User Guide* .

        *Allowed values:* `ALL`
        """
        return pulumi.get(self, "include_execution_data")

    @include_execution_data.setter
    def include_execution_data(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipeIncludeExecutionDataOption']]]]):
        pulumi.set(self, "include_execution_data", value)

    @property
    @pulumi.getter
    def level(self) -> Optional[pulumi.Input['PipeLogLevel']]:
        """
        The level of logging detail to include. This applies to all log destinations for the pipe.
        """
        return pulumi.get(self, "level")

    @level.setter
    def level(self, value: Optional[pulumi.Input['PipeLogLevel']]):
        pulumi.set(self, "level", value)

    @property
    @pulumi.getter(name="s3LogDestination")
    def s3_log_destination(self) -> Optional[pulumi.Input['PipeS3LogDestinationArgs']]:
        """
        The Amazon S3 logging configuration settings for the pipe.
        """
        return pulumi.get(self, "s3_log_destination")

    @s3_log_destination.setter
    def s3_log_destination(self, value: Optional[pulumi.Input['PipeS3LogDestinationArgs']]):
        pulumi.set(self, "s3_log_destination", value)


if not MYPY:
    class PipeMqBrokerAccessCredentialsPropertiesArgsDict(TypedDict):
        basic_auth: pulumi.Input[str]
        """
        Optional SecretManager ARN which stores the database credentials
        """
elif False:
    PipeMqBrokerAccessCredentialsPropertiesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeMqBrokerAccessCredentialsPropertiesArgs:
    def __init__(__self__, *,
                 basic_auth: pulumi.Input[str]):
        """
        :param pulumi.Input[str] basic_auth: Optional SecretManager ARN which stores the database credentials
        """
        pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> pulumi.Input[str]:
        """
        Optional SecretManager ARN which stores the database credentials
        """
        return pulumi.get(self, "basic_auth")

    @basic_auth.setter
    def basic_auth(self, value: pulumi.Input[str]):
        pulumi.set(self, "basic_auth", value)


if not MYPY:
    class PipeMskAccessCredentials0PropertiesArgsDict(TypedDict):
        sasl_scram512_auth: pulumi.Input[str]
        """
        Optional SecretManager ARN which stores the database credentials
        """
elif False:
    PipeMskAccessCredentials0PropertiesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeMskAccessCredentials0PropertiesArgs:
    def __init__(__self__, *,
                 sasl_scram512_auth: pulumi.Input[str]):
        """
        :param pulumi.Input[str] sasl_scram512_auth: Optional SecretManager ARN which stores the database credentials
        """
        pulumi.set(__self__, "sasl_scram512_auth", sasl_scram512_auth)

    @property
    @pulumi.getter(name="saslScram512Auth")
    def sasl_scram512_auth(self) -> pulumi.Input[str]:
        """
        Optional SecretManager ARN which stores the database credentials
        """
        return pulumi.get(self, "sasl_scram512_auth")

    @sasl_scram512_auth.setter
    def sasl_scram512_auth(self, value: pulumi.Input[str]):
        pulumi.set(self, "sasl_scram512_auth", value)


if not MYPY:
    class PipeMskAccessCredentials1PropertiesArgsDict(TypedDict):
        client_certificate_tls_auth: pulumi.Input[str]
        """
        Optional SecretManager ARN which stores the database credentials
        """
elif False:
    PipeMskAccessCredentials1PropertiesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeMskAccessCredentials1PropertiesArgs:
    def __init__(__self__, *,
                 client_certificate_tls_auth: pulumi.Input[str]):
        """
        :param pulumi.Input[str] client_certificate_tls_auth: Optional SecretManager ARN which stores the database credentials
        """
        pulumi.set(__self__, "client_certificate_tls_auth", client_certificate_tls_auth)

    @property
    @pulumi.getter(name="clientCertificateTlsAuth")
    def client_certificate_tls_auth(self) -> pulumi.Input[str]:
        """
        Optional SecretManager ARN which stores the database credentials
        """
        return pulumi.get(self, "client_certificate_tls_auth")

    @client_certificate_tls_auth.setter
    def client_certificate_tls_auth(self, value: pulumi.Input[str]):
        pulumi.set(self, "client_certificate_tls_auth", value)


if not MYPY:
    class PipeMultiMeasureAttributeMappingArgsDict(TypedDict):
        measure_value: pulumi.Input[str]
        """
        Dynamic path to the measurement attribute in the source event.
        """
        measure_value_type: pulumi.Input['PipeMeasureValueType']
        """
        Data type of the measurement attribute in the source event.
        """
        multi_measure_attribute_name: pulumi.Input[str]
        """
        Target measure name to be used.
        """
elif False:
    PipeMultiMeasureAttributeMappingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeMultiMeasureAttributeMappingArgs:
    def __init__(__self__, *,
                 measure_value: pulumi.Input[str],
                 measure_value_type: pulumi.Input['PipeMeasureValueType'],
                 multi_measure_attribute_name: pulumi.Input[str]):
        """
        :param pulumi.Input[str] measure_value: Dynamic path to the measurement attribute in the source event.
        :param pulumi.Input['PipeMeasureValueType'] measure_value_type: Data type of the measurement attribute in the source event.
        :param pulumi.Input[str] multi_measure_attribute_name: Target measure name to be used.
        """
        pulumi.set(__self__, "measure_value", measure_value)
        pulumi.set(__self__, "measure_value_type", measure_value_type)
        pulumi.set(__self__, "multi_measure_attribute_name", multi_measure_attribute_name)

    @property
    @pulumi.getter(name="measureValue")
    def measure_value(self) -> pulumi.Input[str]:
        """
        Dynamic path to the measurement attribute in the source event.
        """
        return pulumi.get(self, "measure_value")

    @measure_value.setter
    def measure_value(self, value: pulumi.Input[str]):
        pulumi.set(self, "measure_value", value)

    @property
    @pulumi.getter(name="measureValueType")
    def measure_value_type(self) -> pulumi.Input['PipeMeasureValueType']:
        """
        Data type of the measurement attribute in the source event.
        """
        return pulumi.get(self, "measure_value_type")

    @measure_value_type.setter
    def measure_value_type(self, value: pulumi.Input['PipeMeasureValueType']):
        pulumi.set(self, "measure_value_type", value)

    @property
    @pulumi.getter(name="multiMeasureAttributeName")
    def multi_measure_attribute_name(self) -> pulumi.Input[str]:
        """
        Target measure name to be used.
        """
        return pulumi.get(self, "multi_measure_attribute_name")

    @multi_measure_attribute_name.setter
    def multi_measure_attribute_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "multi_measure_attribute_name", value)


if not MYPY:
    class PipeMultiMeasureMappingArgsDict(TypedDict):
        multi_measure_attribute_mappings: pulumi.Input[Sequence[pulumi.Input['PipeMultiMeasureAttributeMappingArgsDict']]]
        """
        Mappings that represent multiple source event fields mapped to measures in the same Timestream for LiveAnalytics record.
        """
        multi_measure_name: pulumi.Input[str]
        """
        The name of the multiple measurements per record (multi-measure).
        """
elif False:
    PipeMultiMeasureMappingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeMultiMeasureMappingArgs:
    def __init__(__self__, *,
                 multi_measure_attribute_mappings: pulumi.Input[Sequence[pulumi.Input['PipeMultiMeasureAttributeMappingArgs']]],
                 multi_measure_name: pulumi.Input[str]):
        """
        :param pulumi.Input[Sequence[pulumi.Input['PipeMultiMeasureAttributeMappingArgs']]] multi_measure_attribute_mappings: Mappings that represent multiple source event fields mapped to measures in the same Timestream for LiveAnalytics record.
        :param pulumi.Input[str] multi_measure_name: The name of the multiple measurements per record (multi-measure).
        """
        pulumi.set(__self__, "multi_measure_attribute_mappings", multi_measure_attribute_mappings)
        pulumi.set(__self__, "multi_measure_name", multi_measure_name)

    @property
    @pulumi.getter(name="multiMeasureAttributeMappings")
    def multi_measure_attribute_mappings(self) -> pulumi.Input[Sequence[pulumi.Input['PipeMultiMeasureAttributeMappingArgs']]]:
        """
        Mappings that represent multiple source event fields mapped to measures in the same Timestream for LiveAnalytics record.
        """
        return pulumi.get(self, "multi_measure_attribute_mappings")

    @multi_measure_attribute_mappings.setter
    def multi_measure_attribute_mappings(self, value: pulumi.Input[Sequence[pulumi.Input['PipeMultiMeasureAttributeMappingArgs']]]):
        pulumi.set(self, "multi_measure_attribute_mappings", value)

    @property
    @pulumi.getter(name="multiMeasureName")
    def multi_measure_name(self) -> pulumi.Input[str]:
        """
        The name of the multiple measurements per record (multi-measure).
        """
        return pulumi.get(self, "multi_measure_name")

    @multi_measure_name.setter
    def multi_measure_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "multi_measure_name", value)


if not MYPY:
    class PipeNetworkConfigurationArgsDict(TypedDict):
        awsvpc_configuration: NotRequired[pulumi.Input['PipeAwsVpcConfigurationArgsDict']]
        """
        Use this structure to specify the VPC subnets and security groups for the task, and whether a public IP address is to be used. This structure is relevant only for ECS tasks that use the `awsvpc` network mode.
        """
elif False:
    PipeNetworkConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeNetworkConfigurationArgs:
    def __init__(__self__, *,
                 awsvpc_configuration: Optional[pulumi.Input['PipeAwsVpcConfigurationArgs']] = None):
        """
        :param pulumi.Input['PipeAwsVpcConfigurationArgs'] awsvpc_configuration: Use this structure to specify the VPC subnets and security groups for the task, and whether a public IP address is to be used. This structure is relevant only for ECS tasks that use the `awsvpc` network mode.
        """
        if awsvpc_configuration is not None:
            pulumi.set(__self__, "awsvpc_configuration", awsvpc_configuration)

    @property
    @pulumi.getter(name="awsvpcConfiguration")
    def awsvpc_configuration(self) -> Optional[pulumi.Input['PipeAwsVpcConfigurationArgs']]:
        """
        Use this structure to specify the VPC subnets and security groups for the task, and whether a public IP address is to be used. This structure is relevant only for ECS tasks that use the `awsvpc` network mode.
        """
        return pulumi.get(self, "awsvpc_configuration")

    @awsvpc_configuration.setter
    def awsvpc_configuration(self, value: Optional[pulumi.Input['PipeAwsVpcConfigurationArgs']]):
        pulumi.set(self, "awsvpc_configuration", value)


if not MYPY:
    class PipePlacementConstraintArgsDict(TypedDict):
        expression: NotRequired[pulumi.Input[str]]
        """
        A cluster query language expression to apply to the constraint. You cannot specify an expression if the constraint type is `distinctInstance` . To learn more, see [Cluster Query Language](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-query-language.html) in the Amazon Elastic Container Service Developer Guide.
        """
        type: NotRequired[pulumi.Input['PipePlacementConstraintType']]
        """
        The type of constraint. Use distinctInstance to ensure that each task in a particular group is running on a different container instance. Use memberOf to restrict the selection to a group of valid candidates.
        """
elif False:
    PipePlacementConstraintArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipePlacementConstraintArgs:
    def __init__(__self__, *,
                 expression: Optional[pulumi.Input[str]] = None,
                 type: Optional[pulumi.Input['PipePlacementConstraintType']] = None):
        """
        :param pulumi.Input[str] expression: A cluster query language expression to apply to the constraint. You cannot specify an expression if the constraint type is `distinctInstance` . To learn more, see [Cluster Query Language](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-query-language.html) in the Amazon Elastic Container Service Developer Guide.
        :param pulumi.Input['PipePlacementConstraintType'] type: The type of constraint. Use distinctInstance to ensure that each task in a particular group is running on a different container instance. Use memberOf to restrict the selection to a group of valid candidates.
        """
        if expression is not None:
            pulumi.set(__self__, "expression", expression)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def expression(self) -> Optional[pulumi.Input[str]]:
        """
        A cluster query language expression to apply to the constraint. You cannot specify an expression if the constraint type is `distinctInstance` . To learn more, see [Cluster Query Language](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-query-language.html) in the Amazon Elastic Container Service Developer Guide.
        """
        return pulumi.get(self, "expression")

    @expression.setter
    def expression(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "expression", value)

    @property
    @pulumi.getter
    def type(self) -> Optional[pulumi.Input['PipePlacementConstraintType']]:
        """
        The type of constraint. Use distinctInstance to ensure that each task in a particular group is running on a different container instance. Use memberOf to restrict the selection to a group of valid candidates.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: Optional[pulumi.Input['PipePlacementConstraintType']]):
        pulumi.set(self, "type", value)


if not MYPY:
    class PipePlacementStrategyArgsDict(TypedDict):
        field: NotRequired[pulumi.Input[str]]
        """
        The field to apply the placement strategy against. For the spread placement strategy, valid values are instanceId (or host, which has the same effect), or any platform or custom attribute that is applied to a container instance, such as attribute:ecs.availability-zone. For the binpack placement strategy, valid values are cpu and memory. For the random placement strategy, this field is not used.
        """
        type: NotRequired[pulumi.Input['PipePlacementStrategyType']]
        """
        The type of placement strategy. The random placement strategy randomly places tasks on available candidates. The spread placement strategy spreads placement across available candidates evenly based on the field parameter. The binpack strategy places tasks on available candidates that have the least available amount of the resource that is specified with the field parameter. For example, if you binpack on memory, a task is placed on the instance with the least amount of remaining memory (but still enough to run the task).
        """
elif False:
    PipePlacementStrategyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipePlacementStrategyArgs:
    def __init__(__self__, *,
                 field: Optional[pulumi.Input[str]] = None,
                 type: Optional[pulumi.Input['PipePlacementStrategyType']] = None):
        """
        :param pulumi.Input[str] field: The field to apply the placement strategy against. For the spread placement strategy, valid values are instanceId (or host, which has the same effect), or any platform or custom attribute that is applied to a container instance, such as attribute:ecs.availability-zone. For the binpack placement strategy, valid values are cpu and memory. For the random placement strategy, this field is not used.
        :param pulumi.Input['PipePlacementStrategyType'] type: The type of placement strategy. The random placement strategy randomly places tasks on available candidates. The spread placement strategy spreads placement across available candidates evenly based on the field parameter. The binpack strategy places tasks on available candidates that have the least available amount of the resource that is specified with the field parameter. For example, if you binpack on memory, a task is placed on the instance with the least amount of remaining memory (but still enough to run the task).
        """
        if field is not None:
            pulumi.set(__self__, "field", field)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def field(self) -> Optional[pulumi.Input[str]]:
        """
        The field to apply the placement strategy against. For the spread placement strategy, valid values are instanceId (or host, which has the same effect), or any platform or custom attribute that is applied to a container instance, such as attribute:ecs.availability-zone. For the binpack placement strategy, valid values are cpu and memory. For the random placement strategy, this field is not used.
        """
        return pulumi.get(self, "field")

    @field.setter
    def field(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "field", value)

    @property
    @pulumi.getter
    def type(self) -> Optional[pulumi.Input['PipePlacementStrategyType']]:
        """
        The type of placement strategy. The random placement strategy randomly places tasks on available candidates. The spread placement strategy spreads placement across available candidates evenly based on the field parameter. The binpack strategy places tasks on available candidates that have the least available amount of the resource that is specified with the field parameter. For example, if you binpack on memory, a task is placed on the instance with the least amount of remaining memory (but still enough to run the task).
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: Optional[pulumi.Input['PipePlacementStrategyType']]):
        pulumi.set(self, "type", value)


if not MYPY:
    class PipeS3LogDestinationArgsDict(TypedDict):
        bucket_name: NotRequired[pulumi.Input[str]]
        """
        The name of the Amazon S3 bucket to which EventBridge delivers the log records for the pipe.
        """
        bucket_owner: NotRequired[pulumi.Input[str]]
        """
        The AWS account that owns the Amazon S3 bucket to which EventBridge delivers the log records for the pipe.
        """
        output_format: NotRequired[pulumi.Input['PipeS3OutputFormat']]
        """
        The format EventBridge uses for the log records.

        EventBridge currently only supports `json` formatting.
        """
        prefix: NotRequired[pulumi.Input[str]]
        """
        The prefix text with which to begin Amazon S3 log object names.

        For more information, see [Organizing objects using prefixes](https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-prefixes.html) in the *Amazon Simple Storage Service User Guide* .
        """
elif False:
    PipeS3LogDestinationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeS3LogDestinationArgs:
    def __init__(__self__, *,
                 bucket_name: Optional[pulumi.Input[str]] = None,
                 bucket_owner: Optional[pulumi.Input[str]] = None,
                 output_format: Optional[pulumi.Input['PipeS3OutputFormat']] = None,
                 prefix: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] bucket_name: The name of the Amazon S3 bucket to which EventBridge delivers the log records for the pipe.
        :param pulumi.Input[str] bucket_owner: The AWS account that owns the Amazon S3 bucket to which EventBridge delivers the log records for the pipe.
        :param pulumi.Input['PipeS3OutputFormat'] output_format: The format EventBridge uses for the log records.
               
               EventBridge currently only supports `json` formatting.
        :param pulumi.Input[str] prefix: The prefix text with which to begin Amazon S3 log object names.
               
               For more information, see [Organizing objects using prefixes](https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-prefixes.html) in the *Amazon Simple Storage Service User Guide* .
        """
        if bucket_name is not None:
            pulumi.set(__self__, "bucket_name", bucket_name)
        if bucket_owner is not None:
            pulumi.set(__self__, "bucket_owner", bucket_owner)
        if output_format is not None:
            pulumi.set(__self__, "output_format", output_format)
        if prefix is not None:
            pulumi.set(__self__, "prefix", prefix)

    @property
    @pulumi.getter(name="bucketName")
    def bucket_name(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the Amazon S3 bucket to which EventBridge delivers the log records for the pipe.
        """
        return pulumi.get(self, "bucket_name")

    @bucket_name.setter
    def bucket_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "bucket_name", value)

    @property
    @pulumi.getter(name="bucketOwner")
    def bucket_owner(self) -> Optional[pulumi.Input[str]]:
        """
        The AWS account that owns the Amazon S3 bucket to which EventBridge delivers the log records for the pipe.
        """
        return pulumi.get(self, "bucket_owner")

    @bucket_owner.setter
    def bucket_owner(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "bucket_owner", value)

    @property
    @pulumi.getter(name="outputFormat")
    def output_format(self) -> Optional[pulumi.Input['PipeS3OutputFormat']]:
        """
        The format EventBridge uses for the log records.

        EventBridge currently only supports `json` formatting.
        """
        return pulumi.get(self, "output_format")

    @output_format.setter
    def output_format(self, value: Optional[pulumi.Input['PipeS3OutputFormat']]):
        pulumi.set(self, "output_format", value)

    @property
    @pulumi.getter
    def prefix(self) -> Optional[pulumi.Input[str]]:
        """
        The prefix text with which to begin Amazon S3 log object names.

        For more information, see [Organizing objects using prefixes](https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-prefixes.html) in the *Amazon Simple Storage Service User Guide* .
        """
        return pulumi.get(self, "prefix")

    @prefix.setter
    def prefix(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "prefix", value)


if not MYPY:
    class PipeSageMakerPipelineParameterArgsDict(TypedDict):
        name: pulumi.Input[str]
        """
        Name of parameter to start execution of a SageMaker AI Model Building Pipeline.
        """
        value: pulumi.Input[str]
        """
        Value of parameter to start execution of a SageMaker AI Model Building Pipeline.
        """
elif False:
    PipeSageMakerPipelineParameterArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeSageMakerPipelineParameterArgs:
    def __init__(__self__, *,
                 name: pulumi.Input[str],
                 value: pulumi.Input[str]):
        """
        :param pulumi.Input[str] name: Name of parameter to start execution of a SageMaker AI Model Building Pipeline.
        :param pulumi.Input[str] value: Value of parameter to start execution of a SageMaker AI Model Building Pipeline.
        """
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def name(self) -> pulumi.Input[str]:
        """
        Name of parameter to start execution of a SageMaker AI Model Building Pipeline.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: pulumi.Input[str]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter
    def value(self) -> pulumi.Input[str]:
        """
        Value of parameter to start execution of a SageMaker AI Model Building Pipeline.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: pulumi.Input[str]):
        pulumi.set(self, "value", value)


if not MYPY:
    class PipeSelfManagedKafkaAccessConfigurationCredentials0PropertiesArgsDict(TypedDict):
        basic_auth: pulumi.Input[str]
        """
        Optional SecretManager ARN which stores the database credentials
        """
elif False:
    PipeSelfManagedKafkaAccessConfigurationCredentials0PropertiesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeSelfManagedKafkaAccessConfigurationCredentials0PropertiesArgs:
    def __init__(__self__, *,
                 basic_auth: pulumi.Input[str]):
        """
        :param pulumi.Input[str] basic_auth: Optional SecretManager ARN which stores the database credentials
        """
        pulumi.set(__self__, "basic_auth", basic_auth)

    @property
    @pulumi.getter(name="basicAuth")
    def basic_auth(self) -> pulumi.Input[str]:
        """
        Optional SecretManager ARN which stores the database credentials
        """
        return pulumi.get(self, "basic_auth")

    @basic_auth.setter
    def basic_auth(self, value: pulumi.Input[str]):
        pulumi.set(self, "basic_auth", value)


if not MYPY:
    class PipeSelfManagedKafkaAccessConfigurationCredentials1PropertiesArgsDict(TypedDict):
        sasl_scram512_auth: pulumi.Input[str]
        """
        Optional SecretManager ARN which stores the database credentials
        """
elif False:
    PipeSelfManagedKafkaAccessConfigurationCredentials1PropertiesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeSelfManagedKafkaAccessConfigurationCredentials1PropertiesArgs:
    def __init__(__self__, *,
                 sasl_scram512_auth: pulumi.Input[str]):
        """
        :param pulumi.Input[str] sasl_scram512_auth: Optional SecretManager ARN which stores the database credentials
        """
        pulumi.set(__self__, "sasl_scram512_auth", sasl_scram512_auth)

    @property
    @pulumi.getter(name="saslScram512Auth")
    def sasl_scram512_auth(self) -> pulumi.Input[str]:
        """
        Optional SecretManager ARN which stores the database credentials
        """
        return pulumi.get(self, "sasl_scram512_auth")

    @sasl_scram512_auth.setter
    def sasl_scram512_auth(self, value: pulumi.Input[str]):
        pulumi.set(self, "sasl_scram512_auth", value)


if not MYPY:
    class PipeSelfManagedKafkaAccessConfigurationCredentials2PropertiesArgsDict(TypedDict):
        sasl_scram256_auth: pulumi.Input[str]
        """
        Optional SecretManager ARN which stores the database credentials
        """
elif False:
    PipeSelfManagedKafkaAccessConfigurationCredentials2PropertiesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeSelfManagedKafkaAccessConfigurationCredentials2PropertiesArgs:
    def __init__(__self__, *,
                 sasl_scram256_auth: pulumi.Input[str]):
        """
        :param pulumi.Input[str] sasl_scram256_auth: Optional SecretManager ARN which stores the database credentials
        """
        pulumi.set(__self__, "sasl_scram256_auth", sasl_scram256_auth)

    @property
    @pulumi.getter(name="saslScram256Auth")
    def sasl_scram256_auth(self) -> pulumi.Input[str]:
        """
        Optional SecretManager ARN which stores the database credentials
        """
        return pulumi.get(self, "sasl_scram256_auth")

    @sasl_scram256_auth.setter
    def sasl_scram256_auth(self, value: pulumi.Input[str]):
        pulumi.set(self, "sasl_scram256_auth", value)


if not MYPY:
    class PipeSelfManagedKafkaAccessConfigurationCredentials3PropertiesArgsDict(TypedDict):
        client_certificate_tls_auth: pulumi.Input[str]
        """
        Optional SecretManager ARN which stores the database credentials
        """
elif False:
    PipeSelfManagedKafkaAccessConfigurationCredentials3PropertiesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeSelfManagedKafkaAccessConfigurationCredentials3PropertiesArgs:
    def __init__(__self__, *,
                 client_certificate_tls_auth: pulumi.Input[str]):
        """
        :param pulumi.Input[str] client_certificate_tls_auth: Optional SecretManager ARN which stores the database credentials
        """
        pulumi.set(__self__, "client_certificate_tls_auth", client_certificate_tls_auth)

    @property
    @pulumi.getter(name="clientCertificateTlsAuth")
    def client_certificate_tls_auth(self) -> pulumi.Input[str]:
        """
        Optional SecretManager ARN which stores the database credentials
        """
        return pulumi.get(self, "client_certificate_tls_auth")

    @client_certificate_tls_auth.setter
    def client_certificate_tls_auth(self, value: pulumi.Input[str]):
        pulumi.set(self, "client_certificate_tls_auth", value)


if not MYPY:
    class PipeSelfManagedKafkaAccessConfigurationVpcArgsDict(TypedDict):
        security_group: NotRequired[pulumi.Input[Sequence[pulumi.Input[str]]]]
        """
        List of SecurityGroupId.
        """
        subnets: NotRequired[pulumi.Input[Sequence[pulumi.Input[str]]]]
        """
        List of SubnetId.
        """
elif False:
    PipeSelfManagedKafkaAccessConfigurationVpcArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeSelfManagedKafkaAccessConfigurationVpcArgs:
    def __init__(__self__, *,
                 security_group: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 subnets: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] security_group: List of SecurityGroupId.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] subnets: List of SubnetId.
        """
        if security_group is not None:
            pulumi.set(__self__, "security_group", security_group)
        if subnets is not None:
            pulumi.set(__self__, "subnets", subnets)

    @property
    @pulumi.getter(name="securityGroup")
    def security_group(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        List of SecurityGroupId.
        """
        return pulumi.get(self, "security_group")

    @security_group.setter
    def security_group(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "security_group", value)

    @property
    @pulumi.getter
    def subnets(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        List of SubnetId.
        """
        return pulumi.get(self, "subnets")

    @subnets.setter
    def subnets(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "subnets", value)


if not MYPY:
    class PipeSingleMeasureMappingArgsDict(TypedDict):
        measure_name: pulumi.Input[str]
        """
        Target measure name for the measurement attribute in the Timestream table.
        """
        measure_value: pulumi.Input[str]
        """
        Dynamic path of the source field to map to the measure in the record.
        """
        measure_value_type: pulumi.Input['PipeMeasureValueType']
        """
        Data type of the source field.
        """
elif False:
    PipeSingleMeasureMappingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeSingleMeasureMappingArgs:
    def __init__(__self__, *,
                 measure_name: pulumi.Input[str],
                 measure_value: pulumi.Input[str],
                 measure_value_type: pulumi.Input['PipeMeasureValueType']):
        """
        :param pulumi.Input[str] measure_name: Target measure name for the measurement attribute in the Timestream table.
        :param pulumi.Input[str] measure_value: Dynamic path of the source field to map to the measure in the record.
        :param pulumi.Input['PipeMeasureValueType'] measure_value_type: Data type of the source field.
        """
        pulumi.set(__self__, "measure_name", measure_name)
        pulumi.set(__self__, "measure_value", measure_value)
        pulumi.set(__self__, "measure_value_type", measure_value_type)

    @property
    @pulumi.getter(name="measureName")
    def measure_name(self) -> pulumi.Input[str]:
        """
        Target measure name for the measurement attribute in the Timestream table.
        """
        return pulumi.get(self, "measure_name")

    @measure_name.setter
    def measure_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "measure_name", value)

    @property
    @pulumi.getter(name="measureValue")
    def measure_value(self) -> pulumi.Input[str]:
        """
        Dynamic path of the source field to map to the measure in the record.
        """
        return pulumi.get(self, "measure_value")

    @measure_value.setter
    def measure_value(self, value: pulumi.Input[str]):
        pulumi.set(self, "measure_value", value)

    @property
    @pulumi.getter(name="measureValueType")
    def measure_value_type(self) -> pulumi.Input['PipeMeasureValueType']:
        """
        Data type of the source field.
        """
        return pulumi.get(self, "measure_value_type")

    @measure_value_type.setter
    def measure_value_type(self, value: pulumi.Input['PipeMeasureValueType']):
        pulumi.set(self, "measure_value_type", value)


if not MYPY:
    class PipeSourceActiveMqBrokerParametersArgsDict(TypedDict):
        credentials: pulumi.Input['PipeMqBrokerAccessCredentialsPropertiesArgsDict']
        """
        The credentials needed to access the resource.
        """
        queue_name: pulumi.Input[str]
        """
        The name of the destination queue to consume.
        """
        batch_size: NotRequired[pulumi.Input[int]]
        """
        The maximum number of records to include in each batch.
        """
        maximum_batching_window_in_seconds: NotRequired[pulumi.Input[int]]
        """
        The maximum length of a time to wait for events.
        """
elif False:
    PipeSourceActiveMqBrokerParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeSourceActiveMqBrokerParametersArgs:
    def __init__(__self__, *,
                 credentials: pulumi.Input['PipeMqBrokerAccessCredentialsPropertiesArgs'],
                 queue_name: pulumi.Input[str],
                 batch_size: Optional[pulumi.Input[int]] = None,
                 maximum_batching_window_in_seconds: Optional[pulumi.Input[int]] = None):
        """
        :param pulumi.Input['PipeMqBrokerAccessCredentialsPropertiesArgs'] credentials: The credentials needed to access the resource.
        :param pulumi.Input[str] queue_name: The name of the destination queue to consume.
        :param pulumi.Input[int] batch_size: The maximum number of records to include in each batch.
        :param pulumi.Input[int] maximum_batching_window_in_seconds: The maximum length of a time to wait for events.
        """
        pulumi.set(__self__, "credentials", credentials)
        pulumi.set(__self__, "queue_name", queue_name)
        if batch_size is not None:
            pulumi.set(__self__, "batch_size", batch_size)
        if maximum_batching_window_in_seconds is not None:
            pulumi.set(__self__, "maximum_batching_window_in_seconds", maximum_batching_window_in_seconds)

    @property
    @pulumi.getter
    def credentials(self) -> pulumi.Input['PipeMqBrokerAccessCredentialsPropertiesArgs']:
        """
        The credentials needed to access the resource.
        """
        return pulumi.get(self, "credentials")

    @credentials.setter
    def credentials(self, value: pulumi.Input['PipeMqBrokerAccessCredentialsPropertiesArgs']):
        pulumi.set(self, "credentials", value)

    @property
    @pulumi.getter(name="queueName")
    def queue_name(self) -> pulumi.Input[str]:
        """
        The name of the destination queue to consume.
        """
        return pulumi.get(self, "queue_name")

    @queue_name.setter
    def queue_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "queue_name", value)

    @property
    @pulumi.getter(name="batchSize")
    def batch_size(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum number of records to include in each batch.
        """
        return pulumi.get(self, "batch_size")

    @batch_size.setter
    def batch_size(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "batch_size", value)

    @property
    @pulumi.getter(name="maximumBatchingWindowInSeconds")
    def maximum_batching_window_in_seconds(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum length of a time to wait for events.
        """
        return pulumi.get(self, "maximum_batching_window_in_seconds")

    @maximum_batching_window_in_seconds.setter
    def maximum_batching_window_in_seconds(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "maximum_batching_window_in_seconds", value)


if not MYPY:
    class PipeSourceDynamoDbStreamParametersArgsDict(TypedDict):
        starting_position: pulumi.Input['PipeDynamoDbStreamStartPosition']
        """
        (Streams only) The position in a stream from which to start reading.

        *Valid values* : `TRIM_HORIZON | LATEST`
        """
        batch_size: NotRequired[pulumi.Input[int]]
        """
        The maximum number of records to include in each batch.
        """
        dead_letter_config: NotRequired[pulumi.Input['PipeDeadLetterConfigArgsDict']]
        """
        Define the target queue to send dead-letter queue events to.
        """
        maximum_batching_window_in_seconds: NotRequired[pulumi.Input[int]]
        """
        The maximum length of a time to wait for events.
        """
        maximum_record_age_in_seconds: NotRequired[pulumi.Input[int]]
        """
        Discard records older than the specified age. The default value is -1, which sets the maximum age to infinite. When the value is set to infinite, EventBridge never discards old records.
        """
        maximum_retry_attempts: NotRequired[pulumi.Input[int]]
        """
        Discard records after the specified number of retries. The default value is -1, which sets the maximum number of retries to infinite. When MaximumRetryAttempts is infinite, EventBridge retries failed records until the record expires in the event source.
        """
        on_partial_batch_item_failure: NotRequired[pulumi.Input['PipeOnPartialBatchItemFailureStreams']]
        """
        Define how to handle item process failures. `AUTOMATIC_BISECT` halves each batch and retry each half until all the records are processed or there is one failed message left in the batch.
        """
        parallelization_factor: NotRequired[pulumi.Input[int]]
        """
        The number of batches to process concurrently from each shard. The default value is 1.
        """
elif False:
    PipeSourceDynamoDbStreamParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeSourceDynamoDbStreamParametersArgs:
    def __init__(__self__, *,
                 starting_position: pulumi.Input['PipeDynamoDbStreamStartPosition'],
                 batch_size: Optional[pulumi.Input[int]] = None,
                 dead_letter_config: Optional[pulumi.Input['PipeDeadLetterConfigArgs']] = None,
                 maximum_batching_window_in_seconds: Optional[pulumi.Input[int]] = None,
                 maximum_record_age_in_seconds: Optional[pulumi.Input[int]] = None,
                 maximum_retry_attempts: Optional[pulumi.Input[int]] = None,
                 on_partial_batch_item_failure: Optional[pulumi.Input['PipeOnPartialBatchItemFailureStreams']] = None,
                 parallelization_factor: Optional[pulumi.Input[int]] = None):
        """
        :param pulumi.Input['PipeDynamoDbStreamStartPosition'] starting_position: (Streams only) The position in a stream from which to start reading.
               
               *Valid values* : `TRIM_HORIZON | LATEST`
        :param pulumi.Input[int] batch_size: The maximum number of records to include in each batch.
        :param pulumi.Input['PipeDeadLetterConfigArgs'] dead_letter_config: Define the target queue to send dead-letter queue events to.
        :param pulumi.Input[int] maximum_batching_window_in_seconds: The maximum length of a time to wait for events.
        :param pulumi.Input[int] maximum_record_age_in_seconds: Discard records older than the specified age. The default value is -1, which sets the maximum age to infinite. When the value is set to infinite, EventBridge never discards old records.
        :param pulumi.Input[int] maximum_retry_attempts: Discard records after the specified number of retries. The default value is -1, which sets the maximum number of retries to infinite. When MaximumRetryAttempts is infinite, EventBridge retries failed records until the record expires in the event source.
        :param pulumi.Input['PipeOnPartialBatchItemFailureStreams'] on_partial_batch_item_failure: Define how to handle item process failures. `AUTOMATIC_BISECT` halves each batch and retry each half until all the records are processed or there is one failed message left in the batch.
        :param pulumi.Input[int] parallelization_factor: The number of batches to process concurrently from each shard. The default value is 1.
        """
        pulumi.set(__self__, "starting_position", starting_position)
        if batch_size is not None:
            pulumi.set(__self__, "batch_size", batch_size)
        if dead_letter_config is not None:
            pulumi.set(__self__, "dead_letter_config", dead_letter_config)
        if maximum_batching_window_in_seconds is not None:
            pulumi.set(__self__, "maximum_batching_window_in_seconds", maximum_batching_window_in_seconds)
        if maximum_record_age_in_seconds is not None:
            pulumi.set(__self__, "maximum_record_age_in_seconds", maximum_record_age_in_seconds)
        if maximum_retry_attempts is not None:
            pulumi.set(__self__, "maximum_retry_attempts", maximum_retry_attempts)
        if on_partial_batch_item_failure is not None:
            pulumi.set(__self__, "on_partial_batch_item_failure", on_partial_batch_item_failure)
        if parallelization_factor is not None:
            pulumi.set(__self__, "parallelization_factor", parallelization_factor)

    @property
    @pulumi.getter(name="startingPosition")
    def starting_position(self) -> pulumi.Input['PipeDynamoDbStreamStartPosition']:
        """
        (Streams only) The position in a stream from which to start reading.

        *Valid values* : `TRIM_HORIZON | LATEST`
        """
        return pulumi.get(self, "starting_position")

    @starting_position.setter
    def starting_position(self, value: pulumi.Input['PipeDynamoDbStreamStartPosition']):
        pulumi.set(self, "starting_position", value)

    @property
    @pulumi.getter(name="batchSize")
    def batch_size(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum number of records to include in each batch.
        """
        return pulumi.get(self, "batch_size")

    @batch_size.setter
    def batch_size(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "batch_size", value)

    @property
    @pulumi.getter(name="deadLetterConfig")
    def dead_letter_config(self) -> Optional[pulumi.Input['PipeDeadLetterConfigArgs']]:
        """
        Define the target queue to send dead-letter queue events to.
        """
        return pulumi.get(self, "dead_letter_config")

    @dead_letter_config.setter
    def dead_letter_config(self, value: Optional[pulumi.Input['PipeDeadLetterConfigArgs']]):
        pulumi.set(self, "dead_letter_config", value)

    @property
    @pulumi.getter(name="maximumBatchingWindowInSeconds")
    def maximum_batching_window_in_seconds(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum length of a time to wait for events.
        """
        return pulumi.get(self, "maximum_batching_window_in_seconds")

    @maximum_batching_window_in_seconds.setter
    def maximum_batching_window_in_seconds(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "maximum_batching_window_in_seconds", value)

    @property
    @pulumi.getter(name="maximumRecordAgeInSeconds")
    def maximum_record_age_in_seconds(self) -> Optional[pulumi.Input[int]]:
        """
        Discard records older than the specified age. The default value is -1, which sets the maximum age to infinite. When the value is set to infinite, EventBridge never discards old records.
        """
        return pulumi.get(self, "maximum_record_age_in_seconds")

    @maximum_record_age_in_seconds.setter
    def maximum_record_age_in_seconds(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "maximum_record_age_in_seconds", value)

    @property
    @pulumi.getter(name="maximumRetryAttempts")
    def maximum_retry_attempts(self) -> Optional[pulumi.Input[int]]:
        """
        Discard records after the specified number of retries. The default value is -1, which sets the maximum number of retries to infinite. When MaximumRetryAttempts is infinite, EventBridge retries failed records until the record expires in the event source.
        """
        return pulumi.get(self, "maximum_retry_attempts")

    @maximum_retry_attempts.setter
    def maximum_retry_attempts(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "maximum_retry_attempts", value)

    @property
    @pulumi.getter(name="onPartialBatchItemFailure")
    def on_partial_batch_item_failure(self) -> Optional[pulumi.Input['PipeOnPartialBatchItemFailureStreams']]:
        """
        Define how to handle item process failures. `AUTOMATIC_BISECT` halves each batch and retry each half until all the records are processed or there is one failed message left in the batch.
        """
        return pulumi.get(self, "on_partial_batch_item_failure")

    @on_partial_batch_item_failure.setter
    def on_partial_batch_item_failure(self, value: Optional[pulumi.Input['PipeOnPartialBatchItemFailureStreams']]):
        pulumi.set(self, "on_partial_batch_item_failure", value)

    @property
    @pulumi.getter(name="parallelizationFactor")
    def parallelization_factor(self) -> Optional[pulumi.Input[int]]:
        """
        The number of batches to process concurrently from each shard. The default value is 1.
        """
        return pulumi.get(self, "parallelization_factor")

    @parallelization_factor.setter
    def parallelization_factor(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "parallelization_factor", value)


if not MYPY:
    class PipeSourceKinesisStreamParametersArgsDict(TypedDict):
        starting_position: pulumi.Input['PipeKinesisStreamStartPosition']
        """
        The position in a stream from which to start reading.
        """
        batch_size: NotRequired[pulumi.Input[int]]
        """
        The maximum number of records to include in each batch.
        """
        dead_letter_config: NotRequired[pulumi.Input['PipeDeadLetterConfigArgsDict']]
        """
        Define the target queue to send dead-letter queue events to.
        """
        maximum_batching_window_in_seconds: NotRequired[pulumi.Input[int]]
        """
        The maximum length of a time to wait for events.
        """
        maximum_record_age_in_seconds: NotRequired[pulumi.Input[int]]
        """
        Discard records older than the specified age. The default value is -1, which sets the maximum age to infinite. When the value is set to infinite, EventBridge never discards old records.
        """
        maximum_retry_attempts: NotRequired[pulumi.Input[int]]
        """
        Discard records after the specified number of retries. The default value is -1, which sets the maximum number of retries to infinite. When MaximumRetryAttempts is infinite, EventBridge retries failed records until the record expires in the event source.
        """
        on_partial_batch_item_failure: NotRequired[pulumi.Input['PipeOnPartialBatchItemFailureStreams']]
        """
        Define how to handle item process failures. `AUTOMATIC_BISECT` halves each batch and retry each half until all the records are processed or there is one failed message left in the batch.
        """
        parallelization_factor: NotRequired[pulumi.Input[int]]
        """
        The number of batches to process concurrently from each shard. The default value is 1.
        """
        starting_position_timestamp: NotRequired[pulumi.Input[str]]
        """
        With `StartingPosition` set to `AT_TIMESTAMP` , the time from which to start reading, in Unix time seconds.
        """
elif False:
    PipeSourceKinesisStreamParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeSourceKinesisStreamParametersArgs:
    def __init__(__self__, *,
                 starting_position: pulumi.Input['PipeKinesisStreamStartPosition'],
                 batch_size: Optional[pulumi.Input[int]] = None,
                 dead_letter_config: Optional[pulumi.Input['PipeDeadLetterConfigArgs']] = None,
                 maximum_batching_window_in_seconds: Optional[pulumi.Input[int]] = None,
                 maximum_record_age_in_seconds: Optional[pulumi.Input[int]] = None,
                 maximum_retry_attempts: Optional[pulumi.Input[int]] = None,
                 on_partial_batch_item_failure: Optional[pulumi.Input['PipeOnPartialBatchItemFailureStreams']] = None,
                 parallelization_factor: Optional[pulumi.Input[int]] = None,
                 starting_position_timestamp: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input['PipeKinesisStreamStartPosition'] starting_position: The position in a stream from which to start reading.
        :param pulumi.Input[int] batch_size: The maximum number of records to include in each batch.
        :param pulumi.Input['PipeDeadLetterConfigArgs'] dead_letter_config: Define the target queue to send dead-letter queue events to.
        :param pulumi.Input[int] maximum_batching_window_in_seconds: The maximum length of a time to wait for events.
        :param pulumi.Input[int] maximum_record_age_in_seconds: Discard records older than the specified age. The default value is -1, which sets the maximum age to infinite. When the value is set to infinite, EventBridge never discards old records.
        :param pulumi.Input[int] maximum_retry_attempts: Discard records after the specified number of retries. The default value is -1, which sets the maximum number of retries to infinite. When MaximumRetryAttempts is infinite, EventBridge retries failed records until the record expires in the event source.
        :param pulumi.Input['PipeOnPartialBatchItemFailureStreams'] on_partial_batch_item_failure: Define how to handle item process failures. `AUTOMATIC_BISECT` halves each batch and retry each half until all the records are processed or there is one failed message left in the batch.
        :param pulumi.Input[int] parallelization_factor: The number of batches to process concurrently from each shard. The default value is 1.
        :param pulumi.Input[str] starting_position_timestamp: With `StartingPosition` set to `AT_TIMESTAMP` , the time from which to start reading, in Unix time seconds.
        """
        pulumi.set(__self__, "starting_position", starting_position)
        if batch_size is not None:
            pulumi.set(__self__, "batch_size", batch_size)
        if dead_letter_config is not None:
            pulumi.set(__self__, "dead_letter_config", dead_letter_config)
        if maximum_batching_window_in_seconds is not None:
            pulumi.set(__self__, "maximum_batching_window_in_seconds", maximum_batching_window_in_seconds)
        if maximum_record_age_in_seconds is not None:
            pulumi.set(__self__, "maximum_record_age_in_seconds", maximum_record_age_in_seconds)
        if maximum_retry_attempts is not None:
            pulumi.set(__self__, "maximum_retry_attempts", maximum_retry_attempts)
        if on_partial_batch_item_failure is not None:
            pulumi.set(__self__, "on_partial_batch_item_failure", on_partial_batch_item_failure)
        if parallelization_factor is not None:
            pulumi.set(__self__, "parallelization_factor", parallelization_factor)
        if starting_position_timestamp is not None:
            pulumi.set(__self__, "starting_position_timestamp", starting_position_timestamp)

    @property
    @pulumi.getter(name="startingPosition")
    def starting_position(self) -> pulumi.Input['PipeKinesisStreamStartPosition']:
        """
        The position in a stream from which to start reading.
        """
        return pulumi.get(self, "starting_position")

    @starting_position.setter
    def starting_position(self, value: pulumi.Input['PipeKinesisStreamStartPosition']):
        pulumi.set(self, "starting_position", value)

    @property
    @pulumi.getter(name="batchSize")
    def batch_size(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum number of records to include in each batch.
        """
        return pulumi.get(self, "batch_size")

    @batch_size.setter
    def batch_size(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "batch_size", value)

    @property
    @pulumi.getter(name="deadLetterConfig")
    def dead_letter_config(self) -> Optional[pulumi.Input['PipeDeadLetterConfigArgs']]:
        """
        Define the target queue to send dead-letter queue events to.
        """
        return pulumi.get(self, "dead_letter_config")

    @dead_letter_config.setter
    def dead_letter_config(self, value: Optional[pulumi.Input['PipeDeadLetterConfigArgs']]):
        pulumi.set(self, "dead_letter_config", value)

    @property
    @pulumi.getter(name="maximumBatchingWindowInSeconds")
    def maximum_batching_window_in_seconds(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum length of a time to wait for events.
        """
        return pulumi.get(self, "maximum_batching_window_in_seconds")

    @maximum_batching_window_in_seconds.setter
    def maximum_batching_window_in_seconds(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "maximum_batching_window_in_seconds", value)

    @property
    @pulumi.getter(name="maximumRecordAgeInSeconds")
    def maximum_record_age_in_seconds(self) -> Optional[pulumi.Input[int]]:
        """
        Discard records older than the specified age. The default value is -1, which sets the maximum age to infinite. When the value is set to infinite, EventBridge never discards old records.
        """
        return pulumi.get(self, "maximum_record_age_in_seconds")

    @maximum_record_age_in_seconds.setter
    def maximum_record_age_in_seconds(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "maximum_record_age_in_seconds", value)

    @property
    @pulumi.getter(name="maximumRetryAttempts")
    def maximum_retry_attempts(self) -> Optional[pulumi.Input[int]]:
        """
        Discard records after the specified number of retries. The default value is -1, which sets the maximum number of retries to infinite. When MaximumRetryAttempts is infinite, EventBridge retries failed records until the record expires in the event source.
        """
        return pulumi.get(self, "maximum_retry_attempts")

    @maximum_retry_attempts.setter
    def maximum_retry_attempts(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "maximum_retry_attempts", value)

    @property
    @pulumi.getter(name="onPartialBatchItemFailure")
    def on_partial_batch_item_failure(self) -> Optional[pulumi.Input['PipeOnPartialBatchItemFailureStreams']]:
        """
        Define how to handle item process failures. `AUTOMATIC_BISECT` halves each batch and retry each half until all the records are processed or there is one failed message left in the batch.
        """
        return pulumi.get(self, "on_partial_batch_item_failure")

    @on_partial_batch_item_failure.setter
    def on_partial_batch_item_failure(self, value: Optional[pulumi.Input['PipeOnPartialBatchItemFailureStreams']]):
        pulumi.set(self, "on_partial_batch_item_failure", value)

    @property
    @pulumi.getter(name="parallelizationFactor")
    def parallelization_factor(self) -> Optional[pulumi.Input[int]]:
        """
        The number of batches to process concurrently from each shard. The default value is 1.
        """
        return pulumi.get(self, "parallelization_factor")

    @parallelization_factor.setter
    def parallelization_factor(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "parallelization_factor", value)

    @property
    @pulumi.getter(name="startingPositionTimestamp")
    def starting_position_timestamp(self) -> Optional[pulumi.Input[str]]:
        """
        With `StartingPosition` set to `AT_TIMESTAMP` , the time from which to start reading, in Unix time seconds.
        """
        return pulumi.get(self, "starting_position_timestamp")

    @starting_position_timestamp.setter
    def starting_position_timestamp(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "starting_position_timestamp", value)


if not MYPY:
    class PipeSourceManagedStreamingKafkaParametersArgsDict(TypedDict):
        topic_name: pulumi.Input[str]
        """
        The name of the topic that the pipe will read from.
        """
        batch_size: NotRequired[pulumi.Input[int]]
        """
        The maximum number of records to include in each batch.
        """
        consumer_group_id: NotRequired[pulumi.Input[str]]
        """
        The name of the destination queue to consume.
        """
        credentials: NotRequired[pulumi.Input[Union['PipeMskAccessCredentials0PropertiesArgsDict', 'PipeMskAccessCredentials1PropertiesArgsDict']]]
        """
        The credentials needed to access the resource.
        """
        maximum_batching_window_in_seconds: NotRequired[pulumi.Input[int]]
        """
        The maximum length of a time to wait for events.
        """
        starting_position: NotRequired[pulumi.Input['PipeMskStartPosition']]
        """
        The position in a stream from which to start reading.
        """
elif False:
    PipeSourceManagedStreamingKafkaParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeSourceManagedStreamingKafkaParametersArgs:
    def __init__(__self__, *,
                 topic_name: pulumi.Input[str],
                 batch_size: Optional[pulumi.Input[int]] = None,
                 consumer_group_id: Optional[pulumi.Input[str]] = None,
                 credentials: Optional[pulumi.Input[Union['PipeMskAccessCredentials0PropertiesArgs', 'PipeMskAccessCredentials1PropertiesArgs']]] = None,
                 maximum_batching_window_in_seconds: Optional[pulumi.Input[int]] = None,
                 starting_position: Optional[pulumi.Input['PipeMskStartPosition']] = None):
        """
        :param pulumi.Input[str] topic_name: The name of the topic that the pipe will read from.
        :param pulumi.Input[int] batch_size: The maximum number of records to include in each batch.
        :param pulumi.Input[str] consumer_group_id: The name of the destination queue to consume.
        :param pulumi.Input[Union['PipeMskAccessCredentials0PropertiesArgs', 'PipeMskAccessCredentials1PropertiesArgs']] credentials: The credentials needed to access the resource.
        :param pulumi.Input[int] maximum_batching_window_in_seconds: The maximum length of a time to wait for events.
        :param pulumi.Input['PipeMskStartPosition'] starting_position: The position in a stream from which to start reading.
        """
        pulumi.set(__self__, "topic_name", topic_name)
        if batch_size is not None:
            pulumi.set(__self__, "batch_size", batch_size)
        if consumer_group_id is not None:
            pulumi.set(__self__, "consumer_group_id", consumer_group_id)
        if credentials is not None:
            pulumi.set(__self__, "credentials", credentials)
        if maximum_batching_window_in_seconds is not None:
            pulumi.set(__self__, "maximum_batching_window_in_seconds", maximum_batching_window_in_seconds)
        if starting_position is not None:
            pulumi.set(__self__, "starting_position", starting_position)

    @property
    @pulumi.getter(name="topicName")
    def topic_name(self) -> pulumi.Input[str]:
        """
        The name of the topic that the pipe will read from.
        """
        return pulumi.get(self, "topic_name")

    @topic_name.setter
    def topic_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "topic_name", value)

    @property
    @pulumi.getter(name="batchSize")
    def batch_size(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum number of records to include in each batch.
        """
        return pulumi.get(self, "batch_size")

    @batch_size.setter
    def batch_size(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "batch_size", value)

    @property
    @pulumi.getter(name="consumerGroupId")
    def consumer_group_id(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the destination queue to consume.
        """
        return pulumi.get(self, "consumer_group_id")

    @consumer_group_id.setter
    def consumer_group_id(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "consumer_group_id", value)

    @property
    @pulumi.getter
    def credentials(self) -> Optional[pulumi.Input[Union['PipeMskAccessCredentials0PropertiesArgs', 'PipeMskAccessCredentials1PropertiesArgs']]]:
        """
        The credentials needed to access the resource.
        """
        return pulumi.get(self, "credentials")

    @credentials.setter
    def credentials(self, value: Optional[pulumi.Input[Union['PipeMskAccessCredentials0PropertiesArgs', 'PipeMskAccessCredentials1PropertiesArgs']]]):
        pulumi.set(self, "credentials", value)

    @property
    @pulumi.getter(name="maximumBatchingWindowInSeconds")
    def maximum_batching_window_in_seconds(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum length of a time to wait for events.
        """
        return pulumi.get(self, "maximum_batching_window_in_seconds")

    @maximum_batching_window_in_seconds.setter
    def maximum_batching_window_in_seconds(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "maximum_batching_window_in_seconds", value)

    @property
    @pulumi.getter(name="startingPosition")
    def starting_position(self) -> Optional[pulumi.Input['PipeMskStartPosition']]:
        """
        The position in a stream from which to start reading.
        """
        return pulumi.get(self, "starting_position")

    @starting_position.setter
    def starting_position(self, value: Optional[pulumi.Input['PipeMskStartPosition']]):
        pulumi.set(self, "starting_position", value)


if not MYPY:
    class PipeSourceParametersArgsDict(TypedDict):
        active_mq_broker_parameters: NotRequired[pulumi.Input['PipeSourceActiveMqBrokerParametersArgsDict']]
        """
        The parameters for using an Active MQ broker as a source.
        """
        dynamo_db_stream_parameters: NotRequired[pulumi.Input['PipeSourceDynamoDbStreamParametersArgsDict']]
        """
        The parameters for using a DynamoDB stream as a source.
        """
        filter_criteria: NotRequired[pulumi.Input['PipeFilterCriteriaArgsDict']]
        """
        The collection of event patterns used to filter events.

        To remove a filter, specify a `FilterCriteria` object with an empty array of `Filter` objects.

        For more information, see [Events and Event Patterns](https://docs.aws.amazon.com/eventbridge/latest/userguide/eventbridge-and-event-patterns.html) in the *Amazon EventBridge User Guide* .
        """
        kinesis_stream_parameters: NotRequired[pulumi.Input['PipeSourceKinesisStreamParametersArgsDict']]
        """
        The parameters for using a Kinesis stream as a source.
        """
        managed_streaming_kafka_parameters: NotRequired[pulumi.Input['PipeSourceManagedStreamingKafkaParametersArgsDict']]
        """
        The parameters for using an MSK stream as a source.
        """
        rabbit_mq_broker_parameters: NotRequired[pulumi.Input['PipeSourceRabbitMqBrokerParametersArgsDict']]
        """
        The parameters for using a Rabbit MQ broker as a source.
        """
        self_managed_kafka_parameters: NotRequired[pulumi.Input['PipeSourceSelfManagedKafkaParametersArgsDict']]
        """
        The parameters for using a self-managed Apache Kafka stream as a source.

        A *self managed* cluster refers to any Apache Kafka cluster not hosted by AWS . This includes both clusters you manage yourself, as well as those hosted by a third-party provider, such as [Confluent Cloud](https://docs.aws.amazon.com/https://www.confluent.io/) , [CloudKarafka](https://docs.aws.amazon.com/https://www.cloudkarafka.com/) , or [Redpanda](https://docs.aws.amazon.com/https://redpanda.com/) . For more information, see [Apache Kafka streams as a source](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-kafka.html) in the *Amazon EventBridge User Guide* .
        """
        sqs_queue_parameters: NotRequired[pulumi.Input['PipeSourceSqsQueueParametersArgsDict']]
        """
        The parameters for using a Amazon SQS stream as a source.
        """
elif False:
    PipeSourceParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeSourceParametersArgs:
    def __init__(__self__, *,
                 active_mq_broker_parameters: Optional[pulumi.Input['PipeSourceActiveMqBrokerParametersArgs']] = None,
                 dynamo_db_stream_parameters: Optional[pulumi.Input['PipeSourceDynamoDbStreamParametersArgs']] = None,
                 filter_criteria: Optional[pulumi.Input['PipeFilterCriteriaArgs']] = None,
                 kinesis_stream_parameters: Optional[pulumi.Input['PipeSourceKinesisStreamParametersArgs']] = None,
                 managed_streaming_kafka_parameters: Optional[pulumi.Input['PipeSourceManagedStreamingKafkaParametersArgs']] = None,
                 rabbit_mq_broker_parameters: Optional[pulumi.Input['PipeSourceRabbitMqBrokerParametersArgs']] = None,
                 self_managed_kafka_parameters: Optional[pulumi.Input['PipeSourceSelfManagedKafkaParametersArgs']] = None,
                 sqs_queue_parameters: Optional[pulumi.Input['PipeSourceSqsQueueParametersArgs']] = None):
        """
        :param pulumi.Input['PipeSourceActiveMqBrokerParametersArgs'] active_mq_broker_parameters: The parameters for using an Active MQ broker as a source.
        :param pulumi.Input['PipeSourceDynamoDbStreamParametersArgs'] dynamo_db_stream_parameters: The parameters for using a DynamoDB stream as a source.
        :param pulumi.Input['PipeFilterCriteriaArgs'] filter_criteria: The collection of event patterns used to filter events.
               
               To remove a filter, specify a `FilterCriteria` object with an empty array of `Filter` objects.
               
               For more information, see [Events and Event Patterns](https://docs.aws.amazon.com/eventbridge/latest/userguide/eventbridge-and-event-patterns.html) in the *Amazon EventBridge User Guide* .
        :param pulumi.Input['PipeSourceKinesisStreamParametersArgs'] kinesis_stream_parameters: The parameters for using a Kinesis stream as a source.
        :param pulumi.Input['PipeSourceManagedStreamingKafkaParametersArgs'] managed_streaming_kafka_parameters: The parameters for using an MSK stream as a source.
        :param pulumi.Input['PipeSourceRabbitMqBrokerParametersArgs'] rabbit_mq_broker_parameters: The parameters for using a Rabbit MQ broker as a source.
        :param pulumi.Input['PipeSourceSelfManagedKafkaParametersArgs'] self_managed_kafka_parameters: The parameters for using a self-managed Apache Kafka stream as a source.
               
               A *self managed* cluster refers to any Apache Kafka cluster not hosted by AWS . This includes both clusters you manage yourself, as well as those hosted by a third-party provider, such as [Confluent Cloud](https://docs.aws.amazon.com/https://www.confluent.io/) , [CloudKarafka](https://docs.aws.amazon.com/https://www.cloudkarafka.com/) , or [Redpanda](https://docs.aws.amazon.com/https://redpanda.com/) . For more information, see [Apache Kafka streams as a source](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-kafka.html) in the *Amazon EventBridge User Guide* .
        :param pulumi.Input['PipeSourceSqsQueueParametersArgs'] sqs_queue_parameters: The parameters for using a Amazon SQS stream as a source.
        """
        if active_mq_broker_parameters is not None:
            pulumi.set(__self__, "active_mq_broker_parameters", active_mq_broker_parameters)
        if dynamo_db_stream_parameters is not None:
            pulumi.set(__self__, "dynamo_db_stream_parameters", dynamo_db_stream_parameters)
        if filter_criteria is not None:
            pulumi.set(__self__, "filter_criteria", filter_criteria)
        if kinesis_stream_parameters is not None:
            pulumi.set(__self__, "kinesis_stream_parameters", kinesis_stream_parameters)
        if managed_streaming_kafka_parameters is not None:
            pulumi.set(__self__, "managed_streaming_kafka_parameters", managed_streaming_kafka_parameters)
        if rabbit_mq_broker_parameters is not None:
            pulumi.set(__self__, "rabbit_mq_broker_parameters", rabbit_mq_broker_parameters)
        if self_managed_kafka_parameters is not None:
            pulumi.set(__self__, "self_managed_kafka_parameters", self_managed_kafka_parameters)
        if sqs_queue_parameters is not None:
            pulumi.set(__self__, "sqs_queue_parameters", sqs_queue_parameters)

    @property
    @pulumi.getter(name="activeMqBrokerParameters")
    def active_mq_broker_parameters(self) -> Optional[pulumi.Input['PipeSourceActiveMqBrokerParametersArgs']]:
        """
        The parameters for using an Active MQ broker as a source.
        """
        return pulumi.get(self, "active_mq_broker_parameters")

    @active_mq_broker_parameters.setter
    def active_mq_broker_parameters(self, value: Optional[pulumi.Input['PipeSourceActiveMqBrokerParametersArgs']]):
        pulumi.set(self, "active_mq_broker_parameters", value)

    @property
    @pulumi.getter(name="dynamoDbStreamParameters")
    def dynamo_db_stream_parameters(self) -> Optional[pulumi.Input['PipeSourceDynamoDbStreamParametersArgs']]:
        """
        The parameters for using a DynamoDB stream as a source.
        """
        return pulumi.get(self, "dynamo_db_stream_parameters")

    @dynamo_db_stream_parameters.setter
    def dynamo_db_stream_parameters(self, value: Optional[pulumi.Input['PipeSourceDynamoDbStreamParametersArgs']]):
        pulumi.set(self, "dynamo_db_stream_parameters", value)

    @property
    @pulumi.getter(name="filterCriteria")
    def filter_criteria(self) -> Optional[pulumi.Input['PipeFilterCriteriaArgs']]:
        """
        The collection of event patterns used to filter events.

        To remove a filter, specify a `FilterCriteria` object with an empty array of `Filter` objects.

        For more information, see [Events and Event Patterns](https://docs.aws.amazon.com/eventbridge/latest/userguide/eventbridge-and-event-patterns.html) in the *Amazon EventBridge User Guide* .
        """
        return pulumi.get(self, "filter_criteria")

    @filter_criteria.setter
    def filter_criteria(self, value: Optional[pulumi.Input['PipeFilterCriteriaArgs']]):
        pulumi.set(self, "filter_criteria", value)

    @property
    @pulumi.getter(name="kinesisStreamParameters")
    def kinesis_stream_parameters(self) -> Optional[pulumi.Input['PipeSourceKinesisStreamParametersArgs']]:
        """
        The parameters for using a Kinesis stream as a source.
        """
        return pulumi.get(self, "kinesis_stream_parameters")

    @kinesis_stream_parameters.setter
    def kinesis_stream_parameters(self, value: Optional[pulumi.Input['PipeSourceKinesisStreamParametersArgs']]):
        pulumi.set(self, "kinesis_stream_parameters", value)

    @property
    @pulumi.getter(name="managedStreamingKafkaParameters")
    def managed_streaming_kafka_parameters(self) -> Optional[pulumi.Input['PipeSourceManagedStreamingKafkaParametersArgs']]:
        """
        The parameters for using an MSK stream as a source.
        """
        return pulumi.get(self, "managed_streaming_kafka_parameters")

    @managed_streaming_kafka_parameters.setter
    def managed_streaming_kafka_parameters(self, value: Optional[pulumi.Input['PipeSourceManagedStreamingKafkaParametersArgs']]):
        pulumi.set(self, "managed_streaming_kafka_parameters", value)

    @property
    @pulumi.getter(name="rabbitMqBrokerParameters")
    def rabbit_mq_broker_parameters(self) -> Optional[pulumi.Input['PipeSourceRabbitMqBrokerParametersArgs']]:
        """
        The parameters for using a Rabbit MQ broker as a source.
        """
        return pulumi.get(self, "rabbit_mq_broker_parameters")

    @rabbit_mq_broker_parameters.setter
    def rabbit_mq_broker_parameters(self, value: Optional[pulumi.Input['PipeSourceRabbitMqBrokerParametersArgs']]):
        pulumi.set(self, "rabbit_mq_broker_parameters", value)

    @property
    @pulumi.getter(name="selfManagedKafkaParameters")
    def self_managed_kafka_parameters(self) -> Optional[pulumi.Input['PipeSourceSelfManagedKafkaParametersArgs']]:
        """
        The parameters for using a self-managed Apache Kafka stream as a source.

        A *self managed* cluster refers to any Apache Kafka cluster not hosted by AWS . This includes both clusters you manage yourself, as well as those hosted by a third-party provider, such as [Confluent Cloud](https://docs.aws.amazon.com/https://www.confluent.io/) , [CloudKarafka](https://docs.aws.amazon.com/https://www.cloudkarafka.com/) , or [Redpanda](https://docs.aws.amazon.com/https://redpanda.com/) . For more information, see [Apache Kafka streams as a source](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-kafka.html) in the *Amazon EventBridge User Guide* .
        """
        return pulumi.get(self, "self_managed_kafka_parameters")

    @self_managed_kafka_parameters.setter
    def self_managed_kafka_parameters(self, value: Optional[pulumi.Input['PipeSourceSelfManagedKafkaParametersArgs']]):
        pulumi.set(self, "self_managed_kafka_parameters", value)

    @property
    @pulumi.getter(name="sqsQueueParameters")
    def sqs_queue_parameters(self) -> Optional[pulumi.Input['PipeSourceSqsQueueParametersArgs']]:
        """
        The parameters for using a Amazon SQS stream as a source.
        """
        return pulumi.get(self, "sqs_queue_parameters")

    @sqs_queue_parameters.setter
    def sqs_queue_parameters(self, value: Optional[pulumi.Input['PipeSourceSqsQueueParametersArgs']]):
        pulumi.set(self, "sqs_queue_parameters", value)


if not MYPY:
    class PipeSourceRabbitMqBrokerParametersArgsDict(TypedDict):
        credentials: pulumi.Input['PipeMqBrokerAccessCredentialsPropertiesArgsDict']
        """
        The credentials needed to access the resource.
        """
        queue_name: pulumi.Input[str]
        """
        The name of the destination queue to consume.
        """
        batch_size: NotRequired[pulumi.Input[int]]
        """
        The maximum number of records to include in each batch.
        """
        maximum_batching_window_in_seconds: NotRequired[pulumi.Input[int]]
        """
        The maximum length of a time to wait for events.
        """
        virtual_host: NotRequired[pulumi.Input[str]]
        """
        The name of the virtual host associated with the source broker.
        """
elif False:
    PipeSourceRabbitMqBrokerParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeSourceRabbitMqBrokerParametersArgs:
    def __init__(__self__, *,
                 credentials: pulumi.Input['PipeMqBrokerAccessCredentialsPropertiesArgs'],
                 queue_name: pulumi.Input[str],
                 batch_size: Optional[pulumi.Input[int]] = None,
                 maximum_batching_window_in_seconds: Optional[pulumi.Input[int]] = None,
                 virtual_host: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input['PipeMqBrokerAccessCredentialsPropertiesArgs'] credentials: The credentials needed to access the resource.
        :param pulumi.Input[str] queue_name: The name of the destination queue to consume.
        :param pulumi.Input[int] batch_size: The maximum number of records to include in each batch.
        :param pulumi.Input[int] maximum_batching_window_in_seconds: The maximum length of a time to wait for events.
        :param pulumi.Input[str] virtual_host: The name of the virtual host associated with the source broker.
        """
        pulumi.set(__self__, "credentials", credentials)
        pulumi.set(__self__, "queue_name", queue_name)
        if batch_size is not None:
            pulumi.set(__self__, "batch_size", batch_size)
        if maximum_batching_window_in_seconds is not None:
            pulumi.set(__self__, "maximum_batching_window_in_seconds", maximum_batching_window_in_seconds)
        if virtual_host is not None:
            pulumi.set(__self__, "virtual_host", virtual_host)

    @property
    @pulumi.getter
    def credentials(self) -> pulumi.Input['PipeMqBrokerAccessCredentialsPropertiesArgs']:
        """
        The credentials needed to access the resource.
        """
        return pulumi.get(self, "credentials")

    @credentials.setter
    def credentials(self, value: pulumi.Input['PipeMqBrokerAccessCredentialsPropertiesArgs']):
        pulumi.set(self, "credentials", value)

    @property
    @pulumi.getter(name="queueName")
    def queue_name(self) -> pulumi.Input[str]:
        """
        The name of the destination queue to consume.
        """
        return pulumi.get(self, "queue_name")

    @queue_name.setter
    def queue_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "queue_name", value)

    @property
    @pulumi.getter(name="batchSize")
    def batch_size(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum number of records to include in each batch.
        """
        return pulumi.get(self, "batch_size")

    @batch_size.setter
    def batch_size(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "batch_size", value)

    @property
    @pulumi.getter(name="maximumBatchingWindowInSeconds")
    def maximum_batching_window_in_seconds(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum length of a time to wait for events.
        """
        return pulumi.get(self, "maximum_batching_window_in_seconds")

    @maximum_batching_window_in_seconds.setter
    def maximum_batching_window_in_seconds(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "maximum_batching_window_in_seconds", value)

    @property
    @pulumi.getter(name="virtualHost")
    def virtual_host(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the virtual host associated with the source broker.
        """
        return pulumi.get(self, "virtual_host")

    @virtual_host.setter
    def virtual_host(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "virtual_host", value)


if not MYPY:
    class PipeSourceSelfManagedKafkaParametersArgsDict(TypedDict):
        topic_name: pulumi.Input[str]
        """
        The name of the topic that the pipe will read from.
        """
        additional_bootstrap_servers: NotRequired[pulumi.Input[Sequence[pulumi.Input[str]]]]
        """
        An array of server URLs.
        """
        batch_size: NotRequired[pulumi.Input[int]]
        """
        The maximum number of records to include in each batch.
        """
        consumer_group_id: NotRequired[pulumi.Input[str]]
        """
        The name of the destination queue to consume.
        """
        credentials: NotRequired[pulumi.Input[Union['PipeSelfManagedKafkaAccessConfigurationCredentials0PropertiesArgsDict', 'PipeSelfManagedKafkaAccessConfigurationCredentials1PropertiesArgsDict', 'PipeSelfManagedKafkaAccessConfigurationCredentials2PropertiesArgsDict', 'PipeSelfManagedKafkaAccessConfigurationCredentials3PropertiesArgsDict']]]
        """
        The credentials needed to access the resource.
        """
        maximum_batching_window_in_seconds: NotRequired[pulumi.Input[int]]
        """
        The maximum length of a time to wait for events.
        """
        server_root_ca_certificate: NotRequired[pulumi.Input[str]]
        """
        Optional SecretManager ARN which stores the database credentials
        """
        starting_position: NotRequired[pulumi.Input['PipeSelfManagedKafkaStartPosition']]
        """
        The position in a stream from which to start reading.
        """
        vpc: NotRequired[pulumi.Input['PipeSelfManagedKafkaAccessConfigurationVpcArgsDict']]
        """
        This structure specifies the VPC subnets and security groups for the stream, and whether a public IP address is to be used.
        """
elif False:
    PipeSourceSelfManagedKafkaParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeSourceSelfManagedKafkaParametersArgs:
    def __init__(__self__, *,
                 topic_name: pulumi.Input[str],
                 additional_bootstrap_servers: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 batch_size: Optional[pulumi.Input[int]] = None,
                 consumer_group_id: Optional[pulumi.Input[str]] = None,
                 credentials: Optional[pulumi.Input[Union['PipeSelfManagedKafkaAccessConfigurationCredentials0PropertiesArgs', 'PipeSelfManagedKafkaAccessConfigurationCredentials1PropertiesArgs', 'PipeSelfManagedKafkaAccessConfigurationCredentials2PropertiesArgs', 'PipeSelfManagedKafkaAccessConfigurationCredentials3PropertiesArgs']]] = None,
                 maximum_batching_window_in_seconds: Optional[pulumi.Input[int]] = None,
                 server_root_ca_certificate: Optional[pulumi.Input[str]] = None,
                 starting_position: Optional[pulumi.Input['PipeSelfManagedKafkaStartPosition']] = None,
                 vpc: Optional[pulumi.Input['PipeSelfManagedKafkaAccessConfigurationVpcArgs']] = None):
        """
        :param pulumi.Input[str] topic_name: The name of the topic that the pipe will read from.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] additional_bootstrap_servers: An array of server URLs.
        :param pulumi.Input[int] batch_size: The maximum number of records to include in each batch.
        :param pulumi.Input[str] consumer_group_id: The name of the destination queue to consume.
        :param pulumi.Input[Union['PipeSelfManagedKafkaAccessConfigurationCredentials0PropertiesArgs', 'PipeSelfManagedKafkaAccessConfigurationCredentials1PropertiesArgs', 'PipeSelfManagedKafkaAccessConfigurationCredentials2PropertiesArgs', 'PipeSelfManagedKafkaAccessConfigurationCredentials3PropertiesArgs']] credentials: The credentials needed to access the resource.
        :param pulumi.Input[int] maximum_batching_window_in_seconds: The maximum length of a time to wait for events.
        :param pulumi.Input[str] server_root_ca_certificate: Optional SecretManager ARN which stores the database credentials
        :param pulumi.Input['PipeSelfManagedKafkaStartPosition'] starting_position: The position in a stream from which to start reading.
        :param pulumi.Input['PipeSelfManagedKafkaAccessConfigurationVpcArgs'] vpc: This structure specifies the VPC subnets and security groups for the stream, and whether a public IP address is to be used.
        """
        pulumi.set(__self__, "topic_name", topic_name)
        if additional_bootstrap_servers is not None:
            pulumi.set(__self__, "additional_bootstrap_servers", additional_bootstrap_servers)
        if batch_size is not None:
            pulumi.set(__self__, "batch_size", batch_size)
        if consumer_group_id is not None:
            pulumi.set(__self__, "consumer_group_id", consumer_group_id)
        if credentials is not None:
            pulumi.set(__self__, "credentials", credentials)
        if maximum_batching_window_in_seconds is not None:
            pulumi.set(__self__, "maximum_batching_window_in_seconds", maximum_batching_window_in_seconds)
        if server_root_ca_certificate is not None:
            pulumi.set(__self__, "server_root_ca_certificate", server_root_ca_certificate)
        if starting_position is not None:
            pulumi.set(__self__, "starting_position", starting_position)
        if vpc is not None:
            pulumi.set(__self__, "vpc", vpc)

    @property
    @pulumi.getter(name="topicName")
    def topic_name(self) -> pulumi.Input[str]:
        """
        The name of the topic that the pipe will read from.
        """
        return pulumi.get(self, "topic_name")

    @topic_name.setter
    def topic_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "topic_name", value)

    @property
    @pulumi.getter(name="additionalBootstrapServers")
    def additional_bootstrap_servers(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        An array of server URLs.
        """
        return pulumi.get(self, "additional_bootstrap_servers")

    @additional_bootstrap_servers.setter
    def additional_bootstrap_servers(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "additional_bootstrap_servers", value)

    @property
    @pulumi.getter(name="batchSize")
    def batch_size(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum number of records to include in each batch.
        """
        return pulumi.get(self, "batch_size")

    @batch_size.setter
    def batch_size(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "batch_size", value)

    @property
    @pulumi.getter(name="consumerGroupId")
    def consumer_group_id(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the destination queue to consume.
        """
        return pulumi.get(self, "consumer_group_id")

    @consumer_group_id.setter
    def consumer_group_id(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "consumer_group_id", value)

    @property
    @pulumi.getter
    def credentials(self) -> Optional[pulumi.Input[Union['PipeSelfManagedKafkaAccessConfigurationCredentials0PropertiesArgs', 'PipeSelfManagedKafkaAccessConfigurationCredentials1PropertiesArgs', 'PipeSelfManagedKafkaAccessConfigurationCredentials2PropertiesArgs', 'PipeSelfManagedKafkaAccessConfigurationCredentials3PropertiesArgs']]]:
        """
        The credentials needed to access the resource.
        """
        return pulumi.get(self, "credentials")

    @credentials.setter
    def credentials(self, value: Optional[pulumi.Input[Union['PipeSelfManagedKafkaAccessConfigurationCredentials0PropertiesArgs', 'PipeSelfManagedKafkaAccessConfigurationCredentials1PropertiesArgs', 'PipeSelfManagedKafkaAccessConfigurationCredentials2PropertiesArgs', 'PipeSelfManagedKafkaAccessConfigurationCredentials3PropertiesArgs']]]):
        pulumi.set(self, "credentials", value)

    @property
    @pulumi.getter(name="maximumBatchingWindowInSeconds")
    def maximum_batching_window_in_seconds(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum length of a time to wait for events.
        """
        return pulumi.get(self, "maximum_batching_window_in_seconds")

    @maximum_batching_window_in_seconds.setter
    def maximum_batching_window_in_seconds(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "maximum_batching_window_in_seconds", value)

    @property
    @pulumi.getter(name="serverRootCaCertificate")
    def server_root_ca_certificate(self) -> Optional[pulumi.Input[str]]:
        """
        Optional SecretManager ARN which stores the database credentials
        """
        return pulumi.get(self, "server_root_ca_certificate")

    @server_root_ca_certificate.setter
    def server_root_ca_certificate(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "server_root_ca_certificate", value)

    @property
    @pulumi.getter(name="startingPosition")
    def starting_position(self) -> Optional[pulumi.Input['PipeSelfManagedKafkaStartPosition']]:
        """
        The position in a stream from which to start reading.
        """
        return pulumi.get(self, "starting_position")

    @starting_position.setter
    def starting_position(self, value: Optional[pulumi.Input['PipeSelfManagedKafkaStartPosition']]):
        pulumi.set(self, "starting_position", value)

    @property
    @pulumi.getter
    def vpc(self) -> Optional[pulumi.Input['PipeSelfManagedKafkaAccessConfigurationVpcArgs']]:
        """
        This structure specifies the VPC subnets and security groups for the stream, and whether a public IP address is to be used.
        """
        return pulumi.get(self, "vpc")

    @vpc.setter
    def vpc(self, value: Optional[pulumi.Input['PipeSelfManagedKafkaAccessConfigurationVpcArgs']]):
        pulumi.set(self, "vpc", value)


if not MYPY:
    class PipeSourceSqsQueueParametersArgsDict(TypedDict):
        batch_size: NotRequired[pulumi.Input[int]]
        """
        The maximum number of records to include in each batch.
        """
        maximum_batching_window_in_seconds: NotRequired[pulumi.Input[int]]
        """
        The maximum length of a time to wait for events.
        """
elif False:
    PipeSourceSqsQueueParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeSourceSqsQueueParametersArgs:
    def __init__(__self__, *,
                 batch_size: Optional[pulumi.Input[int]] = None,
                 maximum_batching_window_in_seconds: Optional[pulumi.Input[int]] = None):
        """
        :param pulumi.Input[int] batch_size: The maximum number of records to include in each batch.
        :param pulumi.Input[int] maximum_batching_window_in_seconds: The maximum length of a time to wait for events.
        """
        if batch_size is not None:
            pulumi.set(__self__, "batch_size", batch_size)
        if maximum_batching_window_in_seconds is not None:
            pulumi.set(__self__, "maximum_batching_window_in_seconds", maximum_batching_window_in_seconds)

    @property
    @pulumi.getter(name="batchSize")
    def batch_size(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum number of records to include in each batch.
        """
        return pulumi.get(self, "batch_size")

    @batch_size.setter
    def batch_size(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "batch_size", value)

    @property
    @pulumi.getter(name="maximumBatchingWindowInSeconds")
    def maximum_batching_window_in_seconds(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum length of a time to wait for events.
        """
        return pulumi.get(self, "maximum_batching_window_in_seconds")

    @maximum_batching_window_in_seconds.setter
    def maximum_batching_window_in_seconds(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "maximum_batching_window_in_seconds", value)


if not MYPY:
    class PipeTagArgsDict(TypedDict):
        key: pulumi.Input[str]
        """
        The key of the key-value pair.
        """
        value: pulumi.Input[str]
        """
        The value of the key-value pair.
        """
elif False:
    PipeTagArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeTagArgs:
    def __init__(__self__, *,
                 key: pulumi.Input[str],
                 value: pulumi.Input[str]):
        """
        :param pulumi.Input[str] key: The key of the key-value pair.
        :param pulumi.Input[str] value: The value of the key-value pair.
        """
        pulumi.set(__self__, "key", key)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def key(self) -> pulumi.Input[str]:
        """
        The key of the key-value pair.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: pulumi.Input[str]):
        pulumi.set(self, "key", value)

    @property
    @pulumi.getter
    def value(self) -> pulumi.Input[str]:
        """
        The value of the key-value pair.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: pulumi.Input[str]):
        pulumi.set(self, "value", value)


if not MYPY:
    class PipeTargetBatchJobParametersArgsDict(TypedDict):
        job_definition: pulumi.Input[str]
        """
        The job definition used by this job. This value can be one of `name` , `name:revision` , or the Amazon Resource Name (ARN) for the job definition. If name is specified without a revision then the latest active revision is used.
        """
        job_name: pulumi.Input[str]
        """
        The name of the job. It can be up to 128 letters long. The first character must be alphanumeric, can contain uppercase and lowercase letters, numbers, hyphens (-), and underscores (_).
        """
        array_properties: NotRequired[pulumi.Input['PipeBatchArrayPropertiesArgsDict']]
        """
        The array properties for the submitted job, such as the size of the array. The array size can be between 2 and 10,000. If you specify array properties for a job, it becomes an array job. This parameter is used only if the target is an AWS Batch job.
        """
        container_overrides: NotRequired[pulumi.Input['PipeBatchContainerOverridesArgsDict']]
        """
        The overrides that are sent to a container.
        """
        depends_on: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipeBatchJobDependencyArgsDict']]]]
        """
        A list of dependencies for the job. A job can depend upon a maximum of 20 jobs. You can specify a `SEQUENTIAL` type dependency without specifying a job ID for array jobs so that each child array job completes sequentially, starting at index 0. You can also specify an `N_TO_N` type dependency with a job ID for array jobs. In that case, each index child of this job must wait for the corresponding index child of each dependency to complete before it can begin.
        """
        parameters: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[str]]]]
        """
        Additional parameters passed to the job that replace parameter substitution placeholders that are set in the job definition. Parameters are specified as a key and value pair mapping. Parameters included here override any corresponding parameter defaults from the job definition.
        """
        retry_strategy: NotRequired[pulumi.Input['PipeBatchRetryStrategyArgsDict']]
        """
        The retry strategy to use for failed jobs. When a retry strategy is specified here, it overrides the retry strategy defined in the job definition.
        """
elif False:
    PipeTargetBatchJobParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeTargetBatchJobParametersArgs:
    def __init__(__self__, *,
                 job_definition: pulumi.Input[str],
                 job_name: pulumi.Input[str],
                 array_properties: Optional[pulumi.Input['PipeBatchArrayPropertiesArgs']] = None,
                 container_overrides: Optional[pulumi.Input['PipeBatchContainerOverridesArgs']] = None,
                 depends_on: Optional[pulumi.Input[Sequence[pulumi.Input['PipeBatchJobDependencyArgs']]]] = None,
                 parameters: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 retry_strategy: Optional[pulumi.Input['PipeBatchRetryStrategyArgs']] = None):
        """
        :param pulumi.Input[str] job_definition: The job definition used by this job. This value can be one of `name` , `name:revision` , or the Amazon Resource Name (ARN) for the job definition. If name is specified without a revision then the latest active revision is used.
        :param pulumi.Input[str] job_name: The name of the job. It can be up to 128 letters long. The first character must be alphanumeric, can contain uppercase and lowercase letters, numbers, hyphens (-), and underscores (_).
        :param pulumi.Input['PipeBatchArrayPropertiesArgs'] array_properties: The array properties for the submitted job, such as the size of the array. The array size can be between 2 and 10,000. If you specify array properties for a job, it becomes an array job. This parameter is used only if the target is an AWS Batch job.
        :param pulumi.Input['PipeBatchContainerOverridesArgs'] container_overrides: The overrides that are sent to a container.
        :param pulumi.Input[Sequence[pulumi.Input['PipeBatchJobDependencyArgs']]] depends_on: A list of dependencies for the job. A job can depend upon a maximum of 20 jobs. You can specify a `SEQUENTIAL` type dependency without specifying a job ID for array jobs so that each child array job completes sequentially, starting at index 0. You can also specify an `N_TO_N` type dependency with a job ID for array jobs. In that case, each index child of this job must wait for the corresponding index child of each dependency to complete before it can begin.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] parameters: Additional parameters passed to the job that replace parameter substitution placeholders that are set in the job definition. Parameters are specified as a key and value pair mapping. Parameters included here override any corresponding parameter defaults from the job definition.
        :param pulumi.Input['PipeBatchRetryStrategyArgs'] retry_strategy: The retry strategy to use for failed jobs. When a retry strategy is specified here, it overrides the retry strategy defined in the job definition.
        """
        pulumi.set(__self__, "job_definition", job_definition)
        pulumi.set(__self__, "job_name", job_name)
        if array_properties is not None:
            pulumi.set(__self__, "array_properties", array_properties)
        if container_overrides is not None:
            pulumi.set(__self__, "container_overrides", container_overrides)
        if depends_on is not None:
            pulumi.set(__self__, "depends_on", depends_on)
        if parameters is not None:
            pulumi.set(__self__, "parameters", parameters)
        if retry_strategy is not None:
            pulumi.set(__self__, "retry_strategy", retry_strategy)

    @property
    @pulumi.getter(name="jobDefinition")
    def job_definition(self) -> pulumi.Input[str]:
        """
        The job definition used by this job. This value can be one of `name` , `name:revision` , or the Amazon Resource Name (ARN) for the job definition. If name is specified without a revision then the latest active revision is used.
        """
        return pulumi.get(self, "job_definition")

    @job_definition.setter
    def job_definition(self, value: pulumi.Input[str]):
        pulumi.set(self, "job_definition", value)

    @property
    @pulumi.getter(name="jobName")
    def job_name(self) -> pulumi.Input[str]:
        """
        The name of the job. It can be up to 128 letters long. The first character must be alphanumeric, can contain uppercase and lowercase letters, numbers, hyphens (-), and underscores (_).
        """
        return pulumi.get(self, "job_name")

    @job_name.setter
    def job_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "job_name", value)

    @property
    @pulumi.getter(name="arrayProperties")
    def array_properties(self) -> Optional[pulumi.Input['PipeBatchArrayPropertiesArgs']]:
        """
        The array properties for the submitted job, such as the size of the array. The array size can be between 2 and 10,000. If you specify array properties for a job, it becomes an array job. This parameter is used only if the target is an AWS Batch job.
        """
        return pulumi.get(self, "array_properties")

    @array_properties.setter
    def array_properties(self, value: Optional[pulumi.Input['PipeBatchArrayPropertiesArgs']]):
        pulumi.set(self, "array_properties", value)

    @property
    @pulumi.getter(name="containerOverrides")
    def container_overrides(self) -> Optional[pulumi.Input['PipeBatchContainerOverridesArgs']]:
        """
        The overrides that are sent to a container.
        """
        return pulumi.get(self, "container_overrides")

    @container_overrides.setter
    def container_overrides(self, value: Optional[pulumi.Input['PipeBatchContainerOverridesArgs']]):
        pulumi.set(self, "container_overrides", value)

    @property
    @pulumi.getter(name="dependsOn")
    def depends_on(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipeBatchJobDependencyArgs']]]]:
        """
        A list of dependencies for the job. A job can depend upon a maximum of 20 jobs. You can specify a `SEQUENTIAL` type dependency without specifying a job ID for array jobs so that each child array job completes sequentially, starting at index 0. You can also specify an `N_TO_N` type dependency with a job ID for array jobs. In that case, each index child of this job must wait for the corresponding index child of each dependency to complete before it can begin.
        """
        return pulumi.get(self, "depends_on")

    @depends_on.setter
    def depends_on(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipeBatchJobDependencyArgs']]]]):
        pulumi.set(self, "depends_on", value)

    @property
    @pulumi.getter
    def parameters(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        Additional parameters passed to the job that replace parameter substitution placeholders that are set in the job definition. Parameters are specified as a key and value pair mapping. Parameters included here override any corresponding parameter defaults from the job definition.
        """
        return pulumi.get(self, "parameters")

    @parameters.setter
    def parameters(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "parameters", value)

    @property
    @pulumi.getter(name="retryStrategy")
    def retry_strategy(self) -> Optional[pulumi.Input['PipeBatchRetryStrategyArgs']]:
        """
        The retry strategy to use for failed jobs. When a retry strategy is specified here, it overrides the retry strategy defined in the job definition.
        """
        return pulumi.get(self, "retry_strategy")

    @retry_strategy.setter
    def retry_strategy(self, value: Optional[pulumi.Input['PipeBatchRetryStrategyArgs']]):
        pulumi.set(self, "retry_strategy", value)


if not MYPY:
    class PipeTargetCloudWatchLogsParametersArgsDict(TypedDict):
        log_stream_name: NotRequired[pulumi.Input[str]]
        """
        The name of the log stream.
        """
        timestamp: NotRequired[pulumi.Input[str]]
        """
        The time the event occurred, expressed as the number of milliseconds after Jan 1, 1970 00:00:00 UTC.
        """
elif False:
    PipeTargetCloudWatchLogsParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeTargetCloudWatchLogsParametersArgs:
    def __init__(__self__, *,
                 log_stream_name: Optional[pulumi.Input[str]] = None,
                 timestamp: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] log_stream_name: The name of the log stream.
        :param pulumi.Input[str] timestamp: The time the event occurred, expressed as the number of milliseconds after Jan 1, 1970 00:00:00 UTC.
        """
        if log_stream_name is not None:
            pulumi.set(__self__, "log_stream_name", log_stream_name)
        if timestamp is not None:
            pulumi.set(__self__, "timestamp", timestamp)

    @property
    @pulumi.getter(name="logStreamName")
    def log_stream_name(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the log stream.
        """
        return pulumi.get(self, "log_stream_name")

    @log_stream_name.setter
    def log_stream_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "log_stream_name", value)

    @property
    @pulumi.getter
    def timestamp(self) -> Optional[pulumi.Input[str]]:
        """
        The time the event occurred, expressed as the number of milliseconds after Jan 1, 1970 00:00:00 UTC.
        """
        return pulumi.get(self, "timestamp")

    @timestamp.setter
    def timestamp(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "timestamp", value)


if not MYPY:
    class PipeTargetEcsTaskParametersArgsDict(TypedDict):
        task_definition_arn: pulumi.Input[str]
        """
        The ARN of the task definition to use if the event target is an Amazon ECS task.
        """
        capacity_provider_strategy: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipeCapacityProviderStrategyItemArgsDict']]]]
        """
        The capacity provider strategy to use for the task.

        If a `capacityProviderStrategy` is specified, the `launchType` parameter must be omitted. If no `capacityProviderStrategy` or launchType is specified, the `defaultCapacityProviderStrategy` for the cluster is used.
        """
        enable_ecs_managed_tags: NotRequired[pulumi.Input[bool]]
        """
        Specifies whether to enable Amazon ECS managed tags for the task. For more information, see [Tagging Your Amazon ECS Resources](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html) in the Amazon Elastic Container Service Developer Guide.
        """
        enable_execute_command: NotRequired[pulumi.Input[bool]]
        """
        Whether or not to enable the execute command functionality for the containers in this task. If true, this enables execute command functionality on all containers in the task.
        """
        group: NotRequired[pulumi.Input[str]]
        """
        Specifies an Amazon ECS task group for the task. The maximum length is 255 characters.
        """
        launch_type: NotRequired[pulumi.Input['PipeLaunchType']]
        """
        Specifies the launch type on which your task is running. The launch type that you specify here must match one of the launch type (compatibilities) of the target task. The `FARGATE` value is supported only in the Regions where AWS Fargate with Amazon ECS is supported. For more information, see [AWS Fargate on Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/AWS-Fargate.html) in the *Amazon Elastic Container Service Developer Guide* .
        """
        network_configuration: NotRequired[pulumi.Input['PipeNetworkConfigurationArgsDict']]
        """
        Use this structure if the Amazon ECS task uses the `awsvpc` network mode. This structure specifies the VPC subnets and security groups associated with the task, and whether a public IP address is to be used. This structure is required if `LaunchType` is `FARGATE` because the `awsvpc` mode is required for Fargate tasks.

        If you specify `NetworkConfiguration` when the target ECS task does not use the `awsvpc` network mode, the task fails.
        """
        overrides: NotRequired[pulumi.Input['PipeEcsTaskOverrideArgsDict']]
        """
        The overrides that are associated with a task.
        """
        placement_constraints: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipePlacementConstraintArgsDict']]]]
        """
        An array of placement constraint objects to use for the task. You can specify up to 10 constraints per task (including constraints in the task definition and those specified at runtime).
        """
        placement_strategy: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipePlacementStrategyArgsDict']]]]
        """
        The placement strategy objects to use for the task. You can specify a maximum of five strategy rules per task.
        """
        platform_version: NotRequired[pulumi.Input[str]]
        """
        Specifies the platform version for the task. Specify only the numeric portion of the platform version, such as `1.1.0` .

        This structure is used only if `LaunchType` is `FARGATE` . For more information about valid platform versions, see [AWS Fargate Platform Versions](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html) in the *Amazon Elastic Container Service Developer Guide* .
        """
        propagate_tags: NotRequired[pulumi.Input['PipePropagateTags']]
        """
        Specifies whether to propagate the tags from the task definition to the task. If no value is specified, the tags are not propagated. Tags can only be propagated to the task during task creation. To add tags to a task after task creation, use the `TagResource` API action.
        """
        reference_id: NotRequired[pulumi.Input[str]]
        """
        The reference ID to use for the task.
        """
        tags: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipeTagArgsDict']]]]
        """
        The metadata that you apply to the task to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. To learn more, see [RunTask](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_RunTask.html#ECS-RunTask-request-tags) in the Amazon ECS API Reference.
        """
        task_count: NotRequired[pulumi.Input[int]]
        """
        The number of tasks to create based on `TaskDefinition` . The default is 1.
        """
elif False:
    PipeTargetEcsTaskParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeTargetEcsTaskParametersArgs:
    def __init__(__self__, *,
                 task_definition_arn: pulumi.Input[str],
                 capacity_provider_strategy: Optional[pulumi.Input[Sequence[pulumi.Input['PipeCapacityProviderStrategyItemArgs']]]] = None,
                 enable_ecs_managed_tags: Optional[pulumi.Input[bool]] = None,
                 enable_execute_command: Optional[pulumi.Input[bool]] = None,
                 group: Optional[pulumi.Input[str]] = None,
                 launch_type: Optional[pulumi.Input['PipeLaunchType']] = None,
                 network_configuration: Optional[pulumi.Input['PipeNetworkConfigurationArgs']] = None,
                 overrides: Optional[pulumi.Input['PipeEcsTaskOverrideArgs']] = None,
                 placement_constraints: Optional[pulumi.Input[Sequence[pulumi.Input['PipePlacementConstraintArgs']]]] = None,
                 placement_strategy: Optional[pulumi.Input[Sequence[pulumi.Input['PipePlacementStrategyArgs']]]] = None,
                 platform_version: Optional[pulumi.Input[str]] = None,
                 propagate_tags: Optional[pulumi.Input['PipePropagateTags']] = None,
                 reference_id: Optional[pulumi.Input[str]] = None,
                 tags: Optional[pulumi.Input[Sequence[pulumi.Input['PipeTagArgs']]]] = None,
                 task_count: Optional[pulumi.Input[int]] = None):
        """
        :param pulumi.Input[str] task_definition_arn: The ARN of the task definition to use if the event target is an Amazon ECS task.
        :param pulumi.Input[Sequence[pulumi.Input['PipeCapacityProviderStrategyItemArgs']]] capacity_provider_strategy: The capacity provider strategy to use for the task.
               
               If a `capacityProviderStrategy` is specified, the `launchType` parameter must be omitted. If no `capacityProviderStrategy` or launchType is specified, the `defaultCapacityProviderStrategy` for the cluster is used.
        :param pulumi.Input[bool] enable_ecs_managed_tags: Specifies whether to enable Amazon ECS managed tags for the task. For more information, see [Tagging Your Amazon ECS Resources](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html) in the Amazon Elastic Container Service Developer Guide.
        :param pulumi.Input[bool] enable_execute_command: Whether or not to enable the execute command functionality for the containers in this task. If true, this enables execute command functionality on all containers in the task.
        :param pulumi.Input[str] group: Specifies an Amazon ECS task group for the task. The maximum length is 255 characters.
        :param pulumi.Input['PipeLaunchType'] launch_type: Specifies the launch type on which your task is running. The launch type that you specify here must match one of the launch type (compatibilities) of the target task. The `FARGATE` value is supported only in the Regions where AWS Fargate with Amazon ECS is supported. For more information, see [AWS Fargate on Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/AWS-Fargate.html) in the *Amazon Elastic Container Service Developer Guide* .
        :param pulumi.Input['PipeNetworkConfigurationArgs'] network_configuration: Use this structure if the Amazon ECS task uses the `awsvpc` network mode. This structure specifies the VPC subnets and security groups associated with the task, and whether a public IP address is to be used. This structure is required if `LaunchType` is `FARGATE` because the `awsvpc` mode is required for Fargate tasks.
               
               If you specify `NetworkConfiguration` when the target ECS task does not use the `awsvpc` network mode, the task fails.
        :param pulumi.Input['PipeEcsTaskOverrideArgs'] overrides: The overrides that are associated with a task.
        :param pulumi.Input[Sequence[pulumi.Input['PipePlacementConstraintArgs']]] placement_constraints: An array of placement constraint objects to use for the task. You can specify up to 10 constraints per task (including constraints in the task definition and those specified at runtime).
        :param pulumi.Input[Sequence[pulumi.Input['PipePlacementStrategyArgs']]] placement_strategy: The placement strategy objects to use for the task. You can specify a maximum of five strategy rules per task.
        :param pulumi.Input[str] platform_version: Specifies the platform version for the task. Specify only the numeric portion of the platform version, such as `1.1.0` .
               
               This structure is used only if `LaunchType` is `FARGATE` . For more information about valid platform versions, see [AWS Fargate Platform Versions](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html) in the *Amazon Elastic Container Service Developer Guide* .
        :param pulumi.Input['PipePropagateTags'] propagate_tags: Specifies whether to propagate the tags from the task definition to the task. If no value is specified, the tags are not propagated. Tags can only be propagated to the task during task creation. To add tags to a task after task creation, use the `TagResource` API action.
        :param pulumi.Input[str] reference_id: The reference ID to use for the task.
        :param pulumi.Input[Sequence[pulumi.Input['PipeTagArgs']]] tags: The metadata that you apply to the task to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. To learn more, see [RunTask](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_RunTask.html#ECS-RunTask-request-tags) in the Amazon ECS API Reference.
        :param pulumi.Input[int] task_count: The number of tasks to create based on `TaskDefinition` . The default is 1.
        """
        pulumi.set(__self__, "task_definition_arn", task_definition_arn)
        if capacity_provider_strategy is not None:
            pulumi.set(__self__, "capacity_provider_strategy", capacity_provider_strategy)
        if enable_ecs_managed_tags is not None:
            pulumi.set(__self__, "enable_ecs_managed_tags", enable_ecs_managed_tags)
        if enable_execute_command is not None:
            pulumi.set(__self__, "enable_execute_command", enable_execute_command)
        if group is not None:
            pulumi.set(__self__, "group", group)
        if launch_type is not None:
            pulumi.set(__self__, "launch_type", launch_type)
        if network_configuration is not None:
            pulumi.set(__self__, "network_configuration", network_configuration)
        if overrides is not None:
            pulumi.set(__self__, "overrides", overrides)
        if placement_constraints is not None:
            pulumi.set(__self__, "placement_constraints", placement_constraints)
        if placement_strategy is not None:
            pulumi.set(__self__, "placement_strategy", placement_strategy)
        if platform_version is not None:
            pulumi.set(__self__, "platform_version", platform_version)
        if propagate_tags is not None:
            pulumi.set(__self__, "propagate_tags", propagate_tags)
        if reference_id is not None:
            pulumi.set(__self__, "reference_id", reference_id)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)
        if task_count is not None:
            pulumi.set(__self__, "task_count", task_count)

    @property
    @pulumi.getter(name="taskDefinitionArn")
    def task_definition_arn(self) -> pulumi.Input[str]:
        """
        The ARN of the task definition to use if the event target is an Amazon ECS task.
        """
        return pulumi.get(self, "task_definition_arn")

    @task_definition_arn.setter
    def task_definition_arn(self, value: pulumi.Input[str]):
        pulumi.set(self, "task_definition_arn", value)

    @property
    @pulumi.getter(name="capacityProviderStrategy")
    def capacity_provider_strategy(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipeCapacityProviderStrategyItemArgs']]]]:
        """
        The capacity provider strategy to use for the task.

        If a `capacityProviderStrategy` is specified, the `launchType` parameter must be omitted. If no `capacityProviderStrategy` or launchType is specified, the `defaultCapacityProviderStrategy` for the cluster is used.
        """
        return pulumi.get(self, "capacity_provider_strategy")

    @capacity_provider_strategy.setter
    def capacity_provider_strategy(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipeCapacityProviderStrategyItemArgs']]]]):
        pulumi.set(self, "capacity_provider_strategy", value)

    @property
    @pulumi.getter(name="enableEcsManagedTags")
    def enable_ecs_managed_tags(self) -> Optional[pulumi.Input[bool]]:
        """
        Specifies whether to enable Amazon ECS managed tags for the task. For more information, see [Tagging Your Amazon ECS Resources](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using-tags.html) in the Amazon Elastic Container Service Developer Guide.
        """
        return pulumi.get(self, "enable_ecs_managed_tags")

    @enable_ecs_managed_tags.setter
    def enable_ecs_managed_tags(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_ecs_managed_tags", value)

    @property
    @pulumi.getter(name="enableExecuteCommand")
    def enable_execute_command(self) -> Optional[pulumi.Input[bool]]:
        """
        Whether or not to enable the execute command functionality for the containers in this task. If true, this enables execute command functionality on all containers in the task.
        """
        return pulumi.get(self, "enable_execute_command")

    @enable_execute_command.setter
    def enable_execute_command(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_execute_command", value)

    @property
    @pulumi.getter
    def group(self) -> Optional[pulumi.Input[str]]:
        """
        Specifies an Amazon ECS task group for the task. The maximum length is 255 characters.
        """
        return pulumi.get(self, "group")

    @group.setter
    def group(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "group", value)

    @property
    @pulumi.getter(name="launchType")
    def launch_type(self) -> Optional[pulumi.Input['PipeLaunchType']]:
        """
        Specifies the launch type on which your task is running. The launch type that you specify here must match one of the launch type (compatibilities) of the target task. The `FARGATE` value is supported only in the Regions where AWS Fargate with Amazon ECS is supported. For more information, see [AWS Fargate on Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/AWS-Fargate.html) in the *Amazon Elastic Container Service Developer Guide* .
        """
        return pulumi.get(self, "launch_type")

    @launch_type.setter
    def launch_type(self, value: Optional[pulumi.Input['PipeLaunchType']]):
        pulumi.set(self, "launch_type", value)

    @property
    @pulumi.getter(name="networkConfiguration")
    def network_configuration(self) -> Optional[pulumi.Input['PipeNetworkConfigurationArgs']]:
        """
        Use this structure if the Amazon ECS task uses the `awsvpc` network mode. This structure specifies the VPC subnets and security groups associated with the task, and whether a public IP address is to be used. This structure is required if `LaunchType` is `FARGATE` because the `awsvpc` mode is required for Fargate tasks.

        If you specify `NetworkConfiguration` when the target ECS task does not use the `awsvpc` network mode, the task fails.
        """
        return pulumi.get(self, "network_configuration")

    @network_configuration.setter
    def network_configuration(self, value: Optional[pulumi.Input['PipeNetworkConfigurationArgs']]):
        pulumi.set(self, "network_configuration", value)

    @property
    @pulumi.getter
    def overrides(self) -> Optional[pulumi.Input['PipeEcsTaskOverrideArgs']]:
        """
        The overrides that are associated with a task.
        """
        return pulumi.get(self, "overrides")

    @overrides.setter
    def overrides(self, value: Optional[pulumi.Input['PipeEcsTaskOverrideArgs']]):
        pulumi.set(self, "overrides", value)

    @property
    @pulumi.getter(name="placementConstraints")
    def placement_constraints(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipePlacementConstraintArgs']]]]:
        """
        An array of placement constraint objects to use for the task. You can specify up to 10 constraints per task (including constraints in the task definition and those specified at runtime).
        """
        return pulumi.get(self, "placement_constraints")

    @placement_constraints.setter
    def placement_constraints(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipePlacementConstraintArgs']]]]):
        pulumi.set(self, "placement_constraints", value)

    @property
    @pulumi.getter(name="placementStrategy")
    def placement_strategy(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipePlacementStrategyArgs']]]]:
        """
        The placement strategy objects to use for the task. You can specify a maximum of five strategy rules per task.
        """
        return pulumi.get(self, "placement_strategy")

    @placement_strategy.setter
    def placement_strategy(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipePlacementStrategyArgs']]]]):
        pulumi.set(self, "placement_strategy", value)

    @property
    @pulumi.getter(name="platformVersion")
    def platform_version(self) -> Optional[pulumi.Input[str]]:
        """
        Specifies the platform version for the task. Specify only the numeric portion of the platform version, such as `1.1.0` .

        This structure is used only if `LaunchType` is `FARGATE` . For more information about valid platform versions, see [AWS Fargate Platform Versions](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html) in the *Amazon Elastic Container Service Developer Guide* .
        """
        return pulumi.get(self, "platform_version")

    @platform_version.setter
    def platform_version(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "platform_version", value)

    @property
    @pulumi.getter(name="propagateTags")
    def propagate_tags(self) -> Optional[pulumi.Input['PipePropagateTags']]:
        """
        Specifies whether to propagate the tags from the task definition to the task. If no value is specified, the tags are not propagated. Tags can only be propagated to the task during task creation. To add tags to a task after task creation, use the `TagResource` API action.
        """
        return pulumi.get(self, "propagate_tags")

    @propagate_tags.setter
    def propagate_tags(self, value: Optional[pulumi.Input['PipePropagateTags']]):
        pulumi.set(self, "propagate_tags", value)

    @property
    @pulumi.getter(name="referenceId")
    def reference_id(self) -> Optional[pulumi.Input[str]]:
        """
        The reference ID to use for the task.
        """
        return pulumi.get(self, "reference_id")

    @reference_id.setter
    def reference_id(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "reference_id", value)

    @property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipeTagArgs']]]]:
        """
        The metadata that you apply to the task to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. To learn more, see [RunTask](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_RunTask.html#ECS-RunTask-request-tags) in the Amazon ECS API Reference.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipeTagArgs']]]]):
        pulumi.set(self, "tags", value)

    @property
    @pulumi.getter(name="taskCount")
    def task_count(self) -> Optional[pulumi.Input[int]]:
        """
        The number of tasks to create based on `TaskDefinition` . The default is 1.
        """
        return pulumi.get(self, "task_count")

    @task_count.setter
    def task_count(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "task_count", value)


if not MYPY:
    class PipeTargetEventBridgeEventBusParametersArgsDict(TypedDict):
        detail_type: NotRequired[pulumi.Input[str]]
        """
        A free-form string, with a maximum of 128 characters, used to decide what fields to expect in the event detail.
        """
        endpoint_id: NotRequired[pulumi.Input[str]]
        """
        The URL subdomain of the endpoint. For example, if the URL for Endpoint is https://abcde.veo.endpoints.event.amazonaws.com, then the EndpointId is `abcde.veo` .
        """
        resources: NotRequired[pulumi.Input[Sequence[pulumi.Input[str]]]]
        """
        AWS resources, identified by Amazon Resource Name (ARN), which the event primarily concerns. Any number, including zero, may be present.
        """
        source: NotRequired[pulumi.Input[str]]
        """
        The source of the event.
        """
        time: NotRequired[pulumi.Input[str]]
        """
        The time stamp of the event, per [RFC3339](https://docs.aws.amazon.com/https://www.rfc-editor.org/rfc/rfc3339.txt) . If no time stamp is provided, the time stamp of the [PutEvents](https://docs.aws.amazon.com/eventbridge/latest/APIReference/API_PutEvents.html) call is used.
        """
elif False:
    PipeTargetEventBridgeEventBusParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeTargetEventBridgeEventBusParametersArgs:
    def __init__(__self__, *,
                 detail_type: Optional[pulumi.Input[str]] = None,
                 endpoint_id: Optional[pulumi.Input[str]] = None,
                 resources: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 source: Optional[pulumi.Input[str]] = None,
                 time: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] detail_type: A free-form string, with a maximum of 128 characters, used to decide what fields to expect in the event detail.
        :param pulumi.Input[str] endpoint_id: The URL subdomain of the endpoint. For example, if the URL for Endpoint is https://abcde.veo.endpoints.event.amazonaws.com, then the EndpointId is `abcde.veo` .
        :param pulumi.Input[Sequence[pulumi.Input[str]]] resources: AWS resources, identified by Amazon Resource Name (ARN), which the event primarily concerns. Any number, including zero, may be present.
        :param pulumi.Input[str] source: The source of the event.
        :param pulumi.Input[str] time: The time stamp of the event, per [RFC3339](https://docs.aws.amazon.com/https://www.rfc-editor.org/rfc/rfc3339.txt) . If no time stamp is provided, the time stamp of the [PutEvents](https://docs.aws.amazon.com/eventbridge/latest/APIReference/API_PutEvents.html) call is used.
        """
        if detail_type is not None:
            pulumi.set(__self__, "detail_type", detail_type)
        if endpoint_id is not None:
            pulumi.set(__self__, "endpoint_id", endpoint_id)
        if resources is not None:
            pulumi.set(__self__, "resources", resources)
        if source is not None:
            pulumi.set(__self__, "source", source)
        if time is not None:
            pulumi.set(__self__, "time", time)

    @property
    @pulumi.getter(name="detailType")
    def detail_type(self) -> Optional[pulumi.Input[str]]:
        """
        A free-form string, with a maximum of 128 characters, used to decide what fields to expect in the event detail.
        """
        return pulumi.get(self, "detail_type")

    @detail_type.setter
    def detail_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "detail_type", value)

    @property
    @pulumi.getter(name="endpointId")
    def endpoint_id(self) -> Optional[pulumi.Input[str]]:
        """
        The URL subdomain of the endpoint. For example, if the URL for Endpoint is https://abcde.veo.endpoints.event.amazonaws.com, then the EndpointId is `abcde.veo` .
        """
        return pulumi.get(self, "endpoint_id")

    @endpoint_id.setter
    def endpoint_id(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "endpoint_id", value)

    @property
    @pulumi.getter
    def resources(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        AWS resources, identified by Amazon Resource Name (ARN), which the event primarily concerns. Any number, including zero, may be present.
        """
        return pulumi.get(self, "resources")

    @resources.setter
    def resources(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "resources", value)

    @property
    @pulumi.getter
    def source(self) -> Optional[pulumi.Input[str]]:
        """
        The source of the event.
        """
        return pulumi.get(self, "source")

    @source.setter
    def source(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "source", value)

    @property
    @pulumi.getter
    def time(self) -> Optional[pulumi.Input[str]]:
        """
        The time stamp of the event, per [RFC3339](https://docs.aws.amazon.com/https://www.rfc-editor.org/rfc/rfc3339.txt) . If no time stamp is provided, the time stamp of the [PutEvents](https://docs.aws.amazon.com/eventbridge/latest/APIReference/API_PutEvents.html) call is used.
        """
        return pulumi.get(self, "time")

    @time.setter
    def time(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "time", value)


if not MYPY:
    class PipeTargetHttpParametersArgsDict(TypedDict):
        header_parameters: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[str]]]]
        """
        The headers that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.
        """
        path_parameter_values: NotRequired[pulumi.Input[Sequence[pulumi.Input[str]]]]
        """
        The path parameter values to be used to populate API Gateway REST API or EventBridge ApiDestination path wildcards ("*").
        """
        query_string_parameters: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[str]]]]
        """
        The query string keys/values that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.
        """
elif False:
    PipeTargetHttpParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeTargetHttpParametersArgs:
    def __init__(__self__, *,
                 header_parameters: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 path_parameter_values: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 query_string_parameters: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None):
        """
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] header_parameters: The headers that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] path_parameter_values: The path parameter values to be used to populate API Gateway REST API or EventBridge ApiDestination path wildcards ("*").
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] query_string_parameters: The query string keys/values that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.
        """
        if header_parameters is not None:
            pulumi.set(__self__, "header_parameters", header_parameters)
        if path_parameter_values is not None:
            pulumi.set(__self__, "path_parameter_values", path_parameter_values)
        if query_string_parameters is not None:
            pulumi.set(__self__, "query_string_parameters", query_string_parameters)

    @property
    @pulumi.getter(name="headerParameters")
    def header_parameters(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        The headers that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.
        """
        return pulumi.get(self, "header_parameters")

    @header_parameters.setter
    def header_parameters(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "header_parameters", value)

    @property
    @pulumi.getter(name="pathParameterValues")
    def path_parameter_values(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        The path parameter values to be used to populate API Gateway REST API or EventBridge ApiDestination path wildcards ("*").
        """
        return pulumi.get(self, "path_parameter_values")

    @path_parameter_values.setter
    def path_parameter_values(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "path_parameter_values", value)

    @property
    @pulumi.getter(name="queryStringParameters")
    def query_string_parameters(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        The query string keys/values that need to be sent as part of request invoking the API Gateway REST API or EventBridge ApiDestination.
        """
        return pulumi.get(self, "query_string_parameters")

    @query_string_parameters.setter
    def query_string_parameters(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "query_string_parameters", value)


if not MYPY:
    class PipeTargetKinesisStreamParametersArgsDict(TypedDict):
        partition_key: pulumi.Input[str]
        """
        Determines which shard in the stream the data record is assigned to. Partition keys are Unicode strings with a maximum length limit of 256 characters for each key. Amazon Kinesis Data Streams uses the partition key as input to a hash function that maps the partition key and associated data to a specific shard. Specifically, an MD5 hash function is used to map partition keys to 128-bit integer values and to map associated data records to shards. As a result of this hashing mechanism, all data records with the same partition key map to the same shard within the stream.
        """
elif False:
    PipeTargetKinesisStreamParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeTargetKinesisStreamParametersArgs:
    def __init__(__self__, *,
                 partition_key: pulumi.Input[str]):
        """
        :param pulumi.Input[str] partition_key: Determines which shard in the stream the data record is assigned to. Partition keys are Unicode strings with a maximum length limit of 256 characters for each key. Amazon Kinesis Data Streams uses the partition key as input to a hash function that maps the partition key and associated data to a specific shard. Specifically, an MD5 hash function is used to map partition keys to 128-bit integer values and to map associated data records to shards. As a result of this hashing mechanism, all data records with the same partition key map to the same shard within the stream.
        """
        pulumi.set(__self__, "partition_key", partition_key)

    @property
    @pulumi.getter(name="partitionKey")
    def partition_key(self) -> pulumi.Input[str]:
        """
        Determines which shard in the stream the data record is assigned to. Partition keys are Unicode strings with a maximum length limit of 256 characters for each key. Amazon Kinesis Data Streams uses the partition key as input to a hash function that maps the partition key and associated data to a specific shard. Specifically, an MD5 hash function is used to map partition keys to 128-bit integer values and to map associated data records to shards. As a result of this hashing mechanism, all data records with the same partition key map to the same shard within the stream.
        """
        return pulumi.get(self, "partition_key")

    @partition_key.setter
    def partition_key(self, value: pulumi.Input[str]):
        pulumi.set(self, "partition_key", value)


if not MYPY:
    class PipeTargetLambdaFunctionParametersArgsDict(TypedDict):
        invocation_type: NotRequired[pulumi.Input['PipeTargetInvocationType']]
        """
        Specify whether to invoke the function synchronously or asynchronously.

        - `REQUEST_RESPONSE` (default) - Invoke synchronously. This corresponds to the `RequestResponse` option in the `InvocationType` parameter for the Lambda [Invoke](https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html#API_Invoke_RequestSyntax) API.
        - `FIRE_AND_FORGET` - Invoke asynchronously. This corresponds to the `Event` option in the `InvocationType` parameter for the Lambda [Invoke](https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html#API_Invoke_RequestSyntax) API.

        For more information, see [Invocation types](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes.html#pipes-invocation) in the *Amazon EventBridge User Guide* .
        """
elif False:
    PipeTargetLambdaFunctionParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeTargetLambdaFunctionParametersArgs:
    def __init__(__self__, *,
                 invocation_type: Optional[pulumi.Input['PipeTargetInvocationType']] = None):
        """
        :param pulumi.Input['PipeTargetInvocationType'] invocation_type: Specify whether to invoke the function synchronously or asynchronously.
               
               - `REQUEST_RESPONSE` (default) - Invoke synchronously. This corresponds to the `RequestResponse` option in the `InvocationType` parameter for the Lambda [Invoke](https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html#API_Invoke_RequestSyntax) API.
               - `FIRE_AND_FORGET` - Invoke asynchronously. This corresponds to the `Event` option in the `InvocationType` parameter for the Lambda [Invoke](https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html#API_Invoke_RequestSyntax) API.
               
               For more information, see [Invocation types](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes.html#pipes-invocation) in the *Amazon EventBridge User Guide* .
        """
        if invocation_type is not None:
            pulumi.set(__self__, "invocation_type", invocation_type)

    @property
    @pulumi.getter(name="invocationType")
    def invocation_type(self) -> Optional[pulumi.Input['PipeTargetInvocationType']]:
        """
        Specify whether to invoke the function synchronously or asynchronously.

        - `REQUEST_RESPONSE` (default) - Invoke synchronously. This corresponds to the `RequestResponse` option in the `InvocationType` parameter for the Lambda [Invoke](https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html#API_Invoke_RequestSyntax) API.
        - `FIRE_AND_FORGET` - Invoke asynchronously. This corresponds to the `Event` option in the `InvocationType` parameter for the Lambda [Invoke](https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html#API_Invoke_RequestSyntax) API.

        For more information, see [Invocation types](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes.html#pipes-invocation) in the *Amazon EventBridge User Guide* .
        """
        return pulumi.get(self, "invocation_type")

    @invocation_type.setter
    def invocation_type(self, value: Optional[pulumi.Input['PipeTargetInvocationType']]):
        pulumi.set(self, "invocation_type", value)


if not MYPY:
    class PipeTargetParametersArgsDict(TypedDict):
        batch_job_parameters: NotRequired[pulumi.Input['PipeTargetBatchJobParametersArgsDict']]
        """
        The parameters for using an AWS Batch job as a target.
        """
        cloud_watch_logs_parameters: NotRequired[pulumi.Input['PipeTargetCloudWatchLogsParametersArgsDict']]
        """
        The parameters for using an CloudWatch Logs log stream as a target.
        """
        ecs_task_parameters: NotRequired[pulumi.Input['PipeTargetEcsTaskParametersArgsDict']]
        """
        The parameters for using an Amazon ECS task as a target.
        """
        event_bridge_event_bus_parameters: NotRequired[pulumi.Input['PipeTargetEventBridgeEventBusParametersArgsDict']]
        """
        The parameters for using an EventBridge event bus as a target.
        """
        http_parameters: NotRequired[pulumi.Input['PipeTargetHttpParametersArgsDict']]
        """
        These are custom parameter to be used when the target is an API Gateway REST APIs or EventBridge ApiDestinations.
        """
        input_template: NotRequired[pulumi.Input[str]]
        """
        Valid JSON text passed to the target. In this case, nothing from the event itself is passed to the target. For more information, see [The JavaScript Object Notation (JSON) Data Interchange Format](https://docs.aws.amazon.com/http://www.rfc-editor.org/rfc/rfc7159.txt) .

        To remove an input template, specify an empty string.
        """
        kinesis_stream_parameters: NotRequired[pulumi.Input['PipeTargetKinesisStreamParametersArgsDict']]
        """
        The parameters for using a Kinesis stream as a target.
        """
        lambda_function_parameters: NotRequired[pulumi.Input['PipeTargetLambdaFunctionParametersArgsDict']]
        """
        The parameters for using a Lambda function as a target.
        """
        redshift_data_parameters: NotRequired[pulumi.Input['PipeTargetRedshiftDataParametersArgsDict']]
        """
        These are custom parameters to be used when the target is a Amazon Redshift cluster to invoke the Amazon Redshift Data API BatchExecuteStatement.
        """
        sage_maker_pipeline_parameters: NotRequired[pulumi.Input['PipeTargetSageMakerPipelineParametersArgsDict']]
        """
        The parameters for using a SageMaker AI pipeline as a target.
        """
        sqs_queue_parameters: NotRequired[pulumi.Input['PipeTargetSqsQueueParametersArgsDict']]
        """
        The parameters for using a Amazon SQS stream as a target.
        """
        step_function_state_machine_parameters: NotRequired[pulumi.Input['PipeTargetStateMachineParametersArgsDict']]
        """
        The parameters for using a Step Functions state machine as a target.
        """
        timestream_parameters: NotRequired[pulumi.Input['PipeTargetTimestreamParametersArgsDict']]
        """
        The parameters for using a Timestream for LiveAnalytics table as a target.
        """
elif False:
    PipeTargetParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeTargetParametersArgs:
    def __init__(__self__, *,
                 batch_job_parameters: Optional[pulumi.Input['PipeTargetBatchJobParametersArgs']] = None,
                 cloud_watch_logs_parameters: Optional[pulumi.Input['PipeTargetCloudWatchLogsParametersArgs']] = None,
                 ecs_task_parameters: Optional[pulumi.Input['PipeTargetEcsTaskParametersArgs']] = None,
                 event_bridge_event_bus_parameters: Optional[pulumi.Input['PipeTargetEventBridgeEventBusParametersArgs']] = None,
                 http_parameters: Optional[pulumi.Input['PipeTargetHttpParametersArgs']] = None,
                 input_template: Optional[pulumi.Input[str]] = None,
                 kinesis_stream_parameters: Optional[pulumi.Input['PipeTargetKinesisStreamParametersArgs']] = None,
                 lambda_function_parameters: Optional[pulumi.Input['PipeTargetLambdaFunctionParametersArgs']] = None,
                 redshift_data_parameters: Optional[pulumi.Input['PipeTargetRedshiftDataParametersArgs']] = None,
                 sage_maker_pipeline_parameters: Optional[pulumi.Input['PipeTargetSageMakerPipelineParametersArgs']] = None,
                 sqs_queue_parameters: Optional[pulumi.Input['PipeTargetSqsQueueParametersArgs']] = None,
                 step_function_state_machine_parameters: Optional[pulumi.Input['PipeTargetStateMachineParametersArgs']] = None,
                 timestream_parameters: Optional[pulumi.Input['PipeTargetTimestreamParametersArgs']] = None):
        """
        :param pulumi.Input['PipeTargetBatchJobParametersArgs'] batch_job_parameters: The parameters for using an AWS Batch job as a target.
        :param pulumi.Input['PipeTargetCloudWatchLogsParametersArgs'] cloud_watch_logs_parameters: The parameters for using an CloudWatch Logs log stream as a target.
        :param pulumi.Input['PipeTargetEcsTaskParametersArgs'] ecs_task_parameters: The parameters for using an Amazon ECS task as a target.
        :param pulumi.Input['PipeTargetEventBridgeEventBusParametersArgs'] event_bridge_event_bus_parameters: The parameters for using an EventBridge event bus as a target.
        :param pulumi.Input['PipeTargetHttpParametersArgs'] http_parameters: These are custom parameter to be used when the target is an API Gateway REST APIs or EventBridge ApiDestinations.
        :param pulumi.Input[str] input_template: Valid JSON text passed to the target. In this case, nothing from the event itself is passed to the target. For more information, see [The JavaScript Object Notation (JSON) Data Interchange Format](https://docs.aws.amazon.com/http://www.rfc-editor.org/rfc/rfc7159.txt) .
               
               To remove an input template, specify an empty string.
        :param pulumi.Input['PipeTargetKinesisStreamParametersArgs'] kinesis_stream_parameters: The parameters for using a Kinesis stream as a target.
        :param pulumi.Input['PipeTargetLambdaFunctionParametersArgs'] lambda_function_parameters: The parameters for using a Lambda function as a target.
        :param pulumi.Input['PipeTargetRedshiftDataParametersArgs'] redshift_data_parameters: These are custom parameters to be used when the target is a Amazon Redshift cluster to invoke the Amazon Redshift Data API BatchExecuteStatement.
        :param pulumi.Input['PipeTargetSageMakerPipelineParametersArgs'] sage_maker_pipeline_parameters: The parameters for using a SageMaker AI pipeline as a target.
        :param pulumi.Input['PipeTargetSqsQueueParametersArgs'] sqs_queue_parameters: The parameters for using a Amazon SQS stream as a target.
        :param pulumi.Input['PipeTargetStateMachineParametersArgs'] step_function_state_machine_parameters: The parameters for using a Step Functions state machine as a target.
        :param pulumi.Input['PipeTargetTimestreamParametersArgs'] timestream_parameters: The parameters for using a Timestream for LiveAnalytics table as a target.
        """
        if batch_job_parameters is not None:
            pulumi.set(__self__, "batch_job_parameters", batch_job_parameters)
        if cloud_watch_logs_parameters is not None:
            pulumi.set(__self__, "cloud_watch_logs_parameters", cloud_watch_logs_parameters)
        if ecs_task_parameters is not None:
            pulumi.set(__self__, "ecs_task_parameters", ecs_task_parameters)
        if event_bridge_event_bus_parameters is not None:
            pulumi.set(__self__, "event_bridge_event_bus_parameters", event_bridge_event_bus_parameters)
        if http_parameters is not None:
            pulumi.set(__self__, "http_parameters", http_parameters)
        if input_template is not None:
            pulumi.set(__self__, "input_template", input_template)
        if kinesis_stream_parameters is not None:
            pulumi.set(__self__, "kinesis_stream_parameters", kinesis_stream_parameters)
        if lambda_function_parameters is not None:
            pulumi.set(__self__, "lambda_function_parameters", lambda_function_parameters)
        if redshift_data_parameters is not None:
            pulumi.set(__self__, "redshift_data_parameters", redshift_data_parameters)
        if sage_maker_pipeline_parameters is not None:
            pulumi.set(__self__, "sage_maker_pipeline_parameters", sage_maker_pipeline_parameters)
        if sqs_queue_parameters is not None:
            pulumi.set(__self__, "sqs_queue_parameters", sqs_queue_parameters)
        if step_function_state_machine_parameters is not None:
            pulumi.set(__self__, "step_function_state_machine_parameters", step_function_state_machine_parameters)
        if timestream_parameters is not None:
            pulumi.set(__self__, "timestream_parameters", timestream_parameters)

    @property
    @pulumi.getter(name="batchJobParameters")
    def batch_job_parameters(self) -> Optional[pulumi.Input['PipeTargetBatchJobParametersArgs']]:
        """
        The parameters for using an AWS Batch job as a target.
        """
        return pulumi.get(self, "batch_job_parameters")

    @batch_job_parameters.setter
    def batch_job_parameters(self, value: Optional[pulumi.Input['PipeTargetBatchJobParametersArgs']]):
        pulumi.set(self, "batch_job_parameters", value)

    @property
    @pulumi.getter(name="cloudWatchLogsParameters")
    def cloud_watch_logs_parameters(self) -> Optional[pulumi.Input['PipeTargetCloudWatchLogsParametersArgs']]:
        """
        The parameters for using an CloudWatch Logs log stream as a target.
        """
        return pulumi.get(self, "cloud_watch_logs_parameters")

    @cloud_watch_logs_parameters.setter
    def cloud_watch_logs_parameters(self, value: Optional[pulumi.Input['PipeTargetCloudWatchLogsParametersArgs']]):
        pulumi.set(self, "cloud_watch_logs_parameters", value)

    @property
    @pulumi.getter(name="ecsTaskParameters")
    def ecs_task_parameters(self) -> Optional[pulumi.Input['PipeTargetEcsTaskParametersArgs']]:
        """
        The parameters for using an Amazon ECS task as a target.
        """
        return pulumi.get(self, "ecs_task_parameters")

    @ecs_task_parameters.setter
    def ecs_task_parameters(self, value: Optional[pulumi.Input['PipeTargetEcsTaskParametersArgs']]):
        pulumi.set(self, "ecs_task_parameters", value)

    @property
    @pulumi.getter(name="eventBridgeEventBusParameters")
    def event_bridge_event_bus_parameters(self) -> Optional[pulumi.Input['PipeTargetEventBridgeEventBusParametersArgs']]:
        """
        The parameters for using an EventBridge event bus as a target.
        """
        return pulumi.get(self, "event_bridge_event_bus_parameters")

    @event_bridge_event_bus_parameters.setter
    def event_bridge_event_bus_parameters(self, value: Optional[pulumi.Input['PipeTargetEventBridgeEventBusParametersArgs']]):
        pulumi.set(self, "event_bridge_event_bus_parameters", value)

    @property
    @pulumi.getter(name="httpParameters")
    def http_parameters(self) -> Optional[pulumi.Input['PipeTargetHttpParametersArgs']]:
        """
        These are custom parameter to be used when the target is an API Gateway REST APIs or EventBridge ApiDestinations.
        """
        return pulumi.get(self, "http_parameters")

    @http_parameters.setter
    def http_parameters(self, value: Optional[pulumi.Input['PipeTargetHttpParametersArgs']]):
        pulumi.set(self, "http_parameters", value)

    @property
    @pulumi.getter(name="inputTemplate")
    def input_template(self) -> Optional[pulumi.Input[str]]:
        """
        Valid JSON text passed to the target. In this case, nothing from the event itself is passed to the target. For more information, see [The JavaScript Object Notation (JSON) Data Interchange Format](https://docs.aws.amazon.com/http://www.rfc-editor.org/rfc/rfc7159.txt) .

        To remove an input template, specify an empty string.
        """
        return pulumi.get(self, "input_template")

    @input_template.setter
    def input_template(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "input_template", value)

    @property
    @pulumi.getter(name="kinesisStreamParameters")
    def kinesis_stream_parameters(self) -> Optional[pulumi.Input['PipeTargetKinesisStreamParametersArgs']]:
        """
        The parameters for using a Kinesis stream as a target.
        """
        return pulumi.get(self, "kinesis_stream_parameters")

    @kinesis_stream_parameters.setter
    def kinesis_stream_parameters(self, value: Optional[pulumi.Input['PipeTargetKinesisStreamParametersArgs']]):
        pulumi.set(self, "kinesis_stream_parameters", value)

    @property
    @pulumi.getter(name="lambdaFunctionParameters")
    def lambda_function_parameters(self) -> Optional[pulumi.Input['PipeTargetLambdaFunctionParametersArgs']]:
        """
        The parameters for using a Lambda function as a target.
        """
        return pulumi.get(self, "lambda_function_parameters")

    @lambda_function_parameters.setter
    def lambda_function_parameters(self, value: Optional[pulumi.Input['PipeTargetLambdaFunctionParametersArgs']]):
        pulumi.set(self, "lambda_function_parameters", value)

    @property
    @pulumi.getter(name="redshiftDataParameters")
    def redshift_data_parameters(self) -> Optional[pulumi.Input['PipeTargetRedshiftDataParametersArgs']]:
        """
        These are custom parameters to be used when the target is a Amazon Redshift cluster to invoke the Amazon Redshift Data API BatchExecuteStatement.
        """
        return pulumi.get(self, "redshift_data_parameters")

    @redshift_data_parameters.setter
    def redshift_data_parameters(self, value: Optional[pulumi.Input['PipeTargetRedshiftDataParametersArgs']]):
        pulumi.set(self, "redshift_data_parameters", value)

    @property
    @pulumi.getter(name="sageMakerPipelineParameters")
    def sage_maker_pipeline_parameters(self) -> Optional[pulumi.Input['PipeTargetSageMakerPipelineParametersArgs']]:
        """
        The parameters for using a SageMaker AI pipeline as a target.
        """
        return pulumi.get(self, "sage_maker_pipeline_parameters")

    @sage_maker_pipeline_parameters.setter
    def sage_maker_pipeline_parameters(self, value: Optional[pulumi.Input['PipeTargetSageMakerPipelineParametersArgs']]):
        pulumi.set(self, "sage_maker_pipeline_parameters", value)

    @property
    @pulumi.getter(name="sqsQueueParameters")
    def sqs_queue_parameters(self) -> Optional[pulumi.Input['PipeTargetSqsQueueParametersArgs']]:
        """
        The parameters for using a Amazon SQS stream as a target.
        """
        return pulumi.get(self, "sqs_queue_parameters")

    @sqs_queue_parameters.setter
    def sqs_queue_parameters(self, value: Optional[pulumi.Input['PipeTargetSqsQueueParametersArgs']]):
        pulumi.set(self, "sqs_queue_parameters", value)

    @property
    @pulumi.getter(name="stepFunctionStateMachineParameters")
    def step_function_state_machine_parameters(self) -> Optional[pulumi.Input['PipeTargetStateMachineParametersArgs']]:
        """
        The parameters for using a Step Functions state machine as a target.
        """
        return pulumi.get(self, "step_function_state_machine_parameters")

    @step_function_state_machine_parameters.setter
    def step_function_state_machine_parameters(self, value: Optional[pulumi.Input['PipeTargetStateMachineParametersArgs']]):
        pulumi.set(self, "step_function_state_machine_parameters", value)

    @property
    @pulumi.getter(name="timestreamParameters")
    def timestream_parameters(self) -> Optional[pulumi.Input['PipeTargetTimestreamParametersArgs']]:
        """
        The parameters for using a Timestream for LiveAnalytics table as a target.
        """
        return pulumi.get(self, "timestream_parameters")

    @timestream_parameters.setter
    def timestream_parameters(self, value: Optional[pulumi.Input['PipeTargetTimestreamParametersArgs']]):
        pulumi.set(self, "timestream_parameters", value)


if not MYPY:
    class PipeTargetRedshiftDataParametersArgsDict(TypedDict):
        database: pulumi.Input[str]
        """
        Redshift Database
        """
        sqls: pulumi.Input[Sequence[pulumi.Input[str]]]
        """
        A list of SQLs.
        """
        db_user: NotRequired[pulumi.Input[str]]
        """
        Database user name
        """
        secret_manager_arn: NotRequired[pulumi.Input[str]]
        """
        Optional SecretManager ARN which stores the database credentials
        """
        statement_name: NotRequired[pulumi.Input[str]]
        """
        A name for Redshift DataAPI statement which can be used as filter of ListStatement.
        """
        with_event: NotRequired[pulumi.Input[bool]]
        """
        Indicates whether to send an event back to EventBridge after the SQL statement runs.
        """
elif False:
    PipeTargetRedshiftDataParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeTargetRedshiftDataParametersArgs:
    def __init__(__self__, *,
                 database: pulumi.Input[str],
                 sqls: pulumi.Input[Sequence[pulumi.Input[str]]],
                 db_user: Optional[pulumi.Input[str]] = None,
                 secret_manager_arn: Optional[pulumi.Input[str]] = None,
                 statement_name: Optional[pulumi.Input[str]] = None,
                 with_event: Optional[pulumi.Input[bool]] = None):
        """
        :param pulumi.Input[str] database: Redshift Database
        :param pulumi.Input[Sequence[pulumi.Input[str]]] sqls: A list of SQLs.
        :param pulumi.Input[str] db_user: Database user name
        :param pulumi.Input[str] secret_manager_arn: Optional SecretManager ARN which stores the database credentials
        :param pulumi.Input[str] statement_name: A name for Redshift DataAPI statement which can be used as filter of ListStatement.
        :param pulumi.Input[bool] with_event: Indicates whether to send an event back to EventBridge after the SQL statement runs.
        """
        pulumi.set(__self__, "database", database)
        pulumi.set(__self__, "sqls", sqls)
        if db_user is not None:
            pulumi.set(__self__, "db_user", db_user)
        if secret_manager_arn is not None:
            pulumi.set(__self__, "secret_manager_arn", secret_manager_arn)
        if statement_name is not None:
            pulumi.set(__self__, "statement_name", statement_name)
        if with_event is not None:
            pulumi.set(__self__, "with_event", with_event)

    @property
    @pulumi.getter
    def database(self) -> pulumi.Input[str]:
        """
        Redshift Database
        """
        return pulumi.get(self, "database")

    @database.setter
    def database(self, value: pulumi.Input[str]):
        pulumi.set(self, "database", value)

    @property
    @pulumi.getter
    def sqls(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        A list of SQLs.
        """
        return pulumi.get(self, "sqls")

    @sqls.setter
    def sqls(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "sqls", value)

    @property
    @pulumi.getter(name="dbUser")
    def db_user(self) -> Optional[pulumi.Input[str]]:
        """
        Database user name
        """
        return pulumi.get(self, "db_user")

    @db_user.setter
    def db_user(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "db_user", value)

    @property
    @pulumi.getter(name="secretManagerArn")
    def secret_manager_arn(self) -> Optional[pulumi.Input[str]]:
        """
        Optional SecretManager ARN which stores the database credentials
        """
        return pulumi.get(self, "secret_manager_arn")

    @secret_manager_arn.setter
    def secret_manager_arn(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "secret_manager_arn", value)

    @property
    @pulumi.getter(name="statementName")
    def statement_name(self) -> Optional[pulumi.Input[str]]:
        """
        A name for Redshift DataAPI statement which can be used as filter of ListStatement.
        """
        return pulumi.get(self, "statement_name")

    @statement_name.setter
    def statement_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "statement_name", value)

    @property
    @pulumi.getter(name="withEvent")
    def with_event(self) -> Optional[pulumi.Input[bool]]:
        """
        Indicates whether to send an event back to EventBridge after the SQL statement runs.
        """
        return pulumi.get(self, "with_event")

    @with_event.setter
    def with_event(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "with_event", value)


if not MYPY:
    class PipeTargetSageMakerPipelineParametersArgsDict(TypedDict):
        pipeline_parameter_list: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipeSageMakerPipelineParameterArgsDict']]]]
        """
        List of Parameter names and values for SageMaker AI Model Building Pipeline execution.
        """
elif False:
    PipeTargetSageMakerPipelineParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeTargetSageMakerPipelineParametersArgs:
    def __init__(__self__, *,
                 pipeline_parameter_list: Optional[pulumi.Input[Sequence[pulumi.Input['PipeSageMakerPipelineParameterArgs']]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input['PipeSageMakerPipelineParameterArgs']]] pipeline_parameter_list: List of Parameter names and values for SageMaker AI Model Building Pipeline execution.
        """
        if pipeline_parameter_list is not None:
            pulumi.set(__self__, "pipeline_parameter_list", pipeline_parameter_list)

    @property
    @pulumi.getter(name="pipelineParameterList")
    def pipeline_parameter_list(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipeSageMakerPipelineParameterArgs']]]]:
        """
        List of Parameter names and values for SageMaker AI Model Building Pipeline execution.
        """
        return pulumi.get(self, "pipeline_parameter_list")

    @pipeline_parameter_list.setter
    def pipeline_parameter_list(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipeSageMakerPipelineParameterArgs']]]]):
        pulumi.set(self, "pipeline_parameter_list", value)


if not MYPY:
    class PipeTargetSqsQueueParametersArgsDict(TypedDict):
        message_deduplication_id: NotRequired[pulumi.Input[str]]
        """
        This parameter applies only to FIFO (first-in-first-out) queues.

        The token used for deduplication of sent messages.
        """
        message_group_id: NotRequired[pulumi.Input[str]]
        """
        The FIFO message group ID to use as the target.
        """
elif False:
    PipeTargetSqsQueueParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeTargetSqsQueueParametersArgs:
    def __init__(__self__, *,
                 message_deduplication_id: Optional[pulumi.Input[str]] = None,
                 message_group_id: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] message_deduplication_id: This parameter applies only to FIFO (first-in-first-out) queues.
               
               The token used for deduplication of sent messages.
        :param pulumi.Input[str] message_group_id: The FIFO message group ID to use as the target.
        """
        if message_deduplication_id is not None:
            pulumi.set(__self__, "message_deduplication_id", message_deduplication_id)
        if message_group_id is not None:
            pulumi.set(__self__, "message_group_id", message_group_id)

    @property
    @pulumi.getter(name="messageDeduplicationId")
    def message_deduplication_id(self) -> Optional[pulumi.Input[str]]:
        """
        This parameter applies only to FIFO (first-in-first-out) queues.

        The token used for deduplication of sent messages.
        """
        return pulumi.get(self, "message_deduplication_id")

    @message_deduplication_id.setter
    def message_deduplication_id(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "message_deduplication_id", value)

    @property
    @pulumi.getter(name="messageGroupId")
    def message_group_id(self) -> Optional[pulumi.Input[str]]:
        """
        The FIFO message group ID to use as the target.
        """
        return pulumi.get(self, "message_group_id")

    @message_group_id.setter
    def message_group_id(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "message_group_id", value)


if not MYPY:
    class PipeTargetStateMachineParametersArgsDict(TypedDict):
        invocation_type: NotRequired[pulumi.Input['PipeTargetInvocationType']]
        """
        Specify whether to invoke the Step Functions state machine synchronously or asynchronously.

        - `REQUEST_RESPONSE` (default) - Invoke synchronously. For more information, see [StartSyncExecution](https://docs.aws.amazon.com/step-functions/latest/apireference/API_StartSyncExecution.html) in the *AWS Step Functions API Reference* .

        > `REQUEST_RESPONSE` is not supported for `STANDARD` state machine workflows.
        - `FIRE_AND_FORGET` - Invoke asynchronously. For more information, see [StartExecution](https://docs.aws.amazon.com/step-functions/latest/apireference/API_StartExecution.html) in the *AWS Step Functions API Reference* .

        For more information, see [Invocation types](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes.html#pipes-invocation) in the *Amazon EventBridge User Guide* .
        """
elif False:
    PipeTargetStateMachineParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeTargetStateMachineParametersArgs:
    def __init__(__self__, *,
                 invocation_type: Optional[pulumi.Input['PipeTargetInvocationType']] = None):
        """
        :param pulumi.Input['PipeTargetInvocationType'] invocation_type: Specify whether to invoke the Step Functions state machine synchronously or asynchronously.
               
               - `REQUEST_RESPONSE` (default) - Invoke synchronously. For more information, see [StartSyncExecution](https://docs.aws.amazon.com/step-functions/latest/apireference/API_StartSyncExecution.html) in the *AWS Step Functions API Reference* .
               
               > `REQUEST_RESPONSE` is not supported for `STANDARD` state machine workflows.
               - `FIRE_AND_FORGET` - Invoke asynchronously. For more information, see [StartExecution](https://docs.aws.amazon.com/step-functions/latest/apireference/API_StartExecution.html) in the *AWS Step Functions API Reference* .
               
               For more information, see [Invocation types](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes.html#pipes-invocation) in the *Amazon EventBridge User Guide* .
        """
        if invocation_type is not None:
            pulumi.set(__self__, "invocation_type", invocation_type)

    @property
    @pulumi.getter(name="invocationType")
    def invocation_type(self) -> Optional[pulumi.Input['PipeTargetInvocationType']]:
        """
        Specify whether to invoke the Step Functions state machine synchronously or asynchronously.

        - `REQUEST_RESPONSE` (default) - Invoke synchronously. For more information, see [StartSyncExecution](https://docs.aws.amazon.com/step-functions/latest/apireference/API_StartSyncExecution.html) in the *AWS Step Functions API Reference* .

        > `REQUEST_RESPONSE` is not supported for `STANDARD` state machine workflows.
        - `FIRE_AND_FORGET` - Invoke asynchronously. For more information, see [StartExecution](https://docs.aws.amazon.com/step-functions/latest/apireference/API_StartExecution.html) in the *AWS Step Functions API Reference* .

        For more information, see [Invocation types](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes.html#pipes-invocation) in the *Amazon EventBridge User Guide* .
        """
        return pulumi.get(self, "invocation_type")

    @invocation_type.setter
    def invocation_type(self, value: Optional[pulumi.Input['PipeTargetInvocationType']]):
        pulumi.set(self, "invocation_type", value)


if not MYPY:
    class PipeTargetTimestreamParametersArgsDict(TypedDict):
        dimension_mappings: pulumi.Input[Sequence[pulumi.Input['PipeDimensionMappingArgsDict']]]
        """
        Map source data to dimensions in the target Timestream for LiveAnalytics table.

        For more information, see [Amazon Timestream for LiveAnalytics concepts](https://docs.aws.amazon.com/timestream/latest/developerguide/concepts.html)
        """
        time_value: pulumi.Input[str]
        """
        Dynamic path to the source data field that represents the time value for your data.
        """
        version_value: pulumi.Input[str]
        """
        64 bit version value or source data field that represents the version value for your data.

        Write requests with a higher version number will update the existing measure values of the record and version. In cases where the measure value is the same, the version will still be updated.

        Default value is 1.

        Timestream for LiveAnalytics does not support updating partial measure values in a record.

        Write requests for duplicate data with a higher version number will update the existing measure value and version. In cases where the measure value is the same, `Version` will still be updated. Default value is `1` .

        > `Version` must be `1` or greater, or you will receive a `ValidationException` error.
        """
        epoch_time_unit: NotRequired[pulumi.Input['PipeEpochTimeUnit']]
        """
        The granularity of the time units used. Default is `MILLISECONDS` .

        Required if `TimeFieldType` is specified as `EPOCH` .
        """
        multi_measure_mappings: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipeMultiMeasureMappingArgsDict']]]]
        """
        Maps multiple measures from the source event to the same record in the specified Timestream for LiveAnalytics table.
        """
        single_measure_mappings: NotRequired[pulumi.Input[Sequence[pulumi.Input['PipeSingleMeasureMappingArgsDict']]]]
        """
        Mappings of single source data fields to individual records in the specified Timestream for LiveAnalytics table.
        """
        time_field_type: NotRequired[pulumi.Input['PipeTimeFieldType']]
        """
        The type of time value used.

        The default is `EPOCH` .
        """
        timestamp_format: NotRequired[pulumi.Input[str]]
        """
        How to format the timestamps. For example, `yyyy-MM-dd'T'HH:mm:ss'Z'` .

        Required if `TimeFieldType` is specified as `TIMESTAMP_FORMAT` .
        """
elif False:
    PipeTargetTimestreamParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class PipeTargetTimestreamParametersArgs:
    def __init__(__self__, *,
                 dimension_mappings: pulumi.Input[Sequence[pulumi.Input['PipeDimensionMappingArgs']]],
                 time_value: pulumi.Input[str],
                 version_value: pulumi.Input[str],
                 epoch_time_unit: Optional[pulumi.Input['PipeEpochTimeUnit']] = None,
                 multi_measure_mappings: Optional[pulumi.Input[Sequence[pulumi.Input['PipeMultiMeasureMappingArgs']]]] = None,
                 single_measure_mappings: Optional[pulumi.Input[Sequence[pulumi.Input['PipeSingleMeasureMappingArgs']]]] = None,
                 time_field_type: Optional[pulumi.Input['PipeTimeFieldType']] = None,
                 timestamp_format: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input['PipeDimensionMappingArgs']]] dimension_mappings: Map source data to dimensions in the target Timestream for LiveAnalytics table.
               
               For more information, see [Amazon Timestream for LiveAnalytics concepts](https://docs.aws.amazon.com/timestream/latest/developerguide/concepts.html)
        :param pulumi.Input[str] time_value: Dynamic path to the source data field that represents the time value for your data.
        :param pulumi.Input[str] version_value: 64 bit version value or source data field that represents the version value for your data.
               
               Write requests with a higher version number will update the existing measure values of the record and version. In cases where the measure value is the same, the version will still be updated.
               
               Default value is 1.
               
               Timestream for LiveAnalytics does not support updating partial measure values in a record.
               
               Write requests for duplicate data with a higher version number will update the existing measure value and version. In cases where the measure value is the same, `Version` will still be updated. Default value is `1` .
               
               > `Version` must be `1` or greater, or you will receive a `ValidationException` error.
        :param pulumi.Input['PipeEpochTimeUnit'] epoch_time_unit: The granularity of the time units used. Default is `MILLISECONDS` .
               
               Required if `TimeFieldType` is specified as `EPOCH` .
        :param pulumi.Input[Sequence[pulumi.Input['PipeMultiMeasureMappingArgs']]] multi_measure_mappings: Maps multiple measures from the source event to the same record in the specified Timestream for LiveAnalytics table.
        :param pulumi.Input[Sequence[pulumi.Input['PipeSingleMeasureMappingArgs']]] single_measure_mappings: Mappings of single source data fields to individual records in the specified Timestream for LiveAnalytics table.
        :param pulumi.Input['PipeTimeFieldType'] time_field_type: The type of time value used.
               
               The default is `EPOCH` .
        :param pulumi.Input[str] timestamp_format: How to format the timestamps. For example, `yyyy-MM-dd'T'HH:mm:ss'Z'` .
               
               Required if `TimeFieldType` is specified as `TIMESTAMP_FORMAT` .
        """
        pulumi.set(__self__, "dimension_mappings", dimension_mappings)
        pulumi.set(__self__, "time_value", time_value)
        pulumi.set(__self__, "version_value", version_value)
        if epoch_time_unit is not None:
            pulumi.set(__self__, "epoch_time_unit", epoch_time_unit)
        if multi_measure_mappings is not None:
            pulumi.set(__self__, "multi_measure_mappings", multi_measure_mappings)
        if single_measure_mappings is not None:
            pulumi.set(__self__, "single_measure_mappings", single_measure_mappings)
        if time_field_type is not None:
            pulumi.set(__self__, "time_field_type", time_field_type)
        if timestamp_format is not None:
            pulumi.set(__self__, "timestamp_format", timestamp_format)

    @property
    @pulumi.getter(name="dimensionMappings")
    def dimension_mappings(self) -> pulumi.Input[Sequence[pulumi.Input['PipeDimensionMappingArgs']]]:
        """
        Map source data to dimensions in the target Timestream for LiveAnalytics table.

        For more information, see [Amazon Timestream for LiveAnalytics concepts](https://docs.aws.amazon.com/timestream/latest/developerguide/concepts.html)
        """
        return pulumi.get(self, "dimension_mappings")

    @dimension_mappings.setter
    def dimension_mappings(self, value: pulumi.Input[Sequence[pulumi.Input['PipeDimensionMappingArgs']]]):
        pulumi.set(self, "dimension_mappings", value)

    @property
    @pulumi.getter(name="timeValue")
    def time_value(self) -> pulumi.Input[str]:
        """
        Dynamic path to the source data field that represents the time value for your data.
        """
        return pulumi.get(self, "time_value")

    @time_value.setter
    def time_value(self, value: pulumi.Input[str]):
        pulumi.set(self, "time_value", value)

    @property
    @pulumi.getter(name="versionValue")
    def version_value(self) -> pulumi.Input[str]:
        """
        64 bit version value or source data field that represents the version value for your data.

        Write requests with a higher version number will update the existing measure values of the record and version. In cases where the measure value is the same, the version will still be updated.

        Default value is 1.

        Timestream for LiveAnalytics does not support updating partial measure values in a record.

        Write requests for duplicate data with a higher version number will update the existing measure value and version. In cases where the measure value is the same, `Version` will still be updated. Default value is `1` .

        > `Version` must be `1` or greater, or you will receive a `ValidationException` error.
        """
        return pulumi.get(self, "version_value")

    @version_value.setter
    def version_value(self, value: pulumi.Input[str]):
        pulumi.set(self, "version_value", value)

    @property
    @pulumi.getter(name="epochTimeUnit")
    def epoch_time_unit(self) -> Optional[pulumi.Input['PipeEpochTimeUnit']]:
        """
        The granularity of the time units used. Default is `MILLISECONDS` .

        Required if `TimeFieldType` is specified as `EPOCH` .
        """
        return pulumi.get(self, "epoch_time_unit")

    @epoch_time_unit.setter
    def epoch_time_unit(self, value: Optional[pulumi.Input['PipeEpochTimeUnit']]):
        pulumi.set(self, "epoch_time_unit", value)

    @property
    @pulumi.getter(name="multiMeasureMappings")
    def multi_measure_mappings(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipeMultiMeasureMappingArgs']]]]:
        """
        Maps multiple measures from the source event to the same record in the specified Timestream for LiveAnalytics table.
        """
        return pulumi.get(self, "multi_measure_mappings")

    @multi_measure_mappings.setter
    def multi_measure_mappings(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipeMultiMeasureMappingArgs']]]]):
        pulumi.set(self, "multi_measure_mappings", value)

    @property
    @pulumi.getter(name="singleMeasureMappings")
    def single_measure_mappings(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['PipeSingleMeasureMappingArgs']]]]:
        """
        Mappings of single source data fields to individual records in the specified Timestream for LiveAnalytics table.
        """
        return pulumi.get(self, "single_measure_mappings")

    @single_measure_mappings.setter
    def single_measure_mappings(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['PipeSingleMeasureMappingArgs']]]]):
        pulumi.set(self, "single_measure_mappings", value)

    @property
    @pulumi.getter(name="timeFieldType")
    def time_field_type(self) -> Optional[pulumi.Input['PipeTimeFieldType']]:
        """
        The type of time value used.

        The default is `EPOCH` .
        """
        return pulumi.get(self, "time_field_type")

    @time_field_type.setter
    def time_field_type(self, value: Optional[pulumi.Input['PipeTimeFieldType']]):
        pulumi.set(self, "time_field_type", value)

    @property
    @pulumi.getter(name="timestampFormat")
    def timestamp_format(self) -> Optional[pulumi.Input[str]]:
        """
        How to format the timestamps. For example, `yyyy-MM-dd'T'HH:mm:ss'Z'` .

        Required if `TimeFieldType` is specified as `TIMESTAMP_FORMAT` .
        """
        return pulumi.get(self, "timestamp_format")

    @timestamp_format.setter
    def timestamp_format(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "timestamp_format", value)


