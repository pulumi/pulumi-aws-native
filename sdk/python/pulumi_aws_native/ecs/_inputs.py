# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins as _builtins
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from .. import _utilities
from ._enums import *

__all__ = [
    'CapacityProviderAcceleratorCountRequestArgs',
    'CapacityProviderAcceleratorCountRequestArgsDict',
    'CapacityProviderAcceleratorTotalMemoryMiBRequestArgs',
    'CapacityProviderAcceleratorTotalMemoryMiBRequestArgsDict',
    'CapacityProviderAutoScalingGroupProviderArgs',
    'CapacityProviderAutoScalingGroupProviderArgsDict',
    'CapacityProviderBaselineEbsBandwidthMbpsRequestArgs',
    'CapacityProviderBaselineEbsBandwidthMbpsRequestArgsDict',
    'CapacityProviderInstanceLaunchTemplateArgs',
    'CapacityProviderInstanceLaunchTemplateArgsDict',
    'CapacityProviderInstanceRequirementsRequestArgs',
    'CapacityProviderInstanceRequirementsRequestArgsDict',
    'CapacityProviderManagedInstancesNetworkConfigurationArgs',
    'CapacityProviderManagedInstancesNetworkConfigurationArgsDict',
    'CapacityProviderManagedInstancesProviderArgs',
    'CapacityProviderManagedInstancesProviderArgsDict',
    'CapacityProviderManagedInstancesStorageConfigurationArgs',
    'CapacityProviderManagedInstancesStorageConfigurationArgsDict',
    'CapacityProviderManagedScalingArgs',
    'CapacityProviderManagedScalingArgsDict',
    'CapacityProviderMemoryGiBPerVCpuRequestArgs',
    'CapacityProviderMemoryGiBPerVCpuRequestArgsDict',
    'CapacityProviderMemoryMiBRequestArgs',
    'CapacityProviderMemoryMiBRequestArgsDict',
    'CapacityProviderNetworkBandwidthGbpsRequestArgs',
    'CapacityProviderNetworkBandwidthGbpsRequestArgsDict',
    'CapacityProviderNetworkInterfaceCountRequestArgs',
    'CapacityProviderNetworkInterfaceCountRequestArgsDict',
    'CapacityProviderTotalLocalStorageGbRequestArgs',
    'CapacityProviderTotalLocalStorageGbRequestArgsDict',
    'CapacityProviderVCpuCountRangeRequestArgs',
    'CapacityProviderVCpuCountRangeRequestArgsDict',
    'ClusterCapacityProviderAssociationsCapacityProviderStrategyArgs',
    'ClusterCapacityProviderAssociationsCapacityProviderStrategyArgsDict',
    'ClusterCapacityProviderStrategyItemArgs',
    'ClusterCapacityProviderStrategyItemArgsDict',
    'ClusterConfigurationArgs',
    'ClusterConfigurationArgsDict',
    'ClusterExecuteCommandConfigurationArgs',
    'ClusterExecuteCommandConfigurationArgsDict',
    'ClusterExecuteCommandLogConfigurationArgs',
    'ClusterExecuteCommandLogConfigurationArgsDict',
    'ClusterManagedStorageConfigurationArgs',
    'ClusterManagedStorageConfigurationArgsDict',
    'ClusterServiceConnectDefaultsArgs',
    'ClusterServiceConnectDefaultsArgsDict',
    'ClusterSettingsArgs',
    'ClusterSettingsArgsDict',
    'ServiceAdvancedConfigurationArgs',
    'ServiceAdvancedConfigurationArgsDict',
    'ServiceAwsVpcConfigurationArgs',
    'ServiceAwsVpcConfigurationArgsDict',
    'ServiceCanaryConfigurationArgs',
    'ServiceCanaryConfigurationArgsDict',
    'ServiceCapacityProviderStrategyItemArgs',
    'ServiceCapacityProviderStrategyItemArgsDict',
    'ServiceConnectAccessLogConfigurationArgs',
    'ServiceConnectAccessLogConfigurationArgsDict',
    'ServiceConnectClientAliasArgs',
    'ServiceConnectClientAliasArgsDict',
    'ServiceConnectConfigurationArgs',
    'ServiceConnectConfigurationArgsDict',
    'ServiceConnectServiceArgs',
    'ServiceConnectServiceArgsDict',
    'ServiceConnectTestTrafficRulesHeaderValueArgs',
    'ServiceConnectTestTrafficRulesHeaderValueArgsDict',
    'ServiceConnectTestTrafficRulesHeaderArgs',
    'ServiceConnectTestTrafficRulesHeaderArgsDict',
    'ServiceConnectTestTrafficRulesArgs',
    'ServiceConnectTestTrafficRulesArgsDict',
    'ServiceConnectTlsCertificateAuthorityArgs',
    'ServiceConnectTlsCertificateAuthorityArgsDict',
    'ServiceConnectTlsConfigurationArgs',
    'ServiceConnectTlsConfigurationArgsDict',
    'ServiceDeploymentAlarmsArgs',
    'ServiceDeploymentAlarmsArgsDict',
    'ServiceDeploymentCircuitBreakerArgs',
    'ServiceDeploymentCircuitBreakerArgsDict',
    'ServiceDeploymentConfigurationArgs',
    'ServiceDeploymentConfigurationArgsDict',
    'ServiceDeploymentControllerArgs',
    'ServiceDeploymentControllerArgsDict',
    'ServiceDeploymentLifecycleHookArgs',
    'ServiceDeploymentLifecycleHookArgsDict',
    'ServiceEbsTagSpecificationArgs',
    'ServiceEbsTagSpecificationArgsDict',
    'ServiceForceNewDeploymentArgs',
    'ServiceForceNewDeploymentArgsDict',
    'ServiceLinearConfigurationArgs',
    'ServiceLinearConfigurationArgsDict',
    'ServiceLoadBalancerArgs',
    'ServiceLoadBalancerArgsDict',
    'ServiceLogConfigurationArgs',
    'ServiceLogConfigurationArgsDict',
    'ServiceManagedEbsVolumeConfigurationArgs',
    'ServiceManagedEbsVolumeConfigurationArgsDict',
    'ServiceNetworkConfigurationArgs',
    'ServiceNetworkConfigurationArgsDict',
    'ServicePlacementConstraintArgs',
    'ServicePlacementConstraintArgsDict',
    'ServicePlacementStrategyArgs',
    'ServicePlacementStrategyArgsDict',
    'ServiceRegistryArgs',
    'ServiceRegistryArgsDict',
    'ServiceSecretArgs',
    'ServiceSecretArgsDict',
    'ServiceTagArgs',
    'ServiceTagArgsDict',
    'ServiceTimeoutConfigurationArgs',
    'ServiceTimeoutConfigurationArgsDict',
    'ServiceVolumeConfigurationArgs',
    'ServiceVolumeConfigurationArgsDict',
    'ServiceVpcLatticeConfigurationArgs',
    'ServiceVpcLatticeConfigurationArgsDict',
    'TaskDefinitionAuthorizationConfigArgs',
    'TaskDefinitionAuthorizationConfigArgsDict',
    'TaskDefinitionContainerDefinitionArgs',
    'TaskDefinitionContainerDefinitionArgsDict',
    'TaskDefinitionContainerDependencyArgs',
    'TaskDefinitionContainerDependencyArgsDict',
    'TaskDefinitionDeviceArgs',
    'TaskDefinitionDeviceArgsDict',
    'TaskDefinitionDockerVolumeConfigurationArgs',
    'TaskDefinitionDockerVolumeConfigurationArgsDict',
    'TaskDefinitionEfsVolumeConfigurationArgs',
    'TaskDefinitionEfsVolumeConfigurationArgsDict',
    'TaskDefinitionEnvironmentFileArgs',
    'TaskDefinitionEnvironmentFileArgsDict',
    'TaskDefinitionEphemeralStorageArgs',
    'TaskDefinitionEphemeralStorageArgsDict',
    'TaskDefinitionFSxAuthorizationConfigArgs',
    'TaskDefinitionFSxAuthorizationConfigArgsDict',
    'TaskDefinitionFSxWindowsFileServerVolumeConfigurationArgs',
    'TaskDefinitionFSxWindowsFileServerVolumeConfigurationArgsDict',
    'TaskDefinitionFirelensConfigurationArgs',
    'TaskDefinitionFirelensConfigurationArgsDict',
    'TaskDefinitionHealthCheckArgs',
    'TaskDefinitionHealthCheckArgsDict',
    'TaskDefinitionHostEntryArgs',
    'TaskDefinitionHostEntryArgsDict',
    'TaskDefinitionHostVolumePropertiesArgs',
    'TaskDefinitionHostVolumePropertiesArgsDict',
    'TaskDefinitionInferenceAcceleratorArgs',
    'TaskDefinitionInferenceAcceleratorArgsDict',
    'TaskDefinitionKernelCapabilitiesArgs',
    'TaskDefinitionKernelCapabilitiesArgsDict',
    'TaskDefinitionKeyValuePairArgs',
    'TaskDefinitionKeyValuePairArgsDict',
    'TaskDefinitionLinuxParametersArgs',
    'TaskDefinitionLinuxParametersArgsDict',
    'TaskDefinitionLogConfigurationArgs',
    'TaskDefinitionLogConfigurationArgsDict',
    'TaskDefinitionMountPointArgs',
    'TaskDefinitionMountPointArgsDict',
    'TaskDefinitionPlacementConstraintArgs',
    'TaskDefinitionPlacementConstraintArgsDict',
    'TaskDefinitionPortMappingArgs',
    'TaskDefinitionPortMappingArgsDict',
    'TaskDefinitionProxyConfigurationArgs',
    'TaskDefinitionProxyConfigurationArgsDict',
    'TaskDefinitionRepositoryCredentialsArgs',
    'TaskDefinitionRepositoryCredentialsArgsDict',
    'TaskDefinitionResourceRequirementArgs',
    'TaskDefinitionResourceRequirementArgsDict',
    'TaskDefinitionRestartPolicyArgs',
    'TaskDefinitionRestartPolicyArgsDict',
    'TaskDefinitionRuntimePlatformArgs',
    'TaskDefinitionRuntimePlatformArgsDict',
    'TaskDefinitionSecretArgs',
    'TaskDefinitionSecretArgsDict',
    'TaskDefinitionSystemControlArgs',
    'TaskDefinitionSystemControlArgsDict',
    'TaskDefinitionTmpfsArgs',
    'TaskDefinitionTmpfsArgsDict',
    'TaskDefinitionUlimitArgs',
    'TaskDefinitionUlimitArgsDict',
    'TaskDefinitionVolumeFromArgs',
    'TaskDefinitionVolumeFromArgsDict',
    'TaskDefinitionVolumeArgs',
    'TaskDefinitionVolumeArgsDict',
    'TaskSetAwsVpcConfigurationArgs',
    'TaskSetAwsVpcConfigurationArgsDict',
    'TaskSetCapacityProviderStrategyItemArgs',
    'TaskSetCapacityProviderStrategyItemArgsDict',
    'TaskSetLoadBalancerArgs',
    'TaskSetLoadBalancerArgsDict',
    'TaskSetNetworkConfigurationArgs',
    'TaskSetNetworkConfigurationArgsDict',
    'TaskSetScaleArgs',
    'TaskSetScaleArgsDict',
    'TaskSetServiceRegistryArgs',
    'TaskSetServiceRegistryArgsDict',
]

MYPY = False

if not MYPY:
    class CapacityProviderAcceleratorCountRequestArgsDict(TypedDict):
        max: NotRequired[pulumi.Input[_builtins.int]]
        """
        The maximum number of accelerators. Instance types with more accelerators are excluded from selection.
        """
        min: NotRequired[pulumi.Input[_builtins.int]]
        """
        The minimum number of accelerators. Instance types with fewer accelerators are excluded from selection.
        """
elif False:
    CapacityProviderAcceleratorCountRequestArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class CapacityProviderAcceleratorCountRequestArgs:
    def __init__(__self__, *,
                 max: Optional[pulumi.Input[_builtins.int]] = None,
                 min: Optional[pulumi.Input[_builtins.int]] = None):
        """
        :param pulumi.Input[_builtins.int] max: The maximum number of accelerators. Instance types with more accelerators are excluded from selection.
        :param pulumi.Input[_builtins.int] min: The minimum number of accelerators. Instance types with fewer accelerators are excluded from selection.
        """
        if max is not None:
            pulumi.set(__self__, "max", max)
        if min is not None:
            pulumi.set(__self__, "min", min)

    @_builtins.property
    @pulumi.getter
    def max(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The maximum number of accelerators. Instance types with more accelerators are excluded from selection.
        """
        return pulumi.get(self, "max")

    @max.setter
    def max(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "max", value)

    @_builtins.property
    @pulumi.getter
    def min(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The minimum number of accelerators. Instance types with fewer accelerators are excluded from selection.
        """
        return pulumi.get(self, "min")

    @min.setter
    def min(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "min", value)


if not MYPY:
    class CapacityProviderAcceleratorTotalMemoryMiBRequestArgsDict(TypedDict):
        max: NotRequired[pulumi.Input[_builtins.int]]
        """
        The maximum total accelerator memory in MiB. Instance types with more accelerator memory are excluded from selection.
        """
        min: NotRequired[pulumi.Input[_builtins.int]]
        """
        The minimum total accelerator memory in MiB. Instance types with less accelerator memory are excluded from selection.
        """
elif False:
    CapacityProviderAcceleratorTotalMemoryMiBRequestArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class CapacityProviderAcceleratorTotalMemoryMiBRequestArgs:
    def __init__(__self__, *,
                 max: Optional[pulumi.Input[_builtins.int]] = None,
                 min: Optional[pulumi.Input[_builtins.int]] = None):
        """
        :param pulumi.Input[_builtins.int] max: The maximum total accelerator memory in MiB. Instance types with more accelerator memory are excluded from selection.
        :param pulumi.Input[_builtins.int] min: The minimum total accelerator memory in MiB. Instance types with less accelerator memory are excluded from selection.
        """
        if max is not None:
            pulumi.set(__self__, "max", max)
        if min is not None:
            pulumi.set(__self__, "min", min)

    @_builtins.property
    @pulumi.getter
    def max(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The maximum total accelerator memory in MiB. Instance types with more accelerator memory are excluded from selection.
        """
        return pulumi.get(self, "max")

    @max.setter
    def max(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "max", value)

    @_builtins.property
    @pulumi.getter
    def min(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The minimum total accelerator memory in MiB. Instance types with less accelerator memory are excluded from selection.
        """
        return pulumi.get(self, "min")

    @min.setter
    def min(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "min", value)


if not MYPY:
    class CapacityProviderAutoScalingGroupProviderArgsDict(TypedDict):
        auto_scaling_group_arn: pulumi.Input[_builtins.str]
        """
        The Amazon Resource Name (ARN) that identifies the Auto Scaling group, or the Auto Scaling group name.
        """
        managed_draining: NotRequired[pulumi.Input['CapacityProviderAutoScalingGroupProviderManagedDraining']]
        """
        The managed draining option for the Auto Scaling group capacity provider. When you enable this, Amazon ECS manages and gracefully drains the EC2 container instances that are in the Auto Scaling group capacity provider.
        """
        managed_scaling: NotRequired[pulumi.Input['CapacityProviderManagedScalingArgsDict']]
        """
        The managed scaling settings for the Auto Scaling group capacity provider.
        """
        managed_termination_protection: NotRequired[pulumi.Input['CapacityProviderAutoScalingGroupProviderManagedTerminationProtection']]
        """
        The managed termination protection setting to use for the Auto Scaling group capacity provider. This determines whether the Auto Scaling group has managed termination protection. The default is off.

        > When using managed termination protection, managed scaling must also be used otherwise managed termination protection doesn't work. 

        When managed termination protection is on, Amazon ECS prevents the Amazon EC2 instances in an Auto Scaling group that contain tasks from being terminated during a scale-in action. The Auto Scaling group and each instance in the Auto Scaling group must have instance protection from scale-in actions on as well. For more information, see [Instance Protection](https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-termination.html#instance-protection) in the *AWS Auto Scaling User Guide* .

        When managed termination protection is off, your Amazon EC2 instances aren't protected from termination when the Auto Scaling group scales in.
        """
elif False:
    CapacityProviderAutoScalingGroupProviderArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class CapacityProviderAutoScalingGroupProviderArgs:
    def __init__(__self__, *,
                 auto_scaling_group_arn: pulumi.Input[_builtins.str],
                 managed_draining: Optional[pulumi.Input['CapacityProviderAutoScalingGroupProviderManagedDraining']] = None,
                 managed_scaling: Optional[pulumi.Input['CapacityProviderManagedScalingArgs']] = None,
                 managed_termination_protection: Optional[pulumi.Input['CapacityProviderAutoScalingGroupProviderManagedTerminationProtection']] = None):
        """
        :param pulumi.Input[_builtins.str] auto_scaling_group_arn: The Amazon Resource Name (ARN) that identifies the Auto Scaling group, or the Auto Scaling group name.
        :param pulumi.Input['CapacityProviderAutoScalingGroupProviderManagedDraining'] managed_draining: The managed draining option for the Auto Scaling group capacity provider. When you enable this, Amazon ECS manages and gracefully drains the EC2 container instances that are in the Auto Scaling group capacity provider.
        :param pulumi.Input['CapacityProviderManagedScalingArgs'] managed_scaling: The managed scaling settings for the Auto Scaling group capacity provider.
        :param pulumi.Input['CapacityProviderAutoScalingGroupProviderManagedTerminationProtection'] managed_termination_protection: The managed termination protection setting to use for the Auto Scaling group capacity provider. This determines whether the Auto Scaling group has managed termination protection. The default is off.
               
               > When using managed termination protection, managed scaling must also be used otherwise managed termination protection doesn't work. 
               
               When managed termination protection is on, Amazon ECS prevents the Amazon EC2 instances in an Auto Scaling group that contain tasks from being terminated during a scale-in action. The Auto Scaling group and each instance in the Auto Scaling group must have instance protection from scale-in actions on as well. For more information, see [Instance Protection](https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-termination.html#instance-protection) in the *AWS Auto Scaling User Guide* .
               
               When managed termination protection is off, your Amazon EC2 instances aren't protected from termination when the Auto Scaling group scales in.
        """
        pulumi.set(__self__, "auto_scaling_group_arn", auto_scaling_group_arn)
        if managed_draining is not None:
            pulumi.set(__self__, "managed_draining", managed_draining)
        if managed_scaling is not None:
            pulumi.set(__self__, "managed_scaling", managed_scaling)
        if managed_termination_protection is not None:
            pulumi.set(__self__, "managed_termination_protection", managed_termination_protection)

    @_builtins.property
    @pulumi.getter(name="autoScalingGroupArn")
    def auto_scaling_group_arn(self) -> pulumi.Input[_builtins.str]:
        """
        The Amazon Resource Name (ARN) that identifies the Auto Scaling group, or the Auto Scaling group name.
        """
        return pulumi.get(self, "auto_scaling_group_arn")

    @auto_scaling_group_arn.setter
    def auto_scaling_group_arn(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "auto_scaling_group_arn", value)

    @_builtins.property
    @pulumi.getter(name="managedDraining")
    def managed_draining(self) -> Optional[pulumi.Input['CapacityProviderAutoScalingGroupProviderManagedDraining']]:
        """
        The managed draining option for the Auto Scaling group capacity provider. When you enable this, Amazon ECS manages and gracefully drains the EC2 container instances that are in the Auto Scaling group capacity provider.
        """
        return pulumi.get(self, "managed_draining")

    @managed_draining.setter
    def managed_draining(self, value: Optional[pulumi.Input['CapacityProviderAutoScalingGroupProviderManagedDraining']]):
        pulumi.set(self, "managed_draining", value)

    @_builtins.property
    @pulumi.getter(name="managedScaling")
    def managed_scaling(self) -> Optional[pulumi.Input['CapacityProviderManagedScalingArgs']]:
        """
        The managed scaling settings for the Auto Scaling group capacity provider.
        """
        return pulumi.get(self, "managed_scaling")

    @managed_scaling.setter
    def managed_scaling(self, value: Optional[pulumi.Input['CapacityProviderManagedScalingArgs']]):
        pulumi.set(self, "managed_scaling", value)

    @_builtins.property
    @pulumi.getter(name="managedTerminationProtection")
    def managed_termination_protection(self) -> Optional[pulumi.Input['CapacityProviderAutoScalingGroupProviderManagedTerminationProtection']]:
        """
        The managed termination protection setting to use for the Auto Scaling group capacity provider. This determines whether the Auto Scaling group has managed termination protection. The default is off.

        > When using managed termination protection, managed scaling must also be used otherwise managed termination protection doesn't work. 

        When managed termination protection is on, Amazon ECS prevents the Amazon EC2 instances in an Auto Scaling group that contain tasks from being terminated during a scale-in action. The Auto Scaling group and each instance in the Auto Scaling group must have instance protection from scale-in actions on as well. For more information, see [Instance Protection](https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-termination.html#instance-protection) in the *AWS Auto Scaling User Guide* .

        When managed termination protection is off, your Amazon EC2 instances aren't protected from termination when the Auto Scaling group scales in.
        """
        return pulumi.get(self, "managed_termination_protection")

    @managed_termination_protection.setter
    def managed_termination_protection(self, value: Optional[pulumi.Input['CapacityProviderAutoScalingGroupProviderManagedTerminationProtection']]):
        pulumi.set(self, "managed_termination_protection", value)


if not MYPY:
    class CapacityProviderBaselineEbsBandwidthMbpsRequestArgsDict(TypedDict):
        max: NotRequired[pulumi.Input[_builtins.int]]
        """
        The maximum baseline Amazon EBS bandwidth in Mbps. Instance types with higher Amazon EBS bandwidth are excluded from selection.
        """
        min: NotRequired[pulumi.Input[_builtins.int]]
        """
        The minimum baseline Amazon EBS bandwidth in Mbps. Instance types with lower Amazon EBS bandwidth are excluded from selection.
        """
elif False:
    CapacityProviderBaselineEbsBandwidthMbpsRequestArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class CapacityProviderBaselineEbsBandwidthMbpsRequestArgs:
    def __init__(__self__, *,
                 max: Optional[pulumi.Input[_builtins.int]] = None,
                 min: Optional[pulumi.Input[_builtins.int]] = None):
        """
        :param pulumi.Input[_builtins.int] max: The maximum baseline Amazon EBS bandwidth in Mbps. Instance types with higher Amazon EBS bandwidth are excluded from selection.
        :param pulumi.Input[_builtins.int] min: The minimum baseline Amazon EBS bandwidth in Mbps. Instance types with lower Amazon EBS bandwidth are excluded from selection.
        """
        if max is not None:
            pulumi.set(__self__, "max", max)
        if min is not None:
            pulumi.set(__self__, "min", min)

    @_builtins.property
    @pulumi.getter
    def max(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The maximum baseline Amazon EBS bandwidth in Mbps. Instance types with higher Amazon EBS bandwidth are excluded from selection.
        """
        return pulumi.get(self, "max")

    @max.setter
    def max(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "max", value)

    @_builtins.property
    @pulumi.getter
    def min(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The minimum baseline Amazon EBS bandwidth in Mbps. Instance types with lower Amazon EBS bandwidth are excluded from selection.
        """
        return pulumi.get(self, "min")

    @min.setter
    def min(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "min", value)


if not MYPY:
    class CapacityProviderInstanceLaunchTemplateArgsDict(TypedDict):
        ec2_instance_profile_arn: pulumi.Input[_builtins.str]
        """
        The Amazon Resource Name (ARN) of the instance profile that Amazon ECS applies to Amazon ECS Managed Instances. This instance profile must include the necessary permissions for your tasks to access AWS services and resources.

        For more information, see [Amazon ECS instance profile for Managed Instances](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/managed-instances-instance-profile.html) in the *Amazon ECS Developer Guide* .
        """
        network_configuration: pulumi.Input['CapacityProviderManagedInstancesNetworkConfigurationArgsDict']
        """
        The network configuration for Amazon ECS Managed Instances. This specifies the subnets and security groups that instances use for network connectivity.
        """
        instance_requirements: NotRequired[pulumi.Input['CapacityProviderInstanceRequirementsRequestArgsDict']]
        """
        The instance requirements. You can specify:

        - The instance types
        - Instance requirements such as vCPU count, memory, network performance, and accelerator specifications

        Amazon ECS automatically selects the instances that match the specified criteria.
        """
        monitoring: NotRequired[pulumi.Input['CapacityProviderManagedInstancesMonitoringOptions']]
        """
        CloudWatch provides two categories of monitoring: basic monitoring and detailed monitoring. By default, your managed instance is configured for basic monitoring. You can optionally enable detailed monitoring to help you more quickly identify and act on operational issues. You can enable or turn off detailed monitoring at launch or when the managed instance is running or stopped. For more information, see [Detailed monitoring for Amazon ECS Managed Instances](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/detailed-monitoring-managed-instances.html) in the Amazon ECS Developer Guide.
        """
        storage_configuration: NotRequired[pulumi.Input['CapacityProviderManagedInstancesStorageConfigurationArgsDict']]
        """
        The storage configuration for Amazon ECS Managed Instances. This defines the root volume size and type for the instances.
        """
elif False:
    CapacityProviderInstanceLaunchTemplateArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class CapacityProviderInstanceLaunchTemplateArgs:
    def __init__(__self__, *,
                 ec2_instance_profile_arn: pulumi.Input[_builtins.str],
                 network_configuration: pulumi.Input['CapacityProviderManagedInstancesNetworkConfigurationArgs'],
                 instance_requirements: Optional[pulumi.Input['CapacityProviderInstanceRequirementsRequestArgs']] = None,
                 monitoring: Optional[pulumi.Input['CapacityProviderManagedInstancesMonitoringOptions']] = None,
                 storage_configuration: Optional[pulumi.Input['CapacityProviderManagedInstancesStorageConfigurationArgs']] = None):
        """
        :param pulumi.Input[_builtins.str] ec2_instance_profile_arn: The Amazon Resource Name (ARN) of the instance profile that Amazon ECS applies to Amazon ECS Managed Instances. This instance profile must include the necessary permissions for your tasks to access AWS services and resources.
               
               For more information, see [Amazon ECS instance profile for Managed Instances](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/managed-instances-instance-profile.html) in the *Amazon ECS Developer Guide* .
        :param pulumi.Input['CapacityProviderManagedInstancesNetworkConfigurationArgs'] network_configuration: The network configuration for Amazon ECS Managed Instances. This specifies the subnets and security groups that instances use for network connectivity.
        :param pulumi.Input['CapacityProviderInstanceRequirementsRequestArgs'] instance_requirements: The instance requirements. You can specify:
               
               - The instance types
               - Instance requirements such as vCPU count, memory, network performance, and accelerator specifications
               
               Amazon ECS automatically selects the instances that match the specified criteria.
        :param pulumi.Input['CapacityProviderManagedInstancesMonitoringOptions'] monitoring: CloudWatch provides two categories of monitoring: basic monitoring and detailed monitoring. By default, your managed instance is configured for basic monitoring. You can optionally enable detailed monitoring to help you more quickly identify and act on operational issues. You can enable or turn off detailed monitoring at launch or when the managed instance is running or stopped. For more information, see [Detailed monitoring for Amazon ECS Managed Instances](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/detailed-monitoring-managed-instances.html) in the Amazon ECS Developer Guide.
        :param pulumi.Input['CapacityProviderManagedInstancesStorageConfigurationArgs'] storage_configuration: The storage configuration for Amazon ECS Managed Instances. This defines the root volume size and type for the instances.
        """
        pulumi.set(__self__, "ec2_instance_profile_arn", ec2_instance_profile_arn)
        pulumi.set(__self__, "network_configuration", network_configuration)
        if instance_requirements is not None:
            pulumi.set(__self__, "instance_requirements", instance_requirements)
        if monitoring is not None:
            pulumi.set(__self__, "monitoring", monitoring)
        if storage_configuration is not None:
            pulumi.set(__self__, "storage_configuration", storage_configuration)

    @_builtins.property
    @pulumi.getter(name="ec2InstanceProfileArn")
    def ec2_instance_profile_arn(self) -> pulumi.Input[_builtins.str]:
        """
        The Amazon Resource Name (ARN) of the instance profile that Amazon ECS applies to Amazon ECS Managed Instances. This instance profile must include the necessary permissions for your tasks to access AWS services and resources.

        For more information, see [Amazon ECS instance profile for Managed Instances](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/managed-instances-instance-profile.html) in the *Amazon ECS Developer Guide* .
        """
        return pulumi.get(self, "ec2_instance_profile_arn")

    @ec2_instance_profile_arn.setter
    def ec2_instance_profile_arn(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "ec2_instance_profile_arn", value)

    @_builtins.property
    @pulumi.getter(name="networkConfiguration")
    def network_configuration(self) -> pulumi.Input['CapacityProviderManagedInstancesNetworkConfigurationArgs']:
        """
        The network configuration for Amazon ECS Managed Instances. This specifies the subnets and security groups that instances use for network connectivity.
        """
        return pulumi.get(self, "network_configuration")

    @network_configuration.setter
    def network_configuration(self, value: pulumi.Input['CapacityProviderManagedInstancesNetworkConfigurationArgs']):
        pulumi.set(self, "network_configuration", value)

    @_builtins.property
    @pulumi.getter(name="instanceRequirements")
    def instance_requirements(self) -> Optional[pulumi.Input['CapacityProviderInstanceRequirementsRequestArgs']]:
        """
        The instance requirements. You can specify:

        - The instance types
        - Instance requirements such as vCPU count, memory, network performance, and accelerator specifications

        Amazon ECS automatically selects the instances that match the specified criteria.
        """
        return pulumi.get(self, "instance_requirements")

    @instance_requirements.setter
    def instance_requirements(self, value: Optional[pulumi.Input['CapacityProviderInstanceRequirementsRequestArgs']]):
        pulumi.set(self, "instance_requirements", value)

    @_builtins.property
    @pulumi.getter
    def monitoring(self) -> Optional[pulumi.Input['CapacityProviderManagedInstancesMonitoringOptions']]:
        """
        CloudWatch provides two categories of monitoring: basic monitoring and detailed monitoring. By default, your managed instance is configured for basic monitoring. You can optionally enable detailed monitoring to help you more quickly identify and act on operational issues. You can enable or turn off detailed monitoring at launch or when the managed instance is running or stopped. For more information, see [Detailed monitoring for Amazon ECS Managed Instances](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/detailed-monitoring-managed-instances.html) in the Amazon ECS Developer Guide.
        """
        return pulumi.get(self, "monitoring")

    @monitoring.setter
    def monitoring(self, value: Optional[pulumi.Input['CapacityProviderManagedInstancesMonitoringOptions']]):
        pulumi.set(self, "monitoring", value)

    @_builtins.property
    @pulumi.getter(name="storageConfiguration")
    def storage_configuration(self) -> Optional[pulumi.Input['CapacityProviderManagedInstancesStorageConfigurationArgs']]:
        """
        The storage configuration for Amazon ECS Managed Instances. This defines the root volume size and type for the instances.
        """
        return pulumi.get(self, "storage_configuration")

    @storage_configuration.setter
    def storage_configuration(self, value: Optional[pulumi.Input['CapacityProviderManagedInstancesStorageConfigurationArgs']]):
        pulumi.set(self, "storage_configuration", value)


if not MYPY:
    class CapacityProviderInstanceRequirementsRequestArgsDict(TypedDict):
        memory_mi_b: pulumi.Input['CapacityProviderMemoryMiBRequestArgsDict']
        """
        The minimum and maximum amount of memory in mebibytes (MiB) for the instance types. Amazon ECS selects instance types that have memory within this range.
        """
        v_cpu_count: pulumi.Input['CapacityProviderVCpuCountRangeRequestArgsDict']
        """
        The minimum and maximum number of vCPUs for the instance types. Amazon ECS selects instance types that have vCPU counts within this range.
        """
        accelerator_count: NotRequired[pulumi.Input['CapacityProviderAcceleratorCountRequestArgsDict']]
        """
        The minimum and maximum number of accelerators for the instance types. This is used when you need instances with specific numbers of GPUs or other accelerators.
        """
        accelerator_manufacturers: NotRequired[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestAcceleratorManufacturersItem']]]]
        """
        The accelerator manufacturers to include. You can specify `nvidia` , `amd` , `amazon-web-services` , or `xilinx` depending on your accelerator requirements.
        """
        accelerator_names: NotRequired[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestAcceleratorNamesItem']]]]
        """
        The specific accelerator names to include. For example, you can specify `a100` , `v100` , `k80` , or other specific accelerator models.
        """
        accelerator_total_memory_mi_b: NotRequired[pulumi.Input['CapacityProviderAcceleratorTotalMemoryMiBRequestArgsDict']]
        """
        The minimum and maximum total accelerator memory in mebibytes (MiB). This is important for GPU workloads that require specific amounts of video memory.
        """
        accelerator_types: NotRequired[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestAcceleratorTypesItem']]]]
        """
        The accelerator types to include. You can specify `gpu` for graphics processing units, `fpga` for field programmable gate arrays, or `inference` for machine learning inference accelerators.
        """
        allowed_instance_types: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The instance types to include in the selection. When specified, Amazon ECS only considers these instance types, subject to the other requirements specified.
        """
        bare_metal: NotRequired[pulumi.Input['CapacityProviderInstanceRequirementsRequestBareMetal']]
        """
        Indicates whether to include bare metal instance types. Set to `included` to allow bare metal instances, `excluded` to exclude them, or `required` to use only bare metal instances.
        """
        baseline_ebs_bandwidth_mbps: NotRequired[pulumi.Input['CapacityProviderBaselineEbsBandwidthMbpsRequestArgsDict']]
        """
        The minimum and maximum baseline Amazon EBS bandwidth in megabits per second (Mbps). This is important for workloads with high storage I/O requirements.
        """
        burstable_performance: NotRequired[pulumi.Input['CapacityProviderInstanceRequirementsRequestBurstablePerformance']]
        """
        Indicates whether to include burstable performance instance types (T2, T3, T3a, T4g). Set to `included` to allow burstable instances, `excluded` to exclude them, or `required` to use only burstable instances.
        """
        cpu_manufacturers: NotRequired[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestCpuManufacturersItem']]]]
        """
        The CPU manufacturers to include or exclude. You can specify `intel` , `amd` , or `amazon-web-services` to control which CPU types are used for your workloads.
        """
        excluded_instance_types: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The instance types to exclude from selection. Use this to prevent Amazon ECS from selecting specific instance types that may not be suitable for your workloads.
        """
        instance_generations: NotRequired[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestInstanceGenerationsItem']]]]
        """
        The instance generations to include. You can specify `current` to use the latest generation instances, or `previous` to include previous generation instances for cost optimization.
        """
        local_storage: NotRequired[pulumi.Input['CapacityProviderInstanceRequirementsRequestLocalStorage']]
        """
        Indicates whether to include instance types with local storage. Set to `included` to allow local storage, `excluded` to exclude it, or `required` to use only instances with local storage.
        """
        local_storage_types: NotRequired[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestLocalStorageTypesItem']]]]
        """
        The local storage types to include. You can specify `hdd` for hard disk drives, `ssd` for solid state drives, or both.
        """
        max_spot_price_as_percentage_of_optimal_on_demand_price: NotRequired[pulumi.Input[_builtins.int]]
        """
        The maximum price for Spot instances as a percentage of the optimal On-Demand price. This provides more precise cost control for Spot instance selection.
        """
        memory_gi_b_per_v_cpu: NotRequired[pulumi.Input['CapacityProviderMemoryGiBPerVCpuRequestArgsDict']]
        """
        The minimum and maximum amount of memory per vCPU in gibibytes (GiB). This helps ensure that instance types have the appropriate memory-to-CPU ratio for your workloads.
        """
        network_bandwidth_gbps: NotRequired[pulumi.Input['CapacityProviderNetworkBandwidthGbpsRequestArgsDict']]
        """
        The minimum and maximum network bandwidth in gigabits per second (Gbps). This is crucial for network-intensive workloads that require high throughput.
        """
        network_interface_count: NotRequired[pulumi.Input['CapacityProviderNetworkInterfaceCountRequestArgsDict']]
        """
        The minimum and maximum number of network interfaces for the instance types. This is useful for workloads that require multiple network interfaces.
        """
        on_demand_max_price_percentage_over_lowest_price: NotRequired[pulumi.Input[_builtins.int]]
        """
        The price protection threshold for On-Demand Instances, as a percentage higher than an identified On-Demand price. The identified On-Demand price is the price of the lowest priced current generation C, M, or R instance type with your specified attributes. If no current generation C, M, or R instance type matches your attributes, then the identified price is from either the lowest priced current generation instance types or, failing that, the lowest priced previous generation instance types that match your attributes. When Amazon ECS selects instance types with your attributes, we will exclude instance types whose price exceeds your specified threshold.
        """
        require_hibernate_support: NotRequired[pulumi.Input[_builtins.bool]]
        """
        Indicates whether the instance types must support hibernation. When set to `true` , only instance types that support hibernation are selected.
        """
        spot_max_price_percentage_over_lowest_price: NotRequired[pulumi.Input[_builtins.int]]
        """
        The maximum price for Spot instances as a percentage over the lowest priced On-Demand instance. This helps control Spot instance costs while maintaining access to capacity.
        """
        total_local_storage_gb: NotRequired[pulumi.Input['CapacityProviderTotalLocalStorageGbRequestArgsDict']]
        """
        The minimum and maximum total local storage in gigabytes (GB) for instance types with local storage.
        """
elif False:
    CapacityProviderInstanceRequirementsRequestArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class CapacityProviderInstanceRequirementsRequestArgs:
    def __init__(__self__, *,
                 memory_mi_b: pulumi.Input['CapacityProviderMemoryMiBRequestArgs'],
                 v_cpu_count: pulumi.Input['CapacityProviderVCpuCountRangeRequestArgs'],
                 accelerator_count: Optional[pulumi.Input['CapacityProviderAcceleratorCountRequestArgs']] = None,
                 accelerator_manufacturers: Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestAcceleratorManufacturersItem']]]] = None,
                 accelerator_names: Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestAcceleratorNamesItem']]]] = None,
                 accelerator_total_memory_mi_b: Optional[pulumi.Input['CapacityProviderAcceleratorTotalMemoryMiBRequestArgs']] = None,
                 accelerator_types: Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestAcceleratorTypesItem']]]] = None,
                 allowed_instance_types: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 bare_metal: Optional[pulumi.Input['CapacityProviderInstanceRequirementsRequestBareMetal']] = None,
                 baseline_ebs_bandwidth_mbps: Optional[pulumi.Input['CapacityProviderBaselineEbsBandwidthMbpsRequestArgs']] = None,
                 burstable_performance: Optional[pulumi.Input['CapacityProviderInstanceRequirementsRequestBurstablePerformance']] = None,
                 cpu_manufacturers: Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestCpuManufacturersItem']]]] = None,
                 excluded_instance_types: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 instance_generations: Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestInstanceGenerationsItem']]]] = None,
                 local_storage: Optional[pulumi.Input['CapacityProviderInstanceRequirementsRequestLocalStorage']] = None,
                 local_storage_types: Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestLocalStorageTypesItem']]]] = None,
                 max_spot_price_as_percentage_of_optimal_on_demand_price: Optional[pulumi.Input[_builtins.int]] = None,
                 memory_gi_b_per_v_cpu: Optional[pulumi.Input['CapacityProviderMemoryGiBPerVCpuRequestArgs']] = None,
                 network_bandwidth_gbps: Optional[pulumi.Input['CapacityProviderNetworkBandwidthGbpsRequestArgs']] = None,
                 network_interface_count: Optional[pulumi.Input['CapacityProviderNetworkInterfaceCountRequestArgs']] = None,
                 on_demand_max_price_percentage_over_lowest_price: Optional[pulumi.Input[_builtins.int]] = None,
                 require_hibernate_support: Optional[pulumi.Input[_builtins.bool]] = None,
                 spot_max_price_percentage_over_lowest_price: Optional[pulumi.Input[_builtins.int]] = None,
                 total_local_storage_gb: Optional[pulumi.Input['CapacityProviderTotalLocalStorageGbRequestArgs']] = None):
        """
        :param pulumi.Input['CapacityProviderMemoryMiBRequestArgs'] memory_mi_b: The minimum and maximum amount of memory in mebibytes (MiB) for the instance types. Amazon ECS selects instance types that have memory within this range.
        :param pulumi.Input['CapacityProviderVCpuCountRangeRequestArgs'] v_cpu_count: The minimum and maximum number of vCPUs for the instance types. Amazon ECS selects instance types that have vCPU counts within this range.
        :param pulumi.Input['CapacityProviderAcceleratorCountRequestArgs'] accelerator_count: The minimum and maximum number of accelerators for the instance types. This is used when you need instances with specific numbers of GPUs or other accelerators.
        :param pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestAcceleratorManufacturersItem']]] accelerator_manufacturers: The accelerator manufacturers to include. You can specify `nvidia` , `amd` , `amazon-web-services` , or `xilinx` depending on your accelerator requirements.
        :param pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestAcceleratorNamesItem']]] accelerator_names: The specific accelerator names to include. For example, you can specify `a100` , `v100` , `k80` , or other specific accelerator models.
        :param pulumi.Input['CapacityProviderAcceleratorTotalMemoryMiBRequestArgs'] accelerator_total_memory_mi_b: The minimum and maximum total accelerator memory in mebibytes (MiB). This is important for GPU workloads that require specific amounts of video memory.
        :param pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestAcceleratorTypesItem']]] accelerator_types: The accelerator types to include. You can specify `gpu` for graphics processing units, `fpga` for field programmable gate arrays, or `inference` for machine learning inference accelerators.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] allowed_instance_types: The instance types to include in the selection. When specified, Amazon ECS only considers these instance types, subject to the other requirements specified.
        :param pulumi.Input['CapacityProviderInstanceRequirementsRequestBareMetal'] bare_metal: Indicates whether to include bare metal instance types. Set to `included` to allow bare metal instances, `excluded` to exclude them, or `required` to use only bare metal instances.
        :param pulumi.Input['CapacityProviderBaselineEbsBandwidthMbpsRequestArgs'] baseline_ebs_bandwidth_mbps: The minimum and maximum baseline Amazon EBS bandwidth in megabits per second (Mbps). This is important for workloads with high storage I/O requirements.
        :param pulumi.Input['CapacityProviderInstanceRequirementsRequestBurstablePerformance'] burstable_performance: Indicates whether to include burstable performance instance types (T2, T3, T3a, T4g). Set to `included` to allow burstable instances, `excluded` to exclude them, or `required` to use only burstable instances.
        :param pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestCpuManufacturersItem']]] cpu_manufacturers: The CPU manufacturers to include or exclude. You can specify `intel` , `amd` , or `amazon-web-services` to control which CPU types are used for your workloads.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] excluded_instance_types: The instance types to exclude from selection. Use this to prevent Amazon ECS from selecting specific instance types that may not be suitable for your workloads.
        :param pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestInstanceGenerationsItem']]] instance_generations: The instance generations to include. You can specify `current` to use the latest generation instances, or `previous` to include previous generation instances for cost optimization.
        :param pulumi.Input['CapacityProviderInstanceRequirementsRequestLocalStorage'] local_storage: Indicates whether to include instance types with local storage. Set to `included` to allow local storage, `excluded` to exclude it, or `required` to use only instances with local storage.
        :param pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestLocalStorageTypesItem']]] local_storage_types: The local storage types to include. You can specify `hdd` for hard disk drives, `ssd` for solid state drives, or both.
        :param pulumi.Input[_builtins.int] max_spot_price_as_percentage_of_optimal_on_demand_price: The maximum price for Spot instances as a percentage of the optimal On-Demand price. This provides more precise cost control for Spot instance selection.
        :param pulumi.Input['CapacityProviderMemoryGiBPerVCpuRequestArgs'] memory_gi_b_per_v_cpu: The minimum and maximum amount of memory per vCPU in gibibytes (GiB). This helps ensure that instance types have the appropriate memory-to-CPU ratio for your workloads.
        :param pulumi.Input['CapacityProviderNetworkBandwidthGbpsRequestArgs'] network_bandwidth_gbps: The minimum and maximum network bandwidth in gigabits per second (Gbps). This is crucial for network-intensive workloads that require high throughput.
        :param pulumi.Input['CapacityProviderNetworkInterfaceCountRequestArgs'] network_interface_count: The minimum and maximum number of network interfaces for the instance types. This is useful for workloads that require multiple network interfaces.
        :param pulumi.Input[_builtins.int] on_demand_max_price_percentage_over_lowest_price: The price protection threshold for On-Demand Instances, as a percentage higher than an identified On-Demand price. The identified On-Demand price is the price of the lowest priced current generation C, M, or R instance type with your specified attributes. If no current generation C, M, or R instance type matches your attributes, then the identified price is from either the lowest priced current generation instance types or, failing that, the lowest priced previous generation instance types that match your attributes. When Amazon ECS selects instance types with your attributes, we will exclude instance types whose price exceeds your specified threshold.
        :param pulumi.Input[_builtins.bool] require_hibernate_support: Indicates whether the instance types must support hibernation. When set to `true` , only instance types that support hibernation are selected.
        :param pulumi.Input[_builtins.int] spot_max_price_percentage_over_lowest_price: The maximum price for Spot instances as a percentage over the lowest priced On-Demand instance. This helps control Spot instance costs while maintaining access to capacity.
        :param pulumi.Input['CapacityProviderTotalLocalStorageGbRequestArgs'] total_local_storage_gb: The minimum and maximum total local storage in gigabytes (GB) for instance types with local storage.
        """
        pulumi.set(__self__, "memory_mi_b", memory_mi_b)
        pulumi.set(__self__, "v_cpu_count", v_cpu_count)
        if accelerator_count is not None:
            pulumi.set(__self__, "accelerator_count", accelerator_count)
        if accelerator_manufacturers is not None:
            pulumi.set(__self__, "accelerator_manufacturers", accelerator_manufacturers)
        if accelerator_names is not None:
            pulumi.set(__self__, "accelerator_names", accelerator_names)
        if accelerator_total_memory_mi_b is not None:
            pulumi.set(__self__, "accelerator_total_memory_mi_b", accelerator_total_memory_mi_b)
        if accelerator_types is not None:
            pulumi.set(__self__, "accelerator_types", accelerator_types)
        if allowed_instance_types is not None:
            pulumi.set(__self__, "allowed_instance_types", allowed_instance_types)
        if bare_metal is not None:
            pulumi.set(__self__, "bare_metal", bare_metal)
        if baseline_ebs_bandwidth_mbps is not None:
            pulumi.set(__self__, "baseline_ebs_bandwidth_mbps", baseline_ebs_bandwidth_mbps)
        if burstable_performance is not None:
            pulumi.set(__self__, "burstable_performance", burstable_performance)
        if cpu_manufacturers is not None:
            pulumi.set(__self__, "cpu_manufacturers", cpu_manufacturers)
        if excluded_instance_types is not None:
            pulumi.set(__self__, "excluded_instance_types", excluded_instance_types)
        if instance_generations is not None:
            pulumi.set(__self__, "instance_generations", instance_generations)
        if local_storage is not None:
            pulumi.set(__self__, "local_storage", local_storage)
        if local_storage_types is not None:
            pulumi.set(__self__, "local_storage_types", local_storage_types)
        if max_spot_price_as_percentage_of_optimal_on_demand_price is not None:
            pulumi.set(__self__, "max_spot_price_as_percentage_of_optimal_on_demand_price", max_spot_price_as_percentage_of_optimal_on_demand_price)
        if memory_gi_b_per_v_cpu is not None:
            pulumi.set(__self__, "memory_gi_b_per_v_cpu", memory_gi_b_per_v_cpu)
        if network_bandwidth_gbps is not None:
            pulumi.set(__self__, "network_bandwidth_gbps", network_bandwidth_gbps)
        if network_interface_count is not None:
            pulumi.set(__self__, "network_interface_count", network_interface_count)
        if on_demand_max_price_percentage_over_lowest_price is not None:
            pulumi.set(__self__, "on_demand_max_price_percentage_over_lowest_price", on_demand_max_price_percentage_over_lowest_price)
        if require_hibernate_support is not None:
            pulumi.set(__self__, "require_hibernate_support", require_hibernate_support)
        if spot_max_price_percentage_over_lowest_price is not None:
            pulumi.set(__self__, "spot_max_price_percentage_over_lowest_price", spot_max_price_percentage_over_lowest_price)
        if total_local_storage_gb is not None:
            pulumi.set(__self__, "total_local_storage_gb", total_local_storage_gb)

    @_builtins.property
    @pulumi.getter(name="memoryMiB")
    def memory_mi_b(self) -> pulumi.Input['CapacityProviderMemoryMiBRequestArgs']:
        """
        The minimum and maximum amount of memory in mebibytes (MiB) for the instance types. Amazon ECS selects instance types that have memory within this range.
        """
        return pulumi.get(self, "memory_mi_b")

    @memory_mi_b.setter
    def memory_mi_b(self, value: pulumi.Input['CapacityProviderMemoryMiBRequestArgs']):
        pulumi.set(self, "memory_mi_b", value)

    @_builtins.property
    @pulumi.getter(name="vCpuCount")
    def v_cpu_count(self) -> pulumi.Input['CapacityProviderVCpuCountRangeRequestArgs']:
        """
        The minimum and maximum number of vCPUs for the instance types. Amazon ECS selects instance types that have vCPU counts within this range.
        """
        return pulumi.get(self, "v_cpu_count")

    @v_cpu_count.setter
    def v_cpu_count(self, value: pulumi.Input['CapacityProviderVCpuCountRangeRequestArgs']):
        pulumi.set(self, "v_cpu_count", value)

    @_builtins.property
    @pulumi.getter(name="acceleratorCount")
    def accelerator_count(self) -> Optional[pulumi.Input['CapacityProviderAcceleratorCountRequestArgs']]:
        """
        The minimum and maximum number of accelerators for the instance types. This is used when you need instances with specific numbers of GPUs or other accelerators.
        """
        return pulumi.get(self, "accelerator_count")

    @accelerator_count.setter
    def accelerator_count(self, value: Optional[pulumi.Input['CapacityProviderAcceleratorCountRequestArgs']]):
        pulumi.set(self, "accelerator_count", value)

    @_builtins.property
    @pulumi.getter(name="acceleratorManufacturers")
    def accelerator_manufacturers(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestAcceleratorManufacturersItem']]]]:
        """
        The accelerator manufacturers to include. You can specify `nvidia` , `amd` , `amazon-web-services` , or `xilinx` depending on your accelerator requirements.
        """
        return pulumi.get(self, "accelerator_manufacturers")

    @accelerator_manufacturers.setter
    def accelerator_manufacturers(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestAcceleratorManufacturersItem']]]]):
        pulumi.set(self, "accelerator_manufacturers", value)

    @_builtins.property
    @pulumi.getter(name="acceleratorNames")
    def accelerator_names(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestAcceleratorNamesItem']]]]:
        """
        The specific accelerator names to include. For example, you can specify `a100` , `v100` , `k80` , or other specific accelerator models.
        """
        return pulumi.get(self, "accelerator_names")

    @accelerator_names.setter
    def accelerator_names(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestAcceleratorNamesItem']]]]):
        pulumi.set(self, "accelerator_names", value)

    @_builtins.property
    @pulumi.getter(name="acceleratorTotalMemoryMiB")
    def accelerator_total_memory_mi_b(self) -> Optional[pulumi.Input['CapacityProviderAcceleratorTotalMemoryMiBRequestArgs']]:
        """
        The minimum and maximum total accelerator memory in mebibytes (MiB). This is important for GPU workloads that require specific amounts of video memory.
        """
        return pulumi.get(self, "accelerator_total_memory_mi_b")

    @accelerator_total_memory_mi_b.setter
    def accelerator_total_memory_mi_b(self, value: Optional[pulumi.Input['CapacityProviderAcceleratorTotalMemoryMiBRequestArgs']]):
        pulumi.set(self, "accelerator_total_memory_mi_b", value)

    @_builtins.property
    @pulumi.getter(name="acceleratorTypes")
    def accelerator_types(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestAcceleratorTypesItem']]]]:
        """
        The accelerator types to include. You can specify `gpu` for graphics processing units, `fpga` for field programmable gate arrays, or `inference` for machine learning inference accelerators.
        """
        return pulumi.get(self, "accelerator_types")

    @accelerator_types.setter
    def accelerator_types(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestAcceleratorTypesItem']]]]):
        pulumi.set(self, "accelerator_types", value)

    @_builtins.property
    @pulumi.getter(name="allowedInstanceTypes")
    def allowed_instance_types(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The instance types to include in the selection. When specified, Amazon ECS only considers these instance types, subject to the other requirements specified.
        """
        return pulumi.get(self, "allowed_instance_types")

    @allowed_instance_types.setter
    def allowed_instance_types(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "allowed_instance_types", value)

    @_builtins.property
    @pulumi.getter(name="bareMetal")
    def bare_metal(self) -> Optional[pulumi.Input['CapacityProviderInstanceRequirementsRequestBareMetal']]:
        """
        Indicates whether to include bare metal instance types. Set to `included` to allow bare metal instances, `excluded` to exclude them, or `required` to use only bare metal instances.
        """
        return pulumi.get(self, "bare_metal")

    @bare_metal.setter
    def bare_metal(self, value: Optional[pulumi.Input['CapacityProviderInstanceRequirementsRequestBareMetal']]):
        pulumi.set(self, "bare_metal", value)

    @_builtins.property
    @pulumi.getter(name="baselineEbsBandwidthMbps")
    def baseline_ebs_bandwidth_mbps(self) -> Optional[pulumi.Input['CapacityProviderBaselineEbsBandwidthMbpsRequestArgs']]:
        """
        The minimum and maximum baseline Amazon EBS bandwidth in megabits per second (Mbps). This is important for workloads with high storage I/O requirements.
        """
        return pulumi.get(self, "baseline_ebs_bandwidth_mbps")

    @baseline_ebs_bandwidth_mbps.setter
    def baseline_ebs_bandwidth_mbps(self, value: Optional[pulumi.Input['CapacityProviderBaselineEbsBandwidthMbpsRequestArgs']]):
        pulumi.set(self, "baseline_ebs_bandwidth_mbps", value)

    @_builtins.property
    @pulumi.getter(name="burstablePerformance")
    def burstable_performance(self) -> Optional[pulumi.Input['CapacityProviderInstanceRequirementsRequestBurstablePerformance']]:
        """
        Indicates whether to include burstable performance instance types (T2, T3, T3a, T4g). Set to `included` to allow burstable instances, `excluded` to exclude them, or `required` to use only burstable instances.
        """
        return pulumi.get(self, "burstable_performance")

    @burstable_performance.setter
    def burstable_performance(self, value: Optional[pulumi.Input['CapacityProviderInstanceRequirementsRequestBurstablePerformance']]):
        pulumi.set(self, "burstable_performance", value)

    @_builtins.property
    @pulumi.getter(name="cpuManufacturers")
    def cpu_manufacturers(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestCpuManufacturersItem']]]]:
        """
        The CPU manufacturers to include or exclude. You can specify `intel` , `amd` , or `amazon-web-services` to control which CPU types are used for your workloads.
        """
        return pulumi.get(self, "cpu_manufacturers")

    @cpu_manufacturers.setter
    def cpu_manufacturers(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestCpuManufacturersItem']]]]):
        pulumi.set(self, "cpu_manufacturers", value)

    @_builtins.property
    @pulumi.getter(name="excludedInstanceTypes")
    def excluded_instance_types(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The instance types to exclude from selection. Use this to prevent Amazon ECS from selecting specific instance types that may not be suitable for your workloads.
        """
        return pulumi.get(self, "excluded_instance_types")

    @excluded_instance_types.setter
    def excluded_instance_types(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "excluded_instance_types", value)

    @_builtins.property
    @pulumi.getter(name="instanceGenerations")
    def instance_generations(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestInstanceGenerationsItem']]]]:
        """
        The instance generations to include. You can specify `current` to use the latest generation instances, or `previous` to include previous generation instances for cost optimization.
        """
        return pulumi.get(self, "instance_generations")

    @instance_generations.setter
    def instance_generations(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestInstanceGenerationsItem']]]]):
        pulumi.set(self, "instance_generations", value)

    @_builtins.property
    @pulumi.getter(name="localStorage")
    def local_storage(self) -> Optional[pulumi.Input['CapacityProviderInstanceRequirementsRequestLocalStorage']]:
        """
        Indicates whether to include instance types with local storage. Set to `included` to allow local storage, `excluded` to exclude it, or `required` to use only instances with local storage.
        """
        return pulumi.get(self, "local_storage")

    @local_storage.setter
    def local_storage(self, value: Optional[pulumi.Input['CapacityProviderInstanceRequirementsRequestLocalStorage']]):
        pulumi.set(self, "local_storage", value)

    @_builtins.property
    @pulumi.getter(name="localStorageTypes")
    def local_storage_types(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestLocalStorageTypesItem']]]]:
        """
        The local storage types to include. You can specify `hdd` for hard disk drives, `ssd` for solid state drives, or both.
        """
        return pulumi.get(self, "local_storage_types")

    @local_storage_types.setter
    def local_storage_types(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['CapacityProviderInstanceRequirementsRequestLocalStorageTypesItem']]]]):
        pulumi.set(self, "local_storage_types", value)

    @_builtins.property
    @pulumi.getter(name="maxSpotPriceAsPercentageOfOptimalOnDemandPrice")
    def max_spot_price_as_percentage_of_optimal_on_demand_price(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The maximum price for Spot instances as a percentage of the optimal On-Demand price. This provides more precise cost control for Spot instance selection.
        """
        return pulumi.get(self, "max_spot_price_as_percentage_of_optimal_on_demand_price")

    @max_spot_price_as_percentage_of_optimal_on_demand_price.setter
    def max_spot_price_as_percentage_of_optimal_on_demand_price(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "max_spot_price_as_percentage_of_optimal_on_demand_price", value)

    @_builtins.property
    @pulumi.getter(name="memoryGiBPerVCpu")
    def memory_gi_b_per_v_cpu(self) -> Optional[pulumi.Input['CapacityProviderMemoryGiBPerVCpuRequestArgs']]:
        """
        The minimum and maximum amount of memory per vCPU in gibibytes (GiB). This helps ensure that instance types have the appropriate memory-to-CPU ratio for your workloads.
        """
        return pulumi.get(self, "memory_gi_b_per_v_cpu")

    @memory_gi_b_per_v_cpu.setter
    def memory_gi_b_per_v_cpu(self, value: Optional[pulumi.Input['CapacityProviderMemoryGiBPerVCpuRequestArgs']]):
        pulumi.set(self, "memory_gi_b_per_v_cpu", value)

    @_builtins.property
    @pulumi.getter(name="networkBandwidthGbps")
    def network_bandwidth_gbps(self) -> Optional[pulumi.Input['CapacityProviderNetworkBandwidthGbpsRequestArgs']]:
        """
        The minimum and maximum network bandwidth in gigabits per second (Gbps). This is crucial for network-intensive workloads that require high throughput.
        """
        return pulumi.get(self, "network_bandwidth_gbps")

    @network_bandwidth_gbps.setter
    def network_bandwidth_gbps(self, value: Optional[pulumi.Input['CapacityProviderNetworkBandwidthGbpsRequestArgs']]):
        pulumi.set(self, "network_bandwidth_gbps", value)

    @_builtins.property
    @pulumi.getter(name="networkInterfaceCount")
    def network_interface_count(self) -> Optional[pulumi.Input['CapacityProviderNetworkInterfaceCountRequestArgs']]:
        """
        The minimum and maximum number of network interfaces for the instance types. This is useful for workloads that require multiple network interfaces.
        """
        return pulumi.get(self, "network_interface_count")

    @network_interface_count.setter
    def network_interface_count(self, value: Optional[pulumi.Input['CapacityProviderNetworkInterfaceCountRequestArgs']]):
        pulumi.set(self, "network_interface_count", value)

    @_builtins.property
    @pulumi.getter(name="onDemandMaxPricePercentageOverLowestPrice")
    def on_demand_max_price_percentage_over_lowest_price(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The price protection threshold for On-Demand Instances, as a percentage higher than an identified On-Demand price. The identified On-Demand price is the price of the lowest priced current generation C, M, or R instance type with your specified attributes. If no current generation C, M, or R instance type matches your attributes, then the identified price is from either the lowest priced current generation instance types or, failing that, the lowest priced previous generation instance types that match your attributes. When Amazon ECS selects instance types with your attributes, we will exclude instance types whose price exceeds your specified threshold.
        """
        return pulumi.get(self, "on_demand_max_price_percentage_over_lowest_price")

    @on_demand_max_price_percentage_over_lowest_price.setter
    def on_demand_max_price_percentage_over_lowest_price(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "on_demand_max_price_percentage_over_lowest_price", value)

    @_builtins.property
    @pulumi.getter(name="requireHibernateSupport")
    def require_hibernate_support(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Indicates whether the instance types must support hibernation. When set to `true` , only instance types that support hibernation are selected.
        """
        return pulumi.get(self, "require_hibernate_support")

    @require_hibernate_support.setter
    def require_hibernate_support(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "require_hibernate_support", value)

    @_builtins.property
    @pulumi.getter(name="spotMaxPricePercentageOverLowestPrice")
    def spot_max_price_percentage_over_lowest_price(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The maximum price for Spot instances as a percentage over the lowest priced On-Demand instance. This helps control Spot instance costs while maintaining access to capacity.
        """
        return pulumi.get(self, "spot_max_price_percentage_over_lowest_price")

    @spot_max_price_percentage_over_lowest_price.setter
    def spot_max_price_percentage_over_lowest_price(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "spot_max_price_percentage_over_lowest_price", value)

    @_builtins.property
    @pulumi.getter(name="totalLocalStorageGb")
    def total_local_storage_gb(self) -> Optional[pulumi.Input['CapacityProviderTotalLocalStorageGbRequestArgs']]:
        """
        The minimum and maximum total local storage in gigabytes (GB) for instance types with local storage.
        """
        return pulumi.get(self, "total_local_storage_gb")

    @total_local_storage_gb.setter
    def total_local_storage_gb(self, value: Optional[pulumi.Input['CapacityProviderTotalLocalStorageGbRequestArgs']]):
        pulumi.set(self, "total_local_storage_gb", value)


if not MYPY:
    class CapacityProviderManagedInstancesNetworkConfigurationArgsDict(TypedDict):
        subnets: pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]
        """
        The list of subnet IDs where Amazon ECS can launch Amazon ECS Managed Instances. Instances are distributed across the specified subnets for high availability. All subnets must be in the same VPC.
        """
        security_groups: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The list of security group IDs to apply to Amazon ECS Managed Instances. These security groups control the network traffic allowed to and from the instances.
        """
elif False:
    CapacityProviderManagedInstancesNetworkConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class CapacityProviderManagedInstancesNetworkConfigurationArgs:
    def __init__(__self__, *,
                 subnets: pulumi.Input[Sequence[pulumi.Input[_builtins.str]]],
                 security_groups: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] subnets: The list of subnet IDs where Amazon ECS can launch Amazon ECS Managed Instances. Instances are distributed across the specified subnets for high availability. All subnets must be in the same VPC.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] security_groups: The list of security group IDs to apply to Amazon ECS Managed Instances. These security groups control the network traffic allowed to and from the instances.
        """
        pulumi.set(__self__, "subnets", subnets)
        if security_groups is not None:
            pulumi.set(__self__, "security_groups", security_groups)

    @_builtins.property
    @pulumi.getter
    def subnets(self) -> pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]:
        """
        The list of subnet IDs where Amazon ECS can launch Amazon ECS Managed Instances. Instances are distributed across the specified subnets for high availability. All subnets must be in the same VPC.
        """
        return pulumi.get(self, "subnets")

    @subnets.setter
    def subnets(self, value: pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]):
        pulumi.set(self, "subnets", value)

    @_builtins.property
    @pulumi.getter(name="securityGroups")
    def security_groups(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The list of security group IDs to apply to Amazon ECS Managed Instances. These security groups control the network traffic allowed to and from the instances.
        """
        return pulumi.get(self, "security_groups")

    @security_groups.setter
    def security_groups(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "security_groups", value)


if not MYPY:
    class CapacityProviderManagedInstancesProviderArgsDict(TypedDict):
        infrastructure_role_arn: pulumi.Input[_builtins.str]
        """
        The Amazon Resource Name (ARN) of the infrastructure role that Amazon ECS assumes to manage instances. This role must include permissions for Amazon EC2 instance lifecycle management, networking, and any additional AWS services required for your workloads.

        For more information, see [Amazon ECS infrastructure IAM role](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/infrastructure_IAM_role.html) in the *Amazon ECS Developer Guide* .
        """
        instance_launch_template: pulumi.Input['CapacityProviderInstanceLaunchTemplateArgsDict']
        """
        The launch template that defines how Amazon ECS launches Amazon ECS Managed Instances. This includes the instance profile for your tasks, network and storage configuration, and instance requirements that determine which Amazon EC2 instance types can be used.

        For more information, see [Store instance launch parameters in Amazon EC2 launch templates](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-launch-templates.html) in the *Amazon EC2 User Guide* .
        """
        propagate_tags: NotRequired[pulumi.Input['CapacityProviderManagedInstancesProviderPropagateTags']]
        """
        Determines whether tags from the capacity provider are automatically applied to Amazon ECS Managed Instances. This helps with cost allocation and resource management by ensuring consistent tagging across your infrastructure.
        """
elif False:
    CapacityProviderManagedInstancesProviderArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class CapacityProviderManagedInstancesProviderArgs:
    def __init__(__self__, *,
                 infrastructure_role_arn: pulumi.Input[_builtins.str],
                 instance_launch_template: pulumi.Input['CapacityProviderInstanceLaunchTemplateArgs'],
                 propagate_tags: Optional[pulumi.Input['CapacityProviderManagedInstancesProviderPropagateTags']] = None):
        """
        :param pulumi.Input[_builtins.str] infrastructure_role_arn: The Amazon Resource Name (ARN) of the infrastructure role that Amazon ECS assumes to manage instances. This role must include permissions for Amazon EC2 instance lifecycle management, networking, and any additional AWS services required for your workloads.
               
               For more information, see [Amazon ECS infrastructure IAM role](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/infrastructure_IAM_role.html) in the *Amazon ECS Developer Guide* .
        :param pulumi.Input['CapacityProviderInstanceLaunchTemplateArgs'] instance_launch_template: The launch template that defines how Amazon ECS launches Amazon ECS Managed Instances. This includes the instance profile for your tasks, network and storage configuration, and instance requirements that determine which Amazon EC2 instance types can be used.
               
               For more information, see [Store instance launch parameters in Amazon EC2 launch templates](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-launch-templates.html) in the *Amazon EC2 User Guide* .
        :param pulumi.Input['CapacityProviderManagedInstancesProviderPropagateTags'] propagate_tags: Determines whether tags from the capacity provider are automatically applied to Amazon ECS Managed Instances. This helps with cost allocation and resource management by ensuring consistent tagging across your infrastructure.
        """
        pulumi.set(__self__, "infrastructure_role_arn", infrastructure_role_arn)
        pulumi.set(__self__, "instance_launch_template", instance_launch_template)
        if propagate_tags is not None:
            pulumi.set(__self__, "propagate_tags", propagate_tags)

    @_builtins.property
    @pulumi.getter(name="infrastructureRoleArn")
    def infrastructure_role_arn(self) -> pulumi.Input[_builtins.str]:
        """
        The Amazon Resource Name (ARN) of the infrastructure role that Amazon ECS assumes to manage instances. This role must include permissions for Amazon EC2 instance lifecycle management, networking, and any additional AWS services required for your workloads.

        For more information, see [Amazon ECS infrastructure IAM role](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/infrastructure_IAM_role.html) in the *Amazon ECS Developer Guide* .
        """
        return pulumi.get(self, "infrastructure_role_arn")

    @infrastructure_role_arn.setter
    def infrastructure_role_arn(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "infrastructure_role_arn", value)

    @_builtins.property
    @pulumi.getter(name="instanceLaunchTemplate")
    def instance_launch_template(self) -> pulumi.Input['CapacityProviderInstanceLaunchTemplateArgs']:
        """
        The launch template that defines how Amazon ECS launches Amazon ECS Managed Instances. This includes the instance profile for your tasks, network and storage configuration, and instance requirements that determine which Amazon EC2 instance types can be used.

        For more information, see [Store instance launch parameters in Amazon EC2 launch templates](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-launch-templates.html) in the *Amazon EC2 User Guide* .
        """
        return pulumi.get(self, "instance_launch_template")

    @instance_launch_template.setter
    def instance_launch_template(self, value: pulumi.Input['CapacityProviderInstanceLaunchTemplateArgs']):
        pulumi.set(self, "instance_launch_template", value)

    @_builtins.property
    @pulumi.getter(name="propagateTags")
    def propagate_tags(self) -> Optional[pulumi.Input['CapacityProviderManagedInstancesProviderPropagateTags']]:
        """
        Determines whether tags from the capacity provider are automatically applied to Amazon ECS Managed Instances. This helps with cost allocation and resource management by ensuring consistent tagging across your infrastructure.
        """
        return pulumi.get(self, "propagate_tags")

    @propagate_tags.setter
    def propagate_tags(self, value: Optional[pulumi.Input['CapacityProviderManagedInstancesProviderPropagateTags']]):
        pulumi.set(self, "propagate_tags", value)


if not MYPY:
    class CapacityProviderManagedInstancesStorageConfigurationArgsDict(TypedDict):
        storage_size_gi_b: pulumi.Input[_builtins.int]
        """
        The size of the tasks volume.
        """
elif False:
    CapacityProviderManagedInstancesStorageConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class CapacityProviderManagedInstancesStorageConfigurationArgs:
    def __init__(__self__, *,
                 storage_size_gi_b: pulumi.Input[_builtins.int]):
        """
        :param pulumi.Input[_builtins.int] storage_size_gi_b: The size of the tasks volume.
        """
        pulumi.set(__self__, "storage_size_gi_b", storage_size_gi_b)

    @_builtins.property
    @pulumi.getter(name="storageSizeGiB")
    def storage_size_gi_b(self) -> pulumi.Input[_builtins.int]:
        """
        The size of the tasks volume.
        """
        return pulumi.get(self, "storage_size_gi_b")

    @storage_size_gi_b.setter
    def storage_size_gi_b(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "storage_size_gi_b", value)


if not MYPY:
    class CapacityProviderManagedScalingArgsDict(TypedDict):
        """
        The managed scaling settings for the Auto Scaling group capacity provider.
        """
        instance_warmup_period: NotRequired[pulumi.Input[_builtins.int]]
        """
        The period of time, in seconds, after a newly launched Amazon EC2 instance can contribute to CloudWatch metrics for Auto Scaling group. If this parameter is omitted, the default value of `300` seconds is used.
        """
        maximum_scaling_step_size: NotRequired[pulumi.Input[_builtins.int]]
        """
        The maximum number of Amazon EC2 instances that Amazon ECS will scale out at one time. If this parameter is omitted, the default value of `10000` is used.
        """
        minimum_scaling_step_size: NotRequired[pulumi.Input[_builtins.int]]
        """
        The minimum number of Amazon EC2 instances that Amazon ECS will scale out at one time. The scale in process is not affected by this parameter If this parameter is omitted, the default value of `1` is used.

        When additional capacity is required, Amazon ECS will scale up the minimum scaling step size even if the actual demand is less than the minimum scaling step size.
        """
        status: NotRequired[pulumi.Input['CapacityProviderManagedScalingStatus']]
        """
        Determines whether to use managed scaling for the capacity provider.
        """
        target_capacity: NotRequired[pulumi.Input[_builtins.int]]
        """
        The target capacity utilization as a percentage for the capacity provider. The specified value must be greater than `0` and less than or equal to `100` . For example, if you want the capacity provider to maintain 10% spare capacity, then that means the utilization is 90%, so use a `targetCapacity` of `90` . The default value of `100` percent results in the Amazon EC2 instances in your Auto Scaling group being completely used.
        """
elif False:
    CapacityProviderManagedScalingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class CapacityProviderManagedScalingArgs:
    def __init__(__self__, *,
                 instance_warmup_period: Optional[pulumi.Input[_builtins.int]] = None,
                 maximum_scaling_step_size: Optional[pulumi.Input[_builtins.int]] = None,
                 minimum_scaling_step_size: Optional[pulumi.Input[_builtins.int]] = None,
                 status: Optional[pulumi.Input['CapacityProviderManagedScalingStatus']] = None,
                 target_capacity: Optional[pulumi.Input[_builtins.int]] = None):
        """
        The managed scaling settings for the Auto Scaling group capacity provider.
        :param pulumi.Input[_builtins.int] instance_warmup_period: The period of time, in seconds, after a newly launched Amazon EC2 instance can contribute to CloudWatch metrics for Auto Scaling group. If this parameter is omitted, the default value of `300` seconds is used.
        :param pulumi.Input[_builtins.int] maximum_scaling_step_size: The maximum number of Amazon EC2 instances that Amazon ECS will scale out at one time. If this parameter is omitted, the default value of `10000` is used.
        :param pulumi.Input[_builtins.int] minimum_scaling_step_size: The minimum number of Amazon EC2 instances that Amazon ECS will scale out at one time. The scale in process is not affected by this parameter If this parameter is omitted, the default value of `1` is used.
               
               When additional capacity is required, Amazon ECS will scale up the minimum scaling step size even if the actual demand is less than the minimum scaling step size.
        :param pulumi.Input['CapacityProviderManagedScalingStatus'] status: Determines whether to use managed scaling for the capacity provider.
        :param pulumi.Input[_builtins.int] target_capacity: The target capacity utilization as a percentage for the capacity provider. The specified value must be greater than `0` and less than or equal to `100` . For example, if you want the capacity provider to maintain 10% spare capacity, then that means the utilization is 90%, so use a `targetCapacity` of `90` . The default value of `100` percent results in the Amazon EC2 instances in your Auto Scaling group being completely used.
        """
        if instance_warmup_period is not None:
            pulumi.set(__self__, "instance_warmup_period", instance_warmup_period)
        if maximum_scaling_step_size is not None:
            pulumi.set(__self__, "maximum_scaling_step_size", maximum_scaling_step_size)
        if minimum_scaling_step_size is not None:
            pulumi.set(__self__, "minimum_scaling_step_size", minimum_scaling_step_size)
        if status is not None:
            pulumi.set(__self__, "status", status)
        if target_capacity is not None:
            pulumi.set(__self__, "target_capacity", target_capacity)

    @_builtins.property
    @pulumi.getter(name="instanceWarmupPeriod")
    def instance_warmup_period(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The period of time, in seconds, after a newly launched Amazon EC2 instance can contribute to CloudWatch metrics for Auto Scaling group. If this parameter is omitted, the default value of `300` seconds is used.
        """
        return pulumi.get(self, "instance_warmup_period")

    @instance_warmup_period.setter
    def instance_warmup_period(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "instance_warmup_period", value)

    @_builtins.property
    @pulumi.getter(name="maximumScalingStepSize")
    def maximum_scaling_step_size(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The maximum number of Amazon EC2 instances that Amazon ECS will scale out at one time. If this parameter is omitted, the default value of `10000` is used.
        """
        return pulumi.get(self, "maximum_scaling_step_size")

    @maximum_scaling_step_size.setter
    def maximum_scaling_step_size(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "maximum_scaling_step_size", value)

    @_builtins.property
    @pulumi.getter(name="minimumScalingStepSize")
    def minimum_scaling_step_size(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The minimum number of Amazon EC2 instances that Amazon ECS will scale out at one time. The scale in process is not affected by this parameter If this parameter is omitted, the default value of `1` is used.

        When additional capacity is required, Amazon ECS will scale up the minimum scaling step size even if the actual demand is less than the minimum scaling step size.
        """
        return pulumi.get(self, "minimum_scaling_step_size")

    @minimum_scaling_step_size.setter
    def minimum_scaling_step_size(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "minimum_scaling_step_size", value)

    @_builtins.property
    @pulumi.getter
    def status(self) -> Optional[pulumi.Input['CapacityProviderManagedScalingStatus']]:
        """
        Determines whether to use managed scaling for the capacity provider.
        """
        return pulumi.get(self, "status")

    @status.setter
    def status(self, value: Optional[pulumi.Input['CapacityProviderManagedScalingStatus']]):
        pulumi.set(self, "status", value)

    @_builtins.property
    @pulumi.getter(name="targetCapacity")
    def target_capacity(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The target capacity utilization as a percentage for the capacity provider. The specified value must be greater than `0` and less than or equal to `100` . For example, if you want the capacity provider to maintain 10% spare capacity, then that means the utilization is 90%, so use a `targetCapacity` of `90` . The default value of `100` percent results in the Amazon EC2 instances in your Auto Scaling group being completely used.
        """
        return pulumi.get(self, "target_capacity")

    @target_capacity.setter
    def target_capacity(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "target_capacity", value)


if not MYPY:
    class CapacityProviderMemoryGiBPerVCpuRequestArgsDict(TypedDict):
        max: NotRequired[pulumi.Input[_builtins.float]]
        """
        The maximum amount of memory per vCPU in GiB. Instance types with a higher memory-to-vCPU ratio are excluded from selection.
        """
        min: NotRequired[pulumi.Input[_builtins.float]]
        """
        The minimum amount of memory per vCPU in GiB. Instance types with a lower memory-to-vCPU ratio are excluded from selection.
        """
elif False:
    CapacityProviderMemoryGiBPerVCpuRequestArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class CapacityProviderMemoryGiBPerVCpuRequestArgs:
    def __init__(__self__, *,
                 max: Optional[pulumi.Input[_builtins.float]] = None,
                 min: Optional[pulumi.Input[_builtins.float]] = None):
        """
        :param pulumi.Input[_builtins.float] max: The maximum amount of memory per vCPU in GiB. Instance types with a higher memory-to-vCPU ratio are excluded from selection.
        :param pulumi.Input[_builtins.float] min: The minimum amount of memory per vCPU in GiB. Instance types with a lower memory-to-vCPU ratio are excluded from selection.
        """
        if max is not None:
            pulumi.set(__self__, "max", max)
        if min is not None:
            pulumi.set(__self__, "min", min)

    @_builtins.property
    @pulumi.getter
    def max(self) -> Optional[pulumi.Input[_builtins.float]]:
        """
        The maximum amount of memory per vCPU in GiB. Instance types with a higher memory-to-vCPU ratio are excluded from selection.
        """
        return pulumi.get(self, "max")

    @max.setter
    def max(self, value: Optional[pulumi.Input[_builtins.float]]):
        pulumi.set(self, "max", value)

    @_builtins.property
    @pulumi.getter
    def min(self) -> Optional[pulumi.Input[_builtins.float]]:
        """
        The minimum amount of memory per vCPU in GiB. Instance types with a lower memory-to-vCPU ratio are excluded from selection.
        """
        return pulumi.get(self, "min")

    @min.setter
    def min(self, value: Optional[pulumi.Input[_builtins.float]]):
        pulumi.set(self, "min", value)


if not MYPY:
    class CapacityProviderMemoryMiBRequestArgsDict(TypedDict):
        min: pulumi.Input[_builtins.int]
        """
        The minimum amount of memory in MiB. Instance types with less memory than this value are excluded from selection.
        """
        max: NotRequired[pulumi.Input[_builtins.int]]
        """
        The maximum amount of memory in MiB. Instance types with more memory than this value are excluded from selection.
        """
elif False:
    CapacityProviderMemoryMiBRequestArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class CapacityProviderMemoryMiBRequestArgs:
    def __init__(__self__, *,
                 min: pulumi.Input[_builtins.int],
                 max: Optional[pulumi.Input[_builtins.int]] = None):
        """
        :param pulumi.Input[_builtins.int] min: The minimum amount of memory in MiB. Instance types with less memory than this value are excluded from selection.
        :param pulumi.Input[_builtins.int] max: The maximum amount of memory in MiB. Instance types with more memory than this value are excluded from selection.
        """
        pulumi.set(__self__, "min", min)
        if max is not None:
            pulumi.set(__self__, "max", max)

    @_builtins.property
    @pulumi.getter
    def min(self) -> pulumi.Input[_builtins.int]:
        """
        The minimum amount of memory in MiB. Instance types with less memory than this value are excluded from selection.
        """
        return pulumi.get(self, "min")

    @min.setter
    def min(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "min", value)

    @_builtins.property
    @pulumi.getter
    def max(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The maximum amount of memory in MiB. Instance types with more memory than this value are excluded from selection.
        """
        return pulumi.get(self, "max")

    @max.setter
    def max(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "max", value)


if not MYPY:
    class CapacityProviderNetworkBandwidthGbpsRequestArgsDict(TypedDict):
        max: NotRequired[pulumi.Input[_builtins.float]]
        """
        The maximum network bandwidth in Gbps. Instance types with higher network bandwidth are excluded from selection.
        """
        min: NotRequired[pulumi.Input[_builtins.float]]
        """
        The minimum network bandwidth in Gbps. Instance types with lower network bandwidth are excluded from selection.
        """
elif False:
    CapacityProviderNetworkBandwidthGbpsRequestArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class CapacityProviderNetworkBandwidthGbpsRequestArgs:
    def __init__(__self__, *,
                 max: Optional[pulumi.Input[_builtins.float]] = None,
                 min: Optional[pulumi.Input[_builtins.float]] = None):
        """
        :param pulumi.Input[_builtins.float] max: The maximum network bandwidth in Gbps. Instance types with higher network bandwidth are excluded from selection.
        :param pulumi.Input[_builtins.float] min: The minimum network bandwidth in Gbps. Instance types with lower network bandwidth are excluded from selection.
        """
        if max is not None:
            pulumi.set(__self__, "max", max)
        if min is not None:
            pulumi.set(__self__, "min", min)

    @_builtins.property
    @pulumi.getter
    def max(self) -> Optional[pulumi.Input[_builtins.float]]:
        """
        The maximum network bandwidth in Gbps. Instance types with higher network bandwidth are excluded from selection.
        """
        return pulumi.get(self, "max")

    @max.setter
    def max(self, value: Optional[pulumi.Input[_builtins.float]]):
        pulumi.set(self, "max", value)

    @_builtins.property
    @pulumi.getter
    def min(self) -> Optional[pulumi.Input[_builtins.float]]:
        """
        The minimum network bandwidth in Gbps. Instance types with lower network bandwidth are excluded from selection.
        """
        return pulumi.get(self, "min")

    @min.setter
    def min(self, value: Optional[pulumi.Input[_builtins.float]]):
        pulumi.set(self, "min", value)


if not MYPY:
    class CapacityProviderNetworkInterfaceCountRequestArgsDict(TypedDict):
        max: NotRequired[pulumi.Input[_builtins.int]]
        """
        The maximum number of network interfaces. Instance types that support more network interfaces are excluded from selection.
        """
        min: NotRequired[pulumi.Input[_builtins.int]]
        """
        The minimum number of network interfaces. Instance types that support fewer network interfaces are excluded from selection.
        """
elif False:
    CapacityProviderNetworkInterfaceCountRequestArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class CapacityProviderNetworkInterfaceCountRequestArgs:
    def __init__(__self__, *,
                 max: Optional[pulumi.Input[_builtins.int]] = None,
                 min: Optional[pulumi.Input[_builtins.int]] = None):
        """
        :param pulumi.Input[_builtins.int] max: The maximum number of network interfaces. Instance types that support more network interfaces are excluded from selection.
        :param pulumi.Input[_builtins.int] min: The minimum number of network interfaces. Instance types that support fewer network interfaces are excluded from selection.
        """
        if max is not None:
            pulumi.set(__self__, "max", max)
        if min is not None:
            pulumi.set(__self__, "min", min)

    @_builtins.property
    @pulumi.getter
    def max(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The maximum number of network interfaces. Instance types that support more network interfaces are excluded from selection.
        """
        return pulumi.get(self, "max")

    @max.setter
    def max(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "max", value)

    @_builtins.property
    @pulumi.getter
    def min(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The minimum number of network interfaces. Instance types that support fewer network interfaces are excluded from selection.
        """
        return pulumi.get(self, "min")

    @min.setter
    def min(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "min", value)


if not MYPY:
    class CapacityProviderTotalLocalStorageGbRequestArgsDict(TypedDict):
        max: NotRequired[pulumi.Input[_builtins.float]]
        """
        The maximum total local storage in GB. Instance types with more local storage are excluded from selection.
        """
        min: NotRequired[pulumi.Input[_builtins.float]]
        """
        The minimum total local storage in GB. Instance types with less local storage are excluded from selection.
        """
elif False:
    CapacityProviderTotalLocalStorageGbRequestArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class CapacityProviderTotalLocalStorageGbRequestArgs:
    def __init__(__self__, *,
                 max: Optional[pulumi.Input[_builtins.float]] = None,
                 min: Optional[pulumi.Input[_builtins.float]] = None):
        """
        :param pulumi.Input[_builtins.float] max: The maximum total local storage in GB. Instance types with more local storage are excluded from selection.
        :param pulumi.Input[_builtins.float] min: The minimum total local storage in GB. Instance types with less local storage are excluded from selection.
        """
        if max is not None:
            pulumi.set(__self__, "max", max)
        if min is not None:
            pulumi.set(__self__, "min", min)

    @_builtins.property
    @pulumi.getter
    def max(self) -> Optional[pulumi.Input[_builtins.float]]:
        """
        The maximum total local storage in GB. Instance types with more local storage are excluded from selection.
        """
        return pulumi.get(self, "max")

    @max.setter
    def max(self, value: Optional[pulumi.Input[_builtins.float]]):
        pulumi.set(self, "max", value)

    @_builtins.property
    @pulumi.getter
    def min(self) -> Optional[pulumi.Input[_builtins.float]]:
        """
        The minimum total local storage in GB. Instance types with less local storage are excluded from selection.
        """
        return pulumi.get(self, "min")

    @min.setter
    def min(self, value: Optional[pulumi.Input[_builtins.float]]):
        pulumi.set(self, "min", value)


if not MYPY:
    class CapacityProviderVCpuCountRangeRequestArgsDict(TypedDict):
        min: pulumi.Input[_builtins.int]
        """
        The minimum number of vCPUs. Instance types with fewer vCPUs than this value are excluded from selection.
        """
        max: NotRequired[pulumi.Input[_builtins.int]]
        """
        The maximum number of vCPUs. Instance types with more vCPUs than this value are excluded from selection.
        """
elif False:
    CapacityProviderVCpuCountRangeRequestArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class CapacityProviderVCpuCountRangeRequestArgs:
    def __init__(__self__, *,
                 min: pulumi.Input[_builtins.int],
                 max: Optional[pulumi.Input[_builtins.int]] = None):
        """
        :param pulumi.Input[_builtins.int] min: The minimum number of vCPUs. Instance types with fewer vCPUs than this value are excluded from selection.
        :param pulumi.Input[_builtins.int] max: The maximum number of vCPUs. Instance types with more vCPUs than this value are excluded from selection.
        """
        pulumi.set(__self__, "min", min)
        if max is not None:
            pulumi.set(__self__, "max", max)

    @_builtins.property
    @pulumi.getter
    def min(self) -> pulumi.Input[_builtins.int]:
        """
        The minimum number of vCPUs. Instance types with fewer vCPUs than this value are excluded from selection.
        """
        return pulumi.get(self, "min")

    @min.setter
    def min(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "min", value)

    @_builtins.property
    @pulumi.getter
    def max(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The maximum number of vCPUs. Instance types with more vCPUs than this value are excluded from selection.
        """
        return pulumi.get(self, "max")

    @max.setter
    def max(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "max", value)


if not MYPY:
    class ClusterCapacityProviderAssociationsCapacityProviderStrategyArgsDict(TypedDict):
        capacity_provider: pulumi.Input[Union['ClusterCapacityProviderAssociationsCapacityProvider', _builtins.str]]
        base: NotRequired[pulumi.Input[_builtins.int]]
        weight: NotRequired[pulumi.Input[_builtins.int]]
elif False:
    ClusterCapacityProviderAssociationsCapacityProviderStrategyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterCapacityProviderAssociationsCapacityProviderStrategyArgs:
    def __init__(__self__, *,
                 capacity_provider: pulumi.Input[Union['ClusterCapacityProviderAssociationsCapacityProvider', _builtins.str]],
                 base: Optional[pulumi.Input[_builtins.int]] = None,
                 weight: Optional[pulumi.Input[_builtins.int]] = None):
        pulumi.set(__self__, "capacity_provider", capacity_provider)
        if base is not None:
            pulumi.set(__self__, "base", base)
        if weight is not None:
            pulumi.set(__self__, "weight", weight)

    @_builtins.property
    @pulumi.getter(name="capacityProvider")
    def capacity_provider(self) -> pulumi.Input[Union['ClusterCapacityProviderAssociationsCapacityProvider', _builtins.str]]:
        return pulumi.get(self, "capacity_provider")

    @capacity_provider.setter
    def capacity_provider(self, value: pulumi.Input[Union['ClusterCapacityProviderAssociationsCapacityProvider', _builtins.str]]):
        pulumi.set(self, "capacity_provider", value)

    @_builtins.property
    @pulumi.getter
    def base(self) -> Optional[pulumi.Input[_builtins.int]]:
        return pulumi.get(self, "base")

    @base.setter
    def base(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "base", value)

    @_builtins.property
    @pulumi.getter
    def weight(self) -> Optional[pulumi.Input[_builtins.int]]:
        return pulumi.get(self, "weight")

    @weight.setter
    def weight(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "weight", value)


if not MYPY:
    class ClusterCapacityProviderStrategyItemArgsDict(TypedDict):
        """
        The ``CapacityProviderStrategyItem`` property specifies the details of the default capacity provider strategy for the cluster. When services or tasks are run in the cluster with no launch type or capacity provider strategy specified, the default capacity provider strategy is used.
        """
        base: NotRequired[pulumi.Input[_builtins.int]]
        """
        The *base* value designates how many tasks, at a minimum, to run on the specified capacity provider for each service. Only one capacity provider in a capacity provider strategy can have a *base* defined. If no value is specified, the default value of ``0`` is used.
         Base value characteristics:
          +  Only one capacity provider in a strategy can have a base defined
          +  Default value is ``0`` if not specified
          +  Valid range: 0 to 100,000
          +  Base requirements are satisfied first before weight distribution
        """
        capacity_provider: NotRequired[pulumi.Input[_builtins.str]]
        """
        The short name of the capacity provider.
        """
        weight: NotRequired[pulumi.Input[_builtins.int]]
        """
        The *weight* value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The ``weight`` value is taken into consideration after the ``base`` value, if defined, is satisfied.
         If no ``weight`` value is specified, the default value of ``0`` is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of ``0`` can't be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of ``0``, any ``RunTask`` or ``CreateService`` actions using the capacity provider strategy will fail.
         Weight value characteristics:
          +  Weight is considered after the base value is satisfied
          +  Default value is ``0`` if not specified
          +  Valid range: 0 to 1,000
          +  At least one capacity provider must have a weight greater than zero
          +  Capacity providers with weight of ``0`` cannot place tasks
          
         Task distribution logic:
          1.  Base satisfaction: The minimum number of tasks specified by the base value are placed on that capacity provider
          1.  Weight distribution: After base requirements are met, additional tasks are distributed according to weight ratios
          
         Examples:
         Equal Distribution: Two capacity providers both with weight ``1`` will split tasks evenly after base requirements are met.
         Weighted Distribution: If capacityProviderA has weight ``1`` and capacityProviderB has weight ``4``, then for every 1 task on A, 4 tasks will run on B.
        """
elif False:
    ClusterCapacityProviderStrategyItemArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterCapacityProviderStrategyItemArgs:
    def __init__(__self__, *,
                 base: Optional[pulumi.Input[_builtins.int]] = None,
                 capacity_provider: Optional[pulumi.Input[_builtins.str]] = None,
                 weight: Optional[pulumi.Input[_builtins.int]] = None):
        """
        The ``CapacityProviderStrategyItem`` property specifies the details of the default capacity provider strategy for the cluster. When services or tasks are run in the cluster with no launch type or capacity provider strategy specified, the default capacity provider strategy is used.
        :param pulumi.Input[_builtins.int] base: The *base* value designates how many tasks, at a minimum, to run on the specified capacity provider for each service. Only one capacity provider in a capacity provider strategy can have a *base* defined. If no value is specified, the default value of ``0`` is used.
                Base value characteristics:
                 +  Only one capacity provider in a strategy can have a base defined
                 +  Default value is ``0`` if not specified
                 +  Valid range: 0 to 100,000
                 +  Base requirements are satisfied first before weight distribution
        :param pulumi.Input[_builtins.str] capacity_provider: The short name of the capacity provider.
        :param pulumi.Input[_builtins.int] weight: The *weight* value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The ``weight`` value is taken into consideration after the ``base`` value, if defined, is satisfied.
                If no ``weight`` value is specified, the default value of ``0`` is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of ``0`` can't be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of ``0``, any ``RunTask`` or ``CreateService`` actions using the capacity provider strategy will fail.
                Weight value characteristics:
                 +  Weight is considered after the base value is satisfied
                 +  Default value is ``0`` if not specified
                 +  Valid range: 0 to 1,000
                 +  At least one capacity provider must have a weight greater than zero
                 +  Capacity providers with weight of ``0`` cannot place tasks
                 
                Task distribution logic:
                 1.  Base satisfaction: The minimum number of tasks specified by the base value are placed on that capacity provider
                 1.  Weight distribution: After base requirements are met, additional tasks are distributed according to weight ratios
                 
                Examples:
                Equal Distribution: Two capacity providers both with weight ``1`` will split tasks evenly after base requirements are met.
                Weighted Distribution: If capacityProviderA has weight ``1`` and capacityProviderB has weight ``4``, then for every 1 task on A, 4 tasks will run on B.
        """
        if base is not None:
            pulumi.set(__self__, "base", base)
        if capacity_provider is not None:
            pulumi.set(__self__, "capacity_provider", capacity_provider)
        if weight is not None:
            pulumi.set(__self__, "weight", weight)

    @_builtins.property
    @pulumi.getter
    def base(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The *base* value designates how many tasks, at a minimum, to run on the specified capacity provider for each service. Only one capacity provider in a capacity provider strategy can have a *base* defined. If no value is specified, the default value of ``0`` is used.
         Base value characteristics:
          +  Only one capacity provider in a strategy can have a base defined
          +  Default value is ``0`` if not specified
          +  Valid range: 0 to 100,000
          +  Base requirements are satisfied first before weight distribution
        """
        return pulumi.get(self, "base")

    @base.setter
    def base(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "base", value)

    @_builtins.property
    @pulumi.getter(name="capacityProvider")
    def capacity_provider(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The short name of the capacity provider.
        """
        return pulumi.get(self, "capacity_provider")

    @capacity_provider.setter
    def capacity_provider(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "capacity_provider", value)

    @_builtins.property
    @pulumi.getter
    def weight(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The *weight* value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The ``weight`` value is taken into consideration after the ``base`` value, if defined, is satisfied.
         If no ``weight`` value is specified, the default value of ``0`` is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of ``0`` can't be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of ``0``, any ``RunTask`` or ``CreateService`` actions using the capacity provider strategy will fail.
         Weight value characteristics:
          +  Weight is considered after the base value is satisfied
          +  Default value is ``0`` if not specified
          +  Valid range: 0 to 1,000
          +  At least one capacity provider must have a weight greater than zero
          +  Capacity providers with weight of ``0`` cannot place tasks
          
         Task distribution logic:
          1.  Base satisfaction: The minimum number of tasks specified by the base value are placed on that capacity provider
          1.  Weight distribution: After base requirements are met, additional tasks are distributed according to weight ratios
          
         Examples:
         Equal Distribution: Two capacity providers both with weight ``1`` will split tasks evenly after base requirements are met.
         Weighted Distribution: If capacityProviderA has weight ``1`` and capacityProviderB has weight ``4``, then for every 1 task on A, 4 tasks will run on B.
        """
        return pulumi.get(self, "weight")

    @weight.setter
    def weight(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "weight", value)


if not MYPY:
    class ClusterConfigurationArgsDict(TypedDict):
        """
        The execute command and managed storage configuration for the cluster.
        """
        execute_command_configuration: NotRequired[pulumi.Input['ClusterExecuteCommandConfigurationArgsDict']]
        """
        The details of the execute command configuration.
        """
        managed_storage_configuration: NotRequired[pulumi.Input['ClusterManagedStorageConfigurationArgsDict']]
        """
        The details of the managed storage configuration.
        """
elif False:
    ClusterConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterConfigurationArgs:
    def __init__(__self__, *,
                 execute_command_configuration: Optional[pulumi.Input['ClusterExecuteCommandConfigurationArgs']] = None,
                 managed_storage_configuration: Optional[pulumi.Input['ClusterManagedStorageConfigurationArgs']] = None):
        """
        The execute command and managed storage configuration for the cluster.
        :param pulumi.Input['ClusterExecuteCommandConfigurationArgs'] execute_command_configuration: The details of the execute command configuration.
        :param pulumi.Input['ClusterManagedStorageConfigurationArgs'] managed_storage_configuration: The details of the managed storage configuration.
        """
        if execute_command_configuration is not None:
            pulumi.set(__self__, "execute_command_configuration", execute_command_configuration)
        if managed_storage_configuration is not None:
            pulumi.set(__self__, "managed_storage_configuration", managed_storage_configuration)

    @_builtins.property
    @pulumi.getter(name="executeCommandConfiguration")
    def execute_command_configuration(self) -> Optional[pulumi.Input['ClusterExecuteCommandConfigurationArgs']]:
        """
        The details of the execute command configuration.
        """
        return pulumi.get(self, "execute_command_configuration")

    @execute_command_configuration.setter
    def execute_command_configuration(self, value: Optional[pulumi.Input['ClusterExecuteCommandConfigurationArgs']]):
        pulumi.set(self, "execute_command_configuration", value)

    @_builtins.property
    @pulumi.getter(name="managedStorageConfiguration")
    def managed_storage_configuration(self) -> Optional[pulumi.Input['ClusterManagedStorageConfigurationArgs']]:
        """
        The details of the managed storage configuration.
        """
        return pulumi.get(self, "managed_storage_configuration")

    @managed_storage_configuration.setter
    def managed_storage_configuration(self, value: Optional[pulumi.Input['ClusterManagedStorageConfigurationArgs']]):
        pulumi.set(self, "managed_storage_configuration", value)


if not MYPY:
    class ClusterExecuteCommandConfigurationArgsDict(TypedDict):
        """
        The details of the execute command configuration.
        """
        kms_key_id: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specify an KMSlong key ID to encrypt the data between the local client and the container.
        """
        log_configuration: NotRequired[pulumi.Input['ClusterExecuteCommandLogConfigurationArgsDict']]
        """
        The log configuration for the results of the execute command actions. The logs can be sent to CloudWatch Logs or an Amazon S3 bucket. When ``logging=OVERRIDE`` is specified, a ``logConfiguration`` must be provided.
        """
        logging: NotRequired[pulumi.Input[_builtins.str]]
        """
        The log setting to use for redirecting logs for your execute command results. The following log settings are available.
          +  ``NONE``: The execute command session is not logged.
          +  ``DEFAULT``: The ``awslogs`` configuration in the task definition is used. If no logging parameter is specified, it defaults to this value. If no ``awslogs`` log driver is configured in the task definition, the output won't be logged.
          +  ``OVERRIDE``: Specify the logging details as a part of ``logConfiguration``. If the ``OVERRIDE`` logging option is specified, the ``logConfiguration`` is required.
        """
elif False:
    ClusterExecuteCommandConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterExecuteCommandConfigurationArgs:
    def __init__(__self__, *,
                 kms_key_id: Optional[pulumi.Input[_builtins.str]] = None,
                 log_configuration: Optional[pulumi.Input['ClusterExecuteCommandLogConfigurationArgs']] = None,
                 logging: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The details of the execute command configuration.
        :param pulumi.Input[_builtins.str] kms_key_id: Specify an KMSlong key ID to encrypt the data between the local client and the container.
        :param pulumi.Input['ClusterExecuteCommandLogConfigurationArgs'] log_configuration: The log configuration for the results of the execute command actions. The logs can be sent to CloudWatch Logs or an Amazon S3 bucket. When ``logging=OVERRIDE`` is specified, a ``logConfiguration`` must be provided.
        :param pulumi.Input[_builtins.str] logging: The log setting to use for redirecting logs for your execute command results. The following log settings are available.
                 +  ``NONE``: The execute command session is not logged.
                 +  ``DEFAULT``: The ``awslogs`` configuration in the task definition is used. If no logging parameter is specified, it defaults to this value. If no ``awslogs`` log driver is configured in the task definition, the output won't be logged.
                 +  ``OVERRIDE``: Specify the logging details as a part of ``logConfiguration``. If the ``OVERRIDE`` logging option is specified, the ``logConfiguration`` is required.
        """
        if kms_key_id is not None:
            pulumi.set(__self__, "kms_key_id", kms_key_id)
        if log_configuration is not None:
            pulumi.set(__self__, "log_configuration", log_configuration)
        if logging is not None:
            pulumi.set(__self__, "logging", logging)

    @_builtins.property
    @pulumi.getter(name="kmsKeyId")
    def kms_key_id(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specify an KMSlong key ID to encrypt the data between the local client and the container.
        """
        return pulumi.get(self, "kms_key_id")

    @kms_key_id.setter
    def kms_key_id(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "kms_key_id", value)

    @_builtins.property
    @pulumi.getter(name="logConfiguration")
    def log_configuration(self) -> Optional[pulumi.Input['ClusterExecuteCommandLogConfigurationArgs']]:
        """
        The log configuration for the results of the execute command actions. The logs can be sent to CloudWatch Logs or an Amazon S3 bucket. When ``logging=OVERRIDE`` is specified, a ``logConfiguration`` must be provided.
        """
        return pulumi.get(self, "log_configuration")

    @log_configuration.setter
    def log_configuration(self, value: Optional[pulumi.Input['ClusterExecuteCommandLogConfigurationArgs']]):
        pulumi.set(self, "log_configuration", value)

    @_builtins.property
    @pulumi.getter
    def logging(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The log setting to use for redirecting logs for your execute command results. The following log settings are available.
          +  ``NONE``: The execute command session is not logged.
          +  ``DEFAULT``: The ``awslogs`` configuration in the task definition is used. If no logging parameter is specified, it defaults to this value. If no ``awslogs`` log driver is configured in the task definition, the output won't be logged.
          +  ``OVERRIDE``: Specify the logging details as a part of ``logConfiguration``. If the ``OVERRIDE`` logging option is specified, the ``logConfiguration`` is required.
        """
        return pulumi.get(self, "logging")

    @logging.setter
    def logging(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "logging", value)


if not MYPY:
    class ClusterExecuteCommandLogConfigurationArgsDict(TypedDict):
        """
        The log configuration for the results of the execute command actions. The logs can be sent to CloudWatch Logs or an Amazon S3 bucket.
        """
        cloud_watch_encryption_enabled: NotRequired[pulumi.Input[_builtins.bool]]
        """
        Determines whether to use encryption on the CloudWatch logs. If not specified, encryption will be off.
        """
        cloud_watch_log_group_name: NotRequired[pulumi.Input[_builtins.str]]
        """
        The name of the CloudWatch log group to send logs to.
          The CloudWatch log group must already be created.
        """
        s3_bucket_name: NotRequired[pulumi.Input[_builtins.str]]
        """
        The name of the S3 bucket to send logs to.
          The S3 bucket must already be created.
        """
        s3_encryption_enabled: NotRequired[pulumi.Input[_builtins.bool]]
        """
        Determines whether to use encryption on the S3 logs. If not specified, encryption is not used.
        """
        s3_key_prefix: NotRequired[pulumi.Input[_builtins.str]]
        """
        An optional folder in the S3 bucket to place logs in.
        """
elif False:
    ClusterExecuteCommandLogConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterExecuteCommandLogConfigurationArgs:
    def __init__(__self__, *,
                 cloud_watch_encryption_enabled: Optional[pulumi.Input[_builtins.bool]] = None,
                 cloud_watch_log_group_name: Optional[pulumi.Input[_builtins.str]] = None,
                 s3_bucket_name: Optional[pulumi.Input[_builtins.str]] = None,
                 s3_encryption_enabled: Optional[pulumi.Input[_builtins.bool]] = None,
                 s3_key_prefix: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The log configuration for the results of the execute command actions. The logs can be sent to CloudWatch Logs or an Amazon S3 bucket.
        :param pulumi.Input[_builtins.bool] cloud_watch_encryption_enabled: Determines whether to use encryption on the CloudWatch logs. If not specified, encryption will be off.
        :param pulumi.Input[_builtins.str] cloud_watch_log_group_name: The name of the CloudWatch log group to send logs to.
                 The CloudWatch log group must already be created.
        :param pulumi.Input[_builtins.str] s3_bucket_name: The name of the S3 bucket to send logs to.
                 The S3 bucket must already be created.
        :param pulumi.Input[_builtins.bool] s3_encryption_enabled: Determines whether to use encryption on the S3 logs. If not specified, encryption is not used.
        :param pulumi.Input[_builtins.str] s3_key_prefix: An optional folder in the S3 bucket to place logs in.
        """
        if cloud_watch_encryption_enabled is not None:
            pulumi.set(__self__, "cloud_watch_encryption_enabled", cloud_watch_encryption_enabled)
        if cloud_watch_log_group_name is not None:
            pulumi.set(__self__, "cloud_watch_log_group_name", cloud_watch_log_group_name)
        if s3_bucket_name is not None:
            pulumi.set(__self__, "s3_bucket_name", s3_bucket_name)
        if s3_encryption_enabled is not None:
            pulumi.set(__self__, "s3_encryption_enabled", s3_encryption_enabled)
        if s3_key_prefix is not None:
            pulumi.set(__self__, "s3_key_prefix", s3_key_prefix)

    @_builtins.property
    @pulumi.getter(name="cloudWatchEncryptionEnabled")
    def cloud_watch_encryption_enabled(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Determines whether to use encryption on the CloudWatch logs. If not specified, encryption will be off.
        """
        return pulumi.get(self, "cloud_watch_encryption_enabled")

    @cloud_watch_encryption_enabled.setter
    def cloud_watch_encryption_enabled(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "cloud_watch_encryption_enabled", value)

    @_builtins.property
    @pulumi.getter(name="cloudWatchLogGroupName")
    def cloud_watch_log_group_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The name of the CloudWatch log group to send logs to.
          The CloudWatch log group must already be created.
        """
        return pulumi.get(self, "cloud_watch_log_group_name")

    @cloud_watch_log_group_name.setter
    def cloud_watch_log_group_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "cloud_watch_log_group_name", value)

    @_builtins.property
    @pulumi.getter(name="s3BucketName")
    def s3_bucket_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The name of the S3 bucket to send logs to.
          The S3 bucket must already be created.
        """
        return pulumi.get(self, "s3_bucket_name")

    @s3_bucket_name.setter
    def s3_bucket_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "s3_bucket_name", value)

    @_builtins.property
    @pulumi.getter(name="s3EncryptionEnabled")
    def s3_encryption_enabled(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Determines whether to use encryption on the S3 logs. If not specified, encryption is not used.
        """
        return pulumi.get(self, "s3_encryption_enabled")

    @s3_encryption_enabled.setter
    def s3_encryption_enabled(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "s3_encryption_enabled", value)

    @_builtins.property
    @pulumi.getter(name="s3KeyPrefix")
    def s3_key_prefix(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        An optional folder in the S3 bucket to place logs in.
        """
        return pulumi.get(self, "s3_key_prefix")

    @s3_key_prefix.setter
    def s3_key_prefix(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "s3_key_prefix", value)


if not MYPY:
    class ClusterManagedStorageConfigurationArgsDict(TypedDict):
        """
        The managed storage configuration for the cluster.
        """
        fargate_ephemeral_storage_kms_key_id: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specify the KMSlong key ID for Fargate ephemeral storage.
         When you specify a ``fargateEphemeralStorageKmsKeyId``, AWS Fargate uses the key to encrypt data at rest in ephemeral storage. For more information about Fargate ephemeral storage encryption, see [Customer managed keys for Fargate ephemeral storage for Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/fargate-storage-encryption.html) in the *Amazon Elastic Container Service Developer Guide*.
         The key must be a single Region key.
        """
        kms_key_id: NotRequired[pulumi.Input[_builtins.str]]
        """
        Specify a KMSlong key ID to encrypt Amazon ECS managed storage.
          When you specify a ``kmsKeyId``, Amazon ECS uses the key to encrypt data volumes managed by Amazon ECS that are attached to tasks in the cluster. The following data volumes are managed by Amazon ECS: Amazon EBS. For more information about encryption of Amazon EBS volumes attached to Amazon ECS tasks, see [Encrypt data stored in Amazon EBS volumes for Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ebs-kms-encryption.html) in the *Amazon Elastic Container Service Developer Guide*.
         The key must be a single Region key.
        """
elif False:
    ClusterManagedStorageConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterManagedStorageConfigurationArgs:
    def __init__(__self__, *,
                 fargate_ephemeral_storage_kms_key_id: Optional[pulumi.Input[_builtins.str]] = None,
                 kms_key_id: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The managed storage configuration for the cluster.
        :param pulumi.Input[_builtins.str] fargate_ephemeral_storage_kms_key_id: Specify the KMSlong key ID for Fargate ephemeral storage.
                When you specify a ``fargateEphemeralStorageKmsKeyId``, AWS Fargate uses the key to encrypt data at rest in ephemeral storage. For more information about Fargate ephemeral storage encryption, see [Customer managed keys for Fargate ephemeral storage for Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/fargate-storage-encryption.html) in the *Amazon Elastic Container Service Developer Guide*.
                The key must be a single Region key.
        :param pulumi.Input[_builtins.str] kms_key_id: Specify a KMSlong key ID to encrypt Amazon ECS managed storage.
                 When you specify a ``kmsKeyId``, Amazon ECS uses the key to encrypt data volumes managed by Amazon ECS that are attached to tasks in the cluster. The following data volumes are managed by Amazon ECS: Amazon EBS. For more information about encryption of Amazon EBS volumes attached to Amazon ECS tasks, see [Encrypt data stored in Amazon EBS volumes for Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ebs-kms-encryption.html) in the *Amazon Elastic Container Service Developer Guide*.
                The key must be a single Region key.
        """
        if fargate_ephemeral_storage_kms_key_id is not None:
            pulumi.set(__self__, "fargate_ephemeral_storage_kms_key_id", fargate_ephemeral_storage_kms_key_id)
        if kms_key_id is not None:
            pulumi.set(__self__, "kms_key_id", kms_key_id)

    @_builtins.property
    @pulumi.getter(name="fargateEphemeralStorageKmsKeyId")
    def fargate_ephemeral_storage_kms_key_id(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specify the KMSlong key ID for Fargate ephemeral storage.
         When you specify a ``fargateEphemeralStorageKmsKeyId``, AWS Fargate uses the key to encrypt data at rest in ephemeral storage. For more information about Fargate ephemeral storage encryption, see [Customer managed keys for Fargate ephemeral storage for Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/fargate-storage-encryption.html) in the *Amazon Elastic Container Service Developer Guide*.
         The key must be a single Region key.
        """
        return pulumi.get(self, "fargate_ephemeral_storage_kms_key_id")

    @fargate_ephemeral_storage_kms_key_id.setter
    def fargate_ephemeral_storage_kms_key_id(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "fargate_ephemeral_storage_kms_key_id", value)

    @_builtins.property
    @pulumi.getter(name="kmsKeyId")
    def kms_key_id(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Specify a KMSlong key ID to encrypt Amazon ECS managed storage.
          When you specify a ``kmsKeyId``, Amazon ECS uses the key to encrypt data volumes managed by Amazon ECS that are attached to tasks in the cluster. The following data volumes are managed by Amazon ECS: Amazon EBS. For more information about encryption of Amazon EBS volumes attached to Amazon ECS tasks, see [Encrypt data stored in Amazon EBS volumes for Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ebs-kms-encryption.html) in the *Amazon Elastic Container Service Developer Guide*.
         The key must be a single Region key.
        """
        return pulumi.get(self, "kms_key_id")

    @kms_key_id.setter
    def kms_key_id(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "kms_key_id", value)


if not MYPY:
    class ClusterServiceConnectDefaultsArgsDict(TypedDict):
        """
        Use this parameter to set a default Service Connect namespace. After you set a default Service Connect namespace, any new services with Service Connect turned on that are created in the cluster are added as client services in the namespace. This setting only applies to new services that set the ``enabled`` parameter to ``true`` in the ``ServiceConnectConfiguration``. You can set the namespace of each service individually in the ``ServiceConnectConfiguration`` to override this default parameter.
         Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        namespace: NotRequired[pulumi.Input[_builtins.str]]
        """
        The namespace name or full Amazon Resource Name (ARN) of the CMAPlong namespace that's used when you create a service and don't specify a Service Connect configuration. The namespace name can include up to 1024 characters. The name is case-sensitive. The name can't include greater than (>), less than (<), double quotation marks ("), or slash (/).
         If you enter an existing namespace name or ARN, then that namespace will be used. Any namespace type is supported. The namespace must be in this account and this AWS Region.
         If you enter a new name, a CMAPlong namespace will be created. Amazon ECS creates a CMAP namespace with the "API calls" method of instance discovery only. This instance discovery method is the "HTTP" namespace type in the CLIlong. Other types of instance discovery aren't used by Service Connect.
         If you update the cluster with an empty string ``""`` for the namespace name, the cluster configuration for Service Connect is removed. Note that the namespace will remain in CMAP and must be deleted separately.
         For more information about CMAPlong, see [Working with Services](https://docs.aws.amazon.com/cloud-map/latest/dg/working-with-services.html) in the *Developer Guide*.
        """
elif False:
    ClusterServiceConnectDefaultsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterServiceConnectDefaultsArgs:
    def __init__(__self__, *,
                 namespace: Optional[pulumi.Input[_builtins.str]] = None):
        """
        Use this parameter to set a default Service Connect namespace. After you set a default Service Connect namespace, any new services with Service Connect turned on that are created in the cluster are added as client services in the namespace. This setting only applies to new services that set the ``enabled`` parameter to ``true`` in the ``ServiceConnectConfiguration``. You can set the namespace of each service individually in the ``ServiceConnectConfiguration`` to override this default parameter.
         Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.str] namespace: The namespace name or full Amazon Resource Name (ARN) of the CMAPlong namespace that's used when you create a service and don't specify a Service Connect configuration. The namespace name can include up to 1024 characters. The name is case-sensitive. The name can't include greater than (>), less than (<), double quotation marks ("), or slash (/).
                If you enter an existing namespace name or ARN, then that namespace will be used. Any namespace type is supported. The namespace must be in this account and this AWS Region.
                If you enter a new name, a CMAPlong namespace will be created. Amazon ECS creates a CMAP namespace with the "API calls" method of instance discovery only. This instance discovery method is the "HTTP" namespace type in the CLIlong. Other types of instance discovery aren't used by Service Connect.
                If you update the cluster with an empty string ``""`` for the namespace name, the cluster configuration for Service Connect is removed. Note that the namespace will remain in CMAP and must be deleted separately.
                For more information about CMAPlong, see [Working with Services](https://docs.aws.amazon.com/cloud-map/latest/dg/working-with-services.html) in the *Developer Guide*.
        """
        if namespace is not None:
            pulumi.set(__self__, "namespace", namespace)

    @_builtins.property
    @pulumi.getter
    def namespace(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The namespace name or full Amazon Resource Name (ARN) of the CMAPlong namespace that's used when you create a service and don't specify a Service Connect configuration. The namespace name can include up to 1024 characters. The name is case-sensitive. The name can't include greater than (>), less than (<), double quotation marks ("), or slash (/).
         If you enter an existing namespace name or ARN, then that namespace will be used. Any namespace type is supported. The namespace must be in this account and this AWS Region.
         If you enter a new name, a CMAPlong namespace will be created. Amazon ECS creates a CMAP namespace with the "API calls" method of instance discovery only. This instance discovery method is the "HTTP" namespace type in the CLIlong. Other types of instance discovery aren't used by Service Connect.
         If you update the cluster with an empty string ``""`` for the namespace name, the cluster configuration for Service Connect is removed. Note that the namespace will remain in CMAP and must be deleted separately.
         For more information about CMAPlong, see [Working with Services](https://docs.aws.amazon.com/cloud-map/latest/dg/working-with-services.html) in the *Developer Guide*.
        """
        return pulumi.get(self, "namespace")

    @namespace.setter
    def namespace(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "namespace", value)


if not MYPY:
    class ClusterSettingsArgsDict(TypedDict):
        """
        The settings to use when creating a cluster. This parameter is used to turn on CloudWatch Container Insights with enhanced observability or CloudWatch Container Insights for a cluster.
         Container Insights with enhanced observability provides all the Container Insights metrics, plus additional task and container metrics. This version supports enhanced observability for Amazon ECS clusters using the Amazon EC2 and Fargate launch types. After you configure Container Insights with enhanced observability on Amazon ECS, Container Insights auto-collects detailed infrastructure telemetry from the cluster level down to the container level in your environment and displays these critical performance data in curated dashboards removing the heavy lifting in observability set-up. 
         For more information, see [Monitor Amazon ECS containers using Container Insights with enhanced observability](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cloudwatch-container-insights.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        name: NotRequired[pulumi.Input[_builtins.str]]
        """
        The name of the cluster setting. The value is ``containerInsights``.
        """
        value: NotRequired[pulumi.Input[_builtins.str]]
        """
        The value to set for the cluster setting. The supported values are ``enhanced``, ``enabled``, and ``disabled``. 
         To use Container Insights with enhanced observability, set the ``containerInsights`` account setting to ``enhanced``.
         To use Container Insights, set the ``containerInsights`` account setting to ``enabled``.
         If a cluster value is specified, it will override the ``containerInsights`` value set with [PutAccountSetting](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_PutAccountSetting.html) or [PutAccountSettingDefault](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_PutAccountSettingDefault.html).
        """
elif False:
    ClusterSettingsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ClusterSettingsArgs:
    def __init__(__self__, *,
                 name: Optional[pulumi.Input[_builtins.str]] = None,
                 value: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The settings to use when creating a cluster. This parameter is used to turn on CloudWatch Container Insights with enhanced observability or CloudWatch Container Insights for a cluster.
         Container Insights with enhanced observability provides all the Container Insights metrics, plus additional task and container metrics. This version supports enhanced observability for Amazon ECS clusters using the Amazon EC2 and Fargate launch types. After you configure Container Insights with enhanced observability on Amazon ECS, Container Insights auto-collects detailed infrastructure telemetry from the cluster level down to the container level in your environment and displays these critical performance data in curated dashboards removing the heavy lifting in observability set-up. 
         For more information, see [Monitor Amazon ECS containers using Container Insights with enhanced observability](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cloudwatch-container-insights.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.str] name: The name of the cluster setting. The value is ``containerInsights``.
        :param pulumi.Input[_builtins.str] value: The value to set for the cluster setting. The supported values are ``enhanced``, ``enabled``, and ``disabled``. 
                To use Container Insights with enhanced observability, set the ``containerInsights`` account setting to ``enhanced``.
                To use Container Insights, set the ``containerInsights`` account setting to ``enabled``.
                If a cluster value is specified, it will override the ``containerInsights`` value set with [PutAccountSetting](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_PutAccountSetting.html) or [PutAccountSettingDefault](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_PutAccountSettingDefault.html).
        """
        if name is not None:
            pulumi.set(__self__, "name", name)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The name of the cluster setting. The value is ``containerInsights``.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "name", value)

    @_builtins.property
    @pulumi.getter
    def value(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The value to set for the cluster setting. The supported values are ``enhanced``, ``enabled``, and ``disabled``. 
         To use Container Insights with enhanced observability, set the ``containerInsights`` account setting to ``enhanced``.
         To use Container Insights, set the ``containerInsights`` account setting to ``enabled``.
         If a cluster value is specified, it will override the ``containerInsights`` value set with [PutAccountSetting](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_PutAccountSetting.html) or [PutAccountSettingDefault](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_PutAccountSettingDefault.html).
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "value", value)


if not MYPY:
    class ServiceAdvancedConfigurationArgsDict(TypedDict):
        """
        The advanced settings for a load balancer used in blue/green deployments. Specify the alternate target group, listener rules, and IAM role required for traffic shifting during blue/green deployments. For more information, see [Required resources for Amazon ECS blue/green deployments](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/blue-green-deployment-implementation.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        alternate_target_group_arn: pulumi.Input[_builtins.str]
        """
        The Amazon Resource Name (ARN) of the alternate target group for Amazon ECS blue/green deployments.
        """
        production_listener_rule: NotRequired[pulumi.Input[_builtins.str]]
        """
        The Amazon Resource Name (ARN) that that identifies the production listener rule (in the case of an Application Load Balancer) or listener (in the case for an Network Load Balancer) for routing production traffic.
        """
        role_arn: NotRequired[pulumi.Input[_builtins.str]]
        """
        The Amazon Resource Name (ARN) of the IAM role that grants Amazon ECS permission to call the Elastic Load Balancing APIs for you.
        """
        test_listener_rule: NotRequired[pulumi.Input[_builtins.str]]
        """
        The Amazon Resource Name (ARN) that identifies ) that identifies the test listener rule (in the case of an Application Load Balancer) or listener (in the case for an Network Load Balancer) for routing test traffic.
        """
elif False:
    ServiceAdvancedConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceAdvancedConfigurationArgs:
    def __init__(__self__, *,
                 alternate_target_group_arn: pulumi.Input[_builtins.str],
                 production_listener_rule: Optional[pulumi.Input[_builtins.str]] = None,
                 role_arn: Optional[pulumi.Input[_builtins.str]] = None,
                 test_listener_rule: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The advanced settings for a load balancer used in blue/green deployments. Specify the alternate target group, listener rules, and IAM role required for traffic shifting during blue/green deployments. For more information, see [Required resources for Amazon ECS blue/green deployments](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/blue-green-deployment-implementation.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.str] alternate_target_group_arn: The Amazon Resource Name (ARN) of the alternate target group for Amazon ECS blue/green deployments.
        :param pulumi.Input[_builtins.str] production_listener_rule: The Amazon Resource Name (ARN) that that identifies the production listener rule (in the case of an Application Load Balancer) or listener (in the case for an Network Load Balancer) for routing production traffic.
        :param pulumi.Input[_builtins.str] role_arn: The Amazon Resource Name (ARN) of the IAM role that grants Amazon ECS permission to call the Elastic Load Balancing APIs for you.
        :param pulumi.Input[_builtins.str] test_listener_rule: The Amazon Resource Name (ARN) that identifies ) that identifies the test listener rule (in the case of an Application Load Balancer) or listener (in the case for an Network Load Balancer) for routing test traffic.
        """
        pulumi.set(__self__, "alternate_target_group_arn", alternate_target_group_arn)
        if production_listener_rule is not None:
            pulumi.set(__self__, "production_listener_rule", production_listener_rule)
        if role_arn is not None:
            pulumi.set(__self__, "role_arn", role_arn)
        if test_listener_rule is not None:
            pulumi.set(__self__, "test_listener_rule", test_listener_rule)

    @_builtins.property
    @pulumi.getter(name="alternateTargetGroupArn")
    def alternate_target_group_arn(self) -> pulumi.Input[_builtins.str]:
        """
        The Amazon Resource Name (ARN) of the alternate target group for Amazon ECS blue/green deployments.
        """
        return pulumi.get(self, "alternate_target_group_arn")

    @alternate_target_group_arn.setter
    def alternate_target_group_arn(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "alternate_target_group_arn", value)

    @_builtins.property
    @pulumi.getter(name="productionListenerRule")
    def production_listener_rule(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The Amazon Resource Name (ARN) that that identifies the production listener rule (in the case of an Application Load Balancer) or listener (in the case for an Network Load Balancer) for routing production traffic.
        """
        return pulumi.get(self, "production_listener_rule")

    @production_listener_rule.setter
    def production_listener_rule(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "production_listener_rule", value)

    @_builtins.property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The Amazon Resource Name (ARN) of the IAM role that grants Amazon ECS permission to call the Elastic Load Balancing APIs for you.
        """
        return pulumi.get(self, "role_arn")

    @role_arn.setter
    def role_arn(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "role_arn", value)

    @_builtins.property
    @pulumi.getter(name="testListenerRule")
    def test_listener_rule(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The Amazon Resource Name (ARN) that identifies ) that identifies the test listener rule (in the case of an Application Load Balancer) or listener (in the case for an Network Load Balancer) for routing test traffic.
        """
        return pulumi.get(self, "test_listener_rule")

    @test_listener_rule.setter
    def test_listener_rule(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "test_listener_rule", value)


if not MYPY:
    class ServiceAwsVpcConfigurationArgsDict(TypedDict):
        """
        An object representing the networking details for a task or service. For example ``awsVpcConfiguration={subnets=["subnet-12344321"],securityGroups=["sg-12344321"]}``.
        """
        assign_public_ip: NotRequired[pulumi.Input['ServiceAwsVpcConfigurationAssignPublicIp']]
        """
        Whether the task's elastic network interface receives a public IP address. 
         Consider the following when you set this value:
          +  When you use ``create-service`` or ``update-service``, the default is ``DISABLED``. 
          +  When the service ``deploymentController`` is ``ECS``, the value must be ``DISABLED``.
        """
        security_groups: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The IDs of the security groups associated with the task or service. If you don't specify a security group, the default security group for the VPC is used. There's a limit of 5 security groups that can be specified.
          All specified security groups must be from the same VPC.
        """
        subnets: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The IDs of the subnets associated with the task or service. There's a limit of 16 subnets that can be specified.
          All specified subnets must be from the same VPC.
        """
elif False:
    ServiceAwsVpcConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceAwsVpcConfigurationArgs:
    def __init__(__self__, *,
                 assign_public_ip: Optional[pulumi.Input['ServiceAwsVpcConfigurationAssignPublicIp']] = None,
                 security_groups: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 subnets: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None):
        """
        An object representing the networking details for a task or service. For example ``awsVpcConfiguration={subnets=["subnet-12344321"],securityGroups=["sg-12344321"]}``.
        :param pulumi.Input['ServiceAwsVpcConfigurationAssignPublicIp'] assign_public_ip: Whether the task's elastic network interface receives a public IP address. 
                Consider the following when you set this value:
                 +  When you use ``create-service`` or ``update-service``, the default is ``DISABLED``. 
                 +  When the service ``deploymentController`` is ``ECS``, the value must be ``DISABLED``.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] security_groups: The IDs of the security groups associated with the task or service. If you don't specify a security group, the default security group for the VPC is used. There's a limit of 5 security groups that can be specified.
                 All specified security groups must be from the same VPC.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] subnets: The IDs of the subnets associated with the task or service. There's a limit of 16 subnets that can be specified.
                 All specified subnets must be from the same VPC.
        """
        if assign_public_ip is not None:
            pulumi.set(__self__, "assign_public_ip", assign_public_ip)
        if security_groups is not None:
            pulumi.set(__self__, "security_groups", security_groups)
        if subnets is not None:
            pulumi.set(__self__, "subnets", subnets)

    @_builtins.property
    @pulumi.getter(name="assignPublicIp")
    def assign_public_ip(self) -> Optional[pulumi.Input['ServiceAwsVpcConfigurationAssignPublicIp']]:
        """
        Whether the task's elastic network interface receives a public IP address. 
         Consider the following when you set this value:
          +  When you use ``create-service`` or ``update-service``, the default is ``DISABLED``. 
          +  When the service ``deploymentController`` is ``ECS``, the value must be ``DISABLED``.
        """
        return pulumi.get(self, "assign_public_ip")

    @assign_public_ip.setter
    def assign_public_ip(self, value: Optional[pulumi.Input['ServiceAwsVpcConfigurationAssignPublicIp']]):
        pulumi.set(self, "assign_public_ip", value)

    @_builtins.property
    @pulumi.getter(name="securityGroups")
    def security_groups(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The IDs of the security groups associated with the task or service. If you don't specify a security group, the default security group for the VPC is used. There's a limit of 5 security groups that can be specified.
          All specified security groups must be from the same VPC.
        """
        return pulumi.get(self, "security_groups")

    @security_groups.setter
    def security_groups(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "security_groups", value)

    @_builtins.property
    @pulumi.getter
    def subnets(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The IDs of the subnets associated with the task or service. There's a limit of 16 subnets that can be specified.
          All specified subnets must be from the same VPC.
        """
        return pulumi.get(self, "subnets")

    @subnets.setter
    def subnets(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "subnets", value)


if not MYPY:
    class ServiceCanaryConfigurationArgsDict(TypedDict):
        canary_bake_time_in_minutes: NotRequired[pulumi.Input[_builtins.int]]
        """
        The amount of time in minutes to wait during the canary phase before shifting the remaining production traffic to the new service revision. Valid values are 0 to 1440 minutes (24 hours). The default value is 10.
        """
        canary_percent: NotRequired[pulumi.Input[_builtins.float]]
        """
        The percentage of production traffic to shift to the new service revision during the canary phase. Valid values are multiples of 0.1 from 0.1 to 100.0. The default value is 5.0.
        """
elif False:
    ServiceCanaryConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceCanaryConfigurationArgs:
    def __init__(__self__, *,
                 canary_bake_time_in_minutes: Optional[pulumi.Input[_builtins.int]] = None,
                 canary_percent: Optional[pulumi.Input[_builtins.float]] = None):
        """
        :param pulumi.Input[_builtins.int] canary_bake_time_in_minutes: The amount of time in minutes to wait during the canary phase before shifting the remaining production traffic to the new service revision. Valid values are 0 to 1440 minutes (24 hours). The default value is 10.
        :param pulumi.Input[_builtins.float] canary_percent: The percentage of production traffic to shift to the new service revision during the canary phase. Valid values are multiples of 0.1 from 0.1 to 100.0. The default value is 5.0.
        """
        if canary_bake_time_in_minutes is not None:
            pulumi.set(__self__, "canary_bake_time_in_minutes", canary_bake_time_in_minutes)
        if canary_percent is not None:
            pulumi.set(__self__, "canary_percent", canary_percent)

    @_builtins.property
    @pulumi.getter(name="canaryBakeTimeInMinutes")
    def canary_bake_time_in_minutes(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The amount of time in minutes to wait during the canary phase before shifting the remaining production traffic to the new service revision. Valid values are 0 to 1440 minutes (24 hours). The default value is 10.
        """
        return pulumi.get(self, "canary_bake_time_in_minutes")

    @canary_bake_time_in_minutes.setter
    def canary_bake_time_in_minutes(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "canary_bake_time_in_minutes", value)

    @_builtins.property
    @pulumi.getter(name="canaryPercent")
    def canary_percent(self) -> Optional[pulumi.Input[_builtins.float]]:
        """
        The percentage of production traffic to shift to the new service revision during the canary phase. Valid values are multiples of 0.1 from 0.1 to 100.0. The default value is 5.0.
        """
        return pulumi.get(self, "canary_percent")

    @canary_percent.setter
    def canary_percent(self, value: Optional[pulumi.Input[_builtins.float]]):
        pulumi.set(self, "canary_percent", value)


if not MYPY:
    class ServiceCapacityProviderStrategyItemArgsDict(TypedDict):
        """
        The details of a capacity provider strategy. A capacity provider strategy can be set when using the ``RunTask`` or ``CreateService`` APIs or as the default capacity provider strategy for a cluster with the ``CreateCluster`` API.
         Only capacity providers that are already associated with a cluster and have an ``ACTIVE`` or ``UPDATING`` status can be used in a capacity provider strategy. The ``PutClusterCapacityProviders`` API is used to associate a capacity provider with a cluster.
         If specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the ``CreateCapacityProvider`` API operation.
         To use an FARGATElong capacity provider, specify either the ``FARGATE`` or ``FARGATE_SPOT`` capacity providers. The FARGATElong capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.
        """
        base: NotRequired[pulumi.Input[_builtins.int]]
        """
        The *base* value designates how many tasks, at a minimum, to run on the specified capacity provider for each service. Only one capacity provider in a capacity provider strategy can have a *base* defined. If no value is specified, the default value of ``0`` is used.
         Base value characteristics:
          +  Only one capacity provider in a strategy can have a base defined
          +  Default value is ``0`` if not specified
          +  Valid range: 0 to 100,000
          +  Base requirements are satisfied first before weight distribution
        """
        capacity_provider: NotRequired[pulumi.Input[_builtins.str]]
        """
        The short name of the capacity provider.
        """
        weight: NotRequired[pulumi.Input[_builtins.int]]
        """
        The *weight* value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The ``weight`` value is taken into consideration after the ``base`` value, if defined, is satisfied.
         If no ``weight`` value is specified, the default value of ``0`` is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of ``0`` can't be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of ``0``, any ``RunTask`` or ``CreateService`` actions using the capacity provider strategy will fail.
         Weight value characteristics:
          +  Weight is considered after the base value is satisfied
          +  Default value is ``0`` if not specified
          +  Valid range: 0 to 1,000
          +  At least one capacity provider must have a weight greater than zero
          +  Capacity providers with weight of ``0`` cannot place tasks
          
         Task distribution logic:
          1.  Base satisfaction: The minimum number of tasks specified by the base value are placed on that capacity provider
          1.  Weight distribution: After base requirements are met, additional tasks are distributed according to weight ratios
          
         Examples:
         Equal Distribution: Two capacity providers both with weight ``1`` will split tasks evenly after base requirements are met.
         Weighted Distribution: If capacityProviderA has weight ``1`` and capacityProviderB has weight ``4``, then for every 1 task on A, 4 tasks will run on B.
        """
elif False:
    ServiceCapacityProviderStrategyItemArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceCapacityProviderStrategyItemArgs:
    def __init__(__self__, *,
                 base: Optional[pulumi.Input[_builtins.int]] = None,
                 capacity_provider: Optional[pulumi.Input[_builtins.str]] = None,
                 weight: Optional[pulumi.Input[_builtins.int]] = None):
        """
        The details of a capacity provider strategy. A capacity provider strategy can be set when using the ``RunTask`` or ``CreateService`` APIs or as the default capacity provider strategy for a cluster with the ``CreateCluster`` API.
         Only capacity providers that are already associated with a cluster and have an ``ACTIVE`` or ``UPDATING`` status can be used in a capacity provider strategy. The ``PutClusterCapacityProviders`` API is used to associate a capacity provider with a cluster.
         If specifying a capacity provider that uses an Auto Scaling group, the capacity provider must already be created. New Auto Scaling group capacity providers can be created with the ``CreateCapacityProvider`` API operation.
         To use an FARGATElong capacity provider, specify either the ``FARGATE`` or ``FARGATE_SPOT`` capacity providers. The FARGATElong capacity providers are available to all accounts and only need to be associated with a cluster to be used in a capacity provider strategy.
        :param pulumi.Input[_builtins.int] base: The *base* value designates how many tasks, at a minimum, to run on the specified capacity provider for each service. Only one capacity provider in a capacity provider strategy can have a *base* defined. If no value is specified, the default value of ``0`` is used.
                Base value characteristics:
                 +  Only one capacity provider in a strategy can have a base defined
                 +  Default value is ``0`` if not specified
                 +  Valid range: 0 to 100,000
                 +  Base requirements are satisfied first before weight distribution
        :param pulumi.Input[_builtins.str] capacity_provider: The short name of the capacity provider.
        :param pulumi.Input[_builtins.int] weight: The *weight* value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The ``weight`` value is taken into consideration after the ``base`` value, if defined, is satisfied.
                If no ``weight`` value is specified, the default value of ``0`` is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of ``0`` can't be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of ``0``, any ``RunTask`` or ``CreateService`` actions using the capacity provider strategy will fail.
                Weight value characteristics:
                 +  Weight is considered after the base value is satisfied
                 +  Default value is ``0`` if not specified
                 +  Valid range: 0 to 1,000
                 +  At least one capacity provider must have a weight greater than zero
                 +  Capacity providers with weight of ``0`` cannot place tasks
                 
                Task distribution logic:
                 1.  Base satisfaction: The minimum number of tasks specified by the base value are placed on that capacity provider
                 1.  Weight distribution: After base requirements are met, additional tasks are distributed according to weight ratios
                 
                Examples:
                Equal Distribution: Two capacity providers both with weight ``1`` will split tasks evenly after base requirements are met.
                Weighted Distribution: If capacityProviderA has weight ``1`` and capacityProviderB has weight ``4``, then for every 1 task on A, 4 tasks will run on B.
        """
        if base is not None:
            pulumi.set(__self__, "base", base)
        if capacity_provider is not None:
            pulumi.set(__self__, "capacity_provider", capacity_provider)
        if weight is not None:
            pulumi.set(__self__, "weight", weight)

    @_builtins.property
    @pulumi.getter
    def base(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The *base* value designates how many tasks, at a minimum, to run on the specified capacity provider for each service. Only one capacity provider in a capacity provider strategy can have a *base* defined. If no value is specified, the default value of ``0`` is used.
         Base value characteristics:
          +  Only one capacity provider in a strategy can have a base defined
          +  Default value is ``0`` if not specified
          +  Valid range: 0 to 100,000
          +  Base requirements are satisfied first before weight distribution
        """
        return pulumi.get(self, "base")

    @base.setter
    def base(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "base", value)

    @_builtins.property
    @pulumi.getter(name="capacityProvider")
    def capacity_provider(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The short name of the capacity provider.
        """
        return pulumi.get(self, "capacity_provider")

    @capacity_provider.setter
    def capacity_provider(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "capacity_provider", value)

    @_builtins.property
    @pulumi.getter
    def weight(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The *weight* value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The ``weight`` value is taken into consideration after the ``base`` value, if defined, is satisfied.
         If no ``weight`` value is specified, the default value of ``0`` is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of ``0`` can't be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of ``0``, any ``RunTask`` or ``CreateService`` actions using the capacity provider strategy will fail.
         Weight value characteristics:
          +  Weight is considered after the base value is satisfied
          +  Default value is ``0`` if not specified
          +  Valid range: 0 to 1,000
          +  At least one capacity provider must have a weight greater than zero
          +  Capacity providers with weight of ``0`` cannot place tasks
          
         Task distribution logic:
          1.  Base satisfaction: The minimum number of tasks specified by the base value are placed on that capacity provider
          1.  Weight distribution: After base requirements are met, additional tasks are distributed according to weight ratios
          
         Examples:
         Equal Distribution: Two capacity providers both with weight ``1`` will split tasks evenly after base requirements are met.
         Weighted Distribution: If capacityProviderA has weight ``1`` and capacityProviderB has weight ``4``, then for every 1 task on A, 4 tasks will run on B.
        """
        return pulumi.get(self, "weight")

    @weight.setter
    def weight(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "weight", value)


if not MYPY:
    class ServiceConnectAccessLogConfigurationArgsDict(TypedDict):
        format: pulumi.Input['ServiceConnectAccessLogConfigurationFormat']
        """
        The format for Service Connect access log output. Choose TEXT for human-readable logs or JSON for structured data that integrates well with log analysis tools.
        """
        include_query_parameters: NotRequired[pulumi.Input['ServiceConnectAccessLogConfigurationIncludeQueryParameters']]
        """
        Specifies whether to include query parameters in Service Connect access logs.

        When enabled, query parameters from HTTP requests are included in the access logs. Consider security and privacy implications when enabling this feature, as query parameters may contain sensitive information such as request IDs and tokens. By default, this parameter is `DISABLED` .
        """
elif False:
    ServiceConnectAccessLogConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceConnectAccessLogConfigurationArgs:
    def __init__(__self__, *,
                 format: pulumi.Input['ServiceConnectAccessLogConfigurationFormat'],
                 include_query_parameters: Optional[pulumi.Input['ServiceConnectAccessLogConfigurationIncludeQueryParameters']] = None):
        """
        :param pulumi.Input['ServiceConnectAccessLogConfigurationFormat'] format: The format for Service Connect access log output. Choose TEXT for human-readable logs or JSON for structured data that integrates well with log analysis tools.
        :param pulumi.Input['ServiceConnectAccessLogConfigurationIncludeQueryParameters'] include_query_parameters: Specifies whether to include query parameters in Service Connect access logs.
               
               When enabled, query parameters from HTTP requests are included in the access logs. Consider security and privacy implications when enabling this feature, as query parameters may contain sensitive information such as request IDs and tokens. By default, this parameter is `DISABLED` .
        """
        pulumi.set(__self__, "format", format)
        if include_query_parameters is not None:
            pulumi.set(__self__, "include_query_parameters", include_query_parameters)

    @_builtins.property
    @pulumi.getter
    def format(self) -> pulumi.Input['ServiceConnectAccessLogConfigurationFormat']:
        """
        The format for Service Connect access log output. Choose TEXT for human-readable logs or JSON for structured data that integrates well with log analysis tools.
        """
        return pulumi.get(self, "format")

    @format.setter
    def format(self, value: pulumi.Input['ServiceConnectAccessLogConfigurationFormat']):
        pulumi.set(self, "format", value)

    @_builtins.property
    @pulumi.getter(name="includeQueryParameters")
    def include_query_parameters(self) -> Optional[pulumi.Input['ServiceConnectAccessLogConfigurationIncludeQueryParameters']]:
        """
        Specifies whether to include query parameters in Service Connect access logs.

        When enabled, query parameters from HTTP requests are included in the access logs. Consider security and privacy implications when enabling this feature, as query parameters may contain sensitive information such as request IDs and tokens. By default, this parameter is `DISABLED` .
        """
        return pulumi.get(self, "include_query_parameters")

    @include_query_parameters.setter
    def include_query_parameters(self, value: Optional[pulumi.Input['ServiceConnectAccessLogConfigurationIncludeQueryParameters']]):
        pulumi.set(self, "include_query_parameters", value)


if not MYPY:
    class ServiceConnectClientAliasArgsDict(TypedDict):
        """
        Each alias ("endpoint") is a fully-qualified name and port number that other tasks ("clients") can use to connect to this service.
         Each name and port mapping must be unique within the namespace.
         Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        port: pulumi.Input[_builtins.int]
        """
        The listening port number for the Service Connect proxy. This port is available inside of all of the tasks within the same namespace.
         To avoid changing your applications in client Amazon ECS services, set this to the same port that the client application uses by default. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        dns_name: NotRequired[pulumi.Input[_builtins.str]]
        """
        The ``dnsName`` is the name that you use in the applications of client tasks to connect to this service. The name must be a valid DNS name but doesn't need to be fully-qualified. The name can include up to 127 characters. The name can include lowercase letters, numbers, underscores (_), hyphens (-), and periods (.). The name can't start with a hyphen.
         If this parameter isn't specified, the default value of ``discoveryName.namespace`` is used. If the ``discoveryName`` isn't specified, the port mapping name from the task definition is used in ``portName.namespace``.
         To avoid changing your applications in client Amazon ECS services, set this to the same name that the client application uses by default. For example, a few common names are ``database``, ``db``, or the lowercase name of a database, such as ``mysql`` or ``redis``. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        test_traffic_rules: NotRequired[pulumi.Input['ServiceConnectTestTrafficRulesArgsDict']]
        """
        The configuration for test traffic routing rules used during blue/green deployments with Amazon ECS Service Connect. This allows you to route a portion of traffic to the new service revision of your service for testing before shifting all production traffic.
        """
elif False:
    ServiceConnectClientAliasArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceConnectClientAliasArgs:
    def __init__(__self__, *,
                 port: pulumi.Input[_builtins.int],
                 dns_name: Optional[pulumi.Input[_builtins.str]] = None,
                 test_traffic_rules: Optional[pulumi.Input['ServiceConnectTestTrafficRulesArgs']] = None):
        """
        Each alias ("endpoint") is a fully-qualified name and port number that other tasks ("clients") can use to connect to this service.
         Each name and port mapping must be unique within the namespace.
         Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.int] port: The listening port number for the Service Connect proxy. This port is available inside of all of the tasks within the same namespace.
                To avoid changing your applications in client Amazon ECS services, set this to the same port that the client application uses by default. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.str] dns_name: The ``dnsName`` is the name that you use in the applications of client tasks to connect to this service. The name must be a valid DNS name but doesn't need to be fully-qualified. The name can include up to 127 characters. The name can include lowercase letters, numbers, underscores (_), hyphens (-), and periods (.). The name can't start with a hyphen.
                If this parameter isn't specified, the default value of ``discoveryName.namespace`` is used. If the ``discoveryName`` isn't specified, the port mapping name from the task definition is used in ``portName.namespace``.
                To avoid changing your applications in client Amazon ECS services, set this to the same name that the client application uses by default. For example, a few common names are ``database``, ``db``, or the lowercase name of a database, such as ``mysql`` or ``redis``. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input['ServiceConnectTestTrafficRulesArgs'] test_traffic_rules: The configuration for test traffic routing rules used during blue/green deployments with Amazon ECS Service Connect. This allows you to route a portion of traffic to the new service revision of your service for testing before shifting all production traffic.
        """
        pulumi.set(__self__, "port", port)
        if dns_name is not None:
            pulumi.set(__self__, "dns_name", dns_name)
        if test_traffic_rules is not None:
            pulumi.set(__self__, "test_traffic_rules", test_traffic_rules)

    @_builtins.property
    @pulumi.getter
    def port(self) -> pulumi.Input[_builtins.int]:
        """
        The listening port number for the Service Connect proxy. This port is available inside of all of the tasks within the same namespace.
         To avoid changing your applications in client Amazon ECS services, set this to the same port that the client application uses by default. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        return pulumi.get(self, "port")

    @port.setter
    def port(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "port", value)

    @_builtins.property
    @pulumi.getter(name="dnsName")
    def dns_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The ``dnsName`` is the name that you use in the applications of client tasks to connect to this service. The name must be a valid DNS name but doesn't need to be fully-qualified. The name can include up to 127 characters. The name can include lowercase letters, numbers, underscores (_), hyphens (-), and periods (.). The name can't start with a hyphen.
         If this parameter isn't specified, the default value of ``discoveryName.namespace`` is used. If the ``discoveryName`` isn't specified, the port mapping name from the task definition is used in ``portName.namespace``.
         To avoid changing your applications in client Amazon ECS services, set this to the same name that the client application uses by default. For example, a few common names are ``database``, ``db``, or the lowercase name of a database, such as ``mysql`` or ``redis``. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        return pulumi.get(self, "dns_name")

    @dns_name.setter
    def dns_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "dns_name", value)

    @_builtins.property
    @pulumi.getter(name="testTrafficRules")
    def test_traffic_rules(self) -> Optional[pulumi.Input['ServiceConnectTestTrafficRulesArgs']]:
        """
        The configuration for test traffic routing rules used during blue/green deployments with Amazon ECS Service Connect. This allows you to route a portion of traffic to the new service revision of your service for testing before shifting all production traffic.
        """
        return pulumi.get(self, "test_traffic_rules")

    @test_traffic_rules.setter
    def test_traffic_rules(self, value: Optional[pulumi.Input['ServiceConnectTestTrafficRulesArgs']]):
        pulumi.set(self, "test_traffic_rules", value)


if not MYPY:
    class ServiceConnectConfigurationArgsDict(TypedDict):
        """
        The Service Connect configuration of your Amazon ECS service. The configuration for this service to discover and connect to services, and be discovered by, and connected from, other services within a namespace.
         Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        enabled: pulumi.Input[_builtins.bool]
        """
        Specifies whether to use Service Connect with this service.
        """
        access_log_configuration: NotRequired[pulumi.Input['ServiceConnectAccessLogConfigurationArgsDict']]
        """
        The configuration for Service Connect access logging. Access logs capture detailed information about requests made to your service, including request patterns, response codes, and timing data. They can be useful for debugging connectivity issues, monitoring service performance, and auditing service-to-service communication for security and compliance purposes.

        > To enable access logs, you must also specify a `logConfiguration` in the `serviceConnectConfiguration` .
        """
        log_configuration: NotRequired[pulumi.Input['ServiceLogConfigurationArgsDict']]
        """
        The log configuration for the container. This parameter maps to ``LogConfig`` in the docker container create command and the ``--log-driver`` option to docker run.
         By default, containers use the same logging driver that the Docker daemon uses. However, the container might use a different logging driver than the Docker daemon by specifying a log driver configuration in the container definition.
         Understand the following when specifying a log configuration for your containers.
          +  Amazon ECS currently supports a subset of the logging drivers available to the Docker daemon. Additional log drivers may be available in future releases of the Amazon ECS container agent.
         For tasks on FARGATElong, the supported log drivers are ``awslogs``, ``splunk``, and ``awsfirelens``.
         For tasks hosted on Amazon EC2 instances, the supported log drivers are ``awslogs``, ``fluentd``, ``gelf``, ``json-file``, ``journald``,``syslog``, ``splunk``, and ``awsfirelens``.
          +  This parameter requires version 1.18 of the Docker Remote API or greater on your container instance.
          +  For tasks that are hosted on Amazon EC2 instances, the Amazon ECS container agent must register the available logging drivers with the ``ECS_AVAILABLE_LOGGING_DRIVERS`` environment variable before containers placed on that instance can use these log configuration options. For more information, see [Amazon ECS container agent configuration](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html) in the *Amazon Elastic Container Service Developer Guide*.
          +  For tasks that are on FARGATElong, because you don't have access to the underlying infrastructure your tasks are hosted on, any additional software needed must be installed outside of the task. For example, the Fluentd output aggregators or a remote host running Logstash to send Gelf logs to.
        """
        namespace: NotRequired[pulumi.Input[_builtins.str]]
        """
        The namespace name or full Amazon Resource Name (ARN) of the CMAPlong namespace for use with Service Connect. The namespace must be in the same AWS Region as the Amazon ECS service and cluster. The type of namespace doesn't affect Service Connect. For more information about CMAPlong, see [Working with Services](https://docs.aws.amazon.com/cloud-map/latest/dg/working-with-services.html) in the *Developer Guide*.
        """
        services: NotRequired[pulumi.Input[Sequence[pulumi.Input['ServiceConnectServiceArgsDict']]]]
        """
        The list of Service Connect service objects. These are names and aliases (also known as endpoints) that are used by other Amazon ECS services to connect to this service. 
         This field is not required for a "client" Amazon ECS service that's a member of a namespace only to connect to other services within the namespace. An example of this would be a frontend application that accepts incoming requests from either a load balancer that's attached to the service or by other means.
         An object selects a port from the task definition, assigns a name for the CMAPlong service, and a list of aliases (endpoints) and ports for client applications to refer to this service.
        """
elif False:
    ServiceConnectConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceConnectConfigurationArgs:
    def __init__(__self__, *,
                 enabled: pulumi.Input[_builtins.bool],
                 access_log_configuration: Optional[pulumi.Input['ServiceConnectAccessLogConfigurationArgs']] = None,
                 log_configuration: Optional[pulumi.Input['ServiceLogConfigurationArgs']] = None,
                 namespace: Optional[pulumi.Input[_builtins.str]] = None,
                 services: Optional[pulumi.Input[Sequence[pulumi.Input['ServiceConnectServiceArgs']]]] = None):
        """
        The Service Connect configuration of your Amazon ECS service. The configuration for this service to discover and connect to services, and be discovered by, and connected from, other services within a namespace.
         Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.bool] enabled: Specifies whether to use Service Connect with this service.
        :param pulumi.Input['ServiceConnectAccessLogConfigurationArgs'] access_log_configuration: The configuration for Service Connect access logging. Access logs capture detailed information about requests made to your service, including request patterns, response codes, and timing data. They can be useful for debugging connectivity issues, monitoring service performance, and auditing service-to-service communication for security and compliance purposes.
               
               > To enable access logs, you must also specify a `logConfiguration` in the `serviceConnectConfiguration` .
        :param pulumi.Input['ServiceLogConfigurationArgs'] log_configuration: The log configuration for the container. This parameter maps to ``LogConfig`` in the docker container create command and the ``--log-driver`` option to docker run.
                By default, containers use the same logging driver that the Docker daemon uses. However, the container might use a different logging driver than the Docker daemon by specifying a log driver configuration in the container definition.
                Understand the following when specifying a log configuration for your containers.
                 +  Amazon ECS currently supports a subset of the logging drivers available to the Docker daemon. Additional log drivers may be available in future releases of the Amazon ECS container agent.
                For tasks on FARGATElong, the supported log drivers are ``awslogs``, ``splunk``, and ``awsfirelens``.
                For tasks hosted on Amazon EC2 instances, the supported log drivers are ``awslogs``, ``fluentd``, ``gelf``, ``json-file``, ``journald``,``syslog``, ``splunk``, and ``awsfirelens``.
                 +  This parameter requires version 1.18 of the Docker Remote API or greater on your container instance.
                 +  For tasks that are hosted on Amazon EC2 instances, the Amazon ECS container agent must register the available logging drivers with the ``ECS_AVAILABLE_LOGGING_DRIVERS`` environment variable before containers placed on that instance can use these log configuration options. For more information, see [Amazon ECS container agent configuration](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html) in the *Amazon Elastic Container Service Developer Guide*.
                 +  For tasks that are on FARGATElong, because you don't have access to the underlying infrastructure your tasks are hosted on, any additional software needed must be installed outside of the task. For example, the Fluentd output aggregators or a remote host running Logstash to send Gelf logs to.
        :param pulumi.Input[_builtins.str] namespace: The namespace name or full Amazon Resource Name (ARN) of the CMAPlong namespace for use with Service Connect. The namespace must be in the same AWS Region as the Amazon ECS service and cluster. The type of namespace doesn't affect Service Connect. For more information about CMAPlong, see [Working with Services](https://docs.aws.amazon.com/cloud-map/latest/dg/working-with-services.html) in the *Developer Guide*.
        :param pulumi.Input[Sequence[pulumi.Input['ServiceConnectServiceArgs']]] services: The list of Service Connect service objects. These are names and aliases (also known as endpoints) that are used by other Amazon ECS services to connect to this service. 
                This field is not required for a "client" Amazon ECS service that's a member of a namespace only to connect to other services within the namespace. An example of this would be a frontend application that accepts incoming requests from either a load balancer that's attached to the service or by other means.
                An object selects a port from the task definition, assigns a name for the CMAPlong service, and a list of aliases (endpoints) and ports for client applications to refer to this service.
        """
        pulumi.set(__self__, "enabled", enabled)
        if access_log_configuration is not None:
            pulumi.set(__self__, "access_log_configuration", access_log_configuration)
        if log_configuration is not None:
            pulumi.set(__self__, "log_configuration", log_configuration)
        if namespace is not None:
            pulumi.set(__self__, "namespace", namespace)
        if services is not None:
            pulumi.set(__self__, "services", services)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> pulumi.Input[_builtins.bool]:
        """
        Specifies whether to use Service Connect with this service.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: pulumi.Input[_builtins.bool]):
        pulumi.set(self, "enabled", value)

    @_builtins.property
    @pulumi.getter(name="accessLogConfiguration")
    def access_log_configuration(self) -> Optional[pulumi.Input['ServiceConnectAccessLogConfigurationArgs']]:
        """
        The configuration for Service Connect access logging. Access logs capture detailed information about requests made to your service, including request patterns, response codes, and timing data. They can be useful for debugging connectivity issues, monitoring service performance, and auditing service-to-service communication for security and compliance purposes.

        > To enable access logs, you must also specify a `logConfiguration` in the `serviceConnectConfiguration` .
        """
        return pulumi.get(self, "access_log_configuration")

    @access_log_configuration.setter
    def access_log_configuration(self, value: Optional[pulumi.Input['ServiceConnectAccessLogConfigurationArgs']]):
        pulumi.set(self, "access_log_configuration", value)

    @_builtins.property
    @pulumi.getter(name="logConfiguration")
    def log_configuration(self) -> Optional[pulumi.Input['ServiceLogConfigurationArgs']]:
        """
        The log configuration for the container. This parameter maps to ``LogConfig`` in the docker container create command and the ``--log-driver`` option to docker run.
         By default, containers use the same logging driver that the Docker daemon uses. However, the container might use a different logging driver than the Docker daemon by specifying a log driver configuration in the container definition.
         Understand the following when specifying a log configuration for your containers.
          +  Amazon ECS currently supports a subset of the logging drivers available to the Docker daemon. Additional log drivers may be available in future releases of the Amazon ECS container agent.
         For tasks on FARGATElong, the supported log drivers are ``awslogs``, ``splunk``, and ``awsfirelens``.
         For tasks hosted on Amazon EC2 instances, the supported log drivers are ``awslogs``, ``fluentd``, ``gelf``, ``json-file``, ``journald``,``syslog``, ``splunk``, and ``awsfirelens``.
          +  This parameter requires version 1.18 of the Docker Remote API or greater on your container instance.
          +  For tasks that are hosted on Amazon EC2 instances, the Amazon ECS container agent must register the available logging drivers with the ``ECS_AVAILABLE_LOGGING_DRIVERS`` environment variable before containers placed on that instance can use these log configuration options. For more information, see [Amazon ECS container agent configuration](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html) in the *Amazon Elastic Container Service Developer Guide*.
          +  For tasks that are on FARGATElong, because you don't have access to the underlying infrastructure your tasks are hosted on, any additional software needed must be installed outside of the task. For example, the Fluentd output aggregators or a remote host running Logstash to send Gelf logs to.
        """
        return pulumi.get(self, "log_configuration")

    @log_configuration.setter
    def log_configuration(self, value: Optional[pulumi.Input['ServiceLogConfigurationArgs']]):
        pulumi.set(self, "log_configuration", value)

    @_builtins.property
    @pulumi.getter
    def namespace(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The namespace name or full Amazon Resource Name (ARN) of the CMAPlong namespace for use with Service Connect. The namespace must be in the same AWS Region as the Amazon ECS service and cluster. The type of namespace doesn't affect Service Connect. For more information about CMAPlong, see [Working with Services](https://docs.aws.amazon.com/cloud-map/latest/dg/working-with-services.html) in the *Developer Guide*.
        """
        return pulumi.get(self, "namespace")

    @namespace.setter
    def namespace(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "namespace", value)

    @_builtins.property
    @pulumi.getter
    def services(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ServiceConnectServiceArgs']]]]:
        """
        The list of Service Connect service objects. These are names and aliases (also known as endpoints) that are used by other Amazon ECS services to connect to this service. 
         This field is not required for a "client" Amazon ECS service that's a member of a namespace only to connect to other services within the namespace. An example of this would be a frontend application that accepts incoming requests from either a load balancer that's attached to the service or by other means.
         An object selects a port from the task definition, assigns a name for the CMAPlong service, and a list of aliases (endpoints) and ports for client applications to refer to this service.
        """
        return pulumi.get(self, "services")

    @services.setter
    def services(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ServiceConnectServiceArgs']]]]):
        pulumi.set(self, "services", value)


if not MYPY:
    class ServiceConnectServiceArgsDict(TypedDict):
        """
        The Service Connect service object configuration. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        port_name: pulumi.Input[_builtins.str]
        """
        The ``portName`` must match the name of one of the ``portMappings`` from all the containers in the task definition of this Amazon ECS service.
        """
        client_aliases: NotRequired[pulumi.Input[Sequence[pulumi.Input['ServiceConnectClientAliasArgsDict']]]]
        """
        The list of client aliases for this Service Connect service. You use these to assign names that can be used by client applications. The maximum number of client aliases that you can have in this list is 1.
         Each alias ("endpoint") is a fully-qualified name and port number that other Amazon ECS tasks ("clients") can use to connect to this service.
         Each name and port mapping must be unique within the namespace.
         For each ``ServiceConnectService``, you must provide at least one ``clientAlias`` with one ``port``.
        """
        discovery_name: NotRequired[pulumi.Input[_builtins.str]]
        """
        The ``discoveryName`` is the name of the new CMAP service that Amazon ECS creates for this Amazon ECS service. This must be unique within the CMAP namespace. The name can contain up to 64 characters. The name can include lowercase letters, numbers, underscores (_), and hyphens (-). The name can't start with a hyphen.
         If the ``discoveryName`` isn't specified, the port mapping name from the task definition is used in ``portName.namespace``.
        """
        ingress_port_override: NotRequired[pulumi.Input[_builtins.int]]
        """
        The port number for the Service Connect proxy to listen on.
         Use the value of this field to bypass the proxy for traffic on the port number specified in the named ``portMapping`` in the task definition of this application, and then use it in your VPC security groups to allow traffic into the proxy for this Amazon ECS service.
         In ``awsvpc`` mode and Fargate, the default value is the container port number. The container port number is in the ``portMapping`` in the task definition. In bridge mode, the default value is the ephemeral port of the Service Connect proxy.
        """
        timeout: NotRequired[pulumi.Input['ServiceTimeoutConfigurationArgsDict']]
        """
        A reference to an object that represents the configured timeouts for Service Connect.
        """
        tls: NotRequired[pulumi.Input['ServiceConnectTlsConfigurationArgsDict']]
        """
        A reference to an object that represents a Transport Layer Security (TLS) configuration.
        """
elif False:
    ServiceConnectServiceArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceConnectServiceArgs:
    def __init__(__self__, *,
                 port_name: pulumi.Input[_builtins.str],
                 client_aliases: Optional[pulumi.Input[Sequence[pulumi.Input['ServiceConnectClientAliasArgs']]]] = None,
                 discovery_name: Optional[pulumi.Input[_builtins.str]] = None,
                 ingress_port_override: Optional[pulumi.Input[_builtins.int]] = None,
                 timeout: Optional[pulumi.Input['ServiceTimeoutConfigurationArgs']] = None,
                 tls: Optional[pulumi.Input['ServiceConnectTlsConfigurationArgs']] = None):
        """
        The Service Connect service object configuration. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.str] port_name: The ``portName`` must match the name of one of the ``portMappings`` from all the containers in the task definition of this Amazon ECS service.
        :param pulumi.Input[Sequence[pulumi.Input['ServiceConnectClientAliasArgs']]] client_aliases: The list of client aliases for this Service Connect service. You use these to assign names that can be used by client applications. The maximum number of client aliases that you can have in this list is 1.
                Each alias ("endpoint") is a fully-qualified name and port number that other Amazon ECS tasks ("clients") can use to connect to this service.
                Each name and port mapping must be unique within the namespace.
                For each ``ServiceConnectService``, you must provide at least one ``clientAlias`` with one ``port``.
        :param pulumi.Input[_builtins.str] discovery_name: The ``discoveryName`` is the name of the new CMAP service that Amazon ECS creates for this Amazon ECS service. This must be unique within the CMAP namespace. The name can contain up to 64 characters. The name can include lowercase letters, numbers, underscores (_), and hyphens (-). The name can't start with a hyphen.
                If the ``discoveryName`` isn't specified, the port mapping name from the task definition is used in ``portName.namespace``.
        :param pulumi.Input[_builtins.int] ingress_port_override: The port number for the Service Connect proxy to listen on.
                Use the value of this field to bypass the proxy for traffic on the port number specified in the named ``portMapping`` in the task definition of this application, and then use it in your VPC security groups to allow traffic into the proxy for this Amazon ECS service.
                In ``awsvpc`` mode and Fargate, the default value is the container port number. The container port number is in the ``portMapping`` in the task definition. In bridge mode, the default value is the ephemeral port of the Service Connect proxy.
        :param pulumi.Input['ServiceTimeoutConfigurationArgs'] timeout: A reference to an object that represents the configured timeouts for Service Connect.
        :param pulumi.Input['ServiceConnectTlsConfigurationArgs'] tls: A reference to an object that represents a Transport Layer Security (TLS) configuration.
        """
        pulumi.set(__self__, "port_name", port_name)
        if client_aliases is not None:
            pulumi.set(__self__, "client_aliases", client_aliases)
        if discovery_name is not None:
            pulumi.set(__self__, "discovery_name", discovery_name)
        if ingress_port_override is not None:
            pulumi.set(__self__, "ingress_port_override", ingress_port_override)
        if timeout is not None:
            pulumi.set(__self__, "timeout", timeout)
        if tls is not None:
            pulumi.set(__self__, "tls", tls)

    @_builtins.property
    @pulumi.getter(name="portName")
    def port_name(self) -> pulumi.Input[_builtins.str]:
        """
        The ``portName`` must match the name of one of the ``portMappings`` from all the containers in the task definition of this Amazon ECS service.
        """
        return pulumi.get(self, "port_name")

    @port_name.setter
    def port_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "port_name", value)

    @_builtins.property
    @pulumi.getter(name="clientAliases")
    def client_aliases(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ServiceConnectClientAliasArgs']]]]:
        """
        The list of client aliases for this Service Connect service. You use these to assign names that can be used by client applications. The maximum number of client aliases that you can have in this list is 1.
         Each alias ("endpoint") is a fully-qualified name and port number that other Amazon ECS tasks ("clients") can use to connect to this service.
         Each name and port mapping must be unique within the namespace.
         For each ``ServiceConnectService``, you must provide at least one ``clientAlias`` with one ``port``.
        """
        return pulumi.get(self, "client_aliases")

    @client_aliases.setter
    def client_aliases(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ServiceConnectClientAliasArgs']]]]):
        pulumi.set(self, "client_aliases", value)

    @_builtins.property
    @pulumi.getter(name="discoveryName")
    def discovery_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The ``discoveryName`` is the name of the new CMAP service that Amazon ECS creates for this Amazon ECS service. This must be unique within the CMAP namespace. The name can contain up to 64 characters. The name can include lowercase letters, numbers, underscores (_), and hyphens (-). The name can't start with a hyphen.
         If the ``discoveryName`` isn't specified, the port mapping name from the task definition is used in ``portName.namespace``.
        """
        return pulumi.get(self, "discovery_name")

    @discovery_name.setter
    def discovery_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "discovery_name", value)

    @_builtins.property
    @pulumi.getter(name="ingressPortOverride")
    def ingress_port_override(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The port number for the Service Connect proxy to listen on.
         Use the value of this field to bypass the proxy for traffic on the port number specified in the named ``portMapping`` in the task definition of this application, and then use it in your VPC security groups to allow traffic into the proxy for this Amazon ECS service.
         In ``awsvpc`` mode and Fargate, the default value is the container port number. The container port number is in the ``portMapping`` in the task definition. In bridge mode, the default value is the ephemeral port of the Service Connect proxy.
        """
        return pulumi.get(self, "ingress_port_override")

    @ingress_port_override.setter
    def ingress_port_override(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "ingress_port_override", value)

    @_builtins.property
    @pulumi.getter
    def timeout(self) -> Optional[pulumi.Input['ServiceTimeoutConfigurationArgs']]:
        """
        A reference to an object that represents the configured timeouts for Service Connect.
        """
        return pulumi.get(self, "timeout")

    @timeout.setter
    def timeout(self, value: Optional[pulumi.Input['ServiceTimeoutConfigurationArgs']]):
        pulumi.set(self, "timeout", value)

    @_builtins.property
    @pulumi.getter
    def tls(self) -> Optional[pulumi.Input['ServiceConnectTlsConfigurationArgs']]:
        """
        A reference to an object that represents a Transport Layer Security (TLS) configuration.
        """
        return pulumi.get(self, "tls")

    @tls.setter
    def tls(self, value: Optional[pulumi.Input['ServiceConnectTlsConfigurationArgs']]):
        pulumi.set(self, "tls", value)


if not MYPY:
    class ServiceConnectTestTrafficRulesHeaderValueArgsDict(TypedDict):
        exact: pulumi.Input[_builtins.str]
elif False:
    ServiceConnectTestTrafficRulesHeaderValueArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceConnectTestTrafficRulesHeaderValueArgs:
    def __init__(__self__, *,
                 exact: pulumi.Input[_builtins.str]):
        pulumi.set(__self__, "exact", exact)

    @_builtins.property
    @pulumi.getter
    def exact(self) -> pulumi.Input[_builtins.str]:
        return pulumi.get(self, "exact")

    @exact.setter
    def exact(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "exact", value)


if not MYPY:
    class ServiceConnectTestTrafficRulesHeaderArgsDict(TypedDict):
        name: pulumi.Input[_builtins.str]
        value: NotRequired[pulumi.Input['ServiceConnectTestTrafficRulesHeaderValueArgsDict']]
elif False:
    ServiceConnectTestTrafficRulesHeaderArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceConnectTestTrafficRulesHeaderArgs:
    def __init__(__self__, *,
                 name: pulumi.Input[_builtins.str],
                 value: Optional[pulumi.Input['ServiceConnectTestTrafficRulesHeaderValueArgs']] = None):
        pulumi.set(__self__, "name", name)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def name(self) -> pulumi.Input[_builtins.str]:
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "name", value)

    @_builtins.property
    @pulumi.getter
    def value(self) -> Optional[pulumi.Input['ServiceConnectTestTrafficRulesHeaderValueArgs']]:
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: Optional[pulumi.Input['ServiceConnectTestTrafficRulesHeaderValueArgs']]):
        pulumi.set(self, "value", value)


if not MYPY:
    class ServiceConnectTestTrafficRulesArgsDict(TypedDict):
        """
        The test traffic routing configuration for Amazon ECS blue/green deployments. This configuration allows you to define rules for routing specific traffic to the new service revision during the deployment process, allowing for safe testing before full production traffic shift.
         For more information, see [Service Connect for Amazon ECS blue/green deployments](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect-blue-green.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        header: pulumi.Input['ServiceConnectTestTrafficRulesHeaderArgsDict']
        """
        The HTTP header-based routing rules that determine which requests should be routed to the new service version during blue/green deployment testing. These rules provide fine-grained control over test traffic routing based on request headers.
        """
elif False:
    ServiceConnectTestTrafficRulesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceConnectTestTrafficRulesArgs:
    def __init__(__self__, *,
                 header: pulumi.Input['ServiceConnectTestTrafficRulesHeaderArgs']):
        """
        The test traffic routing configuration for Amazon ECS blue/green deployments. This configuration allows you to define rules for routing specific traffic to the new service revision during the deployment process, allowing for safe testing before full production traffic shift.
         For more information, see [Service Connect for Amazon ECS blue/green deployments](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect-blue-green.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input['ServiceConnectTestTrafficRulesHeaderArgs'] header: The HTTP header-based routing rules that determine which requests should be routed to the new service version during blue/green deployment testing. These rules provide fine-grained control over test traffic routing based on request headers.
        """
        pulumi.set(__self__, "header", header)

    @_builtins.property
    @pulumi.getter
    def header(self) -> pulumi.Input['ServiceConnectTestTrafficRulesHeaderArgs']:
        """
        The HTTP header-based routing rules that determine which requests should be routed to the new service version during blue/green deployment testing. These rules provide fine-grained control over test traffic routing based on request headers.
        """
        return pulumi.get(self, "header")

    @header.setter
    def header(self, value: pulumi.Input['ServiceConnectTestTrafficRulesHeaderArgs']):
        pulumi.set(self, "header", value)


if not MYPY:
    class ServiceConnectTlsCertificateAuthorityArgsDict(TypedDict):
        """
        The certificate root authority that secures your service.
        """
        aws_pca_authority_arn: NotRequired[pulumi.Input[_builtins.str]]
        """
        The ARN of the AWS Private Certificate Authority certificate.
        """
elif False:
    ServiceConnectTlsCertificateAuthorityArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceConnectTlsCertificateAuthorityArgs:
    def __init__(__self__, *,
                 aws_pca_authority_arn: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The certificate root authority that secures your service.
        :param pulumi.Input[_builtins.str] aws_pca_authority_arn: The ARN of the AWS Private Certificate Authority certificate.
        """
        if aws_pca_authority_arn is not None:
            pulumi.set(__self__, "aws_pca_authority_arn", aws_pca_authority_arn)

    @_builtins.property
    @pulumi.getter(name="awsPcaAuthorityArn")
    def aws_pca_authority_arn(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The ARN of the AWS Private Certificate Authority certificate.
        """
        return pulumi.get(self, "aws_pca_authority_arn")

    @aws_pca_authority_arn.setter
    def aws_pca_authority_arn(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "aws_pca_authority_arn", value)


if not MYPY:
    class ServiceConnectTlsConfigurationArgsDict(TypedDict):
        """
        The key that encrypts and decrypts your resources for Service Connect TLS.
        """
        issuer_certificate_authority: pulumi.Input['ServiceConnectTlsCertificateAuthorityArgsDict']
        """
        The signer certificate authority.
        """
        kms_key: NotRequired[pulumi.Input[_builtins.str]]
        """
        The AWS Key Management Service key.
        """
        role_arn: NotRequired[pulumi.Input[_builtins.str]]
        """
        The Amazon Resource Name (ARN) of the IAM role that's associated with the Service Connect TLS.
        """
elif False:
    ServiceConnectTlsConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceConnectTlsConfigurationArgs:
    def __init__(__self__, *,
                 issuer_certificate_authority: pulumi.Input['ServiceConnectTlsCertificateAuthorityArgs'],
                 kms_key: Optional[pulumi.Input[_builtins.str]] = None,
                 role_arn: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The key that encrypts and decrypts your resources for Service Connect TLS.
        :param pulumi.Input['ServiceConnectTlsCertificateAuthorityArgs'] issuer_certificate_authority: The signer certificate authority.
        :param pulumi.Input[_builtins.str] kms_key: The AWS Key Management Service key.
        :param pulumi.Input[_builtins.str] role_arn: The Amazon Resource Name (ARN) of the IAM role that's associated with the Service Connect TLS.
        """
        pulumi.set(__self__, "issuer_certificate_authority", issuer_certificate_authority)
        if kms_key is not None:
            pulumi.set(__self__, "kms_key", kms_key)
        if role_arn is not None:
            pulumi.set(__self__, "role_arn", role_arn)

    @_builtins.property
    @pulumi.getter(name="issuerCertificateAuthority")
    def issuer_certificate_authority(self) -> pulumi.Input['ServiceConnectTlsCertificateAuthorityArgs']:
        """
        The signer certificate authority.
        """
        return pulumi.get(self, "issuer_certificate_authority")

    @issuer_certificate_authority.setter
    def issuer_certificate_authority(self, value: pulumi.Input['ServiceConnectTlsCertificateAuthorityArgs']):
        pulumi.set(self, "issuer_certificate_authority", value)

    @_builtins.property
    @pulumi.getter(name="kmsKey")
    def kms_key(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The AWS Key Management Service key.
        """
        return pulumi.get(self, "kms_key")

    @kms_key.setter
    def kms_key(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "kms_key", value)

    @_builtins.property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The Amazon Resource Name (ARN) of the IAM role that's associated with the Service Connect TLS.
        """
        return pulumi.get(self, "role_arn")

    @role_arn.setter
    def role_arn(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "role_arn", value)


if not MYPY:
    class ServiceDeploymentAlarmsArgsDict(TypedDict):
        """
        One of the methods which provide a way for you to quickly identify when a deployment has failed, and then to optionally roll back the failure to the last working deployment.
         When the alarms are generated, Amazon ECS sets the service deployment to failed. Set the rollback parameter to have Amazon ECS to roll back your service to the last completed deployment after a failure.
         You can only use the ``DeploymentAlarms`` method to detect failures when the ``DeploymentController`` is set to ``ECS``.
         For more information, see [Rolling update](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-ecs.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        alarm_names: pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]
        """
        One or more CloudWatch alarm names. Use a "," to separate the alarms.
        """
        enable: pulumi.Input[_builtins.bool]
        """
        Determines whether to use the CloudWatch alarm option in the service deployment process.
        """
        rollback: pulumi.Input[_builtins.bool]
        """
        Determines whether to configure Amazon ECS to roll back the service if a service deployment fails. If rollback is used, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.
        """
elif False:
    ServiceDeploymentAlarmsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceDeploymentAlarmsArgs:
    def __init__(__self__, *,
                 alarm_names: pulumi.Input[Sequence[pulumi.Input[_builtins.str]]],
                 enable: pulumi.Input[_builtins.bool],
                 rollback: pulumi.Input[_builtins.bool]):
        """
        One of the methods which provide a way for you to quickly identify when a deployment has failed, and then to optionally roll back the failure to the last working deployment.
         When the alarms are generated, Amazon ECS sets the service deployment to failed. Set the rollback parameter to have Amazon ECS to roll back your service to the last completed deployment after a failure.
         You can only use the ``DeploymentAlarms`` method to detect failures when the ``DeploymentController`` is set to ``ECS``.
         For more information, see [Rolling update](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-ecs.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] alarm_names: One or more CloudWatch alarm names. Use a "," to separate the alarms.
        :param pulumi.Input[_builtins.bool] enable: Determines whether to use the CloudWatch alarm option in the service deployment process.
        :param pulumi.Input[_builtins.bool] rollback: Determines whether to configure Amazon ECS to roll back the service if a service deployment fails. If rollback is used, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.
        """
        pulumi.set(__self__, "alarm_names", alarm_names)
        pulumi.set(__self__, "enable", enable)
        pulumi.set(__self__, "rollback", rollback)

    @_builtins.property
    @pulumi.getter(name="alarmNames")
    def alarm_names(self) -> pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]:
        """
        One or more CloudWatch alarm names. Use a "," to separate the alarms.
        """
        return pulumi.get(self, "alarm_names")

    @alarm_names.setter
    def alarm_names(self, value: pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]):
        pulumi.set(self, "alarm_names", value)

    @_builtins.property
    @pulumi.getter
    def enable(self) -> pulumi.Input[_builtins.bool]:
        """
        Determines whether to use the CloudWatch alarm option in the service deployment process.
        """
        return pulumi.get(self, "enable")

    @enable.setter
    def enable(self, value: pulumi.Input[_builtins.bool]):
        pulumi.set(self, "enable", value)

    @_builtins.property
    @pulumi.getter
    def rollback(self) -> pulumi.Input[_builtins.bool]:
        """
        Determines whether to configure Amazon ECS to roll back the service if a service deployment fails. If rollback is used, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.
        """
        return pulumi.get(self, "rollback")

    @rollback.setter
    def rollback(self, value: pulumi.Input[_builtins.bool]):
        pulumi.set(self, "rollback", value)


if not MYPY:
    class ServiceDeploymentCircuitBreakerArgsDict(TypedDict):
        """
        The deployment circuit breaker can only be used for services using the rolling update (``ECS``) deployment type.
          The *deployment circuit breaker* determines whether a service deployment will fail if the service can't reach a steady state. If it is turned on, a service deployment will transition to a failed state and stop launching new tasks. You can also configure Amazon ECS to roll back your service to the last completed deployment after a failure. For more information, see [Rolling update](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-ecs.html) in the *Amazon Elastic Container Service Developer Guide*.
         For more information about API failure reasons, see [API failure reasons](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/api_failures_messages.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        enable: pulumi.Input[_builtins.bool]
        """
        Determines whether to use the deployment circuit breaker logic for the service.
        """
        rollback: pulumi.Input[_builtins.bool]
        """
        Determines whether to configure Amazon ECS to roll back the service if a service deployment fails. If rollback is on, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.
        """
elif False:
    ServiceDeploymentCircuitBreakerArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceDeploymentCircuitBreakerArgs:
    def __init__(__self__, *,
                 enable: pulumi.Input[_builtins.bool],
                 rollback: pulumi.Input[_builtins.bool]):
        """
        The deployment circuit breaker can only be used for services using the rolling update (``ECS``) deployment type.
          The *deployment circuit breaker* determines whether a service deployment will fail if the service can't reach a steady state. If it is turned on, a service deployment will transition to a failed state and stop launching new tasks. You can also configure Amazon ECS to roll back your service to the last completed deployment after a failure. For more information, see [Rolling update](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-ecs.html) in the *Amazon Elastic Container Service Developer Guide*.
         For more information about API failure reasons, see [API failure reasons](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/api_failures_messages.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.bool] enable: Determines whether to use the deployment circuit breaker logic for the service.
        :param pulumi.Input[_builtins.bool] rollback: Determines whether to configure Amazon ECS to roll back the service if a service deployment fails. If rollback is on, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.
        """
        pulumi.set(__self__, "enable", enable)
        pulumi.set(__self__, "rollback", rollback)

    @_builtins.property
    @pulumi.getter
    def enable(self) -> pulumi.Input[_builtins.bool]:
        """
        Determines whether to use the deployment circuit breaker logic for the service.
        """
        return pulumi.get(self, "enable")

    @enable.setter
    def enable(self, value: pulumi.Input[_builtins.bool]):
        pulumi.set(self, "enable", value)

    @_builtins.property
    @pulumi.getter
    def rollback(self) -> pulumi.Input[_builtins.bool]:
        """
        Determines whether to configure Amazon ECS to roll back the service if a service deployment fails. If rollback is on, when a service deployment fails, the service is rolled back to the last deployment that completed successfully.
        """
        return pulumi.get(self, "rollback")

    @rollback.setter
    def rollback(self, value: pulumi.Input[_builtins.bool]):
        pulumi.set(self, "rollback", value)


if not MYPY:
    class ServiceDeploymentConfigurationArgsDict(TypedDict):
        """
        Optional deployment parameters that control how many tasks run during a deployment and the ordering of stopping and starting tasks.
        """
        alarms: NotRequired[pulumi.Input['ServiceDeploymentAlarmsArgsDict']]
        """
        Information about the CloudWatch alarms.
        """
        bake_time_in_minutes: NotRequired[pulumi.Input[_builtins.int]]
        """
        The duration when both blue and green service revisions are running simultaneously after the production traffic has shifted.
         The following rules apply when you don't specify a value:
          +  For rolling deployments, the value is set to 3 hours (180 minutes).
          +  When you use an external deployment controller (``EXTERNAL``), or the ACD blue/green deployment controller (``CODE_DEPLOY``), the value is set to 3 hours (180 minutes).
          +  For all other cases, the value is set to 36 hours (2160 minutes).
        """
        canary_configuration: NotRequired[pulumi.Input['ServiceCanaryConfigurationArgsDict']]
        """
        Configuration for canary deployment strategy. Only valid when the deployment strategy is `CANARY` . This configuration enables shifting a fixed percentage of traffic for testing, followed by shifting the remaining traffic after a bake period.
        """
        deployment_circuit_breaker: NotRequired[pulumi.Input['ServiceDeploymentCircuitBreakerArgsDict']]
        """
        The deployment circuit breaker can only be used for services using the rolling update (``ECS``) deployment type.
          The *deployment circuit breaker* determines whether a service deployment will fail if the service can't reach a steady state. If you use the deployment circuit breaker, a service deployment will transition to a failed state and stop launching new tasks. If you use the rollback option, when a service deployment fails, the service is rolled back to the last deployment that completed successfully. For more information, see [Rolling update](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-ecs.html) in the *Amazon Elastic Container Service Developer Guide*
        """
        lifecycle_hooks: NotRequired[pulumi.Input[Sequence[pulumi.Input['ServiceDeploymentLifecycleHookArgsDict']]]]
        """
        An array of deployment lifecycle hook objects to run custom logic at specific stages of the deployment lifecycle.
        """
        linear_configuration: NotRequired[pulumi.Input['ServiceLinearConfigurationArgsDict']]
        """
        Configuration for linear deployment strategy. Only valid when the deployment strategy is `LINEAR` . This configuration enables progressive traffic shifting in equal percentage increments with configurable bake times between each step.
        """
        maximum_percent: NotRequired[pulumi.Input[_builtins.int]]
        """
        If a service is using the rolling update (``ECS``) deployment type, the ``maximumPercent`` parameter represents an upper limit on the number of your service's tasks that are allowed in the ``RUNNING`` or ``PENDING`` state during a deployment, as a percentage of the ``desiredCount`` (rounded down to the nearest integer). This parameter enables you to define the deployment batch size. For example, if your service is using the ``REPLICA`` service scheduler and has a ``desiredCount`` of four tasks and a ``maximumPercent`` value of 200%, the scheduler may start four new tasks before stopping the four older tasks (provided that the cluster resources required to do this are available). The default ``maximumPercent`` value for a service using the ``REPLICA`` service scheduler is 200%.
         The Amazon ECS scheduler uses this parameter to replace unhealthy tasks by starting replacement tasks first and then stopping the unhealthy tasks, as long as cluster resources for starting replacement tasks are available. For more information about how the scheduler replaces unhealthy tasks, see [Amazon ECS services](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html).
         If a service is using either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types, and tasks in the service use the EC2 launch type, the *maximum percent* value is set to the default value. The *maximum percent* value is used to define the upper limit on the number of the tasks in the service that remain in the ``RUNNING`` state while the container instances are in the ``DRAINING`` state.
          You can't specify a custom ``maximumPercent`` value for a service that uses either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types and has tasks that use the EC2 launch type.
          If the service uses either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types, and the tasks in the service use the Fargate launch type, the maximum percent value is not used. The value is still returned when describing your service.
        """
        minimum_healthy_percent: NotRequired[pulumi.Input[_builtins.int]]
        """
        If a service is using the rolling update (``ECS``) deployment type, the ``minimumHealthyPercent`` represents a lower limit on the number of your service's tasks that must remain in the ``RUNNING`` state during a deployment, as a percentage of the ``desiredCount`` (rounded up to the nearest integer). This parameter enables you to deploy without using additional cluster capacity. For example, if your service has a ``desiredCount`` of four tasks and a ``minimumHealthyPercent`` of 50%, the service scheduler may stop two existing tasks to free up cluster capacity before starting two new tasks. 
          If any tasks are unhealthy and if ``maximumPercent`` doesn't allow the Amazon ECS scheduler to start replacement tasks, the scheduler stops the unhealthy tasks one-by-one  using the ``minimumHealthyPercent`` as a constraint  to clear up capacity to launch replacement tasks. For more information about how the scheduler replaces unhealthy tasks, see [Amazon ECS services](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html). 
         For services that *do not* use a load balancer, the following should be noted:
          +  A service is considered healthy if all essential containers within the tasks in the service pass their health checks.
          +  If a task has no essential containers with a health check defined, the service scheduler will wait for 40 seconds after a task reaches a ``RUNNING`` state before the task is counted towards the minimum healthy percent total.
          +  If a task has one or more essential containers with a health check defined, the service scheduler will wait for the task to reach a healthy status before counting it towards the minimum healthy percent total. A task is considered healthy when all essential containers within the task have passed their health checks. The amount of time the service scheduler can wait for is determined by the container health check settings. 
          
         For services that *do* use a load balancer, the following should be noted:
          +  If a task has no essential containers with a health check defined, the service scheduler will wait for the load balancer target group health check to return a healthy status before counting the task towards the minimum healthy percent total.
          +  If a task has an essential container with a health check defined, the service scheduler will wait for both the task to reach a healthy status and the load balancer target group health check to return a healthy status before counting the task towards the minimum healthy percent total.
          
         The default value for a replica service for ``minimumHealthyPercent`` is 100%. The default ``minimumHealthyPercent`` value for a service using the ``DAEMON`` service schedule is 0% for the CLI, the AWS SDKs, and the APIs and 50% for the AWS Management Console.
         The minimum number of healthy tasks during a deployment is the ``desiredCount`` multiplied by the ``minimumHealthyPercent``/100, rounded up to the nearest integer value.
         If a service is using either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types and is running tasks that use the EC2 launch type, the *minimum healthy percent* value is set to the default value. The *minimum healthy percent* value is used to define the lower limit on the number of the tasks in the service that remain in the ``RUNNING`` state while the container instances are in the ``DRAINING`` state.
          You can't specify a custom ``minimumHealthyPercent`` value for a service that uses either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types and has tasks that use the EC2 launch type.
          If a service is using either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types and is running tasks that use the Fargate launch type, the minimum healthy percent value is not used, although it is returned when describing your service.
        """
        strategy: NotRequired[pulumi.Input['ServiceDeploymentConfigurationStrategy']]
        """
        The deployment strategy for the service. Choose from these valid values:
          +  ``ROLLING`` - When you create a service which uses the rolling update (``ROLLING``) deployment strategy, the Amazon ECS service scheduler replaces the currently running tasks with new tasks. The number of tasks that Amazon ECS adds or removes from the service during a rolling update is controlled by the service deployment configuration.
          +  ``BLUE_GREEN`` - A blue/green deployment strategy (``BLUE_GREEN``) is a release methodology that reduces downtime and risk by running two identical production environments called blue and green. With Amazon ECS blue/green deployments, you can validate new service revisions before directing production traffic to them. This approach provides a safer way to deploy changes with the ability to quickly roll back if needed.
        """
elif False:
    ServiceDeploymentConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceDeploymentConfigurationArgs:
    def __init__(__self__, *,
                 alarms: Optional[pulumi.Input['ServiceDeploymentAlarmsArgs']] = None,
                 bake_time_in_minutes: Optional[pulumi.Input[_builtins.int]] = None,
                 canary_configuration: Optional[pulumi.Input['ServiceCanaryConfigurationArgs']] = None,
                 deployment_circuit_breaker: Optional[pulumi.Input['ServiceDeploymentCircuitBreakerArgs']] = None,
                 lifecycle_hooks: Optional[pulumi.Input[Sequence[pulumi.Input['ServiceDeploymentLifecycleHookArgs']]]] = None,
                 linear_configuration: Optional[pulumi.Input['ServiceLinearConfigurationArgs']] = None,
                 maximum_percent: Optional[pulumi.Input[_builtins.int]] = None,
                 minimum_healthy_percent: Optional[pulumi.Input[_builtins.int]] = None,
                 strategy: Optional[pulumi.Input['ServiceDeploymentConfigurationStrategy']] = None):
        """
        Optional deployment parameters that control how many tasks run during a deployment and the ordering of stopping and starting tasks.
        :param pulumi.Input['ServiceDeploymentAlarmsArgs'] alarms: Information about the CloudWatch alarms.
        :param pulumi.Input[_builtins.int] bake_time_in_minutes: The duration when both blue and green service revisions are running simultaneously after the production traffic has shifted.
                The following rules apply when you don't specify a value:
                 +  For rolling deployments, the value is set to 3 hours (180 minutes).
                 +  When you use an external deployment controller (``EXTERNAL``), or the ACD blue/green deployment controller (``CODE_DEPLOY``), the value is set to 3 hours (180 minutes).
                 +  For all other cases, the value is set to 36 hours (2160 minutes).
        :param pulumi.Input['ServiceCanaryConfigurationArgs'] canary_configuration: Configuration for canary deployment strategy. Only valid when the deployment strategy is `CANARY` . This configuration enables shifting a fixed percentage of traffic for testing, followed by shifting the remaining traffic after a bake period.
        :param pulumi.Input['ServiceDeploymentCircuitBreakerArgs'] deployment_circuit_breaker: The deployment circuit breaker can only be used for services using the rolling update (``ECS``) deployment type.
                 The *deployment circuit breaker* determines whether a service deployment will fail if the service can't reach a steady state. If you use the deployment circuit breaker, a service deployment will transition to a failed state and stop launching new tasks. If you use the rollback option, when a service deployment fails, the service is rolled back to the last deployment that completed successfully. For more information, see [Rolling update](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-ecs.html) in the *Amazon Elastic Container Service Developer Guide*
        :param pulumi.Input[Sequence[pulumi.Input['ServiceDeploymentLifecycleHookArgs']]] lifecycle_hooks: An array of deployment lifecycle hook objects to run custom logic at specific stages of the deployment lifecycle.
        :param pulumi.Input['ServiceLinearConfigurationArgs'] linear_configuration: Configuration for linear deployment strategy. Only valid when the deployment strategy is `LINEAR` . This configuration enables progressive traffic shifting in equal percentage increments with configurable bake times between each step.
        :param pulumi.Input[_builtins.int] maximum_percent: If a service is using the rolling update (``ECS``) deployment type, the ``maximumPercent`` parameter represents an upper limit on the number of your service's tasks that are allowed in the ``RUNNING`` or ``PENDING`` state during a deployment, as a percentage of the ``desiredCount`` (rounded down to the nearest integer). This parameter enables you to define the deployment batch size. For example, if your service is using the ``REPLICA`` service scheduler and has a ``desiredCount`` of four tasks and a ``maximumPercent`` value of 200%, the scheduler may start four new tasks before stopping the four older tasks (provided that the cluster resources required to do this are available). The default ``maximumPercent`` value for a service using the ``REPLICA`` service scheduler is 200%.
                The Amazon ECS scheduler uses this parameter to replace unhealthy tasks by starting replacement tasks first and then stopping the unhealthy tasks, as long as cluster resources for starting replacement tasks are available. For more information about how the scheduler replaces unhealthy tasks, see [Amazon ECS services](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html).
                If a service is using either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types, and tasks in the service use the EC2 launch type, the *maximum percent* value is set to the default value. The *maximum percent* value is used to define the upper limit on the number of the tasks in the service that remain in the ``RUNNING`` state while the container instances are in the ``DRAINING`` state.
                 You can't specify a custom ``maximumPercent`` value for a service that uses either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types and has tasks that use the EC2 launch type.
                 If the service uses either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types, and the tasks in the service use the Fargate launch type, the maximum percent value is not used. The value is still returned when describing your service.
        :param pulumi.Input[_builtins.int] minimum_healthy_percent: If a service is using the rolling update (``ECS``) deployment type, the ``minimumHealthyPercent`` represents a lower limit on the number of your service's tasks that must remain in the ``RUNNING`` state during a deployment, as a percentage of the ``desiredCount`` (rounded up to the nearest integer). This parameter enables you to deploy without using additional cluster capacity. For example, if your service has a ``desiredCount`` of four tasks and a ``minimumHealthyPercent`` of 50%, the service scheduler may stop two existing tasks to free up cluster capacity before starting two new tasks. 
                 If any tasks are unhealthy and if ``maximumPercent`` doesn't allow the Amazon ECS scheduler to start replacement tasks, the scheduler stops the unhealthy tasks one-by-one  using the ``minimumHealthyPercent`` as a constraint  to clear up capacity to launch replacement tasks. For more information about how the scheduler replaces unhealthy tasks, see [Amazon ECS services](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html). 
                For services that *do not* use a load balancer, the following should be noted:
                 +  A service is considered healthy if all essential containers within the tasks in the service pass their health checks.
                 +  If a task has no essential containers with a health check defined, the service scheduler will wait for 40 seconds after a task reaches a ``RUNNING`` state before the task is counted towards the minimum healthy percent total.
                 +  If a task has one or more essential containers with a health check defined, the service scheduler will wait for the task to reach a healthy status before counting it towards the minimum healthy percent total. A task is considered healthy when all essential containers within the task have passed their health checks. The amount of time the service scheduler can wait for is determined by the container health check settings. 
                 
                For services that *do* use a load balancer, the following should be noted:
                 +  If a task has no essential containers with a health check defined, the service scheduler will wait for the load balancer target group health check to return a healthy status before counting the task towards the minimum healthy percent total.
                 +  If a task has an essential container with a health check defined, the service scheduler will wait for both the task to reach a healthy status and the load balancer target group health check to return a healthy status before counting the task towards the minimum healthy percent total.
                 
                The default value for a replica service for ``minimumHealthyPercent`` is 100%. The default ``minimumHealthyPercent`` value for a service using the ``DAEMON`` service schedule is 0% for the CLI, the AWS SDKs, and the APIs and 50% for the AWS Management Console.
                The minimum number of healthy tasks during a deployment is the ``desiredCount`` multiplied by the ``minimumHealthyPercent``/100, rounded up to the nearest integer value.
                If a service is using either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types and is running tasks that use the EC2 launch type, the *minimum healthy percent* value is set to the default value. The *minimum healthy percent* value is used to define the lower limit on the number of the tasks in the service that remain in the ``RUNNING`` state while the container instances are in the ``DRAINING`` state.
                 You can't specify a custom ``minimumHealthyPercent`` value for a service that uses either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types and has tasks that use the EC2 launch type.
                 If a service is using either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types and is running tasks that use the Fargate launch type, the minimum healthy percent value is not used, although it is returned when describing your service.
        :param pulumi.Input['ServiceDeploymentConfigurationStrategy'] strategy: The deployment strategy for the service. Choose from these valid values:
                 +  ``ROLLING`` - When you create a service which uses the rolling update (``ROLLING``) deployment strategy, the Amazon ECS service scheduler replaces the currently running tasks with new tasks. The number of tasks that Amazon ECS adds or removes from the service during a rolling update is controlled by the service deployment configuration.
                 +  ``BLUE_GREEN`` - A blue/green deployment strategy (``BLUE_GREEN``) is a release methodology that reduces downtime and risk by running two identical production environments called blue and green. With Amazon ECS blue/green deployments, you can validate new service revisions before directing production traffic to them. This approach provides a safer way to deploy changes with the ability to quickly roll back if needed.
        """
        if alarms is not None:
            pulumi.set(__self__, "alarms", alarms)
        if bake_time_in_minutes is not None:
            pulumi.set(__self__, "bake_time_in_minutes", bake_time_in_minutes)
        if canary_configuration is not None:
            pulumi.set(__self__, "canary_configuration", canary_configuration)
        if deployment_circuit_breaker is not None:
            pulumi.set(__self__, "deployment_circuit_breaker", deployment_circuit_breaker)
        if lifecycle_hooks is not None:
            pulumi.set(__self__, "lifecycle_hooks", lifecycle_hooks)
        if linear_configuration is not None:
            pulumi.set(__self__, "linear_configuration", linear_configuration)
        if maximum_percent is not None:
            pulumi.set(__self__, "maximum_percent", maximum_percent)
        if minimum_healthy_percent is not None:
            pulumi.set(__self__, "minimum_healthy_percent", minimum_healthy_percent)
        if strategy is not None:
            pulumi.set(__self__, "strategy", strategy)

    @_builtins.property
    @pulumi.getter
    def alarms(self) -> Optional[pulumi.Input['ServiceDeploymentAlarmsArgs']]:
        """
        Information about the CloudWatch alarms.
        """
        return pulumi.get(self, "alarms")

    @alarms.setter
    def alarms(self, value: Optional[pulumi.Input['ServiceDeploymentAlarmsArgs']]):
        pulumi.set(self, "alarms", value)

    @_builtins.property
    @pulumi.getter(name="bakeTimeInMinutes")
    def bake_time_in_minutes(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The duration when both blue and green service revisions are running simultaneously after the production traffic has shifted.
         The following rules apply when you don't specify a value:
          +  For rolling deployments, the value is set to 3 hours (180 minutes).
          +  When you use an external deployment controller (``EXTERNAL``), or the ACD blue/green deployment controller (``CODE_DEPLOY``), the value is set to 3 hours (180 minutes).
          +  For all other cases, the value is set to 36 hours (2160 minutes).
        """
        return pulumi.get(self, "bake_time_in_minutes")

    @bake_time_in_minutes.setter
    def bake_time_in_minutes(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "bake_time_in_minutes", value)

    @_builtins.property
    @pulumi.getter(name="canaryConfiguration")
    def canary_configuration(self) -> Optional[pulumi.Input['ServiceCanaryConfigurationArgs']]:
        """
        Configuration for canary deployment strategy. Only valid when the deployment strategy is `CANARY` . This configuration enables shifting a fixed percentage of traffic for testing, followed by shifting the remaining traffic after a bake period.
        """
        return pulumi.get(self, "canary_configuration")

    @canary_configuration.setter
    def canary_configuration(self, value: Optional[pulumi.Input['ServiceCanaryConfigurationArgs']]):
        pulumi.set(self, "canary_configuration", value)

    @_builtins.property
    @pulumi.getter(name="deploymentCircuitBreaker")
    def deployment_circuit_breaker(self) -> Optional[pulumi.Input['ServiceDeploymentCircuitBreakerArgs']]:
        """
        The deployment circuit breaker can only be used for services using the rolling update (``ECS``) deployment type.
          The *deployment circuit breaker* determines whether a service deployment will fail if the service can't reach a steady state. If you use the deployment circuit breaker, a service deployment will transition to a failed state and stop launching new tasks. If you use the rollback option, when a service deployment fails, the service is rolled back to the last deployment that completed successfully. For more information, see [Rolling update](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-ecs.html) in the *Amazon Elastic Container Service Developer Guide*
        """
        return pulumi.get(self, "deployment_circuit_breaker")

    @deployment_circuit_breaker.setter
    def deployment_circuit_breaker(self, value: Optional[pulumi.Input['ServiceDeploymentCircuitBreakerArgs']]):
        pulumi.set(self, "deployment_circuit_breaker", value)

    @_builtins.property
    @pulumi.getter(name="lifecycleHooks")
    def lifecycle_hooks(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ServiceDeploymentLifecycleHookArgs']]]]:
        """
        An array of deployment lifecycle hook objects to run custom logic at specific stages of the deployment lifecycle.
        """
        return pulumi.get(self, "lifecycle_hooks")

    @lifecycle_hooks.setter
    def lifecycle_hooks(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ServiceDeploymentLifecycleHookArgs']]]]):
        pulumi.set(self, "lifecycle_hooks", value)

    @_builtins.property
    @pulumi.getter(name="linearConfiguration")
    def linear_configuration(self) -> Optional[pulumi.Input['ServiceLinearConfigurationArgs']]:
        """
        Configuration for linear deployment strategy. Only valid when the deployment strategy is `LINEAR` . This configuration enables progressive traffic shifting in equal percentage increments with configurable bake times between each step.
        """
        return pulumi.get(self, "linear_configuration")

    @linear_configuration.setter
    def linear_configuration(self, value: Optional[pulumi.Input['ServiceLinearConfigurationArgs']]):
        pulumi.set(self, "linear_configuration", value)

    @_builtins.property
    @pulumi.getter(name="maximumPercent")
    def maximum_percent(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        If a service is using the rolling update (``ECS``) deployment type, the ``maximumPercent`` parameter represents an upper limit on the number of your service's tasks that are allowed in the ``RUNNING`` or ``PENDING`` state during a deployment, as a percentage of the ``desiredCount`` (rounded down to the nearest integer). This parameter enables you to define the deployment batch size. For example, if your service is using the ``REPLICA`` service scheduler and has a ``desiredCount`` of four tasks and a ``maximumPercent`` value of 200%, the scheduler may start four new tasks before stopping the four older tasks (provided that the cluster resources required to do this are available). The default ``maximumPercent`` value for a service using the ``REPLICA`` service scheduler is 200%.
         The Amazon ECS scheduler uses this parameter to replace unhealthy tasks by starting replacement tasks first and then stopping the unhealthy tasks, as long as cluster resources for starting replacement tasks are available. For more information about how the scheduler replaces unhealthy tasks, see [Amazon ECS services](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html).
         If a service is using either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types, and tasks in the service use the EC2 launch type, the *maximum percent* value is set to the default value. The *maximum percent* value is used to define the upper limit on the number of the tasks in the service that remain in the ``RUNNING`` state while the container instances are in the ``DRAINING`` state.
          You can't specify a custom ``maximumPercent`` value for a service that uses either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types and has tasks that use the EC2 launch type.
          If the service uses either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types, and the tasks in the service use the Fargate launch type, the maximum percent value is not used. The value is still returned when describing your service.
        """
        return pulumi.get(self, "maximum_percent")

    @maximum_percent.setter
    def maximum_percent(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "maximum_percent", value)

    @_builtins.property
    @pulumi.getter(name="minimumHealthyPercent")
    def minimum_healthy_percent(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        If a service is using the rolling update (``ECS``) deployment type, the ``minimumHealthyPercent`` represents a lower limit on the number of your service's tasks that must remain in the ``RUNNING`` state during a deployment, as a percentage of the ``desiredCount`` (rounded up to the nearest integer). This parameter enables you to deploy without using additional cluster capacity. For example, if your service has a ``desiredCount`` of four tasks and a ``minimumHealthyPercent`` of 50%, the service scheduler may stop two existing tasks to free up cluster capacity before starting two new tasks. 
          If any tasks are unhealthy and if ``maximumPercent`` doesn't allow the Amazon ECS scheduler to start replacement tasks, the scheduler stops the unhealthy tasks one-by-one  using the ``minimumHealthyPercent`` as a constraint  to clear up capacity to launch replacement tasks. For more information about how the scheduler replaces unhealthy tasks, see [Amazon ECS services](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html). 
         For services that *do not* use a load balancer, the following should be noted:
          +  A service is considered healthy if all essential containers within the tasks in the service pass their health checks.
          +  If a task has no essential containers with a health check defined, the service scheduler will wait for 40 seconds after a task reaches a ``RUNNING`` state before the task is counted towards the minimum healthy percent total.
          +  If a task has one or more essential containers with a health check defined, the service scheduler will wait for the task to reach a healthy status before counting it towards the minimum healthy percent total. A task is considered healthy when all essential containers within the task have passed their health checks. The amount of time the service scheduler can wait for is determined by the container health check settings. 
          
         For services that *do* use a load balancer, the following should be noted:
          +  If a task has no essential containers with a health check defined, the service scheduler will wait for the load balancer target group health check to return a healthy status before counting the task towards the minimum healthy percent total.
          +  If a task has an essential container with a health check defined, the service scheduler will wait for both the task to reach a healthy status and the load balancer target group health check to return a healthy status before counting the task towards the minimum healthy percent total.
          
         The default value for a replica service for ``minimumHealthyPercent`` is 100%. The default ``minimumHealthyPercent`` value for a service using the ``DAEMON`` service schedule is 0% for the CLI, the AWS SDKs, and the APIs and 50% for the AWS Management Console.
         The minimum number of healthy tasks during a deployment is the ``desiredCount`` multiplied by the ``minimumHealthyPercent``/100, rounded up to the nearest integer value.
         If a service is using either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types and is running tasks that use the EC2 launch type, the *minimum healthy percent* value is set to the default value. The *minimum healthy percent* value is used to define the lower limit on the number of the tasks in the service that remain in the ``RUNNING`` state while the container instances are in the ``DRAINING`` state.
          You can't specify a custom ``minimumHealthyPercent`` value for a service that uses either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types and has tasks that use the EC2 launch type.
          If a service is using either the blue/green (``CODE_DEPLOY``) or ``EXTERNAL`` deployment types and is running tasks that use the Fargate launch type, the minimum healthy percent value is not used, although it is returned when describing your service.
        """
        return pulumi.get(self, "minimum_healthy_percent")

    @minimum_healthy_percent.setter
    def minimum_healthy_percent(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "minimum_healthy_percent", value)

    @_builtins.property
    @pulumi.getter
    def strategy(self) -> Optional[pulumi.Input['ServiceDeploymentConfigurationStrategy']]:
        """
        The deployment strategy for the service. Choose from these valid values:
          +  ``ROLLING`` - When you create a service which uses the rolling update (``ROLLING``) deployment strategy, the Amazon ECS service scheduler replaces the currently running tasks with new tasks. The number of tasks that Amazon ECS adds or removes from the service during a rolling update is controlled by the service deployment configuration.
          +  ``BLUE_GREEN`` - A blue/green deployment strategy (``BLUE_GREEN``) is a release methodology that reduces downtime and risk by running two identical production environments called blue and green. With Amazon ECS blue/green deployments, you can validate new service revisions before directing production traffic to them. This approach provides a safer way to deploy changes with the ability to quickly roll back if needed.
        """
        return pulumi.get(self, "strategy")

    @strategy.setter
    def strategy(self, value: Optional[pulumi.Input['ServiceDeploymentConfigurationStrategy']]):
        pulumi.set(self, "strategy", value)


if not MYPY:
    class ServiceDeploymentControllerArgsDict(TypedDict):
        """
        The deployment controller to use for the service.
        """
        type: NotRequired[pulumi.Input['ServiceDeploymentControllerType']]
        """
        The deployment controller type to use.
         The deployment controller is the mechanism that determines how tasks are deployed for your service. The valid options are:
          +  ECS
         When you create a service which uses the ``ECS`` deployment controller, you can choose between the following deployment strategies:
          +  ``ROLLING``: When you create a service which uses the *rolling update* (``ROLLING``) deployment strategy, the ECS service scheduler replaces the currently running tasks with new tasks. The number of tasks that ECS adds or removes from the service during a rolling update is controlled by the service deployment configuration. 
         Rolling update deployments are best suited for the following scenarios:
          +  Gradual service updates: You need to update your service incrementally without taking the entire service offline at once.
          +  Limited resource requirements: You want to avoid the additional resource costs of running two complete environments simultaneously (as required by blue/green deployments).
          +  Acceptable deployment time: Your application can tolerate a longer deployment process, as rolling updates replace tasks one by one.
          +  No need for instant roll back: Your service can tolerate a rollback process that takes minutes rather than seconds.
          +  Simple deployment process: You prefer a straightforward deployment approach without the complexity of managing multiple environments, target groups, and listeners.
          +  No load balancer requirement: Your service doesn't use or require a load balancer, ALB, NLB, or Service Connect (which are required for blue/green deployments).
          +  Stateful applications: Your application maintains state that makes it difficult to run two parallel environments.
          +  Cost sensitivity: You want to minimize deployment costs by not running duplicate environments during deployment.
          
         Rolling updates are the default deployment strategy for services and provide a balance between deployment safety and resource efficiency for many common application scenarios.
          +  ``BLUE_GREEN``: A *blue/green* deployment strategy (``BLUE_GREEN``) is a release methodology that reduces downtime and risk by running two identical production environments called blue and green. With ECS blue/green deployments, you can validate new service revisions before directing production traffic to them. This approach provides a safer way to deploy changes with the ability to quickly roll back if needed.
         ECS blue/green deployments are best suited for the following scenarios:
          +  Service validation: When you need to validate new service revisions before directing production traffic to them
          +  Zero downtime: When your service requires zero-downtime deployments
          +  Instant roll back: When you need the ability to quickly roll back if issues are detected
          +  Load balancer requirement: When your service uses ALB, NLB, or Service Connect
          
          
          +  External
         Use a third-party deployment controller.
          +  Blue/green deployment (powered by ACD)
         ACD installs an updated version of the application as a new replacement task set and reroutes production traffic from the original application task set to the replacement task set. The original task set is terminated after a successful deployment. Use this deployment controller to verify a new deployment of a service before sending production traffic to it.
          
         When updating the deployment controller for a service, consider the following depending on the type of migration you're performing.
          +  If you have a template that contains the ``EXTERNAL`` deployment controller information as well as ``TaskSet`` and ``PrimaryTaskSet`` resources, and you remove the task set resources from the template when updating from ``EXTERNAL`` to ``ECS``, the ``DescribeTaskSet`` and ``DeleteTaskSet`` API calls will return a 400 error after the deployment controller is updated to ``ECS``. This results in a delete failure on the task set resources, even though the stack transitions to ``UPDATE_COMPLETE`` status. For more information, see [Resource removed from stack but not deleted](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/troubleshooting.html#troubleshooting-errors-resource-removed-not-deleted) in the CFNlong User Guide. To fix this issue, delete the task sets directly using the ECS``DeleteTaskSet`` API. For more information about how to delete a task set, see [DeleteTaskSet](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DeleteTaskSet.html) in the ECSlong API Reference.
          +  If you're migrating from ``CODE_DEPLOY`` to ``ECS`` with a new task definition and CFN performs a rollback operation, the ECS``UpdateService`` request fails with the following error:
         Resource handler returned message: "Invalid request provided: Unable to update task definition on services with a CODE_DEPLOY deployment controller. 
          +  After a successful migration from ``ECS`` to ``EXTERNAL`` deployment controller, you need to manually remove the ``ACTIVE`` task set, because ECS no longer manages the deployment. For information about how to delete a task set, see [DeleteTaskSet](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DeleteTaskSet.html) in the ECSlong API Reference.
        """
elif False:
    ServiceDeploymentControllerArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceDeploymentControllerArgs:
    def __init__(__self__, *,
                 type: Optional[pulumi.Input['ServiceDeploymentControllerType']] = None):
        """
        The deployment controller to use for the service.
        :param pulumi.Input['ServiceDeploymentControllerType'] type: The deployment controller type to use.
                The deployment controller is the mechanism that determines how tasks are deployed for your service. The valid options are:
                 +  ECS
                When you create a service which uses the ``ECS`` deployment controller, you can choose between the following deployment strategies:
                 +  ``ROLLING``: When you create a service which uses the *rolling update* (``ROLLING``) deployment strategy, the ECS service scheduler replaces the currently running tasks with new tasks. The number of tasks that ECS adds or removes from the service during a rolling update is controlled by the service deployment configuration. 
                Rolling update deployments are best suited for the following scenarios:
                 +  Gradual service updates: You need to update your service incrementally without taking the entire service offline at once.
                 +  Limited resource requirements: You want to avoid the additional resource costs of running two complete environments simultaneously (as required by blue/green deployments).
                 +  Acceptable deployment time: Your application can tolerate a longer deployment process, as rolling updates replace tasks one by one.
                 +  No need for instant roll back: Your service can tolerate a rollback process that takes minutes rather than seconds.
                 +  Simple deployment process: You prefer a straightforward deployment approach without the complexity of managing multiple environments, target groups, and listeners.
                 +  No load balancer requirement: Your service doesn't use or require a load balancer, ALB, NLB, or Service Connect (which are required for blue/green deployments).
                 +  Stateful applications: Your application maintains state that makes it difficult to run two parallel environments.
                 +  Cost sensitivity: You want to minimize deployment costs by not running duplicate environments during deployment.
                 
                Rolling updates are the default deployment strategy for services and provide a balance between deployment safety and resource efficiency for many common application scenarios.
                 +  ``BLUE_GREEN``: A *blue/green* deployment strategy (``BLUE_GREEN``) is a release methodology that reduces downtime and risk by running two identical production environments called blue and green. With ECS blue/green deployments, you can validate new service revisions before directing production traffic to them. This approach provides a safer way to deploy changes with the ability to quickly roll back if needed.
                ECS blue/green deployments are best suited for the following scenarios:
                 +  Service validation: When you need to validate new service revisions before directing production traffic to them
                 +  Zero downtime: When your service requires zero-downtime deployments
                 +  Instant roll back: When you need the ability to quickly roll back if issues are detected
                 +  Load balancer requirement: When your service uses ALB, NLB, or Service Connect
                 
                 
                 +  External
                Use a third-party deployment controller.
                 +  Blue/green deployment (powered by ACD)
                ACD installs an updated version of the application as a new replacement task set and reroutes production traffic from the original application task set to the replacement task set. The original task set is terminated after a successful deployment. Use this deployment controller to verify a new deployment of a service before sending production traffic to it.
                 
                When updating the deployment controller for a service, consider the following depending on the type of migration you're performing.
                 +  If you have a template that contains the ``EXTERNAL`` deployment controller information as well as ``TaskSet`` and ``PrimaryTaskSet`` resources, and you remove the task set resources from the template when updating from ``EXTERNAL`` to ``ECS``, the ``DescribeTaskSet`` and ``DeleteTaskSet`` API calls will return a 400 error after the deployment controller is updated to ``ECS``. This results in a delete failure on the task set resources, even though the stack transitions to ``UPDATE_COMPLETE`` status. For more information, see [Resource removed from stack but not deleted](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/troubleshooting.html#troubleshooting-errors-resource-removed-not-deleted) in the CFNlong User Guide. To fix this issue, delete the task sets directly using the ECS``DeleteTaskSet`` API. For more information about how to delete a task set, see [DeleteTaskSet](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DeleteTaskSet.html) in the ECSlong API Reference.
                 +  If you're migrating from ``CODE_DEPLOY`` to ``ECS`` with a new task definition and CFN performs a rollback operation, the ECS``UpdateService`` request fails with the following error:
                Resource handler returned message: "Invalid request provided: Unable to update task definition on services with a CODE_DEPLOY deployment controller. 
                 +  After a successful migration from ``ECS`` to ``EXTERNAL`` deployment controller, you need to manually remove the ``ACTIVE`` task set, because ECS no longer manages the deployment. For information about how to delete a task set, see [DeleteTaskSet](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DeleteTaskSet.html) in the ECSlong API Reference.
        """
        if type is not None:
            pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter
    def type(self) -> Optional[pulumi.Input['ServiceDeploymentControllerType']]:
        """
        The deployment controller type to use.
         The deployment controller is the mechanism that determines how tasks are deployed for your service. The valid options are:
          +  ECS
         When you create a service which uses the ``ECS`` deployment controller, you can choose between the following deployment strategies:
          +  ``ROLLING``: When you create a service which uses the *rolling update* (``ROLLING``) deployment strategy, the ECS service scheduler replaces the currently running tasks with new tasks. The number of tasks that ECS adds or removes from the service during a rolling update is controlled by the service deployment configuration. 
         Rolling update deployments are best suited for the following scenarios:
          +  Gradual service updates: You need to update your service incrementally without taking the entire service offline at once.
          +  Limited resource requirements: You want to avoid the additional resource costs of running two complete environments simultaneously (as required by blue/green deployments).
          +  Acceptable deployment time: Your application can tolerate a longer deployment process, as rolling updates replace tasks one by one.
          +  No need for instant roll back: Your service can tolerate a rollback process that takes minutes rather than seconds.
          +  Simple deployment process: You prefer a straightforward deployment approach without the complexity of managing multiple environments, target groups, and listeners.
          +  No load balancer requirement: Your service doesn't use or require a load balancer, ALB, NLB, or Service Connect (which are required for blue/green deployments).
          +  Stateful applications: Your application maintains state that makes it difficult to run two parallel environments.
          +  Cost sensitivity: You want to minimize deployment costs by not running duplicate environments during deployment.
          
         Rolling updates are the default deployment strategy for services and provide a balance between deployment safety and resource efficiency for many common application scenarios.
          +  ``BLUE_GREEN``: A *blue/green* deployment strategy (``BLUE_GREEN``) is a release methodology that reduces downtime and risk by running two identical production environments called blue and green. With ECS blue/green deployments, you can validate new service revisions before directing production traffic to them. This approach provides a safer way to deploy changes with the ability to quickly roll back if needed.
         ECS blue/green deployments are best suited for the following scenarios:
          +  Service validation: When you need to validate new service revisions before directing production traffic to them
          +  Zero downtime: When your service requires zero-downtime deployments
          +  Instant roll back: When you need the ability to quickly roll back if issues are detected
          +  Load balancer requirement: When your service uses ALB, NLB, or Service Connect
          
          
          +  External
         Use a third-party deployment controller.
          +  Blue/green deployment (powered by ACD)
         ACD installs an updated version of the application as a new replacement task set and reroutes production traffic from the original application task set to the replacement task set. The original task set is terminated after a successful deployment. Use this deployment controller to verify a new deployment of a service before sending production traffic to it.
          
         When updating the deployment controller for a service, consider the following depending on the type of migration you're performing.
          +  If you have a template that contains the ``EXTERNAL`` deployment controller information as well as ``TaskSet`` and ``PrimaryTaskSet`` resources, and you remove the task set resources from the template when updating from ``EXTERNAL`` to ``ECS``, the ``DescribeTaskSet`` and ``DeleteTaskSet`` API calls will return a 400 error after the deployment controller is updated to ``ECS``. This results in a delete failure on the task set resources, even though the stack transitions to ``UPDATE_COMPLETE`` status. For more information, see [Resource removed from stack but not deleted](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/troubleshooting.html#troubleshooting-errors-resource-removed-not-deleted) in the CFNlong User Guide. To fix this issue, delete the task sets directly using the ECS``DeleteTaskSet`` API. For more information about how to delete a task set, see [DeleteTaskSet](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DeleteTaskSet.html) in the ECSlong API Reference.
          +  If you're migrating from ``CODE_DEPLOY`` to ``ECS`` with a new task definition and CFN performs a rollback operation, the ECS``UpdateService`` request fails with the following error:
         Resource handler returned message: "Invalid request provided: Unable to update task definition on services with a CODE_DEPLOY deployment controller. 
          +  After a successful migration from ``ECS`` to ``EXTERNAL`` deployment controller, you need to manually remove the ``ACTIVE`` task set, because ECS no longer manages the deployment. For information about how to delete a task set, see [DeleteTaskSet](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DeleteTaskSet.html) in the ECSlong API Reference.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: Optional[pulumi.Input['ServiceDeploymentControllerType']]):
        pulumi.set(self, "type", value)


if not MYPY:
    class ServiceDeploymentLifecycleHookArgsDict(TypedDict):
        """
        A deployment lifecycle hook runs custom logic at specific stages of the deployment process. Currently, you can use Lambda functions as hook targets.
         For more information, see [Lifecycle hooks for Amazon ECS service deployments](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-lifecycle-hooks.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        hook_target_arn: pulumi.Input[_builtins.str]
        """
        The Amazon Resource Name (ARN) of the hook target. Currently, only Lambda function ARNs are supported.
         You must provide this parameter when configuring a deployment lifecycle hook.
        """
        lifecycle_stages: pulumi.Input[Sequence[pulumi.Input['ServiceDeploymentLifecycleHookLifecycleStagesItem']]]
        """
        The lifecycle stages at which to run the hook. Choose from these valid values:
          +  RECONCILE_SERVICE
         The reconciliation stage that only happens when you start a new service deployment with more than 1 service revision in an ACTIVE state.
         You can use a lifecycle hook for this stage.
          +  PRE_SCALE_UP
         The green service revision has not started. The blue service revision is handling 100% of the production traffic. There is no test traffic.
         You can use a lifecycle hook for this stage.
          +  POST_SCALE_UP
         The green service revision has started. The blue service revision is handling 100% of the production traffic. There is no test traffic.
         You can use a lifecycle hook for this stage.
          +  TEST_TRAFFIC_SHIFT
         The blue and green service revisions are running. The blue service revision handles 100% of the production traffic. The green service revision is migrating from 0% to 100% of test traffic.
         You can use a lifecycle hook for this stage.
          +  POST_TEST_TRAFFIC_SHIFT
         The test traffic shift is complete. The green service revision handles 100% of the test traffic.
         You can use a lifecycle hook for this stage.
          +  PRODUCTION_TRAFFIC_SHIFT
         Production traffic is shifting to the green service revision. The green service revision is migrating from 0% to 100% of production traffic.
         You can use a lifecycle hook for this stage.
          +  POST_PRODUCTION_TRAFFIC_SHIFT
         The production traffic shift is complete.
         You can use a lifecycle hook for this stage.
          
         You must provide this parameter when configuring a deployment lifecycle hook.
        """
        role_arn: pulumi.Input[_builtins.str]
        """
        The Amazon Resource Name (ARN) of the IAM role that grants Amazon ECS permission to call Lambda functions on your behalf.
         For more information, see [Permissions required for Lambda functions in Amazon ECS blue/green deployments](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/blue-green-permissions.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        hook_details: NotRequired[Any]
        """
        Use this field to specify custom parameters that ECS passes to your hook target invocations (such as a Lambda function).
         This field must be a JSON object as a string.
        """
elif False:
    ServiceDeploymentLifecycleHookArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceDeploymentLifecycleHookArgs:
    def __init__(__self__, *,
                 hook_target_arn: pulumi.Input[_builtins.str],
                 lifecycle_stages: pulumi.Input[Sequence[pulumi.Input['ServiceDeploymentLifecycleHookLifecycleStagesItem']]],
                 role_arn: pulumi.Input[_builtins.str],
                 hook_details: Optional[Any] = None):
        """
        A deployment lifecycle hook runs custom logic at specific stages of the deployment process. Currently, you can use Lambda functions as hook targets.
         For more information, see [Lifecycle hooks for Amazon ECS service deployments](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-lifecycle-hooks.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.str] hook_target_arn: The Amazon Resource Name (ARN) of the hook target. Currently, only Lambda function ARNs are supported.
                You must provide this parameter when configuring a deployment lifecycle hook.
        :param pulumi.Input[Sequence[pulumi.Input['ServiceDeploymentLifecycleHookLifecycleStagesItem']]] lifecycle_stages: The lifecycle stages at which to run the hook. Choose from these valid values:
                 +  RECONCILE_SERVICE
                The reconciliation stage that only happens when you start a new service deployment with more than 1 service revision in an ACTIVE state.
                You can use a lifecycle hook for this stage.
                 +  PRE_SCALE_UP
                The green service revision has not started. The blue service revision is handling 100% of the production traffic. There is no test traffic.
                You can use a lifecycle hook for this stage.
                 +  POST_SCALE_UP
                The green service revision has started. The blue service revision is handling 100% of the production traffic. There is no test traffic.
                You can use a lifecycle hook for this stage.
                 +  TEST_TRAFFIC_SHIFT
                The blue and green service revisions are running. The blue service revision handles 100% of the production traffic. The green service revision is migrating from 0% to 100% of test traffic.
                You can use a lifecycle hook for this stage.
                 +  POST_TEST_TRAFFIC_SHIFT
                The test traffic shift is complete. The green service revision handles 100% of the test traffic.
                You can use a lifecycle hook for this stage.
                 +  PRODUCTION_TRAFFIC_SHIFT
                Production traffic is shifting to the green service revision. The green service revision is migrating from 0% to 100% of production traffic.
                You can use a lifecycle hook for this stage.
                 +  POST_PRODUCTION_TRAFFIC_SHIFT
                The production traffic shift is complete.
                You can use a lifecycle hook for this stage.
                 
                You must provide this parameter when configuring a deployment lifecycle hook.
        :param pulumi.Input[_builtins.str] role_arn: The Amazon Resource Name (ARN) of the IAM role that grants Amazon ECS permission to call Lambda functions on your behalf.
                For more information, see [Permissions required for Lambda functions in Amazon ECS blue/green deployments](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/blue-green-permissions.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param Any hook_details: Use this field to specify custom parameters that ECS passes to your hook target invocations (such as a Lambda function).
                This field must be a JSON object as a string.
        """
        pulumi.set(__self__, "hook_target_arn", hook_target_arn)
        pulumi.set(__self__, "lifecycle_stages", lifecycle_stages)
        pulumi.set(__self__, "role_arn", role_arn)
        if hook_details is not None:
            pulumi.set(__self__, "hook_details", hook_details)

    @_builtins.property
    @pulumi.getter(name="hookTargetArn")
    def hook_target_arn(self) -> pulumi.Input[_builtins.str]:
        """
        The Amazon Resource Name (ARN) of the hook target. Currently, only Lambda function ARNs are supported.
         You must provide this parameter when configuring a deployment lifecycle hook.
        """
        return pulumi.get(self, "hook_target_arn")

    @hook_target_arn.setter
    def hook_target_arn(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "hook_target_arn", value)

    @_builtins.property
    @pulumi.getter(name="lifecycleStages")
    def lifecycle_stages(self) -> pulumi.Input[Sequence[pulumi.Input['ServiceDeploymentLifecycleHookLifecycleStagesItem']]]:
        """
        The lifecycle stages at which to run the hook. Choose from these valid values:
          +  RECONCILE_SERVICE
         The reconciliation stage that only happens when you start a new service deployment with more than 1 service revision in an ACTIVE state.
         You can use a lifecycle hook for this stage.
          +  PRE_SCALE_UP
         The green service revision has not started. The blue service revision is handling 100% of the production traffic. There is no test traffic.
         You can use a lifecycle hook for this stage.
          +  POST_SCALE_UP
         The green service revision has started. The blue service revision is handling 100% of the production traffic. There is no test traffic.
         You can use a lifecycle hook for this stage.
          +  TEST_TRAFFIC_SHIFT
         The blue and green service revisions are running. The blue service revision handles 100% of the production traffic. The green service revision is migrating from 0% to 100% of test traffic.
         You can use a lifecycle hook for this stage.
          +  POST_TEST_TRAFFIC_SHIFT
         The test traffic shift is complete. The green service revision handles 100% of the test traffic.
         You can use a lifecycle hook for this stage.
          +  PRODUCTION_TRAFFIC_SHIFT
         Production traffic is shifting to the green service revision. The green service revision is migrating from 0% to 100% of production traffic.
         You can use a lifecycle hook for this stage.
          +  POST_PRODUCTION_TRAFFIC_SHIFT
         The production traffic shift is complete.
         You can use a lifecycle hook for this stage.
          
         You must provide this parameter when configuring a deployment lifecycle hook.
        """
        return pulumi.get(self, "lifecycle_stages")

    @lifecycle_stages.setter
    def lifecycle_stages(self, value: pulumi.Input[Sequence[pulumi.Input['ServiceDeploymentLifecycleHookLifecycleStagesItem']]]):
        pulumi.set(self, "lifecycle_stages", value)

    @_builtins.property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> pulumi.Input[_builtins.str]:
        """
        The Amazon Resource Name (ARN) of the IAM role that grants Amazon ECS permission to call Lambda functions on your behalf.
         For more information, see [Permissions required for Lambda functions in Amazon ECS blue/green deployments](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/blue-green-permissions.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        return pulumi.get(self, "role_arn")

    @role_arn.setter
    def role_arn(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "role_arn", value)

    @_builtins.property
    @pulumi.getter(name="hookDetails")
    def hook_details(self) -> Optional[Any]:
        """
        Use this field to specify custom parameters that ECS passes to your hook target invocations (such as a Lambda function).
         This field must be a JSON object as a string.
        """
        return pulumi.get(self, "hook_details")

    @hook_details.setter
    def hook_details(self, value: Optional[Any]):
        pulumi.set(self, "hook_details", value)


if not MYPY:
    class ServiceEbsTagSpecificationArgsDict(TypedDict):
        """
        The tag specifications of an Amazon EBS volume.
        """
        resource_type: pulumi.Input[_builtins.str]
        """
        The type of volume resource.
        """
        propagate_tags: NotRequired[pulumi.Input['ServiceEbsTagSpecificationPropagateTags']]
        """
        Determines whether to propagate the tags from the task definition to 
        the Amazon EBS volume. Tags can only propagate to a ``SERVICE`` specified in 
        ``ServiceVolumeConfiguration``. If no value is specified, the tags aren't 
        propagated.
        """
        tags: NotRequired[pulumi.Input[Sequence[pulumi.Input['ServiceTagArgsDict']]]]
        """
        The tags applied to this Amazon EBS volume. ``AmazonECSCreated`` and ``AmazonECSManaged`` are reserved tags that can't be used.
        """
elif False:
    ServiceEbsTagSpecificationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceEbsTagSpecificationArgs:
    def __init__(__self__, *,
                 resource_type: pulumi.Input[_builtins.str],
                 propagate_tags: Optional[pulumi.Input['ServiceEbsTagSpecificationPropagateTags']] = None,
                 tags: Optional[pulumi.Input[Sequence[pulumi.Input['ServiceTagArgs']]]] = None):
        """
        The tag specifications of an Amazon EBS volume.
        :param pulumi.Input[_builtins.str] resource_type: The type of volume resource.
        :param pulumi.Input['ServiceEbsTagSpecificationPropagateTags'] propagate_tags: Determines whether to propagate the tags from the task definition to 
               the Amazon EBS volume. Tags can only propagate to a ``SERVICE`` specified in 
               ``ServiceVolumeConfiguration``. If no value is specified, the tags aren't 
               propagated.
        :param pulumi.Input[Sequence[pulumi.Input['ServiceTagArgs']]] tags: The tags applied to this Amazon EBS volume. ``AmazonECSCreated`` and ``AmazonECSManaged`` are reserved tags that can't be used.
        """
        pulumi.set(__self__, "resource_type", resource_type)
        if propagate_tags is not None:
            pulumi.set(__self__, "propagate_tags", propagate_tags)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)

    @_builtins.property
    @pulumi.getter(name="resourceType")
    def resource_type(self) -> pulumi.Input[_builtins.str]:
        """
        The type of volume resource.
        """
        return pulumi.get(self, "resource_type")

    @resource_type.setter
    def resource_type(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "resource_type", value)

    @_builtins.property
    @pulumi.getter(name="propagateTags")
    def propagate_tags(self) -> Optional[pulumi.Input['ServiceEbsTagSpecificationPropagateTags']]:
        """
        Determines whether to propagate the tags from the task definition to 
        the Amazon EBS volume. Tags can only propagate to a ``SERVICE`` specified in 
        ``ServiceVolumeConfiguration``. If no value is specified, the tags aren't 
        propagated.
        """
        return pulumi.get(self, "propagate_tags")

    @propagate_tags.setter
    def propagate_tags(self, value: Optional[pulumi.Input['ServiceEbsTagSpecificationPropagateTags']]):
        pulumi.set(self, "propagate_tags", value)

    @_builtins.property
    @pulumi.getter
    def tags(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ServiceTagArgs']]]]:
        """
        The tags applied to this Amazon EBS volume. ``AmazonECSCreated`` and ``AmazonECSManaged`` are reserved tags that can't be used.
        """
        return pulumi.get(self, "tags")

    @tags.setter
    def tags(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ServiceTagArgs']]]]):
        pulumi.set(self, "tags", value)


if not MYPY:
    class ServiceForceNewDeploymentArgsDict(TypedDict):
        """
        Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (``my_image:latest``) or to roll Fargate tasks onto a newer platform version.
        """
        enable_force_new_deployment: pulumi.Input[_builtins.bool]
        """
        Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (``my_image:latest``) or to roll Fargate tasks onto a newer platform version.
        """
        force_new_deployment_nonce: NotRequired[pulumi.Input[_builtins.str]]
        """
        When you change the``ForceNewDeploymentNonce`` value in your template, it signals ECS to start a new deployment even though no other service parameters have changed. The value must be a unique, time- varying value like a timestamp, random string, or sequence number. Use this property when you want to ensure your tasks pick up the latest version of a Docker image that uses the same tag but has been updated in the registry.
        """
elif False:
    ServiceForceNewDeploymentArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceForceNewDeploymentArgs:
    def __init__(__self__, *,
                 enable_force_new_deployment: pulumi.Input[_builtins.bool],
                 force_new_deployment_nonce: Optional[pulumi.Input[_builtins.str]] = None):
        """
        Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (``my_image:latest``) or to roll Fargate tasks onto a newer platform version.
        :param pulumi.Input[_builtins.bool] enable_force_new_deployment: Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (``my_image:latest``) or to roll Fargate tasks onto a newer platform version.
        :param pulumi.Input[_builtins.str] force_new_deployment_nonce: When you change the``ForceNewDeploymentNonce`` value in your template, it signals ECS to start a new deployment even though no other service parameters have changed. The value must be a unique, time- varying value like a timestamp, random string, or sequence number. Use this property when you want to ensure your tasks pick up the latest version of a Docker image that uses the same tag but has been updated in the registry.
        """
        pulumi.set(__self__, "enable_force_new_deployment", enable_force_new_deployment)
        if force_new_deployment_nonce is not None:
            pulumi.set(__self__, "force_new_deployment_nonce", force_new_deployment_nonce)

    @_builtins.property
    @pulumi.getter(name="enableForceNewDeployment")
    def enable_force_new_deployment(self) -> pulumi.Input[_builtins.bool]:
        """
        Determines whether to force a new deployment of the service. By default, deployments aren't forced. You can use this option to start a new deployment with no service definition changes. For example, you can update a service's tasks to use a newer Docker image with the same image/tag combination (``my_image:latest``) or to roll Fargate tasks onto a newer platform version.
        """
        return pulumi.get(self, "enable_force_new_deployment")

    @enable_force_new_deployment.setter
    def enable_force_new_deployment(self, value: pulumi.Input[_builtins.bool]):
        pulumi.set(self, "enable_force_new_deployment", value)

    @_builtins.property
    @pulumi.getter(name="forceNewDeploymentNonce")
    def force_new_deployment_nonce(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        When you change the``ForceNewDeploymentNonce`` value in your template, it signals ECS to start a new deployment even though no other service parameters have changed. The value must be a unique, time- varying value like a timestamp, random string, or sequence number. Use this property when you want to ensure your tasks pick up the latest version of a Docker image that uses the same tag but has been updated in the registry.
        """
        return pulumi.get(self, "force_new_deployment_nonce")

    @force_new_deployment_nonce.setter
    def force_new_deployment_nonce(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "force_new_deployment_nonce", value)


if not MYPY:
    class ServiceLinearConfigurationArgsDict(TypedDict):
        step_bake_time_in_minutes: NotRequired[pulumi.Input[_builtins.int]]
        """
        The amount of time in minutes to wait between each traffic shifting step during a linear deployment. Valid values are 0 to 1440 minutes (24 hours). The default value is 6. This bake time is not applied after reaching 100 percent traffic.
        """
        step_percent: NotRequired[pulumi.Input[_builtins.float]]
        """
        The percentage of production traffic to shift in each step during a linear deployment. Valid values are multiples of 0.1 from 3.0 to 100.0. The default value is 10.0.
        """
elif False:
    ServiceLinearConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceLinearConfigurationArgs:
    def __init__(__self__, *,
                 step_bake_time_in_minutes: Optional[pulumi.Input[_builtins.int]] = None,
                 step_percent: Optional[pulumi.Input[_builtins.float]] = None):
        """
        :param pulumi.Input[_builtins.int] step_bake_time_in_minutes: The amount of time in minutes to wait between each traffic shifting step during a linear deployment. Valid values are 0 to 1440 minutes (24 hours). The default value is 6. This bake time is not applied after reaching 100 percent traffic.
        :param pulumi.Input[_builtins.float] step_percent: The percentage of production traffic to shift in each step during a linear deployment. Valid values are multiples of 0.1 from 3.0 to 100.0. The default value is 10.0.
        """
        if step_bake_time_in_minutes is not None:
            pulumi.set(__self__, "step_bake_time_in_minutes", step_bake_time_in_minutes)
        if step_percent is not None:
            pulumi.set(__self__, "step_percent", step_percent)

    @_builtins.property
    @pulumi.getter(name="stepBakeTimeInMinutes")
    def step_bake_time_in_minutes(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The amount of time in minutes to wait between each traffic shifting step during a linear deployment. Valid values are 0 to 1440 minutes (24 hours). The default value is 6. This bake time is not applied after reaching 100 percent traffic.
        """
        return pulumi.get(self, "step_bake_time_in_minutes")

    @step_bake_time_in_minutes.setter
    def step_bake_time_in_minutes(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "step_bake_time_in_minutes", value)

    @_builtins.property
    @pulumi.getter(name="stepPercent")
    def step_percent(self) -> Optional[pulumi.Input[_builtins.float]]:
        """
        The percentage of production traffic to shift in each step during a linear deployment. Valid values are multiples of 0.1 from 3.0 to 100.0. The default value is 10.0.
        """
        return pulumi.get(self, "step_percent")

    @step_percent.setter
    def step_percent(self, value: Optional[pulumi.Input[_builtins.float]]):
        pulumi.set(self, "step_percent", value)


if not MYPY:
    class ServiceLoadBalancerArgsDict(TypedDict):
        """
        The ``LoadBalancer`` property specifies details on a load balancer that is used with a service.
         If the service is using the ``CODE_DEPLOY`` deployment controller, the service is required to use either an Application Load Balancer or Network Load Balancer. When you are creating an ACDlong deployment group, you specify two target groups (referred to as a ``targetGroupPair``). Each target group binds to a separate task set in the deployment. The load balancer can also have up to two listeners, a required listener for production traffic and an optional listener that allows you to test new revisions of the service before routing production traffic to it.
         Services with tasks that use the ``awsvpc`` network mode (for example, those with the Fargate launch type) only support Application Load Balancers and Network Load Balancers. Classic Load Balancers are not supported. Also, when you create any target groups for these services, you must choose ``ip`` as the target type, not ``instance``. Tasks that use the ``awsvpc`` network mode are associated with an elastic network interface, not an Amazon EC2 instance.
        """
        advanced_configuration: NotRequired[pulumi.Input['ServiceAdvancedConfigurationArgsDict']]
        """
        The advanced settings for the load balancer used in blue/green deployments. Specify the alternate target group, listener rules, and IAM role required for traffic shifting during blue/green deployments.
        """
        container_name: NotRequired[pulumi.Input[_builtins.str]]
        """
        The name of the container (as it appears in a container definition) to associate with the load balancer.
         You need to specify the container name when configuring the target group for an Amazon ECS load balancer.
        """
        container_port: NotRequired[pulumi.Input[_builtins.int]]
        """
        The port on the container to associate with the load balancer. This port must correspond to a ``containerPort`` in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they're launched on must allow ingress traffic on the ``hostPort`` of the port mapping.
        """
        load_balancer_name: NotRequired[pulumi.Input[_builtins.str]]
        """
        The name of the load balancer to associate with the Amazon ECS service or task set.
         If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.
        """
        target_group_arn: NotRequired[pulumi.Input[_builtins.str]]
        """
        The full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.
         A target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. 
         For services using the ``ECS`` deployment controller, you can specify one or multiple target groups. For more information, see [Registering multiple target groups with a service](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html) in the *Amazon Elastic Container Service Developer Guide*.
         For services using the ``CODE_DEPLOY`` deployment controller, you're required to define two target groups for the load balancer. For more information, see [Blue/green deployment with CodeDeploy](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-bluegreen.html) in the *Amazon Elastic Container Service Developer Guide*.
          If your service's task definition uses the ``awsvpc`` network mode, you must choose ``ip`` as the target type, not ``instance``. Do this when creating your target groups because tasks that use the ``awsvpc`` network mode are associated with an elastic network interface, not an Amazon EC2 instance. This network mode is required for the Fargate launch type.
        """
elif False:
    ServiceLoadBalancerArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceLoadBalancerArgs:
    def __init__(__self__, *,
                 advanced_configuration: Optional[pulumi.Input['ServiceAdvancedConfigurationArgs']] = None,
                 container_name: Optional[pulumi.Input[_builtins.str]] = None,
                 container_port: Optional[pulumi.Input[_builtins.int]] = None,
                 load_balancer_name: Optional[pulumi.Input[_builtins.str]] = None,
                 target_group_arn: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The ``LoadBalancer`` property specifies details on a load balancer that is used with a service.
         If the service is using the ``CODE_DEPLOY`` deployment controller, the service is required to use either an Application Load Balancer or Network Load Balancer. When you are creating an ACDlong deployment group, you specify two target groups (referred to as a ``targetGroupPair``). Each target group binds to a separate task set in the deployment. The load balancer can also have up to two listeners, a required listener for production traffic and an optional listener that allows you to test new revisions of the service before routing production traffic to it.
         Services with tasks that use the ``awsvpc`` network mode (for example, those with the Fargate launch type) only support Application Load Balancers and Network Load Balancers. Classic Load Balancers are not supported. Also, when you create any target groups for these services, you must choose ``ip`` as the target type, not ``instance``. Tasks that use the ``awsvpc`` network mode are associated with an elastic network interface, not an Amazon EC2 instance.
        :param pulumi.Input['ServiceAdvancedConfigurationArgs'] advanced_configuration: The advanced settings for the load balancer used in blue/green deployments. Specify the alternate target group, listener rules, and IAM role required for traffic shifting during blue/green deployments.
        :param pulumi.Input[_builtins.str] container_name: The name of the container (as it appears in a container definition) to associate with the load balancer.
                You need to specify the container name when configuring the target group for an Amazon ECS load balancer.
        :param pulumi.Input[_builtins.int] container_port: The port on the container to associate with the load balancer. This port must correspond to a ``containerPort`` in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they're launched on must allow ingress traffic on the ``hostPort`` of the port mapping.
        :param pulumi.Input[_builtins.str] load_balancer_name: The name of the load balancer to associate with the Amazon ECS service or task set.
                If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.
        :param pulumi.Input[_builtins.str] target_group_arn: The full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.
                A target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. 
                For services using the ``ECS`` deployment controller, you can specify one or multiple target groups. For more information, see [Registering multiple target groups with a service](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html) in the *Amazon Elastic Container Service Developer Guide*.
                For services using the ``CODE_DEPLOY`` deployment controller, you're required to define two target groups for the load balancer. For more information, see [Blue/green deployment with CodeDeploy](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-bluegreen.html) in the *Amazon Elastic Container Service Developer Guide*.
                 If your service's task definition uses the ``awsvpc`` network mode, you must choose ``ip`` as the target type, not ``instance``. Do this when creating your target groups because tasks that use the ``awsvpc`` network mode are associated with an elastic network interface, not an Amazon EC2 instance. This network mode is required for the Fargate launch type.
        """
        if advanced_configuration is not None:
            pulumi.set(__self__, "advanced_configuration", advanced_configuration)
        if container_name is not None:
            pulumi.set(__self__, "container_name", container_name)
        if container_port is not None:
            pulumi.set(__self__, "container_port", container_port)
        if load_balancer_name is not None:
            pulumi.set(__self__, "load_balancer_name", load_balancer_name)
        if target_group_arn is not None:
            pulumi.set(__self__, "target_group_arn", target_group_arn)

    @_builtins.property
    @pulumi.getter(name="advancedConfiguration")
    def advanced_configuration(self) -> Optional[pulumi.Input['ServiceAdvancedConfigurationArgs']]:
        """
        The advanced settings for the load balancer used in blue/green deployments. Specify the alternate target group, listener rules, and IAM role required for traffic shifting during blue/green deployments.
        """
        return pulumi.get(self, "advanced_configuration")

    @advanced_configuration.setter
    def advanced_configuration(self, value: Optional[pulumi.Input['ServiceAdvancedConfigurationArgs']]):
        pulumi.set(self, "advanced_configuration", value)

    @_builtins.property
    @pulumi.getter(name="containerName")
    def container_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The name of the container (as it appears in a container definition) to associate with the load balancer.
         You need to specify the container name when configuring the target group for an Amazon ECS load balancer.
        """
        return pulumi.get(self, "container_name")

    @container_name.setter
    def container_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "container_name", value)

    @_builtins.property
    @pulumi.getter(name="containerPort")
    def container_port(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The port on the container to associate with the load balancer. This port must correspond to a ``containerPort`` in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they're launched on must allow ingress traffic on the ``hostPort`` of the port mapping.
        """
        return pulumi.get(self, "container_port")

    @container_port.setter
    def container_port(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "container_port", value)

    @_builtins.property
    @pulumi.getter(name="loadBalancerName")
    def load_balancer_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The name of the load balancer to associate with the Amazon ECS service or task set.
         If you are using an Application Load Balancer or a Network Load Balancer the load balancer name parameter should be omitted.
        """
        return pulumi.get(self, "load_balancer_name")

    @load_balancer_name.setter
    def load_balancer_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "load_balancer_name", value)

    @_builtins.property
    @pulumi.getter(name="targetGroupArn")
    def target_group_arn(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set.
         A target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. 
         For services using the ``ECS`` deployment controller, you can specify one or multiple target groups. For more information, see [Registering multiple target groups with a service](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html) in the *Amazon Elastic Container Service Developer Guide*.
         For services using the ``CODE_DEPLOY`` deployment controller, you're required to define two target groups for the load balancer. For more information, see [Blue/green deployment with CodeDeploy](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-bluegreen.html) in the *Amazon Elastic Container Service Developer Guide*.
          If your service's task definition uses the ``awsvpc`` network mode, you must choose ``ip`` as the target type, not ``instance``. Do this when creating your target groups because tasks that use the ``awsvpc`` network mode are associated with an elastic network interface, not an Amazon EC2 instance. This network mode is required for the Fargate launch type.
        """
        return pulumi.get(self, "target_group_arn")

    @target_group_arn.setter
    def target_group_arn(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "target_group_arn", value)


if not MYPY:
    class ServiceLogConfigurationArgsDict(TypedDict):
        """
        The log configuration for the container. This parameter maps to ``LogConfig`` in the docker container create command and the ``--log-driver`` option to docker run.
         By default, containers use the same logging driver that the Docker daemon uses. However, the container might use a different logging driver than the Docker daemon by specifying a log driver configuration in the container definition.
         Understand the following when specifying a log configuration for your containers.
          +  Amazon ECS currently supports a subset of the logging drivers available to the Docker daemon. Additional log drivers may be available in future releases of the Amazon ECS container agent.
         For tasks on FARGATElong, the supported log drivers are ``awslogs``, ``splunk``, and ``awsfirelens``.
         For tasks hosted on Amazon EC2 instances, the supported log drivers are ``awslogs``, ``fluentd``, ``gelf``, ``json-file``, ``journald``,``syslog``, ``splunk``, and ``awsfirelens``.
          +  This parameter requires version 1.18 of the Docker Remote API or greater on your container instance.
          +  For tasks that are hosted on Amazon EC2 instances, the Amazon ECS container agent must register the available logging drivers with the ``ECS_AVAILABLE_LOGGING_DRIVERS`` environment variable before containers placed on that instance can use these log configuration options. For more information, see [Amazon ECS container agent configuration](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html) in the *Amazon Elastic Container Service Developer Guide*.
          +  For tasks that are on FARGATElong, because you don't have access to the underlying infrastructure your tasks are hosted on, any additional software needed must be installed outside of the task. For example, the Fluentd output aggregators or a remote host running Logstash to send Gelf logs to.
        """
        log_driver: NotRequired[pulumi.Input[_builtins.str]]
        """
        The log driver to use for the container.
         For tasks on FARGATElong, the supported log drivers are ``awslogs``, ``splunk``, and ``awsfirelens``.
         For tasks hosted on Amazon EC2 instances, the supported log drivers are ``awslogs``, ``fluentd``, ``gelf``, ``json-file``, ``journald``, ``syslog``, ``splunk``, and ``awsfirelens``.
         For more information about using the ``awslogs`` log driver, see [Send Amazon ECS logs to CloudWatch](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_awslogs.html) in the *Amazon Elastic Container Service Developer Guide*.
         For more information about using the ``awsfirelens`` log driver, see [Send Amazon ECS logs to an service or Partner](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_firelens.html).
          If you have a custom driver that isn't listed, you can fork the Amazon ECS container agent project that's [available on GitHub](https://docs.aws.amazon.com/https://github.com/aws/amazon-ecs-agent) and customize it to work with that driver. We encourage you to submit pull requests for changes that you would like to have included. However, we don't currently provide support for running modified copies of this software.
        """
        options: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]
        """
        The configuration options to send to the log driver.
         The options you can specify depend on the log driver. Some of the options you can specify when you use the ``awslogs`` log driver to route logs to Amazon CloudWatch include the following:
          + awslogs-create-group Required: No Specify whether you want the log group to be created automatically. If this option isn't specified, it defaults to false. Your IAM policy must include the logs:CreateLogGroup permission before you attempt to use awslogs-create-group. + awslogs-region Required: Yes Specify the Region that the awslogs log driver is to send your Docker logs to. You can choose to send all of your logs from clusters in different Regions to a single region in CloudWatch Logs. This is so that they're all visible in one location. Otherwise, you can separate them by Region for more granularity. Make sure that the specified log group exists in the Region that you specify with this option. + awslogs-group Required: Yes Make sure to specify a log group that the awslogs log driver sends its log streams to. + awslogs-stream-prefix Required: Yes, when using Fargate.Optional when using EC2. Use the awslogs-stream-prefix option to associate a log stream with the specified prefix, the container name, and the ID of the Amazon ECS task that the container belongs to. If you specify a prefix with this option, then the log stream takes the format prefix-name/container-name/ecs-task-id. If you don't specify a prefix with this option, then the log stream is named after the container ID that's assigned by the Docker daemon on the container instance. Because it's difficult to trace logs back to the container that sent them with just the Docker container ID (which is only available on the container instance), we recommend that you specify a prefix with this option. For Amazon ECS services, you can use the service name as the prefix. Doing so, you can trace log streams to the service that the container belongs to, the name of the container that sent them, and the ID of the task that the container belongs to. You must specify a stream-prefix for your logs to have your logs appear in the Log pane when using the Amazon ECS console. + awslogs-datetime-format Required: No This option defines a multiline start pattern in Python strftime format. A log message consists of a line that matches the pattern and any following lines that dont match the pattern. The matched line is the delimiter between log messages. One example of a use case for using this format is for parsing output such as a stack dump, which might otherwise be logged in multiple entries. The correct pattern allows it to be captured in a single entry. For more information, see awslogs-datetime-format. You cannot configure both the awslogs-datetime-format and awslogs-multiline-pattern options. Multiline logging performs regular expression parsing and matching of all log messages. This might have a negative impact on logging performance. + awslogs-multiline-pattern Required: No This option defines a multiline start pattern that uses a regular expression. A log message consists of a line that matches the pattern and any following lines that dont match the pattern. The matched line is the delimiter between log messages. For more information, see awslogs-multiline-pattern. This option is ignored if awslogs-datetime-format is also configured. You cannot configure both the awslogs-datetime-format and awslogs-multiline-pattern options. Multiline logging performs regular expression parsing and matching of all log messages. This might have a negative impact on logging performance. 
         The following options apply to all supported log drivers.
          + mode Required: No Valid values: non-blocking | blocking This option defines the delivery mode of log messages from the container to the log driver specified using logDriver. The delivery mode you choose affects application availability when the flow of logs from container is interrupted. If you use the blocking mode and the flow of logs is interrupted, calls from container code to write to the stdout and stderr streams will block. The logging thread of the application will block as a result. This may cause the application to become unresponsive and lead to container healthcheck failure. If you use the non-blocking mode, the container's logs are instead stored in an in-memory intermediate buffer configured with the max-buffer-size option. This prevents the application from becoming unresponsive when logs cannot be sent. We recommend using this mode if you want to ensure service availability and are okay with some log loss. For more information, see Preventing log loss with non-blocking mode in the awslogs container log driver. You can set a default mode for all containers in a specific Region by using the defaultLogDriverMode account setting. If you don't specify the mode option or configure the account setting, Amazon ECS will default to the non-blocking mode. For more information about the account setting, see Default log driver mode in the Amazon Elastic Container Service Developer Guide. On June 25, 2025, Amazon ECS changed the default log driver mode from blocking to non-blocking to prioritize task availability over logging. To continue using the blocking mode after this change, do one of the following: Set the mode option in your container definition's logConfiguration as blocking. Set the defaultLogDriverMode account setting to blocking. + max-buffer-size Required: No Default value: 10m When non-blocking mode is used, the max-buffer-size log option controls the size of the buffer that's used for intermediate message storage. Make sure to specify an adequate buffer size based on your application. When the buffer fills up, further logs cannot be stored. Logs that cannot be stored are lost. 
         To route logs using the ``splunk`` log router, you need to specify a ``splunk-token`` and a ``splunk-url``.
         When you use the ``awsfirelens`` log router to route logs to an AWS Service or AWS Partner Network destination for log storage and analytics, you can set the ``log-driver-buffer-limit`` option to limit the number of events that are buffered in memory, before being sent to the log router container. It can help to resolve potential log loss issue because high throughput might result in memory running out for the buffer inside of Docker.
         Other options you can specify when using ``awsfirelens`` to route logs depend on the destination. When you export logs to Amazon Data Firehose, you can specify the AWS Region with ``region`` and a name for the log stream with ``delivery_stream``.
         When you export logs to Amazon Kinesis Data Streams, you can specify an AWS Region with ``region`` and a data stream name with ``stream``.
          When you export logs to Amazon OpenSearch Service, you can specify options like ``Name``, ``Host`` (OpenSearch Service endpoint without protocol), ``Port``, ``Index``, ``Type``, ``Aws_auth``, ``Aws_region``, ``Suppress_Type_Name``, and ``tls``. For more information, see [Under the hood: FireLens for Amazon ECS Tasks](https://docs.aws.amazon.com/containers/under-the-hood-firelens-for-amazon-ecs-tasks/).
         When you export logs to Amazon S3, you can specify the bucket using the ``bucket`` option. You can also specify ``region``, ``total_file_size``, ``upload_timeout``, and ``use_put_object`` as options.
         This parameter requires version 1.19 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
        """
        secret_options: NotRequired[pulumi.Input[Sequence[pulumi.Input['ServiceSecretArgsDict']]]]
        """
        The secrets to pass to the log configuration. For more information, see [Specifying sensitive data](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
elif False:
    ServiceLogConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceLogConfigurationArgs:
    def __init__(__self__, *,
                 log_driver: Optional[pulumi.Input[_builtins.str]] = None,
                 options: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]] = None,
                 secret_options: Optional[pulumi.Input[Sequence[pulumi.Input['ServiceSecretArgs']]]] = None):
        """
        The log configuration for the container. This parameter maps to ``LogConfig`` in the docker container create command and the ``--log-driver`` option to docker run.
         By default, containers use the same logging driver that the Docker daemon uses. However, the container might use a different logging driver than the Docker daemon by specifying a log driver configuration in the container definition.
         Understand the following when specifying a log configuration for your containers.
          +  Amazon ECS currently supports a subset of the logging drivers available to the Docker daemon. Additional log drivers may be available in future releases of the Amazon ECS container agent.
         For tasks on FARGATElong, the supported log drivers are ``awslogs``, ``splunk``, and ``awsfirelens``.
         For tasks hosted on Amazon EC2 instances, the supported log drivers are ``awslogs``, ``fluentd``, ``gelf``, ``json-file``, ``journald``,``syslog``, ``splunk``, and ``awsfirelens``.
          +  This parameter requires version 1.18 of the Docker Remote API or greater on your container instance.
          +  For tasks that are hosted on Amazon EC2 instances, the Amazon ECS container agent must register the available logging drivers with the ``ECS_AVAILABLE_LOGGING_DRIVERS`` environment variable before containers placed on that instance can use these log configuration options. For more information, see [Amazon ECS container agent configuration](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html) in the *Amazon Elastic Container Service Developer Guide*.
          +  For tasks that are on FARGATElong, because you don't have access to the underlying infrastructure your tasks are hosted on, any additional software needed must be installed outside of the task. For example, the Fluentd output aggregators or a remote host running Logstash to send Gelf logs to.
        :param pulumi.Input[_builtins.str] log_driver: The log driver to use for the container.
                For tasks on FARGATElong, the supported log drivers are ``awslogs``, ``splunk``, and ``awsfirelens``.
                For tasks hosted on Amazon EC2 instances, the supported log drivers are ``awslogs``, ``fluentd``, ``gelf``, ``json-file``, ``journald``, ``syslog``, ``splunk``, and ``awsfirelens``.
                For more information about using the ``awslogs`` log driver, see [Send Amazon ECS logs to CloudWatch](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_awslogs.html) in the *Amazon Elastic Container Service Developer Guide*.
                For more information about using the ``awsfirelens`` log driver, see [Send Amazon ECS logs to an service or Partner](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_firelens.html).
                 If you have a custom driver that isn't listed, you can fork the Amazon ECS container agent project that's [available on GitHub](https://docs.aws.amazon.com/https://github.com/aws/amazon-ecs-agent) and customize it to work with that driver. We encourage you to submit pull requests for changes that you would like to have included. However, we don't currently provide support for running modified copies of this software.
        :param pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]] options: The configuration options to send to the log driver.
                The options you can specify depend on the log driver. Some of the options you can specify when you use the ``awslogs`` log driver to route logs to Amazon CloudWatch include the following:
                 + awslogs-create-group Required: No Specify whether you want the log group to be created automatically. If this option isn't specified, it defaults to false. Your IAM policy must include the logs:CreateLogGroup permission before you attempt to use awslogs-create-group. + awslogs-region Required: Yes Specify the Region that the awslogs log driver is to send your Docker logs to. You can choose to send all of your logs from clusters in different Regions to a single region in CloudWatch Logs. This is so that they're all visible in one location. Otherwise, you can separate them by Region for more granularity. Make sure that the specified log group exists in the Region that you specify with this option. + awslogs-group Required: Yes Make sure to specify a log group that the awslogs log driver sends its log streams to. + awslogs-stream-prefix Required: Yes, when using Fargate.Optional when using EC2. Use the awslogs-stream-prefix option to associate a log stream with the specified prefix, the container name, and the ID of the Amazon ECS task that the container belongs to. If you specify a prefix with this option, then the log stream takes the format prefix-name/container-name/ecs-task-id. If you don't specify a prefix with this option, then the log stream is named after the container ID that's assigned by the Docker daemon on the container instance. Because it's difficult to trace logs back to the container that sent them with just the Docker container ID (which is only available on the container instance), we recommend that you specify a prefix with this option. For Amazon ECS services, you can use the service name as the prefix. Doing so, you can trace log streams to the service that the container belongs to, the name of the container that sent them, and the ID of the task that the container belongs to. You must specify a stream-prefix for your logs to have your logs appear in the Log pane when using the Amazon ECS console. + awslogs-datetime-format Required: No This option defines a multiline start pattern in Python strftime format. A log message consists of a line that matches the pattern and any following lines that dont match the pattern. The matched line is the delimiter between log messages. One example of a use case for using this format is for parsing output such as a stack dump, which might otherwise be logged in multiple entries. The correct pattern allows it to be captured in a single entry. For more information, see awslogs-datetime-format. You cannot configure both the awslogs-datetime-format and awslogs-multiline-pattern options. Multiline logging performs regular expression parsing and matching of all log messages. This might have a negative impact on logging performance. + awslogs-multiline-pattern Required: No This option defines a multiline start pattern that uses a regular expression. A log message consists of a line that matches the pattern and any following lines that dont match the pattern. The matched line is the delimiter between log messages. For more information, see awslogs-multiline-pattern. This option is ignored if awslogs-datetime-format is also configured. You cannot configure both the awslogs-datetime-format and awslogs-multiline-pattern options. Multiline logging performs regular expression parsing and matching of all log messages. This might have a negative impact on logging performance. 
                The following options apply to all supported log drivers.
                 + mode Required: No Valid values: non-blocking | blocking This option defines the delivery mode of log messages from the container to the log driver specified using logDriver. The delivery mode you choose affects application availability when the flow of logs from container is interrupted. If you use the blocking mode and the flow of logs is interrupted, calls from container code to write to the stdout and stderr streams will block. The logging thread of the application will block as a result. This may cause the application to become unresponsive and lead to container healthcheck failure. If you use the non-blocking mode, the container's logs are instead stored in an in-memory intermediate buffer configured with the max-buffer-size option. This prevents the application from becoming unresponsive when logs cannot be sent. We recommend using this mode if you want to ensure service availability and are okay with some log loss. For more information, see Preventing log loss with non-blocking mode in the awslogs container log driver. You can set a default mode for all containers in a specific Region by using the defaultLogDriverMode account setting. If you don't specify the mode option or configure the account setting, Amazon ECS will default to the non-blocking mode. For more information about the account setting, see Default log driver mode in the Amazon Elastic Container Service Developer Guide. On June 25, 2025, Amazon ECS changed the default log driver mode from blocking to non-blocking to prioritize task availability over logging. To continue using the blocking mode after this change, do one of the following: Set the mode option in your container definition's logConfiguration as blocking. Set the defaultLogDriverMode account setting to blocking. + max-buffer-size Required: No Default value: 10m When non-blocking mode is used, the max-buffer-size log option controls the size of the buffer that's used for intermediate message storage. Make sure to specify an adequate buffer size based on your application. When the buffer fills up, further logs cannot be stored. Logs that cannot be stored are lost. 
                To route logs using the ``splunk`` log router, you need to specify a ``splunk-token`` and a ``splunk-url``.
                When you use the ``awsfirelens`` log router to route logs to an AWS Service or AWS Partner Network destination for log storage and analytics, you can set the ``log-driver-buffer-limit`` option to limit the number of events that are buffered in memory, before being sent to the log router container. It can help to resolve potential log loss issue because high throughput might result in memory running out for the buffer inside of Docker.
                Other options you can specify when using ``awsfirelens`` to route logs depend on the destination. When you export logs to Amazon Data Firehose, you can specify the AWS Region with ``region`` and a name for the log stream with ``delivery_stream``.
                When you export logs to Amazon Kinesis Data Streams, you can specify an AWS Region with ``region`` and a data stream name with ``stream``.
                 When you export logs to Amazon OpenSearch Service, you can specify options like ``Name``, ``Host`` (OpenSearch Service endpoint without protocol), ``Port``, ``Index``, ``Type``, ``Aws_auth``, ``Aws_region``, ``Suppress_Type_Name``, and ``tls``. For more information, see [Under the hood: FireLens for Amazon ECS Tasks](https://docs.aws.amazon.com/containers/under-the-hood-firelens-for-amazon-ecs-tasks/).
                When you export logs to Amazon S3, you can specify the bucket using the ``bucket`` option. You can also specify ``region``, ``total_file_size``, ``upload_timeout``, and ``use_put_object`` as options.
                This parameter requires version 1.19 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
        :param pulumi.Input[Sequence[pulumi.Input['ServiceSecretArgs']]] secret_options: The secrets to pass to the log configuration. For more information, see [Specifying sensitive data](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        if log_driver is not None:
            pulumi.set(__self__, "log_driver", log_driver)
        if options is not None:
            pulumi.set(__self__, "options", options)
        if secret_options is not None:
            pulumi.set(__self__, "secret_options", secret_options)

    @_builtins.property
    @pulumi.getter(name="logDriver")
    def log_driver(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The log driver to use for the container.
         For tasks on FARGATElong, the supported log drivers are ``awslogs``, ``splunk``, and ``awsfirelens``.
         For tasks hosted on Amazon EC2 instances, the supported log drivers are ``awslogs``, ``fluentd``, ``gelf``, ``json-file``, ``journald``, ``syslog``, ``splunk``, and ``awsfirelens``.
         For more information about using the ``awslogs`` log driver, see [Send Amazon ECS logs to CloudWatch](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_awslogs.html) in the *Amazon Elastic Container Service Developer Guide*.
         For more information about using the ``awsfirelens`` log driver, see [Send Amazon ECS logs to an service or Partner](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_firelens.html).
          If you have a custom driver that isn't listed, you can fork the Amazon ECS container agent project that's [available on GitHub](https://docs.aws.amazon.com/https://github.com/aws/amazon-ecs-agent) and customize it to work with that driver. We encourage you to submit pull requests for changes that you would like to have included. However, we don't currently provide support for running modified copies of this software.
        """
        return pulumi.get(self, "log_driver")

    @log_driver.setter
    def log_driver(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "log_driver", value)

    @_builtins.property
    @pulumi.getter
    def options(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]:
        """
        The configuration options to send to the log driver.
         The options you can specify depend on the log driver. Some of the options you can specify when you use the ``awslogs`` log driver to route logs to Amazon CloudWatch include the following:
          + awslogs-create-group Required: No Specify whether you want the log group to be created automatically. If this option isn't specified, it defaults to false. Your IAM policy must include the logs:CreateLogGroup permission before you attempt to use awslogs-create-group. + awslogs-region Required: Yes Specify the Region that the awslogs log driver is to send your Docker logs to. You can choose to send all of your logs from clusters in different Regions to a single region in CloudWatch Logs. This is so that they're all visible in one location. Otherwise, you can separate them by Region for more granularity. Make sure that the specified log group exists in the Region that you specify with this option. + awslogs-group Required: Yes Make sure to specify a log group that the awslogs log driver sends its log streams to. + awslogs-stream-prefix Required: Yes, when using Fargate.Optional when using EC2. Use the awslogs-stream-prefix option to associate a log stream with the specified prefix, the container name, and the ID of the Amazon ECS task that the container belongs to. If you specify a prefix with this option, then the log stream takes the format prefix-name/container-name/ecs-task-id. If you don't specify a prefix with this option, then the log stream is named after the container ID that's assigned by the Docker daemon on the container instance. Because it's difficult to trace logs back to the container that sent them with just the Docker container ID (which is only available on the container instance), we recommend that you specify a prefix with this option. For Amazon ECS services, you can use the service name as the prefix. Doing so, you can trace log streams to the service that the container belongs to, the name of the container that sent them, and the ID of the task that the container belongs to. You must specify a stream-prefix for your logs to have your logs appear in the Log pane when using the Amazon ECS console. + awslogs-datetime-format Required: No This option defines a multiline start pattern in Python strftime format. A log message consists of a line that matches the pattern and any following lines that dont match the pattern. The matched line is the delimiter between log messages. One example of a use case for using this format is for parsing output such as a stack dump, which might otherwise be logged in multiple entries. The correct pattern allows it to be captured in a single entry. For more information, see awslogs-datetime-format. You cannot configure both the awslogs-datetime-format and awslogs-multiline-pattern options. Multiline logging performs regular expression parsing and matching of all log messages. This might have a negative impact on logging performance. + awslogs-multiline-pattern Required: No This option defines a multiline start pattern that uses a regular expression. A log message consists of a line that matches the pattern and any following lines that dont match the pattern. The matched line is the delimiter between log messages. For more information, see awslogs-multiline-pattern. This option is ignored if awslogs-datetime-format is also configured. You cannot configure both the awslogs-datetime-format and awslogs-multiline-pattern options. Multiline logging performs regular expression parsing and matching of all log messages. This might have a negative impact on logging performance. 
         The following options apply to all supported log drivers.
          + mode Required: No Valid values: non-blocking | blocking This option defines the delivery mode of log messages from the container to the log driver specified using logDriver. The delivery mode you choose affects application availability when the flow of logs from container is interrupted. If you use the blocking mode and the flow of logs is interrupted, calls from container code to write to the stdout and stderr streams will block. The logging thread of the application will block as a result. This may cause the application to become unresponsive and lead to container healthcheck failure. If you use the non-blocking mode, the container's logs are instead stored in an in-memory intermediate buffer configured with the max-buffer-size option. This prevents the application from becoming unresponsive when logs cannot be sent. We recommend using this mode if you want to ensure service availability and are okay with some log loss. For more information, see Preventing log loss with non-blocking mode in the awslogs container log driver. You can set a default mode for all containers in a specific Region by using the defaultLogDriverMode account setting. If you don't specify the mode option or configure the account setting, Amazon ECS will default to the non-blocking mode. For more information about the account setting, see Default log driver mode in the Amazon Elastic Container Service Developer Guide. On June 25, 2025, Amazon ECS changed the default log driver mode from blocking to non-blocking to prioritize task availability over logging. To continue using the blocking mode after this change, do one of the following: Set the mode option in your container definition's logConfiguration as blocking. Set the defaultLogDriverMode account setting to blocking. + max-buffer-size Required: No Default value: 10m When non-blocking mode is used, the max-buffer-size log option controls the size of the buffer that's used for intermediate message storage. Make sure to specify an adequate buffer size based on your application. When the buffer fills up, further logs cannot be stored. Logs that cannot be stored are lost. 
         To route logs using the ``splunk`` log router, you need to specify a ``splunk-token`` and a ``splunk-url``.
         When you use the ``awsfirelens`` log router to route logs to an AWS Service or AWS Partner Network destination for log storage and analytics, you can set the ``log-driver-buffer-limit`` option to limit the number of events that are buffered in memory, before being sent to the log router container. It can help to resolve potential log loss issue because high throughput might result in memory running out for the buffer inside of Docker.
         Other options you can specify when using ``awsfirelens`` to route logs depend on the destination. When you export logs to Amazon Data Firehose, you can specify the AWS Region with ``region`` and a name for the log stream with ``delivery_stream``.
         When you export logs to Amazon Kinesis Data Streams, you can specify an AWS Region with ``region`` and a data stream name with ``stream``.
          When you export logs to Amazon OpenSearch Service, you can specify options like ``Name``, ``Host`` (OpenSearch Service endpoint without protocol), ``Port``, ``Index``, ``Type``, ``Aws_auth``, ``Aws_region``, ``Suppress_Type_Name``, and ``tls``. For more information, see [Under the hood: FireLens for Amazon ECS Tasks](https://docs.aws.amazon.com/containers/under-the-hood-firelens-for-amazon-ecs-tasks/).
         When you export logs to Amazon S3, you can specify the bucket using the ``bucket`` option. You can also specify ``region``, ``total_file_size``, ``upload_timeout``, and ``use_put_object`` as options.
         This parameter requires version 1.19 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
        """
        return pulumi.get(self, "options")

    @options.setter
    def options(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "options", value)

    @_builtins.property
    @pulumi.getter(name="secretOptions")
    def secret_options(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ServiceSecretArgs']]]]:
        """
        The secrets to pass to the log configuration. For more information, see [Specifying sensitive data](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        return pulumi.get(self, "secret_options")

    @secret_options.setter
    def secret_options(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ServiceSecretArgs']]]]):
        pulumi.set(self, "secret_options", value)


if not MYPY:
    class ServiceManagedEbsVolumeConfigurationArgsDict(TypedDict):
        """
        The configuration for the Amazon EBS volume that Amazon ECS creates and manages on your behalf. These settings are used to create each Amazon EBS volume, with one volume created for each task in the service. For information about the supported launch types and operating systems, see [Supported operating systems and launch types](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ebs-volumes.html#ebs-volumes-configuration) in the*Amazon Elastic Container Service Developer Guide*.
         Many of these parameters map 1:1 with the Amazon EBS ``CreateVolume`` API request parameters.
        """
        role_arn: pulumi.Input[_builtins.str]
        """
        The ARN of the IAM role to associate with this volume. This is the Amazon ECS infrastructure IAM role that is used to manage your AWS infrastructure. We recommend using the Amazon ECS-managed ``AmazonECSInfrastructureRolePolicyForVolumes`` IAM policy with this role. For more information, see [Amazon ECS infrastructure IAM role](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/infrastructure_IAM_role.html) in the *Amazon ECS Developer Guide*.
        """
        encrypted: NotRequired[pulumi.Input[_builtins.bool]]
        """
        Indicates whether the volume should be encrypted. If you turn on Region-level Amazon EBS encryption by default but set this value as ``false``, the setting is overridden and the volume is encrypted with the KMS key specified for Amazon EBS encryption by default. This parameter maps 1:1 with the ``Encrypted`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
        """
        filesystem_type: NotRequired[pulumi.Input[_builtins.str]]
        """
        The filesystem type for the volume. For volumes created from a snapshot, you must specify the same filesystem type that the volume was using when the snapshot was created. If there is a filesystem type mismatch, the tasks will fail to start.
         The available Linux filesystem types are
         ``ext3``, ``ext4``, and ``xfs``. If no value is specified, the ``xfs`` filesystem type is used by default.
         The available Windows filesystem types are ``NTFS``.
        """
        iops: NotRequired[pulumi.Input[_builtins.int]]
        """
        The number of I/O operations per second (IOPS). For ``gp3``, ``io1``, and ``io2`` volumes, this represents the number of IOPS that are provisioned for the volume. For ``gp2`` volumes, this represents the baseline performance of the volume and the rate at which the volume accumulates I/O credits for bursting.
         The following are the supported values for each volume type.
          +  ``gp3``: 3,000 - 16,000 IOPS
          +  ``io1``: 100 - 64,000 IOPS
          +  ``io2``: 100 - 256,000 IOPS
          
         This parameter is required for ``io1`` and ``io2`` volume types. The default for ``gp3`` volumes is ``3,000 IOPS``. This parameter is not supported for ``st1``, ``sc1``, or ``standard`` volume types.
         This parameter maps 1:1 with the ``Iops`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
        """
        kms_key_id: NotRequired[pulumi.Input[_builtins.str]]
        """
        The Amazon Resource Name (ARN) identifier of the AWS Key Management Service key to use for Amazon EBS encryption. When a key is specified using this parameter, it overrides Amazon EBS default encryption or any KMS key that you specified for cluster-level managed storage encryption. This parameter maps 1:1 with the ``KmsKeyId`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*. For more information about encrypting Amazon EBS volumes attached to tasks, see [Encrypt data stored in Amazon EBS volumes attached to Amazon ECS tasks](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ebs-kms-encryption.html).
          AWS authenticates the AWS Key Management Service key asynchronously. Therefore, if you specify an ID, alias, or ARN that is invalid, the action can appear to complete, but eventually fails.
        """
        size_in_gi_b: NotRequired[pulumi.Input[_builtins.int]]
        """
        The size of the volume in GiB. You must specify either a volume size or a snapshot ID. If you specify a snapshot ID, the snapshot size is used for the volume size by default. You can optionally specify a volume size greater than or equal to the snapshot size. This parameter maps 1:1 with the ``Size`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
         The following are the supported volume size values for each volume type.
          +  ``gp2`` and ``gp3``: 1-16,384
          +  ``io1`` and ``io2``: 4-16,384
          +  ``st1`` and ``sc1``: 125-16,384
          +  ``standard``: 1-1,024
        """
        snapshot_id: NotRequired[pulumi.Input[_builtins.str]]
        """
        The snapshot that Amazon ECS uses to create volumes for attachment to tasks maintained by the service. You must specify either ``snapshotId`` or ``sizeInGiB`` in your volume configuration. This parameter maps 1:1 with the ``SnapshotId`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
        """
        tag_specifications: NotRequired[pulumi.Input[Sequence[pulumi.Input['ServiceEbsTagSpecificationArgsDict']]]]
        """
        The tags to apply to the volume. Amazon ECS applies service-managed tags by default. This parameter maps 1:1 with the ``TagSpecifications.N`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
        """
        throughput: NotRequired[pulumi.Input[_builtins.int]]
        """
        The throughput to provision for a volume, in MiB/s, with a maximum of 1,000 MiB/s. This parameter maps 1:1 with the ``Throughput`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
          This parameter is only supported for the ``gp3`` volume type.
        """
        volume_initialization_rate: NotRequired[pulumi.Input[_builtins.int]]
        """
        The rate, in MiB/s, at which data is fetched from a snapshot of an existing EBS volume to create new volumes for attachment to the tasks maintained by the service. This property can be specified only if you specify a ``snapshotId``. For more information, see [Initialize Amazon EBS volumes](https://docs.aws.amazon.com/ebs/latest/userguide/initalize-volume.html) in the *Amazon EBS User Guide*.
        """
        volume_type: NotRequired[pulumi.Input[_builtins.str]]
        """
        The volume type. This parameter maps 1:1 with the ``VolumeType`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*. For more information, see [Amazon EBS volume types](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html) in the *Amazon EC2 User Guide*.
         The following are the supported volume types.
          +  General Purpose SSD: ``gp2``|``gp3``
          +  Provisioned IOPS SSD: ``io1``|``io2``
          +  Throughput Optimized HDD: ``st1``
          +  Cold HDD: ``sc1``
          +  Magnetic: ``standard``
          The magnetic volume type is not supported on Fargate.
        """
elif False:
    ServiceManagedEbsVolumeConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceManagedEbsVolumeConfigurationArgs:
    def __init__(__self__, *,
                 role_arn: pulumi.Input[_builtins.str],
                 encrypted: Optional[pulumi.Input[_builtins.bool]] = None,
                 filesystem_type: Optional[pulumi.Input[_builtins.str]] = None,
                 iops: Optional[pulumi.Input[_builtins.int]] = None,
                 kms_key_id: Optional[pulumi.Input[_builtins.str]] = None,
                 size_in_gi_b: Optional[pulumi.Input[_builtins.int]] = None,
                 snapshot_id: Optional[pulumi.Input[_builtins.str]] = None,
                 tag_specifications: Optional[pulumi.Input[Sequence[pulumi.Input['ServiceEbsTagSpecificationArgs']]]] = None,
                 throughput: Optional[pulumi.Input[_builtins.int]] = None,
                 volume_initialization_rate: Optional[pulumi.Input[_builtins.int]] = None,
                 volume_type: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The configuration for the Amazon EBS volume that Amazon ECS creates and manages on your behalf. These settings are used to create each Amazon EBS volume, with one volume created for each task in the service. For information about the supported launch types and operating systems, see [Supported operating systems and launch types](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ebs-volumes.html#ebs-volumes-configuration) in the*Amazon Elastic Container Service Developer Guide*.
         Many of these parameters map 1:1 with the Amazon EBS ``CreateVolume`` API request parameters.
        :param pulumi.Input[_builtins.str] role_arn: The ARN of the IAM role to associate with this volume. This is the Amazon ECS infrastructure IAM role that is used to manage your AWS infrastructure. We recommend using the Amazon ECS-managed ``AmazonECSInfrastructureRolePolicyForVolumes`` IAM policy with this role. For more information, see [Amazon ECS infrastructure IAM role](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/infrastructure_IAM_role.html) in the *Amazon ECS Developer Guide*.
        :param pulumi.Input[_builtins.bool] encrypted: Indicates whether the volume should be encrypted. If you turn on Region-level Amazon EBS encryption by default but set this value as ``false``, the setting is overridden and the volume is encrypted with the KMS key specified for Amazon EBS encryption by default. This parameter maps 1:1 with the ``Encrypted`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
        :param pulumi.Input[_builtins.str] filesystem_type: The filesystem type for the volume. For volumes created from a snapshot, you must specify the same filesystem type that the volume was using when the snapshot was created. If there is a filesystem type mismatch, the tasks will fail to start.
                The available Linux filesystem types are
                ``ext3``, ``ext4``, and ``xfs``. If no value is specified, the ``xfs`` filesystem type is used by default.
                The available Windows filesystem types are ``NTFS``.
        :param pulumi.Input[_builtins.int] iops: The number of I/O operations per second (IOPS). For ``gp3``, ``io1``, and ``io2`` volumes, this represents the number of IOPS that are provisioned for the volume. For ``gp2`` volumes, this represents the baseline performance of the volume and the rate at which the volume accumulates I/O credits for bursting.
                The following are the supported values for each volume type.
                 +  ``gp3``: 3,000 - 16,000 IOPS
                 +  ``io1``: 100 - 64,000 IOPS
                 +  ``io2``: 100 - 256,000 IOPS
                 
                This parameter is required for ``io1`` and ``io2`` volume types. The default for ``gp3`` volumes is ``3,000 IOPS``. This parameter is not supported for ``st1``, ``sc1``, or ``standard`` volume types.
                This parameter maps 1:1 with the ``Iops`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
        :param pulumi.Input[_builtins.str] kms_key_id: The Amazon Resource Name (ARN) identifier of the AWS Key Management Service key to use for Amazon EBS encryption. When a key is specified using this parameter, it overrides Amazon EBS default encryption or any KMS key that you specified for cluster-level managed storage encryption. This parameter maps 1:1 with the ``KmsKeyId`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*. For more information about encrypting Amazon EBS volumes attached to tasks, see [Encrypt data stored in Amazon EBS volumes attached to Amazon ECS tasks](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ebs-kms-encryption.html).
                 AWS authenticates the AWS Key Management Service key asynchronously. Therefore, if you specify an ID, alias, or ARN that is invalid, the action can appear to complete, but eventually fails.
        :param pulumi.Input[_builtins.int] size_in_gi_b: The size of the volume in GiB. You must specify either a volume size or a snapshot ID. If you specify a snapshot ID, the snapshot size is used for the volume size by default. You can optionally specify a volume size greater than or equal to the snapshot size. This parameter maps 1:1 with the ``Size`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
                The following are the supported volume size values for each volume type.
                 +  ``gp2`` and ``gp3``: 1-16,384
                 +  ``io1`` and ``io2``: 4-16,384
                 +  ``st1`` and ``sc1``: 125-16,384
                 +  ``standard``: 1-1,024
        :param pulumi.Input[_builtins.str] snapshot_id: The snapshot that Amazon ECS uses to create volumes for attachment to tasks maintained by the service. You must specify either ``snapshotId`` or ``sizeInGiB`` in your volume configuration. This parameter maps 1:1 with the ``SnapshotId`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
        :param pulumi.Input[Sequence[pulumi.Input['ServiceEbsTagSpecificationArgs']]] tag_specifications: The tags to apply to the volume. Amazon ECS applies service-managed tags by default. This parameter maps 1:1 with the ``TagSpecifications.N`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
        :param pulumi.Input[_builtins.int] throughput: The throughput to provision for a volume, in MiB/s, with a maximum of 1,000 MiB/s. This parameter maps 1:1 with the ``Throughput`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
                 This parameter is only supported for the ``gp3`` volume type.
        :param pulumi.Input[_builtins.int] volume_initialization_rate: The rate, in MiB/s, at which data is fetched from a snapshot of an existing EBS volume to create new volumes for attachment to the tasks maintained by the service. This property can be specified only if you specify a ``snapshotId``. For more information, see [Initialize Amazon EBS volumes](https://docs.aws.amazon.com/ebs/latest/userguide/initalize-volume.html) in the *Amazon EBS User Guide*.
        :param pulumi.Input[_builtins.str] volume_type: The volume type. This parameter maps 1:1 with the ``VolumeType`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*. For more information, see [Amazon EBS volume types](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html) in the *Amazon EC2 User Guide*.
                The following are the supported volume types.
                 +  General Purpose SSD: ``gp2``|``gp3``
                 +  Provisioned IOPS SSD: ``io1``|``io2``
                 +  Throughput Optimized HDD: ``st1``
                 +  Cold HDD: ``sc1``
                 +  Magnetic: ``standard``
                 The magnetic volume type is not supported on Fargate.
        """
        pulumi.set(__self__, "role_arn", role_arn)
        if encrypted is not None:
            pulumi.set(__self__, "encrypted", encrypted)
        if filesystem_type is not None:
            pulumi.set(__self__, "filesystem_type", filesystem_type)
        if iops is not None:
            pulumi.set(__self__, "iops", iops)
        if kms_key_id is not None:
            pulumi.set(__self__, "kms_key_id", kms_key_id)
        if size_in_gi_b is not None:
            pulumi.set(__self__, "size_in_gi_b", size_in_gi_b)
        if snapshot_id is not None:
            pulumi.set(__self__, "snapshot_id", snapshot_id)
        if tag_specifications is not None:
            pulumi.set(__self__, "tag_specifications", tag_specifications)
        if throughput is not None:
            pulumi.set(__self__, "throughput", throughput)
        if volume_initialization_rate is not None:
            pulumi.set(__self__, "volume_initialization_rate", volume_initialization_rate)
        if volume_type is not None:
            pulumi.set(__self__, "volume_type", volume_type)

    @_builtins.property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> pulumi.Input[_builtins.str]:
        """
        The ARN of the IAM role to associate with this volume. This is the Amazon ECS infrastructure IAM role that is used to manage your AWS infrastructure. We recommend using the Amazon ECS-managed ``AmazonECSInfrastructureRolePolicyForVolumes`` IAM policy with this role. For more information, see [Amazon ECS infrastructure IAM role](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/infrastructure_IAM_role.html) in the *Amazon ECS Developer Guide*.
        """
        return pulumi.get(self, "role_arn")

    @role_arn.setter
    def role_arn(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "role_arn", value)

    @_builtins.property
    @pulumi.getter
    def encrypted(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Indicates whether the volume should be encrypted. If you turn on Region-level Amazon EBS encryption by default but set this value as ``false``, the setting is overridden and the volume is encrypted with the KMS key specified for Amazon EBS encryption by default. This parameter maps 1:1 with the ``Encrypted`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
        """
        return pulumi.get(self, "encrypted")

    @encrypted.setter
    def encrypted(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "encrypted", value)

    @_builtins.property
    @pulumi.getter(name="filesystemType")
    def filesystem_type(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The filesystem type for the volume. For volumes created from a snapshot, you must specify the same filesystem type that the volume was using when the snapshot was created. If there is a filesystem type mismatch, the tasks will fail to start.
         The available Linux filesystem types are
         ``ext3``, ``ext4``, and ``xfs``. If no value is specified, the ``xfs`` filesystem type is used by default.
         The available Windows filesystem types are ``NTFS``.
        """
        return pulumi.get(self, "filesystem_type")

    @filesystem_type.setter
    def filesystem_type(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "filesystem_type", value)

    @_builtins.property
    @pulumi.getter
    def iops(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The number of I/O operations per second (IOPS). For ``gp3``, ``io1``, and ``io2`` volumes, this represents the number of IOPS that are provisioned for the volume. For ``gp2`` volumes, this represents the baseline performance of the volume and the rate at which the volume accumulates I/O credits for bursting.
         The following are the supported values for each volume type.
          +  ``gp3``: 3,000 - 16,000 IOPS
          +  ``io1``: 100 - 64,000 IOPS
          +  ``io2``: 100 - 256,000 IOPS
          
         This parameter is required for ``io1`` and ``io2`` volume types. The default for ``gp3`` volumes is ``3,000 IOPS``. This parameter is not supported for ``st1``, ``sc1``, or ``standard`` volume types.
         This parameter maps 1:1 with the ``Iops`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
        """
        return pulumi.get(self, "iops")

    @iops.setter
    def iops(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "iops", value)

    @_builtins.property
    @pulumi.getter(name="kmsKeyId")
    def kms_key_id(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The Amazon Resource Name (ARN) identifier of the AWS Key Management Service key to use for Amazon EBS encryption. When a key is specified using this parameter, it overrides Amazon EBS default encryption or any KMS key that you specified for cluster-level managed storage encryption. This parameter maps 1:1 with the ``KmsKeyId`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*. For more information about encrypting Amazon EBS volumes attached to tasks, see [Encrypt data stored in Amazon EBS volumes attached to Amazon ECS tasks](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ebs-kms-encryption.html).
          AWS authenticates the AWS Key Management Service key asynchronously. Therefore, if you specify an ID, alias, or ARN that is invalid, the action can appear to complete, but eventually fails.
        """
        return pulumi.get(self, "kms_key_id")

    @kms_key_id.setter
    def kms_key_id(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "kms_key_id", value)

    @_builtins.property
    @pulumi.getter(name="sizeInGiB")
    def size_in_gi_b(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The size of the volume in GiB. You must specify either a volume size or a snapshot ID. If you specify a snapshot ID, the snapshot size is used for the volume size by default. You can optionally specify a volume size greater than or equal to the snapshot size. This parameter maps 1:1 with the ``Size`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
         The following are the supported volume size values for each volume type.
          +  ``gp2`` and ``gp3``: 1-16,384
          +  ``io1`` and ``io2``: 4-16,384
          +  ``st1`` and ``sc1``: 125-16,384
          +  ``standard``: 1-1,024
        """
        return pulumi.get(self, "size_in_gi_b")

    @size_in_gi_b.setter
    def size_in_gi_b(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "size_in_gi_b", value)

    @_builtins.property
    @pulumi.getter(name="snapshotId")
    def snapshot_id(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The snapshot that Amazon ECS uses to create volumes for attachment to tasks maintained by the service. You must specify either ``snapshotId`` or ``sizeInGiB`` in your volume configuration. This parameter maps 1:1 with the ``SnapshotId`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
        """
        return pulumi.get(self, "snapshot_id")

    @snapshot_id.setter
    def snapshot_id(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "snapshot_id", value)

    @_builtins.property
    @pulumi.getter(name="tagSpecifications")
    def tag_specifications(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['ServiceEbsTagSpecificationArgs']]]]:
        """
        The tags to apply to the volume. Amazon ECS applies service-managed tags by default. This parameter maps 1:1 with the ``TagSpecifications.N`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
        """
        return pulumi.get(self, "tag_specifications")

    @tag_specifications.setter
    def tag_specifications(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['ServiceEbsTagSpecificationArgs']]]]):
        pulumi.set(self, "tag_specifications", value)

    @_builtins.property
    @pulumi.getter
    def throughput(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The throughput to provision for a volume, in MiB/s, with a maximum of 1,000 MiB/s. This parameter maps 1:1 with the ``Throughput`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*.
          This parameter is only supported for the ``gp3`` volume type.
        """
        return pulumi.get(self, "throughput")

    @throughput.setter
    def throughput(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "throughput", value)

    @_builtins.property
    @pulumi.getter(name="volumeInitializationRate")
    def volume_initialization_rate(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The rate, in MiB/s, at which data is fetched from a snapshot of an existing EBS volume to create new volumes for attachment to the tasks maintained by the service. This property can be specified only if you specify a ``snapshotId``. For more information, see [Initialize Amazon EBS volumes](https://docs.aws.amazon.com/ebs/latest/userguide/initalize-volume.html) in the *Amazon EBS User Guide*.
        """
        return pulumi.get(self, "volume_initialization_rate")

    @volume_initialization_rate.setter
    def volume_initialization_rate(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "volume_initialization_rate", value)

    @_builtins.property
    @pulumi.getter(name="volumeType")
    def volume_type(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The volume type. This parameter maps 1:1 with the ``VolumeType`` parameter of the [CreateVolume API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateVolume.html) in the *Amazon EC2 API Reference*. For more information, see [Amazon EBS volume types](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html) in the *Amazon EC2 User Guide*.
         The following are the supported volume types.
          +  General Purpose SSD: ``gp2``|``gp3``
          +  Provisioned IOPS SSD: ``io1``|``io2``
          +  Throughput Optimized HDD: ``st1``
          +  Cold HDD: ``sc1``
          +  Magnetic: ``standard``
          The magnetic volume type is not supported on Fargate.
        """
        return pulumi.get(self, "volume_type")

    @volume_type.setter
    def volume_type(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "volume_type", value)


if not MYPY:
    class ServiceNetworkConfigurationArgsDict(TypedDict):
        """
        The network configuration for a task or service.
        """
        awsvpc_configuration: NotRequired[pulumi.Input['ServiceAwsVpcConfigurationArgsDict']]
        """
        The VPC subnets and security groups that are associated with a task.
          All specified subnets and security groups must be from the same VPC.
        """
elif False:
    ServiceNetworkConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceNetworkConfigurationArgs:
    def __init__(__self__, *,
                 awsvpc_configuration: Optional[pulumi.Input['ServiceAwsVpcConfigurationArgs']] = None):
        """
        The network configuration for a task or service.
        :param pulumi.Input['ServiceAwsVpcConfigurationArgs'] awsvpc_configuration: The VPC subnets and security groups that are associated with a task.
                 All specified subnets and security groups must be from the same VPC.
        """
        if awsvpc_configuration is not None:
            pulumi.set(__self__, "awsvpc_configuration", awsvpc_configuration)

    @_builtins.property
    @pulumi.getter(name="awsvpcConfiguration")
    def awsvpc_configuration(self) -> Optional[pulumi.Input['ServiceAwsVpcConfigurationArgs']]:
        """
        The VPC subnets and security groups that are associated with a task.
          All specified subnets and security groups must be from the same VPC.
        """
        return pulumi.get(self, "awsvpc_configuration")

    @awsvpc_configuration.setter
    def awsvpc_configuration(self, value: Optional[pulumi.Input['ServiceAwsVpcConfigurationArgs']]):
        pulumi.set(self, "awsvpc_configuration", value)


if not MYPY:
    class ServicePlacementConstraintArgsDict(TypedDict):
        """
        An object representing a constraint on task placement. For more information, see [Task placement constraints](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-placement-constraints.html) in the *Amazon Elastic Container Service Developer Guide*.
          If you're using the Fargate launch type, task placement constraints aren't supported.
        """
        type: pulumi.Input['ServicePlacementConstraintType']
        """
        The type of constraint. Use ``distinctInstance`` to ensure that each task in a particular group is running on a different container instance. Use ``memberOf`` to restrict the selection to a group of valid candidates.
        """
        expression: NotRequired[pulumi.Input[_builtins.str]]
        """
        A cluster query language expression to apply to the constraint. The expression can have a maximum length of 2000 characters. You can't specify an expression if the constraint type is ``distinctInstance``. For more information, see [Cluster query language](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-query-language.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
elif False:
    ServicePlacementConstraintArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServicePlacementConstraintArgs:
    def __init__(__self__, *,
                 type: pulumi.Input['ServicePlacementConstraintType'],
                 expression: Optional[pulumi.Input[_builtins.str]] = None):
        """
        An object representing a constraint on task placement. For more information, see [Task placement constraints](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-placement-constraints.html) in the *Amazon Elastic Container Service Developer Guide*.
          If you're using the Fargate launch type, task placement constraints aren't supported.
        :param pulumi.Input['ServicePlacementConstraintType'] type: The type of constraint. Use ``distinctInstance`` to ensure that each task in a particular group is running on a different container instance. Use ``memberOf`` to restrict the selection to a group of valid candidates.
        :param pulumi.Input[_builtins.str] expression: A cluster query language expression to apply to the constraint. The expression can have a maximum length of 2000 characters. You can't specify an expression if the constraint type is ``distinctInstance``. For more information, see [Cluster query language](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-query-language.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        pulumi.set(__self__, "type", type)
        if expression is not None:
            pulumi.set(__self__, "expression", expression)

    @_builtins.property
    @pulumi.getter
    def type(self) -> pulumi.Input['ServicePlacementConstraintType']:
        """
        The type of constraint. Use ``distinctInstance`` to ensure that each task in a particular group is running on a different container instance. Use ``memberOf`` to restrict the selection to a group of valid candidates.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input['ServicePlacementConstraintType']):
        pulumi.set(self, "type", value)

    @_builtins.property
    @pulumi.getter
    def expression(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        A cluster query language expression to apply to the constraint. The expression can have a maximum length of 2000 characters. You can't specify an expression if the constraint type is ``distinctInstance``. For more information, see [Cluster query language](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-query-language.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        return pulumi.get(self, "expression")

    @expression.setter
    def expression(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "expression", value)


if not MYPY:
    class ServicePlacementStrategyArgsDict(TypedDict):
        """
        The task placement strategy for a task or service. For more information, see [Task placement strategies](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-placement-strategies.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        type: pulumi.Input['ServicePlacementStrategyType']
        """
        The type of placement strategy. The ``random`` placement strategy randomly places tasks on available candidates. The ``spread`` placement strategy spreads placement across available candidates evenly based on the ``field`` parameter. The ``binpack`` strategy places tasks on available candidates that have the least available amount of the resource that's specified with the ``field`` parameter. For example, if you binpack on memory, a task is placed on the instance with the least amount of remaining memory but still enough to run the task.
        """
        field: NotRequired[pulumi.Input[_builtins.str]]
        """
        The field to apply the placement strategy against. For the ``spread`` placement strategy, valid values are ``instanceId`` (or ``host``, which has the same effect), or any platform or custom attribute that's applied to a container instance, such as ``attribute:ecs.availability-zone``. For the ``binpack`` placement strategy, valid values are ``cpu`` and ``memory``. For the ``random`` placement strategy, this field is not used.
        """
elif False:
    ServicePlacementStrategyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServicePlacementStrategyArgs:
    def __init__(__self__, *,
                 type: pulumi.Input['ServicePlacementStrategyType'],
                 field: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The task placement strategy for a task or service. For more information, see [Task placement strategies](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-placement-strategies.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input['ServicePlacementStrategyType'] type: The type of placement strategy. The ``random`` placement strategy randomly places tasks on available candidates. The ``spread`` placement strategy spreads placement across available candidates evenly based on the ``field`` parameter. The ``binpack`` strategy places tasks on available candidates that have the least available amount of the resource that's specified with the ``field`` parameter. For example, if you binpack on memory, a task is placed on the instance with the least amount of remaining memory but still enough to run the task.
        :param pulumi.Input[_builtins.str] field: The field to apply the placement strategy against. For the ``spread`` placement strategy, valid values are ``instanceId`` (or ``host``, which has the same effect), or any platform or custom attribute that's applied to a container instance, such as ``attribute:ecs.availability-zone``. For the ``binpack`` placement strategy, valid values are ``cpu`` and ``memory``. For the ``random`` placement strategy, this field is not used.
        """
        pulumi.set(__self__, "type", type)
        if field is not None:
            pulumi.set(__self__, "field", field)

    @_builtins.property
    @pulumi.getter
    def type(self) -> pulumi.Input['ServicePlacementStrategyType']:
        """
        The type of placement strategy. The ``random`` placement strategy randomly places tasks on available candidates. The ``spread`` placement strategy spreads placement across available candidates evenly based on the ``field`` parameter. The ``binpack`` strategy places tasks on available candidates that have the least available amount of the resource that's specified with the ``field`` parameter. For example, if you binpack on memory, a task is placed on the instance with the least amount of remaining memory but still enough to run the task.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input['ServicePlacementStrategyType']):
        pulumi.set(self, "type", value)

    @_builtins.property
    @pulumi.getter
    def field(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The field to apply the placement strategy against. For the ``spread`` placement strategy, valid values are ``instanceId`` (or ``host``, which has the same effect), or any platform or custom attribute that's applied to a container instance, such as ``attribute:ecs.availability-zone``. For the ``binpack`` placement strategy, valid values are ``cpu`` and ``memory``. For the ``random`` placement strategy, this field is not used.
        """
        return pulumi.get(self, "field")

    @field.setter
    def field(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "field", value)


if not MYPY:
    class ServiceRegistryArgsDict(TypedDict):
        """
        The details for the service registry.
         Each service may be associated with one service registry. Multiple service registries for each service are not supported.
         When you add, update, or remove the service registries configuration, Amazon ECS starts a new deployment. New tasks are registered and deregistered to the updated service registry configuration.
        """
        container_name: NotRequired[pulumi.Input[_builtins.str]]
        """
        The container name value to be used for your service discovery service. It's already specified in the task definition. If the task definition that your service task specifies uses the ``bridge`` or ``host`` network mode, you must specify a ``containerName`` and ``containerPort`` combination from the task definition. If the task definition that your service task specifies uses the ``awsvpc`` network mode and a type SRV DNS record is used, you must specify either a ``containerName`` and ``containerPort`` combination or a ``port`` value. However, you can't specify both.
        """
        container_port: NotRequired[pulumi.Input[_builtins.int]]
        """
        The port value to be used for your service discovery service. It's already specified in the task definition. If the task definition your service task specifies uses the ``bridge`` or ``host`` network mode, you must specify a ``containerName`` and ``containerPort`` combination from the task definition. If the task definition your service task specifies uses the ``awsvpc`` network mode and a type SRV DNS record is used, you must specify either a ``containerName`` and ``containerPort`` combination or a ``port`` value. However, you can't specify both.
        """
        port: NotRequired[pulumi.Input[_builtins.int]]
        """
        The port value used if your service discovery service specified an SRV record. This field might be used if both the ``awsvpc`` network mode and SRV records are used.
        """
        registry_arn: NotRequired[pulumi.Input[_builtins.str]]
        """
        The Amazon Resource Name (ARN) of the service registry. The currently supported service registry is CMAP. For more information, see [CreateService](https://docs.aws.amazon.com/cloud-map/latest/api/API_CreateService.html).
        """
elif False:
    ServiceRegistryArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceRegistryArgs:
    def __init__(__self__, *,
                 container_name: Optional[pulumi.Input[_builtins.str]] = None,
                 container_port: Optional[pulumi.Input[_builtins.int]] = None,
                 port: Optional[pulumi.Input[_builtins.int]] = None,
                 registry_arn: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The details for the service registry.
         Each service may be associated with one service registry. Multiple service registries for each service are not supported.
         When you add, update, or remove the service registries configuration, Amazon ECS starts a new deployment. New tasks are registered and deregistered to the updated service registry configuration.
        :param pulumi.Input[_builtins.str] container_name: The container name value to be used for your service discovery service. It's already specified in the task definition. If the task definition that your service task specifies uses the ``bridge`` or ``host`` network mode, you must specify a ``containerName`` and ``containerPort`` combination from the task definition. If the task definition that your service task specifies uses the ``awsvpc`` network mode and a type SRV DNS record is used, you must specify either a ``containerName`` and ``containerPort`` combination or a ``port`` value. However, you can't specify both.
        :param pulumi.Input[_builtins.int] container_port: The port value to be used for your service discovery service. It's already specified in the task definition. If the task definition your service task specifies uses the ``bridge`` or ``host`` network mode, you must specify a ``containerName`` and ``containerPort`` combination from the task definition. If the task definition your service task specifies uses the ``awsvpc`` network mode and a type SRV DNS record is used, you must specify either a ``containerName`` and ``containerPort`` combination or a ``port`` value. However, you can't specify both.
        :param pulumi.Input[_builtins.int] port: The port value used if your service discovery service specified an SRV record. This field might be used if both the ``awsvpc`` network mode and SRV records are used.
        :param pulumi.Input[_builtins.str] registry_arn: The Amazon Resource Name (ARN) of the service registry. The currently supported service registry is CMAP. For more information, see [CreateService](https://docs.aws.amazon.com/cloud-map/latest/api/API_CreateService.html).
        """
        if container_name is not None:
            pulumi.set(__self__, "container_name", container_name)
        if container_port is not None:
            pulumi.set(__self__, "container_port", container_port)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if registry_arn is not None:
            pulumi.set(__self__, "registry_arn", registry_arn)

    @_builtins.property
    @pulumi.getter(name="containerName")
    def container_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The container name value to be used for your service discovery service. It's already specified in the task definition. If the task definition that your service task specifies uses the ``bridge`` or ``host`` network mode, you must specify a ``containerName`` and ``containerPort`` combination from the task definition. If the task definition that your service task specifies uses the ``awsvpc`` network mode and a type SRV DNS record is used, you must specify either a ``containerName`` and ``containerPort`` combination or a ``port`` value. However, you can't specify both.
        """
        return pulumi.get(self, "container_name")

    @container_name.setter
    def container_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "container_name", value)

    @_builtins.property
    @pulumi.getter(name="containerPort")
    def container_port(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The port value to be used for your service discovery service. It's already specified in the task definition. If the task definition your service task specifies uses the ``bridge`` or ``host`` network mode, you must specify a ``containerName`` and ``containerPort`` combination from the task definition. If the task definition your service task specifies uses the ``awsvpc`` network mode and a type SRV DNS record is used, you must specify either a ``containerName`` and ``containerPort`` combination or a ``port`` value. However, you can't specify both.
        """
        return pulumi.get(self, "container_port")

    @container_port.setter
    def container_port(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "container_port", value)

    @_builtins.property
    @pulumi.getter
    def port(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The port value used if your service discovery service specified an SRV record. This field might be used if both the ``awsvpc`` network mode and SRV records are used.
        """
        return pulumi.get(self, "port")

    @port.setter
    def port(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "port", value)

    @_builtins.property
    @pulumi.getter(name="registryArn")
    def registry_arn(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The Amazon Resource Name (ARN) of the service registry. The currently supported service registry is CMAP. For more information, see [CreateService](https://docs.aws.amazon.com/cloud-map/latest/api/API_CreateService.html).
        """
        return pulumi.get(self, "registry_arn")

    @registry_arn.setter
    def registry_arn(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "registry_arn", value)


if not MYPY:
    class ServiceSecretArgsDict(TypedDict):
        """
        An object representing the secret to expose to your container. Secrets can be exposed to a container in the following ways:
          +  To inject sensitive data into your containers as environment variables, use the ``secrets`` container definition parameter.
          +  To reference sensitive information in the log configuration of a container, use the ``secretOptions`` container definition parameter.
          
         For more information, see [Specifying sensitive data](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        name: pulumi.Input[_builtins.str]
        """
        The name of the secret.
        """
        value_from: pulumi.Input[_builtins.str]
        """
        The secret to expose to the container. The supported values are either the full ARN of the ASMlong secret or the full ARN of the parameter in the SSM Parameter Store.
         For information about the require IAMlong permissions, see [Required IAM permissions for Amazon ECS secrets](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data-secrets.html#secrets-iam) (for Secrets Manager) or [Required IAM permissions for Amazon ECS secrets](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data-parameters.html) (for Systems Manager Parameter store) in the *Amazon Elastic Container Service Developer Guide*.
          If the SSM Parameter Store parameter exists in the same Region as the task you're launching, then you can use either the full ARN or name of the parameter. If the parameter exists in a different Region, then the full ARN must be specified.
        """
elif False:
    ServiceSecretArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceSecretArgs:
    def __init__(__self__, *,
                 name: pulumi.Input[_builtins.str],
                 value_from: pulumi.Input[_builtins.str]):
        """
        An object representing the secret to expose to your container. Secrets can be exposed to a container in the following ways:
          +  To inject sensitive data into your containers as environment variables, use the ``secrets`` container definition parameter.
          +  To reference sensitive information in the log configuration of a container, use the ``secretOptions`` container definition parameter.
          
         For more information, see [Specifying sensitive data](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.str] name: The name of the secret.
        :param pulumi.Input[_builtins.str] value_from: The secret to expose to the container. The supported values are either the full ARN of the ASMlong secret or the full ARN of the parameter in the SSM Parameter Store.
                For information about the require IAMlong permissions, see [Required IAM permissions for Amazon ECS secrets](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data-secrets.html#secrets-iam) (for Secrets Manager) or [Required IAM permissions for Amazon ECS secrets](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data-parameters.html) (for Systems Manager Parameter store) in the *Amazon Elastic Container Service Developer Guide*.
                 If the SSM Parameter Store parameter exists in the same Region as the task you're launching, then you can use either the full ARN or name of the parameter. If the parameter exists in a different Region, then the full ARN must be specified.
        """
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "value_from", value_from)

    @_builtins.property
    @pulumi.getter
    def name(self) -> pulumi.Input[_builtins.str]:
        """
        The name of the secret.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "name", value)

    @_builtins.property
    @pulumi.getter(name="valueFrom")
    def value_from(self) -> pulumi.Input[_builtins.str]:
        """
        The secret to expose to the container. The supported values are either the full ARN of the ASMlong secret or the full ARN of the parameter in the SSM Parameter Store.
         For information about the require IAMlong permissions, see [Required IAM permissions for Amazon ECS secrets](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data-secrets.html#secrets-iam) (for Secrets Manager) or [Required IAM permissions for Amazon ECS secrets](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data-parameters.html) (for Systems Manager Parameter store) in the *Amazon Elastic Container Service Developer Guide*.
          If the SSM Parameter Store parameter exists in the same Region as the task you're launching, then you can use either the full ARN or name of the parameter. If the parameter exists in a different Region, then the full ARN must be specified.
        """
        return pulumi.get(self, "value_from")

    @value_from.setter
    def value_from(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "value_from", value)


if not MYPY:
    class ServiceTagArgsDict(TypedDict):
        """
        The metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value. You define them.
         The following basic restrictions apply to tags:
          +  Maximum number of tags per resource - 50
          +  For each resource, each tag key must be unique, and each tag key can have only one value.
          +  Maximum key length - 128 Unicode characters in UTF-8
          +  Maximum value length - 256 Unicode characters in UTF-8
          +  If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.
          +  Tag keys and values are case-sensitive.
          +  Do not use ``aws:``, ``AWS:``, or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for AWS use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.
          
         In order to tag a service that has the following ARN format, you need to migrate the service to the long ARN. You must use the API, CLI or console to migrate the service ARN. For more information, see [Migrate an short service ARN to a long ARN](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-arn-migration.html) in the *Developer Guide*.
          ``arn:aws:ecs:region:aws_account_id:service/service-name`` 
         After the migration is complete, the following are true:
          +   The service ARN is: ``arn:aws:ecs:region:aws_account_id:service/cluster-name/service-name``
          +  You can use CFN to tag the service as you would a service with a long ARN format.
          +  When the ``PhysicalResourceId`` in the CFN stack represents a service, the value does not change and will be the short service ARN.
        """
        key: NotRequired[pulumi.Input[_builtins.str]]
        """
        One part of a key-value pair that make up a tag. A ``key`` is a general label that acts like a category for more specific tag values.
        """
        value: NotRequired[pulumi.Input[_builtins.str]]
        """
        The optional part of a key-value pair that make up a tag. A ``value`` acts as a descriptor within a tag category (key).
        """
elif False:
    ServiceTagArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceTagArgs:
    def __init__(__self__, *,
                 key: Optional[pulumi.Input[_builtins.str]] = None,
                 value: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The metadata that you apply to a resource to help you categorize and organize them. Each tag consists of a key and an optional value. You define them.
         The following basic restrictions apply to tags:
          +  Maximum number of tags per resource - 50
          +  For each resource, each tag key must be unique, and each tag key can have only one value.
          +  Maximum key length - 128 Unicode characters in UTF-8
          +  Maximum value length - 256 Unicode characters in UTF-8
          +  If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @.
          +  Tag keys and values are case-sensitive.
          +  Do not use ``aws:``, ``AWS:``, or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for AWS use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit.
          
         In order to tag a service that has the following ARN format, you need to migrate the service to the long ARN. You must use the API, CLI or console to migrate the service ARN. For more information, see [Migrate an short service ARN to a long ARN](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-arn-migration.html) in the *Developer Guide*.
          ``arn:aws:ecs:region:aws_account_id:service/service-name`` 
         After the migration is complete, the following are true:
          +   The service ARN is: ``arn:aws:ecs:region:aws_account_id:service/cluster-name/service-name``
          +  You can use CFN to tag the service as you would a service with a long ARN format.
          +  When the ``PhysicalResourceId`` in the CFN stack represents a service, the value does not change and will be the short service ARN.
        :param pulumi.Input[_builtins.str] key: One part of a key-value pair that make up a tag. A ``key`` is a general label that acts like a category for more specific tag values.
        :param pulumi.Input[_builtins.str] value: The optional part of a key-value pair that make up a tag. A ``value`` acts as a descriptor within a tag category (key).
        """
        if key is not None:
            pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def key(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        One part of a key-value pair that make up a tag. A ``key`` is a general label that acts like a category for more specific tag values.
        """
        return pulumi.get(self, "key")

    @key.setter
    def key(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "key", value)

    @_builtins.property
    @pulumi.getter
    def value(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The optional part of a key-value pair that make up a tag. A ``value`` acts as a descriptor within a tag category (key).
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "value", value)


if not MYPY:
    class ServiceTimeoutConfigurationArgsDict(TypedDict):
        """
        An object that represents the timeout configurations for Service Connect.
          If ``idleTimeout`` is set to a time that is less than ``perRequestTimeout``, the connection will close when the ``idleTimeout`` is reached and not the ``perRequestTimeout``.
        """
        idle_timeout_seconds: NotRequired[pulumi.Input[_builtins.int]]
        """
        The amount of time in seconds a connection will stay active while idle. A value of ``0`` can be set to disable ``idleTimeout``.
         The ``idleTimeout`` default for ``HTTP``/``HTTP2``/``GRPC`` is 5 minutes.
         The ``idleTimeout`` default for ``TCP`` is 1 hour.
        """
        per_request_timeout_seconds: NotRequired[pulumi.Input[_builtins.int]]
        """
        The amount of time waiting for the upstream to respond with a complete response per request. A value of ``0`` can be set to disable ``perRequestTimeout``. ``perRequestTimeout`` can only be set if Service Connect ``appProtocol`` isn't ``TCP``. Only ``idleTimeout`` is allowed for ``TCP````appProtocol``.
        """
elif False:
    ServiceTimeoutConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceTimeoutConfigurationArgs:
    def __init__(__self__, *,
                 idle_timeout_seconds: Optional[pulumi.Input[_builtins.int]] = None,
                 per_request_timeout_seconds: Optional[pulumi.Input[_builtins.int]] = None):
        """
        An object that represents the timeout configurations for Service Connect.
          If ``idleTimeout`` is set to a time that is less than ``perRequestTimeout``, the connection will close when the ``idleTimeout`` is reached and not the ``perRequestTimeout``.
        :param pulumi.Input[_builtins.int] idle_timeout_seconds: The amount of time in seconds a connection will stay active while idle. A value of ``0`` can be set to disable ``idleTimeout``.
                The ``idleTimeout`` default for ``HTTP``/``HTTP2``/``GRPC`` is 5 minutes.
                The ``idleTimeout`` default for ``TCP`` is 1 hour.
        :param pulumi.Input[_builtins.int] per_request_timeout_seconds: The amount of time waiting for the upstream to respond with a complete response per request. A value of ``0`` can be set to disable ``perRequestTimeout``. ``perRequestTimeout`` can only be set if Service Connect ``appProtocol`` isn't ``TCP``. Only ``idleTimeout`` is allowed for ``TCP````appProtocol``.
        """
        if idle_timeout_seconds is not None:
            pulumi.set(__self__, "idle_timeout_seconds", idle_timeout_seconds)
        if per_request_timeout_seconds is not None:
            pulumi.set(__self__, "per_request_timeout_seconds", per_request_timeout_seconds)

    @_builtins.property
    @pulumi.getter(name="idleTimeoutSeconds")
    def idle_timeout_seconds(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The amount of time in seconds a connection will stay active while idle. A value of ``0`` can be set to disable ``idleTimeout``.
         The ``idleTimeout`` default for ``HTTP``/``HTTP2``/``GRPC`` is 5 minutes.
         The ``idleTimeout`` default for ``TCP`` is 1 hour.
        """
        return pulumi.get(self, "idle_timeout_seconds")

    @idle_timeout_seconds.setter
    def idle_timeout_seconds(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "idle_timeout_seconds", value)

    @_builtins.property
    @pulumi.getter(name="perRequestTimeoutSeconds")
    def per_request_timeout_seconds(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The amount of time waiting for the upstream to respond with a complete response per request. A value of ``0`` can be set to disable ``perRequestTimeout``. ``perRequestTimeout`` can only be set if Service Connect ``appProtocol`` isn't ``TCP``. Only ``idleTimeout`` is allowed for ``TCP````appProtocol``.
        """
        return pulumi.get(self, "per_request_timeout_seconds")

    @per_request_timeout_seconds.setter
    def per_request_timeout_seconds(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "per_request_timeout_seconds", value)


if not MYPY:
    class ServiceVolumeConfigurationArgsDict(TypedDict):
        """
        The configuration for a volume specified in the task definition as a volume that is configured at launch time. Currently, the only supported volume type is an Amazon EBS volume.
        """
        name: pulumi.Input[_builtins.str]
        """
        The name of the volume. This value must match the volume name from the ``Volume`` object in the task definition.
        """
        managed_ebs_volume: NotRequired[pulumi.Input['ServiceManagedEbsVolumeConfigurationArgsDict']]
        """
        The configuration for the Amazon EBS volume that Amazon ECS creates and manages on your behalf. These settings are used to create each Amazon EBS volume, with one volume created for each task in the service. The Amazon EBS volumes are visible in your account in the Amazon EC2 console once they are created.
        """
elif False:
    ServiceVolumeConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceVolumeConfigurationArgs:
    def __init__(__self__, *,
                 name: pulumi.Input[_builtins.str],
                 managed_ebs_volume: Optional[pulumi.Input['ServiceManagedEbsVolumeConfigurationArgs']] = None):
        """
        The configuration for a volume specified in the task definition as a volume that is configured at launch time. Currently, the only supported volume type is an Amazon EBS volume.
        :param pulumi.Input[_builtins.str] name: The name of the volume. This value must match the volume name from the ``Volume`` object in the task definition.
        :param pulumi.Input['ServiceManagedEbsVolumeConfigurationArgs'] managed_ebs_volume: The configuration for the Amazon EBS volume that Amazon ECS creates and manages on your behalf. These settings are used to create each Amazon EBS volume, with one volume created for each task in the service. The Amazon EBS volumes are visible in your account in the Amazon EC2 console once they are created.
        """
        pulumi.set(__self__, "name", name)
        if managed_ebs_volume is not None:
            pulumi.set(__self__, "managed_ebs_volume", managed_ebs_volume)

    @_builtins.property
    @pulumi.getter
    def name(self) -> pulumi.Input[_builtins.str]:
        """
        The name of the volume. This value must match the volume name from the ``Volume`` object in the task definition.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "name", value)

    @_builtins.property
    @pulumi.getter(name="managedEbsVolume")
    def managed_ebs_volume(self) -> Optional[pulumi.Input['ServiceManagedEbsVolumeConfigurationArgs']]:
        """
        The configuration for the Amazon EBS volume that Amazon ECS creates and manages on your behalf. These settings are used to create each Amazon EBS volume, with one volume created for each task in the service. The Amazon EBS volumes are visible in your account in the Amazon EC2 console once they are created.
        """
        return pulumi.get(self, "managed_ebs_volume")

    @managed_ebs_volume.setter
    def managed_ebs_volume(self, value: Optional[pulumi.Input['ServiceManagedEbsVolumeConfigurationArgs']]):
        pulumi.set(self, "managed_ebs_volume", value)


if not MYPY:
    class ServiceVpcLatticeConfigurationArgsDict(TypedDict):
        """
        The VPC Lattice configuration for your service that holds the information for the target group(s) Amazon ECS tasks will be registered to.
        """
        port_name: pulumi.Input[_builtins.str]
        """
        The name of the port mapping to register in the VPC Lattice target group. This is the name of the ``portMapping`` you defined in your task definition.
        """
        role_arn: pulumi.Input[_builtins.str]
        """
        The ARN of the IAM role to associate with this VPC Lattice configuration. This is the Amazon ECS
         infrastructure IAM role that is used to manage your VPC Lattice infrastructure.
        """
        target_group_arn: pulumi.Input[_builtins.str]
        """
        The full Amazon Resource Name (ARN) of the target group or groups associated with the VPC Lattice configuration that the Amazon ECS tasks will be registered to.
        """
elif False:
    ServiceVpcLatticeConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class ServiceVpcLatticeConfigurationArgs:
    def __init__(__self__, *,
                 port_name: pulumi.Input[_builtins.str],
                 role_arn: pulumi.Input[_builtins.str],
                 target_group_arn: pulumi.Input[_builtins.str]):
        """
        The VPC Lattice configuration for your service that holds the information for the target group(s) Amazon ECS tasks will be registered to.
        :param pulumi.Input[_builtins.str] port_name: The name of the port mapping to register in the VPC Lattice target group. This is the name of the ``portMapping`` you defined in your task definition.
        :param pulumi.Input[_builtins.str] role_arn: The ARN of the IAM role to associate with this VPC Lattice configuration. This is the Amazon ECS
                infrastructure IAM role that is used to manage your VPC Lattice infrastructure.
        :param pulumi.Input[_builtins.str] target_group_arn: The full Amazon Resource Name (ARN) of the target group or groups associated with the VPC Lattice configuration that the Amazon ECS tasks will be registered to.
        """
        pulumi.set(__self__, "port_name", port_name)
        pulumi.set(__self__, "role_arn", role_arn)
        pulumi.set(__self__, "target_group_arn", target_group_arn)

    @_builtins.property
    @pulumi.getter(name="portName")
    def port_name(self) -> pulumi.Input[_builtins.str]:
        """
        The name of the port mapping to register in the VPC Lattice target group. This is the name of the ``portMapping`` you defined in your task definition.
        """
        return pulumi.get(self, "port_name")

    @port_name.setter
    def port_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "port_name", value)

    @_builtins.property
    @pulumi.getter(name="roleArn")
    def role_arn(self) -> pulumi.Input[_builtins.str]:
        """
        The ARN of the IAM role to associate with this VPC Lattice configuration. This is the Amazon ECS
         infrastructure IAM role that is used to manage your VPC Lattice infrastructure.
        """
        return pulumi.get(self, "role_arn")

    @role_arn.setter
    def role_arn(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "role_arn", value)

    @_builtins.property
    @pulumi.getter(name="targetGroupArn")
    def target_group_arn(self) -> pulumi.Input[_builtins.str]:
        """
        The full Amazon Resource Name (ARN) of the target group or groups associated with the VPC Lattice configuration that the Amazon ECS tasks will be registered to.
        """
        return pulumi.get(self, "target_group_arn")

    @target_group_arn.setter
    def target_group_arn(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "target_group_arn", value)


if not MYPY:
    class TaskDefinitionAuthorizationConfigArgsDict(TypedDict):
        """
        The authorization configuration details for the Amazon EFS file system.
        """
        access_point_id: NotRequired[pulumi.Input[_builtins.str]]
        """
        The Amazon EFS access point ID to use. If an access point is specified, the root directory value specified in the ``EFSVolumeConfiguration`` must either be omitted or set to ``/`` which will enforce the path set on the EFS access point. If an access point is used, transit encryption must be on in the ``EFSVolumeConfiguration``. For more information, see [Working with Amazon EFS access points](https://docs.aws.amazon.com/efs/latest/ug/efs-access-points.html) in the *Amazon Elastic File System User Guide*.
        """
        iam: NotRequired[pulumi.Input['TaskDefinitionAuthorizationConfigIam']]
        """
        Determines whether to use the Amazon ECS task role defined in a task definition when mounting the Amazon EFS file system. If it is turned on, transit encryption must be turned on in the ``EFSVolumeConfiguration``. If this parameter is omitted, the default value of ``DISABLED`` is used. For more information, see [Using Amazon EFS access points](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/efs-volumes.html#efs-volume-accesspoints) in the *Amazon Elastic Container Service Developer Guide*.
        """
elif False:
    TaskDefinitionAuthorizationConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionAuthorizationConfigArgs:
    def __init__(__self__, *,
                 access_point_id: Optional[pulumi.Input[_builtins.str]] = None,
                 iam: Optional[pulumi.Input['TaskDefinitionAuthorizationConfigIam']] = None):
        """
        The authorization configuration details for the Amazon EFS file system.
        :param pulumi.Input[_builtins.str] access_point_id: The Amazon EFS access point ID to use. If an access point is specified, the root directory value specified in the ``EFSVolumeConfiguration`` must either be omitted or set to ``/`` which will enforce the path set on the EFS access point. If an access point is used, transit encryption must be on in the ``EFSVolumeConfiguration``. For more information, see [Working with Amazon EFS access points](https://docs.aws.amazon.com/efs/latest/ug/efs-access-points.html) in the *Amazon Elastic File System User Guide*.
        :param pulumi.Input['TaskDefinitionAuthorizationConfigIam'] iam: Determines whether to use the Amazon ECS task role defined in a task definition when mounting the Amazon EFS file system. If it is turned on, transit encryption must be turned on in the ``EFSVolumeConfiguration``. If this parameter is omitted, the default value of ``DISABLED`` is used. For more information, see [Using Amazon EFS access points](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/efs-volumes.html#efs-volume-accesspoints) in the *Amazon Elastic Container Service Developer Guide*.
        """
        if access_point_id is not None:
            pulumi.set(__self__, "access_point_id", access_point_id)
        if iam is not None:
            pulumi.set(__self__, "iam", iam)

    @_builtins.property
    @pulumi.getter(name="accessPointId")
    def access_point_id(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The Amazon EFS access point ID to use. If an access point is specified, the root directory value specified in the ``EFSVolumeConfiguration`` must either be omitted or set to ``/`` which will enforce the path set on the EFS access point. If an access point is used, transit encryption must be on in the ``EFSVolumeConfiguration``. For more information, see [Working with Amazon EFS access points](https://docs.aws.amazon.com/efs/latest/ug/efs-access-points.html) in the *Amazon Elastic File System User Guide*.
        """
        return pulumi.get(self, "access_point_id")

    @access_point_id.setter
    def access_point_id(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "access_point_id", value)

    @_builtins.property
    @pulumi.getter
    def iam(self) -> Optional[pulumi.Input['TaskDefinitionAuthorizationConfigIam']]:
        """
        Determines whether to use the Amazon ECS task role defined in a task definition when mounting the Amazon EFS file system. If it is turned on, transit encryption must be turned on in the ``EFSVolumeConfiguration``. If this parameter is omitted, the default value of ``DISABLED`` is used. For more information, see [Using Amazon EFS access points](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/efs-volumes.html#efs-volume-accesspoints) in the *Amazon Elastic Container Service Developer Guide*.
        """
        return pulumi.get(self, "iam")

    @iam.setter
    def iam(self, value: Optional[pulumi.Input['TaskDefinitionAuthorizationConfigIam']]):
        pulumi.set(self, "iam", value)


if not MYPY:
    class TaskDefinitionContainerDefinitionArgsDict(TypedDict):
        """
        The ``ContainerDefinition`` property specifies a container definition. Container definitions are used in task definitions to describe the different containers that are launched as part of a task.
        """
        image: pulumi.Input[_builtins.str]
        """
        The image used to start a container. This string is passed directly to the Docker daemon. By default, images in the Docker Hub registry are available. Other repositories are specified with either ``repository-url/image:tag`` or ``repository-url/image@digest``. For images using tags (repository-url/image:tag), up to 255 characters total are allowed, including letters (uppercase and lowercase), numbers, hyphens, underscores, colons, periods, forward slashes, and number signs (#). For images using digests (repository-url/image@digest), the 255 character limit applies only to the repository URL and image name (everything before the @ sign). The only supported hash function is sha256, and the hash value after sha256: must be exactly 64 characters (only letters A-F, a-f, and numbers 0-9 are allowed). This parameter maps to ``Image`` in the docker container create command and the ``IMAGE`` parameter of docker run.
          +  When a new task starts, the Amazon ECS container agent pulls the latest version of the specified image and tag for the container to use. However, subsequent updates to a repository image aren't propagated to already running tasks.
          +  Images in Amazon ECR repositories can be specified by either using the full ``registry/repository:tag`` or ``registry/repository@digest``. For example, ``012345678910.dkr.ecr.<region-name>.amazonaws.com/<repository-name>:latest`` or ``012345678910.dkr.ecr.<region-name>.amazonaws.com/<repository-name>@sha256:94afd1f2e64d908bc90dbca0035a5b567EXAMPLE``. 
          +  Images in official repositories on Docker Hub use a single name (for example, ``ubuntu`` or ``mongo``).
          +  Images in other repositories on Docker Hub are qualified with an organization name (for example, ``amazon/amazon-ecs-agent``).
          +  Images in other online repositories are qualified further by a domain name (for example, ``quay.io/assemblyline/ubuntu``).
        """
        name: pulumi.Input[_builtins.str]
        """
        The name of a container. If you're linking multiple containers together in a task definition, the ``name`` of one container can be entered in the ``links`` of another container to connect the containers. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. This parameter maps to ``name`` in the docker container create command and the ``--name`` option to docker run.
        """
        command: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The command that's passed to the container. This parameter maps to ``Cmd`` in the docker container create command and the ``COMMAND`` parameter to docker run. If there are multiple arguments, each argument is a separated string in the array.
        """
        cpu: NotRequired[pulumi.Input[_builtins.int]]
        """
        The number of ``cpu`` units reserved for the container. This parameter maps to ``CpuShares`` in the docker container create command and the ``--cpu-shares`` option to docker run.
         This field is optional for tasks using the Fargate launch type, and the only requirement is that the total amount of CPU reserved for all containers within a task be lower than the task-level ``cpu`` value.
          You can determine the number of CPU units that are available per EC2 instance type by multiplying the vCPUs listed for that instance type on the [Amazon EC2 Instances](https://docs.aws.amazon.com/ec2/instance-types/) detail page by 1,024.
          Linux containers share unallocated CPU units with other containers on the container instance with the same ratio as their allocated amount. For example, if you run a single-container task on a single-core instance type with 512 CPU units specified for that container, and that's the only task running on the container instance, that container could use the full 1,024 CPU unit share at any given time. However, if you launched another copy of the same task on that container instance, each task is guaranteed a minimum of 512 CPU units when needed. Moreover, each container could float to higher CPU usage if the other container was not using it. If both tasks were 100% active all of the time, they would be limited to 512 CPU units.
         On Linux container instances, the Docker daemon on the container instance uses the CPU value to calculate the relative CPU share ratios for running containers. The minimum valid CPU share value that the Linux kernel allows is 2, and the maximum valid CPU share value that the Linux kernel allows is 262144. However, the CPU parameter isn't required, and you can use CPU values below 2 or above 262144 in your container definitions. For CPU values below 2 (including null) or above 262144, the behavior varies based on your Amazon ECS container agent version:
          +  *Agent versions less than or equal to 1.1.0:* Null and zero CPU values are passed to Docker as 0, which Docker then converts to 1,024 CPU shares. CPU values of 1 are passed to Docker as 1, which the Linux kernel converts to two CPU shares.
          +  *Agent versions greater than or equal to 1.2.0:* Null, zero, and CPU values of 1 are passed to Docker as 2.
          +  *Agent versions greater than or equal to 1.84.0:* CPU values greater than 256 vCPU are passed to Docker as 256, which is equivalent to 262144 CPU shares.
          
         On Windows container instances, the CPU limit is enforced as an absolute limit, or a quota. Windows containers only have access to the specified amount of CPU that's described in the task definition. A null or zero CPU value is passed to Docker as ``0``, which Windows interprets as 1% of one CPU.
        """
        credential_specs: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        A list of ARNs in SSM or Amazon S3 to a credential spec (``CredSpec``) file that configures the container for Active Directory authentication. We recommend that you use this parameter instead of the ``dockerSecurityOptions``. The maximum number of ARNs is 1.
         There are two formats for each ARN.
          + credentialspecdomainless:MyARN You use credentialspecdomainless:MyARN to provide a CredSpec with an additional section for a secret in . You provide the login credentials to the domain in the secret. Each task that runs on any container instance can join different domains. You can use this format without joining the container instance to a domain. + credentialspec:MyARN You use credentialspec:MyARN to provide a CredSpec for a single domain. You must join the container instance to the domain before you start any tasks that use this task definition. 
         In both formats, replace ``MyARN`` with the ARN in SSM or Amazon S3.
         If you provide a ``credentialspecdomainless:MyARN``, the ``credspec`` must provide a ARN in ASMlong for a secret containing the username, password, and the domain to connect to. For better security, the instance isn't joined to the domain for domainless authentication. Other applications on the instance can't use the domainless credentials. You can use this parameter to run tasks on the same instance, even it the tasks need to join different domains. For more information, see [Using gMSAs for Windows Containers](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/windows-gmsa.html) and [Using gMSAs for Linux Containers](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/linux-gmsa.html).
        """
        depends_on: NotRequired[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionContainerDependencyArgsDict']]]]
        """
        The dependencies defined for container startup and shutdown. A container can contain multiple dependencies. When a dependency is defined for container startup, for container shutdown it is reversed.
         For tasks using the EC2 launch type, the container instances require at least version 1.26.0 of the container agent to turn on container dependencies. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see [Updating the Amazon ECS Container Agent](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-update.html) in the *Amazon Elastic Container Service Developer Guide*. If you're using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ``ecs-init`` package. If your container instances are launched from version ``20190301`` or later, then they contain the required versions of the container agent and ``ecs-init``. For more information, see [Amazon ECS-optimized Linux AMI](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html) in the *Amazon Elastic Container Service Developer Guide*.
         For tasks using the Fargate launch type, the task or service requires the following platforms:
          +  Linux platform version ``1.3.0`` or later.
          +  Windows platform version ``1.0.0`` or later.
          
         If the task definition is used in a blue/green deployment that uses [AWS::CodeDeploy::DeploymentGroup BlueGreenDeploymentConfiguration](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-codedeploy-deploymentgroup-bluegreendeploymentconfiguration.html), the ``dependsOn`` parameter is not supported.
        """
        disable_networking: NotRequired[pulumi.Input[_builtins.bool]]
        """
        When this parameter is true, networking is off within the container. This parameter maps to ``NetworkDisabled`` in the docker container create command.
          This parameter is not supported for Windows containers.
        """
        dns_search_domains: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        A list of DNS search domains that are presented to the container. This parameter maps to ``DnsSearch`` in the docker container create command and the ``--dns-search`` option to docker run.
          This parameter is not supported for Windows containers.
        """
        dns_servers: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        A list of DNS servers that are presented to the container. This parameter maps to ``Dns`` in the docker container create command and the ``--dns`` option to docker run.
          This parameter is not supported for Windows containers.
        """
        docker_labels: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]
        """
        A key/value map of labels to add to the container. This parameter maps to ``Labels`` in the docker container create command and the ``--label`` option to docker run. This parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
        """
        docker_security_options: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        A list of strings to provide custom configuration for multiple security systems. This field isn't valid for containers in tasks using the Fargate launch type.
         For Linux tasks on EC2, this parameter can be used to reference custom labels for SELinux and AppArmor multi-level security systems.
         For any tasks on EC2, this parameter can be used to reference a credential spec file that configures a container for Active Directory authentication. For more information, see [Using gMSAs for Windows Containers](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/windows-gmsa.html) and [Using gMSAs for Linux Containers](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/linux-gmsa.html) in the *Amazon Elastic Container Service Developer Guide*.
         This parameter maps to ``SecurityOpt`` in the docker container create command and the ``--security-opt`` option to docker run.
          The Amazon ECS container agent running on a container instance must register with the ``ECS_SELINUX_CAPABLE=true`` or ``ECS_APPARMOR_CAPABLE=true`` environment variables before containers placed on that instance can use these security options. For more information, see [Amazon ECS Container Agent Configuration](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html) in the *Amazon Elastic Container Service Developer Guide*.
          Valid values: "no-new-privileges" | "apparmor:PROFILE" | "label:value" | "credentialspec:CredentialSpecFilePath"
        """
        entry_point: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        Early versions of the Amazon ECS container agent don't properly handle ``entryPoint`` parameters. If you have problems using ``entryPoint``, update your container agent or enter your commands and arguments as ``command`` array items instead.
          The entry point that's passed to the container. This parameter maps to ``Entrypoint`` in the docker container create command and the ``--entrypoint`` option to docker run.
        """
        environment: NotRequired[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionKeyValuePairArgsDict']]]]
        """
        The environment variables to pass to a container. This parameter maps to ``Env`` in the docker container create command and the ``--env`` option to docker run.
          We don't recommend that you use plaintext environment variables for sensitive information, such as credential data.
        """
        environment_files: NotRequired[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionEnvironmentFileArgsDict']]]]
        """
        A list of files containing the environment variables to pass to a container. This parameter maps to the ``--env-file`` option to docker run.
         You can specify up to ten environment files. The file must have a ``.env`` file extension. Each line in an environment file contains an environment variable in ``VARIABLE=VALUE`` format. Lines beginning with ``#`` are treated as comments and are ignored.
         If there are environment variables specified using the ``environment`` parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they're processed from the top down. We recommend that you use unique variable names. For more information, see [Specifying Environment Variables](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/taskdef-envfiles.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        essential: NotRequired[pulumi.Input[_builtins.bool]]
        """
        If the ``essential`` parameter of a container is marked as ``true``, and that container fails or stops for any reason, all other containers that are part of the task are stopped. If the ``essential`` parameter of a container is marked as ``false``, its failure doesn't affect the rest of the containers in a task. If this parameter is omitted, a container is assumed to be essential.
         All tasks must have at least one essential container. If you have an application that's composed of multiple containers, group containers that are used for a common purpose into components, and separate the different components into multiple task definitions. For more information, see [Application Architecture](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/application_architecture.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        extra_hosts: NotRequired[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionHostEntryArgsDict']]]]
        """
        A list of hostnames and IP address mappings to append to the ``/etc/hosts`` file on the container. This parameter maps to ``ExtraHosts`` in the docker container create command and the ``--add-host`` option to docker run.
          This parameter isn't supported for Windows containers or tasks that use the ``awsvpc`` network mode.
        """
        firelens_configuration: NotRequired[pulumi.Input['TaskDefinitionFirelensConfigurationArgsDict']]
        """
        The FireLens configuration for the container. This is used to specify and configure a log router for container logs. For more information, see [Custom Log Routing](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_firelens.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        health_check: NotRequired[pulumi.Input['TaskDefinitionHealthCheckArgsDict']]
        """
        The container health check command and associated configuration parameters for the container. This parameter maps to ``HealthCheck`` in the docker container create command and the ``HEALTHCHECK`` parameter of docker run.
        """
        hostname: NotRequired[pulumi.Input[_builtins.str]]
        """
        The hostname to use for your container. This parameter maps to ``Hostname`` in the docker container create command and the ``--hostname`` option to docker run.
          The ``hostname`` parameter is not supported if you're using the ``awsvpc`` network mode.
        """
        interactive: NotRequired[pulumi.Input[_builtins.bool]]
        """
        When this parameter is ``true``, you can deploy containerized applications that require ``stdin`` or a ``tty`` to be allocated. This parameter maps to ``OpenStdin`` in the docker container create command and the ``--interactive`` option to docker run.
        """
        links: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The ``links`` parameter allows containers to communicate with each other without the need for port mappings. This parameter is only supported if the network mode of a task definition is ``bridge``. The ``name:internalName`` construct is analogous to ``name:alias`` in Docker links. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed.. This parameter maps to ``Links`` in the docker container create command and the ``--link`` option to docker run.
          This parameter is not supported for Windows containers.
           Containers that are collocated on a single container instance may be able to communicate with each other without requiring links or host port mappings. Network isolation is achieved on the container instance using security groups and VPC settings.
        """
        linux_parameters: NotRequired[pulumi.Input['TaskDefinitionLinuxParametersArgsDict']]
        """
        Linux-specific modifications that are applied to the container, such as Linux kernel capabilities. For more information see [KernelCapabilities](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_KernelCapabilities.html).
          This parameter is not supported for Windows containers.
        """
        log_configuration: NotRequired[pulumi.Input['TaskDefinitionLogConfigurationArgsDict']]
        """
        The log configuration specification for the container.
         This parameter maps to ``LogConfig`` in the docker Create a container command and the ``--log-driver`` option to docker run. By default, containers use the same logging driver that the Docker daemon uses. However, the container may use a different logging driver than the Docker daemon by specifying a log driver with this parameter in the container definition. To use a different logging driver for a container, the log system must be configured properly on the container instance (or on a different log server for remote logging options). For more information on the options for different supported log drivers, see [Configure logging drivers](https://docs.aws.amazon.com/https://docs.docker.com/engine/admin/logging/overview/) in the Docker documentation.
          Amazon ECS currently supports a subset of the logging drivers available to the Docker daemon (shown in the [LogConfiguration](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_LogConfiguration.html) data type). Additional log drivers may be available in future releases of the Amazon ECS container agent.
          This parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
          The Amazon ECS container agent running on a container instance must register the logging drivers available on that instance with the ``ECS_AVAILABLE_LOGGING_DRIVERS`` environment variable before containers placed on that instance can use these log configuration options. For more information, see [Container Agent Configuration](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html) in the *Developer Guide*.
        """
        memory: NotRequired[pulumi.Input[_builtins.int]]
        """
        The amount (in MiB) of memory to present to the container. If your container attempts to exceed the memory specified here, the container is killed. The total amount of memory reserved for all containers within a task must be lower than the task ``memory`` value, if one is specified. This parameter maps to ``Memory`` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/#operation/ContainerCreate) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/) and the ``--memory`` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/#security-configuration).
         If using the Fargate launch type, this parameter is optional.
         If using the EC2 launch type, you must specify either a task-level memory value or a container-level memory value. If you specify both a container-level ``memory`` and ``memoryReservation`` value, ``memory`` must be greater than ``memoryReservation``. If you specify ``memoryReservation``, then that value is subtracted from the available memory resources for the container instance where the container is placed. Otherwise, the value of ``memory`` is used.
         The Docker 20.10.0 or later daemon reserves a minimum of 6 MiB of memory for a container, so you should not specify fewer than 6 MiB of memory for your containers.
         The Docker 19.03.13-ce or earlier daemon reserves a minimum of 4 MiB of memory for a container, so you should not specify fewer than 4 MiB of memory for your containers.
        """
        memory_reservation: NotRequired[pulumi.Input[_builtins.int]]
        """
        The soft limit (in MiB) of memory to reserve for the container. When system memory is under heavy contention, Docker attempts to keep the container memory to this soft limit. However, your container can consume more memory when it needs to, up to either the hard limit specified with the ``memory`` parameter (if applicable), or all of the available memory on the container instance, whichever comes first. This parameter maps to ``MemoryReservation`` in the docker container create command and the ``--memory-reservation`` option to docker run.
         If a task-level memory value is not specified, you must specify a non-zero integer for one or both of ``memory`` or ``memoryReservation`` in a container definition. If you specify both, ``memory`` must be greater than ``memoryReservation``. If you specify ``memoryReservation``, then that value is subtracted from the available memory resources for the container instance where the container is placed. Otherwise, the value of ``memory`` is used.
         For example, if your container normally uses 128 MiB of memory, but occasionally bursts to 256 MiB of memory for short periods of time, you can set a ``memoryReservation`` of 128 MiB, and a ``memory`` hard limit of 300 MiB. This configuration would allow the container to only reserve 128 MiB of memory from the remaining resources on the container instance, but also allow the container to consume more memory resources when needed.
         The Docker 20.10.0 or later daemon reserves a minimum of 6 MiB of memory for a container. So, don't specify less than 6 MiB of memory for your containers. 
         The Docker 19.03.13-ce or earlier daemon reserves a minimum of 4 MiB of memory for a container. So, don't specify less than 4 MiB of memory for your containers.
        """
        mount_points: NotRequired[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionMountPointArgsDict']]]]
        """
        The mount points for data volumes in your container.
         This parameter maps to ``Volumes`` in the docker container create command and the ``--volume`` option to docker run.
         Windows containers can mount whole directories on the same drive as ``$env:ProgramData``. Windows containers can't mount directories on a different drive, and mount point can't be across drives.
        """
        port_mappings: NotRequired[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionPortMappingArgsDict']]]]
        """
        The list of port mappings for the container. Port mappings allow containers to access ports on the host container instance to send or receive traffic.
         For task definitions that use the ``awsvpc`` network mode, you should only specify the ``containerPort``. The ``hostPort`` can be left blank or it must be the same value as the ``containerPort``.
         Port mappings on Windows use the ``NetNAT`` gateway address rather than ``localhost``. There is no loopback for port mappings on Windows, so you cannot access a container's mapped port from the host itself. 
         This parameter maps to ``PortBindings`` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/#operation/ContainerCreate) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/) and the ``--publish`` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/). If the network mode of a task definition is set to ``none``, then you can't specify port mappings. If the network mode of a task definition is set to ``host``, then host ports must either be undefined or they must match the container port in the port mapping.
          After a task reaches the ``RUNNING`` status, manual and automatic host and container port assignments are visible in the *Network Bindings* section of a container description for a selected task in the Amazon ECS console. The assignments are also visible in the ``networkBindings`` section [DescribeTasks](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DescribeTasks.html) responses.
        """
        privileged: NotRequired[pulumi.Input[_builtins.bool]]
        """
        When this parameter is true, the container is given elevated privileges on the host container instance (similar to the ``root`` user). This parameter maps to ``Privileged`` in the docker container create command and the ``--privileged`` option to docker run
          This parameter is not supported for Windows containers or tasks run on FARGATElong.
        """
        pseudo_terminal: NotRequired[pulumi.Input[_builtins.bool]]
        """
        When this parameter is ``true``, a TTY is allocated. This parameter maps to ``Tty`` in the docker container create command and the ``--tty`` option to docker run.
        """
        readonly_root_filesystem: NotRequired[pulumi.Input[_builtins.bool]]
        """
        When this parameter is true, the container is given read-only access to its root file system. This parameter maps to ``ReadonlyRootfs`` in the docker container create command and the ``--read-only`` option to docker run.
          This parameter is not supported for Windows containers.
        """
        repository_credentials: NotRequired[pulumi.Input['TaskDefinitionRepositoryCredentialsArgsDict']]
        """
        The private repository authentication credentials to use.
        """
        resource_requirements: NotRequired[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionResourceRequirementArgsDict']]]]
        """
        The type and amount of a resource to assign to a container. The only supported resource is a GPU.
        """
        restart_policy: NotRequired[pulumi.Input['TaskDefinitionRestartPolicyArgsDict']]
        """
        The restart policy for a container. When you set up a restart policy, Amazon ECS can restart the container without needing to replace the task. For more information, see [Restart individual containers in Amazon ECS tasks with container restart policies](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/container-restart-policy.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        secrets: NotRequired[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionSecretArgsDict']]]]
        """
        The secrets to pass to the container. For more information, see [Specifying Sensitive Data](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        start_timeout: NotRequired[pulumi.Input[_builtins.int]]
        """
        Time duration (in seconds) to wait before giving up on resolving dependencies for a container. For example, you specify two containers in a task definition with containerA having a dependency on containerB reaching a ``COMPLETE``, ``SUCCESS``, or ``HEALTHY`` status. If a ``startTimeout`` value is specified for containerB and it doesn't reach the desired status within that time then containerA gives up and not start. This results in the task transitioning to a ``STOPPED`` state.
          When the ``ECS_CONTAINER_START_TIMEOUT`` container agent configuration variable is used, it's enforced independently from this start timeout value.
          For tasks using the Fargate launch type, the task or service requires the following platforms:
          +  Linux platform version ``1.3.0`` or later.
          +  Windows platform version ``1.0.0`` or later.
          
         For tasks using the EC2 launch type, your container instances require at least version ``1.26.0`` of the container agent to use a container start timeout value. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see [Updating the Amazon ECS Container Agent](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-update.html) in the *Amazon Elastic Container Service Developer Guide*. If you're using an Amazon ECS-optimized Linux AMI, your instance needs at least version ``1.26.0-1`` of the ``ecs-init`` package. If your container instances are launched from version ``20190301`` or later, then they contain the required versions of the container agent and ``ecs-init``. For more information, see [Amazon ECS-optimized Linux AMI](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html) in the *Amazon Elastic Container Service Developer Guide*.
         The valid values for Fargate are 2-120 seconds.
        """
        stop_timeout: NotRequired[pulumi.Input[_builtins.int]]
        """
        Time duration (in seconds) to wait before the container is forcefully killed if it doesn't exit normally on its own.
         For tasks using the Fargate launch type, the task or service requires the following platforms:
          +  Linux platform version ``1.3.0`` or later.
          +  Windows platform version ``1.0.0`` or later.
          
         For tasks that use the Fargate launch type, the max stop timeout value is 120 seconds and if the parameter is not specified, the default value of 30 seconds is used.
         For tasks that use the EC2 launch type, if the ``stopTimeout`` parameter isn't specified, the value set for the Amazon ECS container agent configuration variable ``ECS_CONTAINER_STOP_TIMEOUT`` is used. If neither the ``stopTimeout`` parameter or the ``ECS_CONTAINER_STOP_TIMEOUT`` agent configuration variable are set, then the default values of 30 seconds for Linux containers and 30 seconds on Windows containers are used. Your container instances require at least version 1.26.0 of the container agent to use a container stop timeout value. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see [Updating the Amazon ECS Container Agent](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-update.html) in the *Amazon Elastic Container Service Developer Guide*. If you're using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ``ecs-init`` package. If your container instances are launched from version ``20190301`` or later, then they contain the required versions of the container agent and ``ecs-init``. For more information, see [Amazon ECS-optimized Linux AMI](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html) in the *Amazon Elastic Container Service Developer Guide*.
         The valid values for Fargate are 2-120 seconds.
        """
        system_controls: NotRequired[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionSystemControlArgsDict']]]]
        """
        A list of namespaced kernel parameters to set in the container. This parameter maps to ``Sysctls`` in the docker container create command and the ``--sysctl`` option to docker run. For example, you can configure ``net.ipv4.tcp_keepalive_time`` setting to maintain longer lived connections.
        """
        ulimits: NotRequired[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionUlimitArgsDict']]]]
        """
        A list of ``ulimits`` to set in the container. This parameter maps to ``Ulimits`` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/#operation/ContainerCreate) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/) and the ``--ulimit`` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/). Valid naming values are displayed in the [Ulimit](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_Ulimit.html) data type. This parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
          This parameter is not supported for Windows containers.
        """
        user: NotRequired[pulumi.Input[_builtins.str]]
        """
        The user to use inside the container. This parameter maps to ``User`` in the docker container create command and the ``--user`` option to docker run.
          When running tasks using the ``host`` network mode, don't run containers using the root user (UID 0). We recommend using a non-root user for better security.
          You can specify the ``user`` using the following formats. If specifying a UID or GID, you must specify it as a positive integer.
          +   ``user`` 
          +   ``user:group`` 
          +   ``uid`` 
          +   ``uid:gid`` 
          +   ``user:gid`` 
          +   ``uid:group`` 
          
          This parameter is not supported for Windows containers.
        """
        version_consistency: NotRequired[pulumi.Input['TaskDefinitionContainerDefinitionVersionConsistency']]
        """
        Specifies whether Amazon ECS will resolve the container image tag provided in the container definition to an image digest. By default, the value is ``enabled``. If you set the value for a container as ``disabled``, Amazon ECS will not resolve the provided container image tag to a digest and will use the original image URI specified in the container definition for deployment. For more information about container image resolution, see [Container image resolution](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-ecs.html#deployment-container-image-stability) in the *Amazon ECS Developer Guide*.
        """
        volumes_from: NotRequired[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionVolumeFromArgsDict']]]]
        """
        Data volumes to mount from another container. This parameter maps to ``VolumesFrom`` in the docker container create command and the ``--volumes-from`` option to docker run.
        """
        working_directory: NotRequired[pulumi.Input[_builtins.str]]
        """
        The working directory to run commands inside the container in. This parameter maps to ``WorkingDir`` in the docker container create command and the ``--workdir`` option to docker run.
        """
elif False:
    TaskDefinitionContainerDefinitionArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionContainerDefinitionArgs:
    def __init__(__self__, *,
                 image: pulumi.Input[_builtins.str],
                 name: pulumi.Input[_builtins.str],
                 command: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 cpu: Optional[pulumi.Input[_builtins.int]] = None,
                 credential_specs: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 depends_on: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionContainerDependencyArgs']]]] = None,
                 disable_networking: Optional[pulumi.Input[_builtins.bool]] = None,
                 dns_search_domains: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 dns_servers: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 docker_labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]] = None,
                 docker_security_options: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 entry_point: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 environment: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionKeyValuePairArgs']]]] = None,
                 environment_files: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionEnvironmentFileArgs']]]] = None,
                 essential: Optional[pulumi.Input[_builtins.bool]] = None,
                 extra_hosts: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionHostEntryArgs']]]] = None,
                 firelens_configuration: Optional[pulumi.Input['TaskDefinitionFirelensConfigurationArgs']] = None,
                 health_check: Optional[pulumi.Input['TaskDefinitionHealthCheckArgs']] = None,
                 hostname: Optional[pulumi.Input[_builtins.str]] = None,
                 interactive: Optional[pulumi.Input[_builtins.bool]] = None,
                 links: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 linux_parameters: Optional[pulumi.Input['TaskDefinitionLinuxParametersArgs']] = None,
                 log_configuration: Optional[pulumi.Input['TaskDefinitionLogConfigurationArgs']] = None,
                 memory: Optional[pulumi.Input[_builtins.int]] = None,
                 memory_reservation: Optional[pulumi.Input[_builtins.int]] = None,
                 mount_points: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionMountPointArgs']]]] = None,
                 port_mappings: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionPortMappingArgs']]]] = None,
                 privileged: Optional[pulumi.Input[_builtins.bool]] = None,
                 pseudo_terminal: Optional[pulumi.Input[_builtins.bool]] = None,
                 readonly_root_filesystem: Optional[pulumi.Input[_builtins.bool]] = None,
                 repository_credentials: Optional[pulumi.Input['TaskDefinitionRepositoryCredentialsArgs']] = None,
                 resource_requirements: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionResourceRequirementArgs']]]] = None,
                 restart_policy: Optional[pulumi.Input['TaskDefinitionRestartPolicyArgs']] = None,
                 secrets: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionSecretArgs']]]] = None,
                 start_timeout: Optional[pulumi.Input[_builtins.int]] = None,
                 stop_timeout: Optional[pulumi.Input[_builtins.int]] = None,
                 system_controls: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionSystemControlArgs']]]] = None,
                 ulimits: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionUlimitArgs']]]] = None,
                 user: Optional[pulumi.Input[_builtins.str]] = None,
                 version_consistency: Optional[pulumi.Input['TaskDefinitionContainerDefinitionVersionConsistency']] = None,
                 volumes_from: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionVolumeFromArgs']]]] = None,
                 working_directory: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The ``ContainerDefinition`` property specifies a container definition. Container definitions are used in task definitions to describe the different containers that are launched as part of a task.
        :param pulumi.Input[_builtins.str] image: The image used to start a container. This string is passed directly to the Docker daemon. By default, images in the Docker Hub registry are available. Other repositories are specified with either ``repository-url/image:tag`` or ``repository-url/image@digest``. For images using tags (repository-url/image:tag), up to 255 characters total are allowed, including letters (uppercase and lowercase), numbers, hyphens, underscores, colons, periods, forward slashes, and number signs (#). For images using digests (repository-url/image@digest), the 255 character limit applies only to the repository URL and image name (everything before the @ sign). The only supported hash function is sha256, and the hash value after sha256: must be exactly 64 characters (only letters A-F, a-f, and numbers 0-9 are allowed). This parameter maps to ``Image`` in the docker container create command and the ``IMAGE`` parameter of docker run.
                 +  When a new task starts, the Amazon ECS container agent pulls the latest version of the specified image and tag for the container to use. However, subsequent updates to a repository image aren't propagated to already running tasks.
                 +  Images in Amazon ECR repositories can be specified by either using the full ``registry/repository:tag`` or ``registry/repository@digest``. For example, ``012345678910.dkr.ecr.<region-name>.amazonaws.com/<repository-name>:latest`` or ``012345678910.dkr.ecr.<region-name>.amazonaws.com/<repository-name>@sha256:94afd1f2e64d908bc90dbca0035a5b567EXAMPLE``. 
                 +  Images in official repositories on Docker Hub use a single name (for example, ``ubuntu`` or ``mongo``).
                 +  Images in other repositories on Docker Hub are qualified with an organization name (for example, ``amazon/amazon-ecs-agent``).
                 +  Images in other online repositories are qualified further by a domain name (for example, ``quay.io/assemblyline/ubuntu``).
        :param pulumi.Input[_builtins.str] name: The name of a container. If you're linking multiple containers together in a task definition, the ``name`` of one container can be entered in the ``links`` of another container to connect the containers. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. This parameter maps to ``name`` in the docker container create command and the ``--name`` option to docker run.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] command: The command that's passed to the container. This parameter maps to ``Cmd`` in the docker container create command and the ``COMMAND`` parameter to docker run. If there are multiple arguments, each argument is a separated string in the array.
        :param pulumi.Input[_builtins.int] cpu: The number of ``cpu`` units reserved for the container. This parameter maps to ``CpuShares`` in the docker container create command and the ``--cpu-shares`` option to docker run.
                This field is optional for tasks using the Fargate launch type, and the only requirement is that the total amount of CPU reserved for all containers within a task be lower than the task-level ``cpu`` value.
                 You can determine the number of CPU units that are available per EC2 instance type by multiplying the vCPUs listed for that instance type on the [Amazon EC2 Instances](https://docs.aws.amazon.com/ec2/instance-types/) detail page by 1,024.
                 Linux containers share unallocated CPU units with other containers on the container instance with the same ratio as their allocated amount. For example, if you run a single-container task on a single-core instance type with 512 CPU units specified for that container, and that's the only task running on the container instance, that container could use the full 1,024 CPU unit share at any given time. However, if you launched another copy of the same task on that container instance, each task is guaranteed a minimum of 512 CPU units when needed. Moreover, each container could float to higher CPU usage if the other container was not using it. If both tasks were 100% active all of the time, they would be limited to 512 CPU units.
                On Linux container instances, the Docker daemon on the container instance uses the CPU value to calculate the relative CPU share ratios for running containers. The minimum valid CPU share value that the Linux kernel allows is 2, and the maximum valid CPU share value that the Linux kernel allows is 262144. However, the CPU parameter isn't required, and you can use CPU values below 2 or above 262144 in your container definitions. For CPU values below 2 (including null) or above 262144, the behavior varies based on your Amazon ECS container agent version:
                 +  *Agent versions less than or equal to 1.1.0:* Null and zero CPU values are passed to Docker as 0, which Docker then converts to 1,024 CPU shares. CPU values of 1 are passed to Docker as 1, which the Linux kernel converts to two CPU shares.
                 +  *Agent versions greater than or equal to 1.2.0:* Null, zero, and CPU values of 1 are passed to Docker as 2.
                 +  *Agent versions greater than or equal to 1.84.0:* CPU values greater than 256 vCPU are passed to Docker as 256, which is equivalent to 262144 CPU shares.
                 
                On Windows container instances, the CPU limit is enforced as an absolute limit, or a quota. Windows containers only have access to the specified amount of CPU that's described in the task definition. A null or zero CPU value is passed to Docker as ``0``, which Windows interprets as 1% of one CPU.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] credential_specs: A list of ARNs in SSM or Amazon S3 to a credential spec (``CredSpec``) file that configures the container for Active Directory authentication. We recommend that you use this parameter instead of the ``dockerSecurityOptions``. The maximum number of ARNs is 1.
                There are two formats for each ARN.
                 + credentialspecdomainless:MyARN You use credentialspecdomainless:MyARN to provide a CredSpec with an additional section for a secret in . You provide the login credentials to the domain in the secret. Each task that runs on any container instance can join different domains. You can use this format without joining the container instance to a domain. + credentialspec:MyARN You use credentialspec:MyARN to provide a CredSpec for a single domain. You must join the container instance to the domain before you start any tasks that use this task definition. 
                In both formats, replace ``MyARN`` with the ARN in SSM or Amazon S3.
                If you provide a ``credentialspecdomainless:MyARN``, the ``credspec`` must provide a ARN in ASMlong for a secret containing the username, password, and the domain to connect to. For better security, the instance isn't joined to the domain for domainless authentication. Other applications on the instance can't use the domainless credentials. You can use this parameter to run tasks on the same instance, even it the tasks need to join different domains. For more information, see [Using gMSAs for Windows Containers](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/windows-gmsa.html) and [Using gMSAs for Linux Containers](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/linux-gmsa.html).
        :param pulumi.Input[Sequence[pulumi.Input['TaskDefinitionContainerDependencyArgs']]] depends_on: The dependencies defined for container startup and shutdown. A container can contain multiple dependencies. When a dependency is defined for container startup, for container shutdown it is reversed.
                For tasks using the EC2 launch type, the container instances require at least version 1.26.0 of the container agent to turn on container dependencies. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see [Updating the Amazon ECS Container Agent](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-update.html) in the *Amazon Elastic Container Service Developer Guide*. If you're using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ``ecs-init`` package. If your container instances are launched from version ``20190301`` or later, then they contain the required versions of the container agent and ``ecs-init``. For more information, see [Amazon ECS-optimized Linux AMI](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html) in the *Amazon Elastic Container Service Developer Guide*.
                For tasks using the Fargate launch type, the task or service requires the following platforms:
                 +  Linux platform version ``1.3.0`` or later.
                 +  Windows platform version ``1.0.0`` or later.
                 
                If the task definition is used in a blue/green deployment that uses [AWS::CodeDeploy::DeploymentGroup BlueGreenDeploymentConfiguration](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-codedeploy-deploymentgroup-bluegreendeploymentconfiguration.html), the ``dependsOn`` parameter is not supported.
        :param pulumi.Input[_builtins.bool] disable_networking: When this parameter is true, networking is off within the container. This parameter maps to ``NetworkDisabled`` in the docker container create command.
                 This parameter is not supported for Windows containers.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] dns_search_domains: A list of DNS search domains that are presented to the container. This parameter maps to ``DnsSearch`` in the docker container create command and the ``--dns-search`` option to docker run.
                 This parameter is not supported for Windows containers.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] dns_servers: A list of DNS servers that are presented to the container. This parameter maps to ``Dns`` in the docker container create command and the ``--dns`` option to docker run.
                 This parameter is not supported for Windows containers.
        :param pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]] docker_labels: A key/value map of labels to add to the container. This parameter maps to ``Labels`` in the docker container create command and the ``--label`` option to docker run. This parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] docker_security_options: A list of strings to provide custom configuration for multiple security systems. This field isn't valid for containers in tasks using the Fargate launch type.
                For Linux tasks on EC2, this parameter can be used to reference custom labels for SELinux and AppArmor multi-level security systems.
                For any tasks on EC2, this parameter can be used to reference a credential spec file that configures a container for Active Directory authentication. For more information, see [Using gMSAs for Windows Containers](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/windows-gmsa.html) and [Using gMSAs for Linux Containers](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/linux-gmsa.html) in the *Amazon Elastic Container Service Developer Guide*.
                This parameter maps to ``SecurityOpt`` in the docker container create command and the ``--security-opt`` option to docker run.
                 The Amazon ECS container agent running on a container instance must register with the ``ECS_SELINUX_CAPABLE=true`` or ``ECS_APPARMOR_CAPABLE=true`` environment variables before containers placed on that instance can use these security options. For more information, see [Amazon ECS Container Agent Configuration](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html) in the *Amazon Elastic Container Service Developer Guide*.
                 Valid values: "no-new-privileges" | "apparmor:PROFILE" | "label:value" | "credentialspec:CredentialSpecFilePath"
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] entry_point: Early versions of the Amazon ECS container agent don't properly handle ``entryPoint`` parameters. If you have problems using ``entryPoint``, update your container agent or enter your commands and arguments as ``command`` array items instead.
                 The entry point that's passed to the container. This parameter maps to ``Entrypoint`` in the docker container create command and the ``--entrypoint`` option to docker run.
        :param pulumi.Input[Sequence[pulumi.Input['TaskDefinitionKeyValuePairArgs']]] environment: The environment variables to pass to a container. This parameter maps to ``Env`` in the docker container create command and the ``--env`` option to docker run.
                 We don't recommend that you use plaintext environment variables for sensitive information, such as credential data.
        :param pulumi.Input[Sequence[pulumi.Input['TaskDefinitionEnvironmentFileArgs']]] environment_files: A list of files containing the environment variables to pass to a container. This parameter maps to the ``--env-file`` option to docker run.
                You can specify up to ten environment files. The file must have a ``.env`` file extension. Each line in an environment file contains an environment variable in ``VARIABLE=VALUE`` format. Lines beginning with ``#`` are treated as comments and are ignored.
                If there are environment variables specified using the ``environment`` parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they're processed from the top down. We recommend that you use unique variable names. For more information, see [Specifying Environment Variables](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/taskdef-envfiles.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.bool] essential: If the ``essential`` parameter of a container is marked as ``true``, and that container fails or stops for any reason, all other containers that are part of the task are stopped. If the ``essential`` parameter of a container is marked as ``false``, its failure doesn't affect the rest of the containers in a task. If this parameter is omitted, a container is assumed to be essential.
                All tasks must have at least one essential container. If you have an application that's composed of multiple containers, group containers that are used for a common purpose into components, and separate the different components into multiple task definitions. For more information, see [Application Architecture](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/application_architecture.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[Sequence[pulumi.Input['TaskDefinitionHostEntryArgs']]] extra_hosts: A list of hostnames and IP address mappings to append to the ``/etc/hosts`` file on the container. This parameter maps to ``ExtraHosts`` in the docker container create command and the ``--add-host`` option to docker run.
                 This parameter isn't supported for Windows containers or tasks that use the ``awsvpc`` network mode.
        :param pulumi.Input['TaskDefinitionFirelensConfigurationArgs'] firelens_configuration: The FireLens configuration for the container. This is used to specify and configure a log router for container logs. For more information, see [Custom Log Routing](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_firelens.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input['TaskDefinitionHealthCheckArgs'] health_check: The container health check command and associated configuration parameters for the container. This parameter maps to ``HealthCheck`` in the docker container create command and the ``HEALTHCHECK`` parameter of docker run.
        :param pulumi.Input[_builtins.str] hostname: The hostname to use for your container. This parameter maps to ``Hostname`` in the docker container create command and the ``--hostname`` option to docker run.
                 The ``hostname`` parameter is not supported if you're using the ``awsvpc`` network mode.
        :param pulumi.Input[_builtins.bool] interactive: When this parameter is ``true``, you can deploy containerized applications that require ``stdin`` or a ``tty`` to be allocated. This parameter maps to ``OpenStdin`` in the docker container create command and the ``--interactive`` option to docker run.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] links: The ``links`` parameter allows containers to communicate with each other without the need for port mappings. This parameter is only supported if the network mode of a task definition is ``bridge``. The ``name:internalName`` construct is analogous to ``name:alias`` in Docker links. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed.. This parameter maps to ``Links`` in the docker container create command and the ``--link`` option to docker run.
                 This parameter is not supported for Windows containers.
                  Containers that are collocated on a single container instance may be able to communicate with each other without requiring links or host port mappings. Network isolation is achieved on the container instance using security groups and VPC settings.
        :param pulumi.Input['TaskDefinitionLinuxParametersArgs'] linux_parameters: Linux-specific modifications that are applied to the container, such as Linux kernel capabilities. For more information see [KernelCapabilities](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_KernelCapabilities.html).
                 This parameter is not supported for Windows containers.
        :param pulumi.Input['TaskDefinitionLogConfigurationArgs'] log_configuration: The log configuration specification for the container.
                This parameter maps to ``LogConfig`` in the docker Create a container command and the ``--log-driver`` option to docker run. By default, containers use the same logging driver that the Docker daemon uses. However, the container may use a different logging driver than the Docker daemon by specifying a log driver with this parameter in the container definition. To use a different logging driver for a container, the log system must be configured properly on the container instance (or on a different log server for remote logging options). For more information on the options for different supported log drivers, see [Configure logging drivers](https://docs.aws.amazon.com/https://docs.docker.com/engine/admin/logging/overview/) in the Docker documentation.
                 Amazon ECS currently supports a subset of the logging drivers available to the Docker daemon (shown in the [LogConfiguration](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_LogConfiguration.html) data type). Additional log drivers may be available in future releases of the Amazon ECS container agent.
                 This parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
                 The Amazon ECS container agent running on a container instance must register the logging drivers available on that instance with the ``ECS_AVAILABLE_LOGGING_DRIVERS`` environment variable before containers placed on that instance can use these log configuration options. For more information, see [Container Agent Configuration](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html) in the *Developer Guide*.
        :param pulumi.Input[_builtins.int] memory: The amount (in MiB) of memory to present to the container. If your container attempts to exceed the memory specified here, the container is killed. The total amount of memory reserved for all containers within a task must be lower than the task ``memory`` value, if one is specified. This parameter maps to ``Memory`` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/#operation/ContainerCreate) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/) and the ``--memory`` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/#security-configuration).
                If using the Fargate launch type, this parameter is optional.
                If using the EC2 launch type, you must specify either a task-level memory value or a container-level memory value. If you specify both a container-level ``memory`` and ``memoryReservation`` value, ``memory`` must be greater than ``memoryReservation``. If you specify ``memoryReservation``, then that value is subtracted from the available memory resources for the container instance where the container is placed. Otherwise, the value of ``memory`` is used.
                The Docker 20.10.0 or later daemon reserves a minimum of 6 MiB of memory for a container, so you should not specify fewer than 6 MiB of memory for your containers.
                The Docker 19.03.13-ce or earlier daemon reserves a minimum of 4 MiB of memory for a container, so you should not specify fewer than 4 MiB of memory for your containers.
        :param pulumi.Input[_builtins.int] memory_reservation: The soft limit (in MiB) of memory to reserve for the container. When system memory is under heavy contention, Docker attempts to keep the container memory to this soft limit. However, your container can consume more memory when it needs to, up to either the hard limit specified with the ``memory`` parameter (if applicable), or all of the available memory on the container instance, whichever comes first. This parameter maps to ``MemoryReservation`` in the docker container create command and the ``--memory-reservation`` option to docker run.
                If a task-level memory value is not specified, you must specify a non-zero integer for one or both of ``memory`` or ``memoryReservation`` in a container definition. If you specify both, ``memory`` must be greater than ``memoryReservation``. If you specify ``memoryReservation``, then that value is subtracted from the available memory resources for the container instance where the container is placed. Otherwise, the value of ``memory`` is used.
                For example, if your container normally uses 128 MiB of memory, but occasionally bursts to 256 MiB of memory for short periods of time, you can set a ``memoryReservation`` of 128 MiB, and a ``memory`` hard limit of 300 MiB. This configuration would allow the container to only reserve 128 MiB of memory from the remaining resources on the container instance, but also allow the container to consume more memory resources when needed.
                The Docker 20.10.0 or later daemon reserves a minimum of 6 MiB of memory for a container. So, don't specify less than 6 MiB of memory for your containers. 
                The Docker 19.03.13-ce or earlier daemon reserves a minimum of 4 MiB of memory for a container. So, don't specify less than 4 MiB of memory for your containers.
        :param pulumi.Input[Sequence[pulumi.Input['TaskDefinitionMountPointArgs']]] mount_points: The mount points for data volumes in your container.
                This parameter maps to ``Volumes`` in the docker container create command and the ``--volume`` option to docker run.
                Windows containers can mount whole directories on the same drive as ``$env:ProgramData``. Windows containers can't mount directories on a different drive, and mount point can't be across drives.
        :param pulumi.Input[Sequence[pulumi.Input['TaskDefinitionPortMappingArgs']]] port_mappings: The list of port mappings for the container. Port mappings allow containers to access ports on the host container instance to send or receive traffic.
                For task definitions that use the ``awsvpc`` network mode, you should only specify the ``containerPort``. The ``hostPort`` can be left blank or it must be the same value as the ``containerPort``.
                Port mappings on Windows use the ``NetNAT`` gateway address rather than ``localhost``. There is no loopback for port mappings on Windows, so you cannot access a container's mapped port from the host itself. 
                This parameter maps to ``PortBindings`` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/#operation/ContainerCreate) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/) and the ``--publish`` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/). If the network mode of a task definition is set to ``none``, then you can't specify port mappings. If the network mode of a task definition is set to ``host``, then host ports must either be undefined or they must match the container port in the port mapping.
                 After a task reaches the ``RUNNING`` status, manual and automatic host and container port assignments are visible in the *Network Bindings* section of a container description for a selected task in the Amazon ECS console. The assignments are also visible in the ``networkBindings`` section [DescribeTasks](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DescribeTasks.html) responses.
        :param pulumi.Input[_builtins.bool] privileged: When this parameter is true, the container is given elevated privileges on the host container instance (similar to the ``root`` user). This parameter maps to ``Privileged`` in the docker container create command and the ``--privileged`` option to docker run
                 This parameter is not supported for Windows containers or tasks run on FARGATElong.
        :param pulumi.Input[_builtins.bool] pseudo_terminal: When this parameter is ``true``, a TTY is allocated. This parameter maps to ``Tty`` in the docker container create command and the ``--tty`` option to docker run.
        :param pulumi.Input[_builtins.bool] readonly_root_filesystem: When this parameter is true, the container is given read-only access to its root file system. This parameter maps to ``ReadonlyRootfs`` in the docker container create command and the ``--read-only`` option to docker run.
                 This parameter is not supported for Windows containers.
        :param pulumi.Input['TaskDefinitionRepositoryCredentialsArgs'] repository_credentials: The private repository authentication credentials to use.
        :param pulumi.Input[Sequence[pulumi.Input['TaskDefinitionResourceRequirementArgs']]] resource_requirements: The type and amount of a resource to assign to a container. The only supported resource is a GPU.
        :param pulumi.Input['TaskDefinitionRestartPolicyArgs'] restart_policy: The restart policy for a container. When you set up a restart policy, Amazon ECS can restart the container without needing to replace the task. For more information, see [Restart individual containers in Amazon ECS tasks with container restart policies](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/container-restart-policy.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[Sequence[pulumi.Input['TaskDefinitionSecretArgs']]] secrets: The secrets to pass to the container. For more information, see [Specifying Sensitive Data](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.int] start_timeout: Time duration (in seconds) to wait before giving up on resolving dependencies for a container. For example, you specify two containers in a task definition with containerA having a dependency on containerB reaching a ``COMPLETE``, ``SUCCESS``, or ``HEALTHY`` status. If a ``startTimeout`` value is specified for containerB and it doesn't reach the desired status within that time then containerA gives up and not start. This results in the task transitioning to a ``STOPPED`` state.
                 When the ``ECS_CONTAINER_START_TIMEOUT`` container agent configuration variable is used, it's enforced independently from this start timeout value.
                 For tasks using the Fargate launch type, the task or service requires the following platforms:
                 +  Linux platform version ``1.3.0`` or later.
                 +  Windows platform version ``1.0.0`` or later.
                 
                For tasks using the EC2 launch type, your container instances require at least version ``1.26.0`` of the container agent to use a container start timeout value. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see [Updating the Amazon ECS Container Agent](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-update.html) in the *Amazon Elastic Container Service Developer Guide*. If you're using an Amazon ECS-optimized Linux AMI, your instance needs at least version ``1.26.0-1`` of the ``ecs-init`` package. If your container instances are launched from version ``20190301`` or later, then they contain the required versions of the container agent and ``ecs-init``. For more information, see [Amazon ECS-optimized Linux AMI](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html) in the *Amazon Elastic Container Service Developer Guide*.
                The valid values for Fargate are 2-120 seconds.
        :param pulumi.Input[_builtins.int] stop_timeout: Time duration (in seconds) to wait before the container is forcefully killed if it doesn't exit normally on its own.
                For tasks using the Fargate launch type, the task or service requires the following platforms:
                 +  Linux platform version ``1.3.0`` or later.
                 +  Windows platform version ``1.0.0`` or later.
                 
                For tasks that use the Fargate launch type, the max stop timeout value is 120 seconds and if the parameter is not specified, the default value of 30 seconds is used.
                For tasks that use the EC2 launch type, if the ``stopTimeout`` parameter isn't specified, the value set for the Amazon ECS container agent configuration variable ``ECS_CONTAINER_STOP_TIMEOUT`` is used. If neither the ``stopTimeout`` parameter or the ``ECS_CONTAINER_STOP_TIMEOUT`` agent configuration variable are set, then the default values of 30 seconds for Linux containers and 30 seconds on Windows containers are used. Your container instances require at least version 1.26.0 of the container agent to use a container stop timeout value. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see [Updating the Amazon ECS Container Agent](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-update.html) in the *Amazon Elastic Container Service Developer Guide*. If you're using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ``ecs-init`` package. If your container instances are launched from version ``20190301`` or later, then they contain the required versions of the container agent and ``ecs-init``. For more information, see [Amazon ECS-optimized Linux AMI](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html) in the *Amazon Elastic Container Service Developer Guide*.
                The valid values for Fargate are 2-120 seconds.
        :param pulumi.Input[Sequence[pulumi.Input['TaskDefinitionSystemControlArgs']]] system_controls: A list of namespaced kernel parameters to set in the container. This parameter maps to ``Sysctls`` in the docker container create command and the ``--sysctl`` option to docker run. For example, you can configure ``net.ipv4.tcp_keepalive_time`` setting to maintain longer lived connections.
        :param pulumi.Input[Sequence[pulumi.Input['TaskDefinitionUlimitArgs']]] ulimits: A list of ``ulimits`` to set in the container. This parameter maps to ``Ulimits`` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/#operation/ContainerCreate) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/) and the ``--ulimit`` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/). Valid naming values are displayed in the [Ulimit](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_Ulimit.html) data type. This parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
                 This parameter is not supported for Windows containers.
        :param pulumi.Input[_builtins.str] user: The user to use inside the container. This parameter maps to ``User`` in the docker container create command and the ``--user`` option to docker run.
                 When running tasks using the ``host`` network mode, don't run containers using the root user (UID 0). We recommend using a non-root user for better security.
                 You can specify the ``user`` using the following formats. If specifying a UID or GID, you must specify it as a positive integer.
                 +   ``user`` 
                 +   ``user:group`` 
                 +   ``uid`` 
                 +   ``uid:gid`` 
                 +   ``user:gid`` 
                 +   ``uid:group`` 
                 
                 This parameter is not supported for Windows containers.
        :param pulumi.Input['TaskDefinitionContainerDefinitionVersionConsistency'] version_consistency: Specifies whether Amazon ECS will resolve the container image tag provided in the container definition to an image digest. By default, the value is ``enabled``. If you set the value for a container as ``disabled``, Amazon ECS will not resolve the provided container image tag to a digest and will use the original image URI specified in the container definition for deployment. For more information about container image resolution, see [Container image resolution](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-ecs.html#deployment-container-image-stability) in the *Amazon ECS Developer Guide*.
        :param pulumi.Input[Sequence[pulumi.Input['TaskDefinitionVolumeFromArgs']]] volumes_from: Data volumes to mount from another container. This parameter maps to ``VolumesFrom`` in the docker container create command and the ``--volumes-from`` option to docker run.
        :param pulumi.Input[_builtins.str] working_directory: The working directory to run commands inside the container in. This parameter maps to ``WorkingDir`` in the docker container create command and the ``--workdir`` option to docker run.
        """
        pulumi.set(__self__, "image", image)
        pulumi.set(__self__, "name", name)
        if command is not None:
            pulumi.set(__self__, "command", command)
        if cpu is not None:
            pulumi.set(__self__, "cpu", cpu)
        if credential_specs is not None:
            pulumi.set(__self__, "credential_specs", credential_specs)
        if depends_on is not None:
            pulumi.set(__self__, "depends_on", depends_on)
        if disable_networking is not None:
            pulumi.set(__self__, "disable_networking", disable_networking)
        if dns_search_domains is not None:
            pulumi.set(__self__, "dns_search_domains", dns_search_domains)
        if dns_servers is not None:
            pulumi.set(__self__, "dns_servers", dns_servers)
        if docker_labels is not None:
            pulumi.set(__self__, "docker_labels", docker_labels)
        if docker_security_options is not None:
            pulumi.set(__self__, "docker_security_options", docker_security_options)
        if entry_point is not None:
            pulumi.set(__self__, "entry_point", entry_point)
        if environment is not None:
            pulumi.set(__self__, "environment", environment)
        if environment_files is not None:
            pulumi.set(__self__, "environment_files", environment_files)
        if essential is not None:
            pulumi.set(__self__, "essential", essential)
        if extra_hosts is not None:
            pulumi.set(__self__, "extra_hosts", extra_hosts)
        if firelens_configuration is not None:
            pulumi.set(__self__, "firelens_configuration", firelens_configuration)
        if health_check is not None:
            pulumi.set(__self__, "health_check", health_check)
        if hostname is not None:
            pulumi.set(__self__, "hostname", hostname)
        if interactive is not None:
            pulumi.set(__self__, "interactive", interactive)
        if links is not None:
            pulumi.set(__self__, "links", links)
        if linux_parameters is not None:
            pulumi.set(__self__, "linux_parameters", linux_parameters)
        if log_configuration is not None:
            pulumi.set(__self__, "log_configuration", log_configuration)
        if memory is not None:
            pulumi.set(__self__, "memory", memory)
        if memory_reservation is not None:
            pulumi.set(__self__, "memory_reservation", memory_reservation)
        if mount_points is not None:
            pulumi.set(__self__, "mount_points", mount_points)
        if port_mappings is not None:
            pulumi.set(__self__, "port_mappings", port_mappings)
        if privileged is not None:
            pulumi.set(__self__, "privileged", privileged)
        if pseudo_terminal is not None:
            pulumi.set(__self__, "pseudo_terminal", pseudo_terminal)
        if readonly_root_filesystem is not None:
            pulumi.set(__self__, "readonly_root_filesystem", readonly_root_filesystem)
        if repository_credentials is not None:
            pulumi.set(__self__, "repository_credentials", repository_credentials)
        if resource_requirements is not None:
            pulumi.set(__self__, "resource_requirements", resource_requirements)
        if restart_policy is not None:
            pulumi.set(__self__, "restart_policy", restart_policy)
        if secrets is not None:
            pulumi.set(__self__, "secrets", secrets)
        if start_timeout is not None:
            pulumi.set(__self__, "start_timeout", start_timeout)
        if stop_timeout is not None:
            pulumi.set(__self__, "stop_timeout", stop_timeout)
        if system_controls is not None:
            pulumi.set(__self__, "system_controls", system_controls)
        if ulimits is not None:
            pulumi.set(__self__, "ulimits", ulimits)
        if user is not None:
            pulumi.set(__self__, "user", user)
        if version_consistency is not None:
            pulumi.set(__self__, "version_consistency", version_consistency)
        if volumes_from is not None:
            pulumi.set(__self__, "volumes_from", volumes_from)
        if working_directory is not None:
            pulumi.set(__self__, "working_directory", working_directory)

    @_builtins.property
    @pulumi.getter
    def image(self) -> pulumi.Input[_builtins.str]:
        """
        The image used to start a container. This string is passed directly to the Docker daemon. By default, images in the Docker Hub registry are available. Other repositories are specified with either ``repository-url/image:tag`` or ``repository-url/image@digest``. For images using tags (repository-url/image:tag), up to 255 characters total are allowed, including letters (uppercase and lowercase), numbers, hyphens, underscores, colons, periods, forward slashes, and number signs (#). For images using digests (repository-url/image@digest), the 255 character limit applies only to the repository URL and image name (everything before the @ sign). The only supported hash function is sha256, and the hash value after sha256: must be exactly 64 characters (only letters A-F, a-f, and numbers 0-9 are allowed). This parameter maps to ``Image`` in the docker container create command and the ``IMAGE`` parameter of docker run.
          +  When a new task starts, the Amazon ECS container agent pulls the latest version of the specified image and tag for the container to use. However, subsequent updates to a repository image aren't propagated to already running tasks.
          +  Images in Amazon ECR repositories can be specified by either using the full ``registry/repository:tag`` or ``registry/repository@digest``. For example, ``012345678910.dkr.ecr.<region-name>.amazonaws.com/<repository-name>:latest`` or ``012345678910.dkr.ecr.<region-name>.amazonaws.com/<repository-name>@sha256:94afd1f2e64d908bc90dbca0035a5b567EXAMPLE``. 
          +  Images in official repositories on Docker Hub use a single name (for example, ``ubuntu`` or ``mongo``).
          +  Images in other repositories on Docker Hub are qualified with an organization name (for example, ``amazon/amazon-ecs-agent``).
          +  Images in other online repositories are qualified further by a domain name (for example, ``quay.io/assemblyline/ubuntu``).
        """
        return pulumi.get(self, "image")

    @image.setter
    def image(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "image", value)

    @_builtins.property
    @pulumi.getter
    def name(self) -> pulumi.Input[_builtins.str]:
        """
        The name of a container. If you're linking multiple containers together in a task definition, the ``name`` of one container can be entered in the ``links`` of another container to connect the containers. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed. This parameter maps to ``name`` in the docker container create command and the ``--name`` option to docker run.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "name", value)

    @_builtins.property
    @pulumi.getter
    def command(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The command that's passed to the container. This parameter maps to ``Cmd`` in the docker container create command and the ``COMMAND`` parameter to docker run. If there are multiple arguments, each argument is a separated string in the array.
        """
        return pulumi.get(self, "command")

    @command.setter
    def command(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "command", value)

    @_builtins.property
    @pulumi.getter
    def cpu(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The number of ``cpu`` units reserved for the container. This parameter maps to ``CpuShares`` in the docker container create command and the ``--cpu-shares`` option to docker run.
         This field is optional for tasks using the Fargate launch type, and the only requirement is that the total amount of CPU reserved for all containers within a task be lower than the task-level ``cpu`` value.
          You can determine the number of CPU units that are available per EC2 instance type by multiplying the vCPUs listed for that instance type on the [Amazon EC2 Instances](https://docs.aws.amazon.com/ec2/instance-types/) detail page by 1,024.
          Linux containers share unallocated CPU units with other containers on the container instance with the same ratio as their allocated amount. For example, if you run a single-container task on a single-core instance type with 512 CPU units specified for that container, and that's the only task running on the container instance, that container could use the full 1,024 CPU unit share at any given time. However, if you launched another copy of the same task on that container instance, each task is guaranteed a minimum of 512 CPU units when needed. Moreover, each container could float to higher CPU usage if the other container was not using it. If both tasks were 100% active all of the time, they would be limited to 512 CPU units.
         On Linux container instances, the Docker daemon on the container instance uses the CPU value to calculate the relative CPU share ratios for running containers. The minimum valid CPU share value that the Linux kernel allows is 2, and the maximum valid CPU share value that the Linux kernel allows is 262144. However, the CPU parameter isn't required, and you can use CPU values below 2 or above 262144 in your container definitions. For CPU values below 2 (including null) or above 262144, the behavior varies based on your Amazon ECS container agent version:
          +  *Agent versions less than or equal to 1.1.0:* Null and zero CPU values are passed to Docker as 0, which Docker then converts to 1,024 CPU shares. CPU values of 1 are passed to Docker as 1, which the Linux kernel converts to two CPU shares.
          +  *Agent versions greater than or equal to 1.2.0:* Null, zero, and CPU values of 1 are passed to Docker as 2.
          +  *Agent versions greater than or equal to 1.84.0:* CPU values greater than 256 vCPU are passed to Docker as 256, which is equivalent to 262144 CPU shares.
          
         On Windows container instances, the CPU limit is enforced as an absolute limit, or a quota. Windows containers only have access to the specified amount of CPU that's described in the task definition. A null or zero CPU value is passed to Docker as ``0``, which Windows interprets as 1% of one CPU.
        """
        return pulumi.get(self, "cpu")

    @cpu.setter
    def cpu(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "cpu", value)

    @_builtins.property
    @pulumi.getter(name="credentialSpecs")
    def credential_specs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        A list of ARNs in SSM or Amazon S3 to a credential spec (``CredSpec``) file that configures the container for Active Directory authentication. We recommend that you use this parameter instead of the ``dockerSecurityOptions``. The maximum number of ARNs is 1.
         There are two formats for each ARN.
          + credentialspecdomainless:MyARN You use credentialspecdomainless:MyARN to provide a CredSpec with an additional section for a secret in . You provide the login credentials to the domain in the secret. Each task that runs on any container instance can join different domains. You can use this format without joining the container instance to a domain. + credentialspec:MyARN You use credentialspec:MyARN to provide a CredSpec for a single domain. You must join the container instance to the domain before you start any tasks that use this task definition. 
         In both formats, replace ``MyARN`` with the ARN in SSM or Amazon S3.
         If you provide a ``credentialspecdomainless:MyARN``, the ``credspec`` must provide a ARN in ASMlong for a secret containing the username, password, and the domain to connect to. For better security, the instance isn't joined to the domain for domainless authentication. Other applications on the instance can't use the domainless credentials. You can use this parameter to run tasks on the same instance, even it the tasks need to join different domains. For more information, see [Using gMSAs for Windows Containers](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/windows-gmsa.html) and [Using gMSAs for Linux Containers](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/linux-gmsa.html).
        """
        return pulumi.get(self, "credential_specs")

    @credential_specs.setter
    def credential_specs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "credential_specs", value)

    @_builtins.property
    @pulumi.getter(name="dependsOn")
    def depends_on(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionContainerDependencyArgs']]]]:
        """
        The dependencies defined for container startup and shutdown. A container can contain multiple dependencies. When a dependency is defined for container startup, for container shutdown it is reversed.
         For tasks using the EC2 launch type, the container instances require at least version 1.26.0 of the container agent to turn on container dependencies. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see [Updating the Amazon ECS Container Agent](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-update.html) in the *Amazon Elastic Container Service Developer Guide*. If you're using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ``ecs-init`` package. If your container instances are launched from version ``20190301`` or later, then they contain the required versions of the container agent and ``ecs-init``. For more information, see [Amazon ECS-optimized Linux AMI](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html) in the *Amazon Elastic Container Service Developer Guide*.
         For tasks using the Fargate launch type, the task or service requires the following platforms:
          +  Linux platform version ``1.3.0`` or later.
          +  Windows platform version ``1.0.0`` or later.
          
         If the task definition is used in a blue/green deployment that uses [AWS::CodeDeploy::DeploymentGroup BlueGreenDeploymentConfiguration](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-codedeploy-deploymentgroup-bluegreendeploymentconfiguration.html), the ``dependsOn`` parameter is not supported.
        """
        return pulumi.get(self, "depends_on")

    @depends_on.setter
    def depends_on(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionContainerDependencyArgs']]]]):
        pulumi.set(self, "depends_on", value)

    @_builtins.property
    @pulumi.getter(name="disableNetworking")
    def disable_networking(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        When this parameter is true, networking is off within the container. This parameter maps to ``NetworkDisabled`` in the docker container create command.
          This parameter is not supported for Windows containers.
        """
        return pulumi.get(self, "disable_networking")

    @disable_networking.setter
    def disable_networking(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "disable_networking", value)

    @_builtins.property
    @pulumi.getter(name="dnsSearchDomains")
    def dns_search_domains(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        A list of DNS search domains that are presented to the container. This parameter maps to ``DnsSearch`` in the docker container create command and the ``--dns-search`` option to docker run.
          This parameter is not supported for Windows containers.
        """
        return pulumi.get(self, "dns_search_domains")

    @dns_search_domains.setter
    def dns_search_domains(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "dns_search_domains", value)

    @_builtins.property
    @pulumi.getter(name="dnsServers")
    def dns_servers(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        A list of DNS servers that are presented to the container. This parameter maps to ``Dns`` in the docker container create command and the ``--dns`` option to docker run.
          This parameter is not supported for Windows containers.
        """
        return pulumi.get(self, "dns_servers")

    @dns_servers.setter
    def dns_servers(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "dns_servers", value)

    @_builtins.property
    @pulumi.getter(name="dockerLabels")
    def docker_labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]:
        """
        A key/value map of labels to add to the container. This parameter maps to ``Labels`` in the docker container create command and the ``--label`` option to docker run. This parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
        """
        return pulumi.get(self, "docker_labels")

    @docker_labels.setter
    def docker_labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "docker_labels", value)

    @_builtins.property
    @pulumi.getter(name="dockerSecurityOptions")
    def docker_security_options(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        A list of strings to provide custom configuration for multiple security systems. This field isn't valid for containers in tasks using the Fargate launch type.
         For Linux tasks on EC2, this parameter can be used to reference custom labels for SELinux and AppArmor multi-level security systems.
         For any tasks on EC2, this parameter can be used to reference a credential spec file that configures a container for Active Directory authentication. For more information, see [Using gMSAs for Windows Containers](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/windows-gmsa.html) and [Using gMSAs for Linux Containers](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/linux-gmsa.html) in the *Amazon Elastic Container Service Developer Guide*.
         This parameter maps to ``SecurityOpt`` in the docker container create command and the ``--security-opt`` option to docker run.
          The Amazon ECS container agent running on a container instance must register with the ``ECS_SELINUX_CAPABLE=true`` or ``ECS_APPARMOR_CAPABLE=true`` environment variables before containers placed on that instance can use these security options. For more information, see [Amazon ECS Container Agent Configuration](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html) in the *Amazon Elastic Container Service Developer Guide*.
          Valid values: "no-new-privileges" | "apparmor:PROFILE" | "label:value" | "credentialspec:CredentialSpecFilePath"
        """
        return pulumi.get(self, "docker_security_options")

    @docker_security_options.setter
    def docker_security_options(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "docker_security_options", value)

    @_builtins.property
    @pulumi.getter(name="entryPoint")
    def entry_point(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        Early versions of the Amazon ECS container agent don't properly handle ``entryPoint`` parameters. If you have problems using ``entryPoint``, update your container agent or enter your commands and arguments as ``command`` array items instead.
          The entry point that's passed to the container. This parameter maps to ``Entrypoint`` in the docker container create command and the ``--entrypoint`` option to docker run.
        """
        return pulumi.get(self, "entry_point")

    @entry_point.setter
    def entry_point(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "entry_point", value)

    @_builtins.property
    @pulumi.getter
    def environment(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionKeyValuePairArgs']]]]:
        """
        The environment variables to pass to a container. This parameter maps to ``Env`` in the docker container create command and the ``--env`` option to docker run.
          We don't recommend that you use plaintext environment variables for sensitive information, such as credential data.
        """
        return pulumi.get(self, "environment")

    @environment.setter
    def environment(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionKeyValuePairArgs']]]]):
        pulumi.set(self, "environment", value)

    @_builtins.property
    @pulumi.getter(name="environmentFiles")
    def environment_files(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionEnvironmentFileArgs']]]]:
        """
        A list of files containing the environment variables to pass to a container. This parameter maps to the ``--env-file`` option to docker run.
         You can specify up to ten environment files. The file must have a ``.env`` file extension. Each line in an environment file contains an environment variable in ``VARIABLE=VALUE`` format. Lines beginning with ``#`` are treated as comments and are ignored.
         If there are environment variables specified using the ``environment`` parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they're processed from the top down. We recommend that you use unique variable names. For more information, see [Specifying Environment Variables](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/taskdef-envfiles.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        return pulumi.get(self, "environment_files")

    @environment_files.setter
    def environment_files(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionEnvironmentFileArgs']]]]):
        pulumi.set(self, "environment_files", value)

    @_builtins.property
    @pulumi.getter
    def essential(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        If the ``essential`` parameter of a container is marked as ``true``, and that container fails or stops for any reason, all other containers that are part of the task are stopped. If the ``essential`` parameter of a container is marked as ``false``, its failure doesn't affect the rest of the containers in a task. If this parameter is omitted, a container is assumed to be essential.
         All tasks must have at least one essential container. If you have an application that's composed of multiple containers, group containers that are used for a common purpose into components, and separate the different components into multiple task definitions. For more information, see [Application Architecture](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/application_architecture.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        return pulumi.get(self, "essential")

    @essential.setter
    def essential(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "essential", value)

    @_builtins.property
    @pulumi.getter(name="extraHosts")
    def extra_hosts(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionHostEntryArgs']]]]:
        """
        A list of hostnames and IP address mappings to append to the ``/etc/hosts`` file on the container. This parameter maps to ``ExtraHosts`` in the docker container create command and the ``--add-host`` option to docker run.
          This parameter isn't supported for Windows containers or tasks that use the ``awsvpc`` network mode.
        """
        return pulumi.get(self, "extra_hosts")

    @extra_hosts.setter
    def extra_hosts(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionHostEntryArgs']]]]):
        pulumi.set(self, "extra_hosts", value)

    @_builtins.property
    @pulumi.getter(name="firelensConfiguration")
    def firelens_configuration(self) -> Optional[pulumi.Input['TaskDefinitionFirelensConfigurationArgs']]:
        """
        The FireLens configuration for the container. This is used to specify and configure a log router for container logs. For more information, see [Custom Log Routing](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_firelens.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        return pulumi.get(self, "firelens_configuration")

    @firelens_configuration.setter
    def firelens_configuration(self, value: Optional[pulumi.Input['TaskDefinitionFirelensConfigurationArgs']]):
        pulumi.set(self, "firelens_configuration", value)

    @_builtins.property
    @pulumi.getter(name="healthCheck")
    def health_check(self) -> Optional[pulumi.Input['TaskDefinitionHealthCheckArgs']]:
        """
        The container health check command and associated configuration parameters for the container. This parameter maps to ``HealthCheck`` in the docker container create command and the ``HEALTHCHECK`` parameter of docker run.
        """
        return pulumi.get(self, "health_check")

    @health_check.setter
    def health_check(self, value: Optional[pulumi.Input['TaskDefinitionHealthCheckArgs']]):
        pulumi.set(self, "health_check", value)

    @_builtins.property
    @pulumi.getter
    def hostname(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The hostname to use for your container. This parameter maps to ``Hostname`` in the docker container create command and the ``--hostname`` option to docker run.
          The ``hostname`` parameter is not supported if you're using the ``awsvpc`` network mode.
        """
        return pulumi.get(self, "hostname")

    @hostname.setter
    def hostname(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "hostname", value)

    @_builtins.property
    @pulumi.getter
    def interactive(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        When this parameter is ``true``, you can deploy containerized applications that require ``stdin`` or a ``tty`` to be allocated. This parameter maps to ``OpenStdin`` in the docker container create command and the ``--interactive`` option to docker run.
        """
        return pulumi.get(self, "interactive")

    @interactive.setter
    def interactive(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "interactive", value)

    @_builtins.property
    @pulumi.getter
    def links(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The ``links`` parameter allows containers to communicate with each other without the need for port mappings. This parameter is only supported if the network mode of a task definition is ``bridge``. The ``name:internalName`` construct is analogous to ``name:alias`` in Docker links. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed.. This parameter maps to ``Links`` in the docker container create command and the ``--link`` option to docker run.
          This parameter is not supported for Windows containers.
           Containers that are collocated on a single container instance may be able to communicate with each other without requiring links or host port mappings. Network isolation is achieved on the container instance using security groups and VPC settings.
        """
        return pulumi.get(self, "links")

    @links.setter
    def links(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "links", value)

    @_builtins.property
    @pulumi.getter(name="linuxParameters")
    def linux_parameters(self) -> Optional[pulumi.Input['TaskDefinitionLinuxParametersArgs']]:
        """
        Linux-specific modifications that are applied to the container, such as Linux kernel capabilities. For more information see [KernelCapabilities](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_KernelCapabilities.html).
          This parameter is not supported for Windows containers.
        """
        return pulumi.get(self, "linux_parameters")

    @linux_parameters.setter
    def linux_parameters(self, value: Optional[pulumi.Input['TaskDefinitionLinuxParametersArgs']]):
        pulumi.set(self, "linux_parameters", value)

    @_builtins.property
    @pulumi.getter(name="logConfiguration")
    def log_configuration(self) -> Optional[pulumi.Input['TaskDefinitionLogConfigurationArgs']]:
        """
        The log configuration specification for the container.
         This parameter maps to ``LogConfig`` in the docker Create a container command and the ``--log-driver`` option to docker run. By default, containers use the same logging driver that the Docker daemon uses. However, the container may use a different logging driver than the Docker daemon by specifying a log driver with this parameter in the container definition. To use a different logging driver for a container, the log system must be configured properly on the container instance (or on a different log server for remote logging options). For more information on the options for different supported log drivers, see [Configure logging drivers](https://docs.aws.amazon.com/https://docs.docker.com/engine/admin/logging/overview/) in the Docker documentation.
          Amazon ECS currently supports a subset of the logging drivers available to the Docker daemon (shown in the [LogConfiguration](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_LogConfiguration.html) data type). Additional log drivers may be available in future releases of the Amazon ECS container agent.
          This parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
          The Amazon ECS container agent running on a container instance must register the logging drivers available on that instance with the ``ECS_AVAILABLE_LOGGING_DRIVERS`` environment variable before containers placed on that instance can use these log configuration options. For more information, see [Container Agent Configuration](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html) in the *Developer Guide*.
        """
        return pulumi.get(self, "log_configuration")

    @log_configuration.setter
    def log_configuration(self, value: Optional[pulumi.Input['TaskDefinitionLogConfigurationArgs']]):
        pulumi.set(self, "log_configuration", value)

    @_builtins.property
    @pulumi.getter
    def memory(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The amount (in MiB) of memory to present to the container. If your container attempts to exceed the memory specified here, the container is killed. The total amount of memory reserved for all containers within a task must be lower than the task ``memory`` value, if one is specified. This parameter maps to ``Memory`` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/#operation/ContainerCreate) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/) and the ``--memory`` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/#security-configuration).
         If using the Fargate launch type, this parameter is optional.
         If using the EC2 launch type, you must specify either a task-level memory value or a container-level memory value. If you specify both a container-level ``memory`` and ``memoryReservation`` value, ``memory`` must be greater than ``memoryReservation``. If you specify ``memoryReservation``, then that value is subtracted from the available memory resources for the container instance where the container is placed. Otherwise, the value of ``memory`` is used.
         The Docker 20.10.0 or later daemon reserves a minimum of 6 MiB of memory for a container, so you should not specify fewer than 6 MiB of memory for your containers.
         The Docker 19.03.13-ce or earlier daemon reserves a minimum of 4 MiB of memory for a container, so you should not specify fewer than 4 MiB of memory for your containers.
        """
        return pulumi.get(self, "memory")

    @memory.setter
    def memory(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "memory", value)

    @_builtins.property
    @pulumi.getter(name="memoryReservation")
    def memory_reservation(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The soft limit (in MiB) of memory to reserve for the container. When system memory is under heavy contention, Docker attempts to keep the container memory to this soft limit. However, your container can consume more memory when it needs to, up to either the hard limit specified with the ``memory`` parameter (if applicable), or all of the available memory on the container instance, whichever comes first. This parameter maps to ``MemoryReservation`` in the docker container create command and the ``--memory-reservation`` option to docker run.
         If a task-level memory value is not specified, you must specify a non-zero integer for one or both of ``memory`` or ``memoryReservation`` in a container definition. If you specify both, ``memory`` must be greater than ``memoryReservation``. If you specify ``memoryReservation``, then that value is subtracted from the available memory resources for the container instance where the container is placed. Otherwise, the value of ``memory`` is used.
         For example, if your container normally uses 128 MiB of memory, but occasionally bursts to 256 MiB of memory for short periods of time, you can set a ``memoryReservation`` of 128 MiB, and a ``memory`` hard limit of 300 MiB. This configuration would allow the container to only reserve 128 MiB of memory from the remaining resources on the container instance, but also allow the container to consume more memory resources when needed.
         The Docker 20.10.0 or later daemon reserves a minimum of 6 MiB of memory for a container. So, don't specify less than 6 MiB of memory for your containers. 
         The Docker 19.03.13-ce or earlier daemon reserves a minimum of 4 MiB of memory for a container. So, don't specify less than 4 MiB of memory for your containers.
        """
        return pulumi.get(self, "memory_reservation")

    @memory_reservation.setter
    def memory_reservation(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "memory_reservation", value)

    @_builtins.property
    @pulumi.getter(name="mountPoints")
    def mount_points(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionMountPointArgs']]]]:
        """
        The mount points for data volumes in your container.
         This parameter maps to ``Volumes`` in the docker container create command and the ``--volume`` option to docker run.
         Windows containers can mount whole directories on the same drive as ``$env:ProgramData``. Windows containers can't mount directories on a different drive, and mount point can't be across drives.
        """
        return pulumi.get(self, "mount_points")

    @mount_points.setter
    def mount_points(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionMountPointArgs']]]]):
        pulumi.set(self, "mount_points", value)

    @_builtins.property
    @pulumi.getter(name="portMappings")
    def port_mappings(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionPortMappingArgs']]]]:
        """
        The list of port mappings for the container. Port mappings allow containers to access ports on the host container instance to send or receive traffic.
         For task definitions that use the ``awsvpc`` network mode, you should only specify the ``containerPort``. The ``hostPort`` can be left blank or it must be the same value as the ``containerPort``.
         Port mappings on Windows use the ``NetNAT`` gateway address rather than ``localhost``. There is no loopback for port mappings on Windows, so you cannot access a container's mapped port from the host itself. 
         This parameter maps to ``PortBindings`` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/#operation/ContainerCreate) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/) and the ``--publish`` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/). If the network mode of a task definition is set to ``none``, then you can't specify port mappings. If the network mode of a task definition is set to ``host``, then host ports must either be undefined or they must match the container port in the port mapping.
          After a task reaches the ``RUNNING`` status, manual and automatic host and container port assignments are visible in the *Network Bindings* section of a container description for a selected task in the Amazon ECS console. The assignments are also visible in the ``networkBindings`` section [DescribeTasks](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DescribeTasks.html) responses.
        """
        return pulumi.get(self, "port_mappings")

    @port_mappings.setter
    def port_mappings(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionPortMappingArgs']]]]):
        pulumi.set(self, "port_mappings", value)

    @_builtins.property
    @pulumi.getter
    def privileged(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        When this parameter is true, the container is given elevated privileges on the host container instance (similar to the ``root`` user). This parameter maps to ``Privileged`` in the docker container create command and the ``--privileged`` option to docker run
          This parameter is not supported for Windows containers or tasks run on FARGATElong.
        """
        return pulumi.get(self, "privileged")

    @privileged.setter
    def privileged(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "privileged", value)

    @_builtins.property
    @pulumi.getter(name="pseudoTerminal")
    def pseudo_terminal(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        When this parameter is ``true``, a TTY is allocated. This parameter maps to ``Tty`` in the docker container create command and the ``--tty`` option to docker run.
        """
        return pulumi.get(self, "pseudo_terminal")

    @pseudo_terminal.setter
    def pseudo_terminal(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "pseudo_terminal", value)

    @_builtins.property
    @pulumi.getter(name="readonlyRootFilesystem")
    def readonly_root_filesystem(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        When this parameter is true, the container is given read-only access to its root file system. This parameter maps to ``ReadonlyRootfs`` in the docker container create command and the ``--read-only`` option to docker run.
          This parameter is not supported for Windows containers.
        """
        return pulumi.get(self, "readonly_root_filesystem")

    @readonly_root_filesystem.setter
    def readonly_root_filesystem(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "readonly_root_filesystem", value)

    @_builtins.property
    @pulumi.getter(name="repositoryCredentials")
    def repository_credentials(self) -> Optional[pulumi.Input['TaskDefinitionRepositoryCredentialsArgs']]:
        """
        The private repository authentication credentials to use.
        """
        return pulumi.get(self, "repository_credentials")

    @repository_credentials.setter
    def repository_credentials(self, value: Optional[pulumi.Input['TaskDefinitionRepositoryCredentialsArgs']]):
        pulumi.set(self, "repository_credentials", value)

    @_builtins.property
    @pulumi.getter(name="resourceRequirements")
    def resource_requirements(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionResourceRequirementArgs']]]]:
        """
        The type and amount of a resource to assign to a container. The only supported resource is a GPU.
        """
        return pulumi.get(self, "resource_requirements")

    @resource_requirements.setter
    def resource_requirements(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionResourceRequirementArgs']]]]):
        pulumi.set(self, "resource_requirements", value)

    @_builtins.property
    @pulumi.getter(name="restartPolicy")
    def restart_policy(self) -> Optional[pulumi.Input['TaskDefinitionRestartPolicyArgs']]:
        """
        The restart policy for a container. When you set up a restart policy, Amazon ECS can restart the container without needing to replace the task. For more information, see [Restart individual containers in Amazon ECS tasks with container restart policies](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/container-restart-policy.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        return pulumi.get(self, "restart_policy")

    @restart_policy.setter
    def restart_policy(self, value: Optional[pulumi.Input['TaskDefinitionRestartPolicyArgs']]):
        pulumi.set(self, "restart_policy", value)

    @_builtins.property
    @pulumi.getter
    def secrets(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionSecretArgs']]]]:
        """
        The secrets to pass to the container. For more information, see [Specifying Sensitive Data](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        return pulumi.get(self, "secrets")

    @secrets.setter
    def secrets(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionSecretArgs']]]]):
        pulumi.set(self, "secrets", value)

    @_builtins.property
    @pulumi.getter(name="startTimeout")
    def start_timeout(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        Time duration (in seconds) to wait before giving up on resolving dependencies for a container. For example, you specify two containers in a task definition with containerA having a dependency on containerB reaching a ``COMPLETE``, ``SUCCESS``, or ``HEALTHY`` status. If a ``startTimeout`` value is specified for containerB and it doesn't reach the desired status within that time then containerA gives up and not start. This results in the task transitioning to a ``STOPPED`` state.
          When the ``ECS_CONTAINER_START_TIMEOUT`` container agent configuration variable is used, it's enforced independently from this start timeout value.
          For tasks using the Fargate launch type, the task or service requires the following platforms:
          +  Linux platform version ``1.3.0`` or later.
          +  Windows platform version ``1.0.0`` or later.
          
         For tasks using the EC2 launch type, your container instances require at least version ``1.26.0`` of the container agent to use a container start timeout value. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see [Updating the Amazon ECS Container Agent](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-update.html) in the *Amazon Elastic Container Service Developer Guide*. If you're using an Amazon ECS-optimized Linux AMI, your instance needs at least version ``1.26.0-1`` of the ``ecs-init`` package. If your container instances are launched from version ``20190301`` or later, then they contain the required versions of the container agent and ``ecs-init``. For more information, see [Amazon ECS-optimized Linux AMI](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html) in the *Amazon Elastic Container Service Developer Guide*.
         The valid values for Fargate are 2-120 seconds.
        """
        return pulumi.get(self, "start_timeout")

    @start_timeout.setter
    def start_timeout(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "start_timeout", value)

    @_builtins.property
    @pulumi.getter(name="stopTimeout")
    def stop_timeout(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        Time duration (in seconds) to wait before the container is forcefully killed if it doesn't exit normally on its own.
         For tasks using the Fargate launch type, the task or service requires the following platforms:
          +  Linux platform version ``1.3.0`` or later.
          +  Windows platform version ``1.0.0`` or later.
          
         For tasks that use the Fargate launch type, the max stop timeout value is 120 seconds and if the parameter is not specified, the default value of 30 seconds is used.
         For tasks that use the EC2 launch type, if the ``stopTimeout`` parameter isn't specified, the value set for the Amazon ECS container agent configuration variable ``ECS_CONTAINER_STOP_TIMEOUT`` is used. If neither the ``stopTimeout`` parameter or the ``ECS_CONTAINER_STOP_TIMEOUT`` agent configuration variable are set, then the default values of 30 seconds for Linux containers and 30 seconds on Windows containers are used. Your container instances require at least version 1.26.0 of the container agent to use a container stop timeout value. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see [Updating the Amazon ECS Container Agent](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-update.html) in the *Amazon Elastic Container Service Developer Guide*. If you're using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ``ecs-init`` package. If your container instances are launched from version ``20190301`` or later, then they contain the required versions of the container agent and ``ecs-init``. For more information, see [Amazon ECS-optimized Linux AMI](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html) in the *Amazon Elastic Container Service Developer Guide*.
         The valid values for Fargate are 2-120 seconds.
        """
        return pulumi.get(self, "stop_timeout")

    @stop_timeout.setter
    def stop_timeout(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "stop_timeout", value)

    @_builtins.property
    @pulumi.getter(name="systemControls")
    def system_controls(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionSystemControlArgs']]]]:
        """
        A list of namespaced kernel parameters to set in the container. This parameter maps to ``Sysctls`` in the docker container create command and the ``--sysctl`` option to docker run. For example, you can configure ``net.ipv4.tcp_keepalive_time`` setting to maintain longer lived connections.
        """
        return pulumi.get(self, "system_controls")

    @system_controls.setter
    def system_controls(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionSystemControlArgs']]]]):
        pulumi.set(self, "system_controls", value)

    @_builtins.property
    @pulumi.getter
    def ulimits(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionUlimitArgs']]]]:
        """
        A list of ``ulimits`` to set in the container. This parameter maps to ``Ulimits`` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/#operation/ContainerCreate) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/) and the ``--ulimit`` option to [docker run](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/run/). Valid naming values are displayed in the [Ulimit](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_Ulimit.html) data type. This parameter requires version 1.18 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
          This parameter is not supported for Windows containers.
        """
        return pulumi.get(self, "ulimits")

    @ulimits.setter
    def ulimits(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionUlimitArgs']]]]):
        pulumi.set(self, "ulimits", value)

    @_builtins.property
    @pulumi.getter
    def user(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The user to use inside the container. This parameter maps to ``User`` in the docker container create command and the ``--user`` option to docker run.
          When running tasks using the ``host`` network mode, don't run containers using the root user (UID 0). We recommend using a non-root user for better security.
          You can specify the ``user`` using the following formats. If specifying a UID or GID, you must specify it as a positive integer.
          +   ``user`` 
          +   ``user:group`` 
          +   ``uid`` 
          +   ``uid:gid`` 
          +   ``user:gid`` 
          +   ``uid:group`` 
          
          This parameter is not supported for Windows containers.
        """
        return pulumi.get(self, "user")

    @user.setter
    def user(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "user", value)

    @_builtins.property
    @pulumi.getter(name="versionConsistency")
    def version_consistency(self) -> Optional[pulumi.Input['TaskDefinitionContainerDefinitionVersionConsistency']]:
        """
        Specifies whether Amazon ECS will resolve the container image tag provided in the container definition to an image digest. By default, the value is ``enabled``. If you set the value for a container as ``disabled``, Amazon ECS will not resolve the provided container image tag to a digest and will use the original image URI specified in the container definition for deployment. For more information about container image resolution, see [Container image resolution](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-ecs.html#deployment-container-image-stability) in the *Amazon ECS Developer Guide*.
        """
        return pulumi.get(self, "version_consistency")

    @version_consistency.setter
    def version_consistency(self, value: Optional[pulumi.Input['TaskDefinitionContainerDefinitionVersionConsistency']]):
        pulumi.set(self, "version_consistency", value)

    @_builtins.property
    @pulumi.getter(name="volumesFrom")
    def volumes_from(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionVolumeFromArgs']]]]:
        """
        Data volumes to mount from another container. This parameter maps to ``VolumesFrom`` in the docker container create command and the ``--volumes-from`` option to docker run.
        """
        return pulumi.get(self, "volumes_from")

    @volumes_from.setter
    def volumes_from(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionVolumeFromArgs']]]]):
        pulumi.set(self, "volumes_from", value)

    @_builtins.property
    @pulumi.getter(name="workingDirectory")
    def working_directory(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The working directory to run commands inside the container in. This parameter maps to ``WorkingDir`` in the docker container create command and the ``--workdir`` option to docker run.
        """
        return pulumi.get(self, "working_directory")

    @working_directory.setter
    def working_directory(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "working_directory", value)


if not MYPY:
    class TaskDefinitionContainerDependencyArgsDict(TypedDict):
        """
        The ``ContainerDependency`` property specifies the dependencies defined for container startup and shutdown. A container can contain multiple dependencies. When a dependency is defined for container startup, for container shutdown it is reversed.
         Your Amazon ECS container instances require at least version 1.26.0 of the container agent to enable container dependencies. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see [Updating the Amazon ECS Container Agent](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-update.html) in the *Amazon Elastic Container Service Developer Guide*. If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ``ecs-init`` package. If your container instances are launched from version ``20190301`` or later, then they contain the required versions of the container agent and ``ecs-init``. For more information, see [Amazon ECS-optimized Linux AMI](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html) in the *Amazon Elastic Container Service Developer Guide*.
          For tasks using the Fargate launch type, this parameter requires that the task or service uses platform version 1.3.0 or later.
        """
        condition: NotRequired[pulumi.Input[_builtins.str]]
        """
        The dependency condition of the container. The following are the available conditions and their behavior:
          +  ``START`` - This condition emulates the behavior of links and volumes today. It validates that a dependent container is started before permitting other containers to start.
          +  ``COMPLETE`` - This condition validates that a dependent container runs to completion (exits) before permitting other containers to start. This can be useful for nonessential containers that run a script and then exit. This condition can't be set on an essential container.
          +  ``SUCCESS`` - This condition is the same as ``COMPLETE``, but it also requires that the container exits with a ``zero`` status. This condition can't be set on an essential container.
          +  ``HEALTHY`` - This condition validates that the dependent container passes its Docker health check before permitting other containers to start. This requires that the dependent container has health checks configured. This condition is confirmed only at task startup.
        """
        container_name: NotRequired[pulumi.Input[_builtins.str]]
        """
        The name of a container.
        """
elif False:
    TaskDefinitionContainerDependencyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionContainerDependencyArgs:
    def __init__(__self__, *,
                 condition: Optional[pulumi.Input[_builtins.str]] = None,
                 container_name: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The ``ContainerDependency`` property specifies the dependencies defined for container startup and shutdown. A container can contain multiple dependencies. When a dependency is defined for container startup, for container shutdown it is reversed.
         Your Amazon ECS container instances require at least version 1.26.0 of the container agent to enable container dependencies. However, we recommend using the latest container agent version. For information about checking your agent version and updating to the latest version, see [Updating the Amazon ECS Container Agent](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-update.html) in the *Amazon Elastic Container Service Developer Guide*. If you are using an Amazon ECS-optimized Linux AMI, your instance needs at least version 1.26.0-1 of the ``ecs-init`` package. If your container instances are launched from version ``20190301`` or later, then they contain the required versions of the container agent and ``ecs-init``. For more information, see [Amazon ECS-optimized Linux AMI](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html) in the *Amazon Elastic Container Service Developer Guide*.
          For tasks using the Fargate launch type, this parameter requires that the task or service uses platform version 1.3.0 or later.
        :param pulumi.Input[_builtins.str] condition: The dependency condition of the container. The following are the available conditions and their behavior:
                 +  ``START`` - This condition emulates the behavior of links and volumes today. It validates that a dependent container is started before permitting other containers to start.
                 +  ``COMPLETE`` - This condition validates that a dependent container runs to completion (exits) before permitting other containers to start. This can be useful for nonessential containers that run a script and then exit. This condition can't be set on an essential container.
                 +  ``SUCCESS`` - This condition is the same as ``COMPLETE``, but it also requires that the container exits with a ``zero`` status. This condition can't be set on an essential container.
                 +  ``HEALTHY`` - This condition validates that the dependent container passes its Docker health check before permitting other containers to start. This requires that the dependent container has health checks configured. This condition is confirmed only at task startup.
        :param pulumi.Input[_builtins.str] container_name: The name of a container.
        """
        if condition is not None:
            pulumi.set(__self__, "condition", condition)
        if container_name is not None:
            pulumi.set(__self__, "container_name", container_name)

    @_builtins.property
    @pulumi.getter
    def condition(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The dependency condition of the container. The following are the available conditions and their behavior:
          +  ``START`` - This condition emulates the behavior of links and volumes today. It validates that a dependent container is started before permitting other containers to start.
          +  ``COMPLETE`` - This condition validates that a dependent container runs to completion (exits) before permitting other containers to start. This can be useful for nonessential containers that run a script and then exit. This condition can't be set on an essential container.
          +  ``SUCCESS`` - This condition is the same as ``COMPLETE``, but it also requires that the container exits with a ``zero`` status. This condition can't be set on an essential container.
          +  ``HEALTHY`` - This condition validates that the dependent container passes its Docker health check before permitting other containers to start. This requires that the dependent container has health checks configured. This condition is confirmed only at task startup.
        """
        return pulumi.get(self, "condition")

    @condition.setter
    def condition(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "condition", value)

    @_builtins.property
    @pulumi.getter(name="containerName")
    def container_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The name of a container.
        """
        return pulumi.get(self, "container_name")

    @container_name.setter
    def container_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "container_name", value)


if not MYPY:
    class TaskDefinitionDeviceArgsDict(TypedDict):
        """
        The ``Device`` property specifies an object representing a container instance host device.
        """
        container_path: NotRequired[pulumi.Input[_builtins.str]]
        """
        The path inside the container at which to expose the host device.
        """
        host_path: NotRequired[pulumi.Input[_builtins.str]]
        """
        The path for the device on the host container instance.
        """
        permissions: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The explicit permissions to provide to the container for the device. By default, the container has permissions for ``read``, ``write``, and ``mknod`` for the device.
        """
elif False:
    TaskDefinitionDeviceArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionDeviceArgs:
    def __init__(__self__, *,
                 container_path: Optional[pulumi.Input[_builtins.str]] = None,
                 host_path: Optional[pulumi.Input[_builtins.str]] = None,
                 permissions: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None):
        """
        The ``Device`` property specifies an object representing a container instance host device.
        :param pulumi.Input[_builtins.str] container_path: The path inside the container at which to expose the host device.
        :param pulumi.Input[_builtins.str] host_path: The path for the device on the host container instance.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] permissions: The explicit permissions to provide to the container for the device. By default, the container has permissions for ``read``, ``write``, and ``mknod`` for the device.
        """
        if container_path is not None:
            pulumi.set(__self__, "container_path", container_path)
        if host_path is not None:
            pulumi.set(__self__, "host_path", host_path)
        if permissions is not None:
            pulumi.set(__self__, "permissions", permissions)

    @_builtins.property
    @pulumi.getter(name="containerPath")
    def container_path(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The path inside the container at which to expose the host device.
        """
        return pulumi.get(self, "container_path")

    @container_path.setter
    def container_path(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "container_path", value)

    @_builtins.property
    @pulumi.getter(name="hostPath")
    def host_path(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The path for the device on the host container instance.
        """
        return pulumi.get(self, "host_path")

    @host_path.setter
    def host_path(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "host_path", value)

    @_builtins.property
    @pulumi.getter
    def permissions(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The explicit permissions to provide to the container for the device. By default, the container has permissions for ``read``, ``write``, and ``mknod`` for the device.
        """
        return pulumi.get(self, "permissions")

    @permissions.setter
    def permissions(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "permissions", value)


if not MYPY:
    class TaskDefinitionDockerVolumeConfigurationArgsDict(TypedDict):
        """
        The ``DockerVolumeConfiguration`` property specifies a Docker volume configuration and is used when you use Docker volumes. Docker volumes are only supported when you are using the EC2 launch type. Windows containers only support the use of the ``local`` driver. To use bind mounts, specify a ``host`` instead.
        """
        autoprovision: NotRequired[pulumi.Input[_builtins.bool]]
        """
        If this value is ``true``, the Docker volume is created if it doesn't already exist.
          This field is only used if the ``scope`` is ``shared``.
        """
        driver: NotRequired[pulumi.Input[_builtins.str]]
        """
        The Docker volume driver to use. The driver value must match the driver name provided by Docker because it is used for task placement. If the driver was installed using the Docker plugin CLI, use ``docker plugin ls`` to retrieve the driver name from your container instance. If the driver was installed using another method, use Docker plugin discovery to retrieve the driver name. This parameter maps to ``Driver`` in the docker container create command and the ``xxdriver`` option to docker volume create.
        """
        driver_opts: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]
        """
        A map of Docker driver-specific options passed through. This parameter maps to ``DriverOpts`` in the docker create-volume command and the ``xxopt`` option to docker volume create.
        """
        labels: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]
        """
        Custom metadata to add to your Docker volume. This parameter maps to ``Labels`` in the docker container create command and the ``xxlabel`` option to docker volume create.
        """
        scope: NotRequired[pulumi.Input[_builtins.str]]
        """
        The scope for the Docker volume that determines its lifecycle. Docker volumes that are scoped to a ``task`` are automatically provisioned when the task starts and destroyed when the task stops. Docker volumes that are scoped as ``shared`` persist after the task stops.
        """
elif False:
    TaskDefinitionDockerVolumeConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionDockerVolumeConfigurationArgs:
    def __init__(__self__, *,
                 autoprovision: Optional[pulumi.Input[_builtins.bool]] = None,
                 driver: Optional[pulumi.Input[_builtins.str]] = None,
                 driver_opts: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]] = None,
                 scope: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The ``DockerVolumeConfiguration`` property specifies a Docker volume configuration and is used when you use Docker volumes. Docker volumes are only supported when you are using the EC2 launch type. Windows containers only support the use of the ``local`` driver. To use bind mounts, specify a ``host`` instead.
        :param pulumi.Input[_builtins.bool] autoprovision: If this value is ``true``, the Docker volume is created if it doesn't already exist.
                 This field is only used if the ``scope`` is ``shared``.
        :param pulumi.Input[_builtins.str] driver: The Docker volume driver to use. The driver value must match the driver name provided by Docker because it is used for task placement. If the driver was installed using the Docker plugin CLI, use ``docker plugin ls`` to retrieve the driver name from your container instance. If the driver was installed using another method, use Docker plugin discovery to retrieve the driver name. This parameter maps to ``Driver`` in the docker container create command and the ``xxdriver`` option to docker volume create.
        :param pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]] driver_opts: A map of Docker driver-specific options passed through. This parameter maps to ``DriverOpts`` in the docker create-volume command and the ``xxopt`` option to docker volume create.
        :param pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]] labels: Custom metadata to add to your Docker volume. This parameter maps to ``Labels`` in the docker container create command and the ``xxlabel`` option to docker volume create.
        :param pulumi.Input[_builtins.str] scope: The scope for the Docker volume that determines its lifecycle. Docker volumes that are scoped to a ``task`` are automatically provisioned when the task starts and destroyed when the task stops. Docker volumes that are scoped as ``shared`` persist after the task stops.
        """
        if autoprovision is not None:
            pulumi.set(__self__, "autoprovision", autoprovision)
        if driver is not None:
            pulumi.set(__self__, "driver", driver)
        if driver_opts is not None:
            pulumi.set(__self__, "driver_opts", driver_opts)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if scope is not None:
            pulumi.set(__self__, "scope", scope)

    @_builtins.property
    @pulumi.getter
    def autoprovision(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        If this value is ``true``, the Docker volume is created if it doesn't already exist.
          This field is only used if the ``scope`` is ``shared``.
        """
        return pulumi.get(self, "autoprovision")

    @autoprovision.setter
    def autoprovision(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "autoprovision", value)

    @_builtins.property
    @pulumi.getter
    def driver(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The Docker volume driver to use. The driver value must match the driver name provided by Docker because it is used for task placement. If the driver was installed using the Docker plugin CLI, use ``docker plugin ls`` to retrieve the driver name from your container instance. If the driver was installed using another method, use Docker plugin discovery to retrieve the driver name. This parameter maps to ``Driver`` in the docker container create command and the ``xxdriver`` option to docker volume create.
        """
        return pulumi.get(self, "driver")

    @driver.setter
    def driver(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "driver", value)

    @_builtins.property
    @pulumi.getter(name="driverOpts")
    def driver_opts(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]:
        """
        A map of Docker driver-specific options passed through. This parameter maps to ``DriverOpts`` in the docker create-volume command and the ``xxopt`` option to docker volume create.
        """
        return pulumi.get(self, "driver_opts")

    @driver_opts.setter
    def driver_opts(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "driver_opts", value)

    @_builtins.property
    @pulumi.getter
    def labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]:
        """
        Custom metadata to add to your Docker volume. This parameter maps to ``Labels`` in the docker container create command and the ``xxlabel`` option to docker volume create.
        """
        return pulumi.get(self, "labels")

    @labels.setter
    def labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "labels", value)

    @_builtins.property
    @pulumi.getter
    def scope(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The scope for the Docker volume that determines its lifecycle. Docker volumes that are scoped to a ``task`` are automatically provisioned when the task starts and destroyed when the task stops. Docker volumes that are scoped as ``shared`` persist after the task stops.
        """
        return pulumi.get(self, "scope")

    @scope.setter
    def scope(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "scope", value)


if not MYPY:
    class TaskDefinitionEfsVolumeConfigurationArgsDict(TypedDict):
        """
        This parameter is specified when you're using an Amazon Elastic File System file system for task storage. For more information, see [Amazon EFS volumes](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/efs-volumes.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        filesystem_id: pulumi.Input[_builtins.str]
        """
        The Amazon EFS file system ID to use.
        """
        authorization_config: NotRequired[pulumi.Input['TaskDefinitionAuthorizationConfigArgsDict']]
        """
        The authorization configuration details for the Amazon EFS file system.
        """
        root_directory: NotRequired[pulumi.Input[_builtins.str]]
        """
        The directory within the Amazon EFS file system to mount as the root directory inside the host. If this parameter is omitted, the root of the Amazon EFS volume will be used. Specifying ``/`` will have the same effect as omitting this parameter.
          If an EFS access point is specified in the ``authorizationConfig``, the root directory parameter must either be omitted or set to ``/`` which will enforce the path set on the EFS access point.
        """
        transit_encryption: NotRequired[pulumi.Input['TaskDefinitionEfsVolumeConfigurationTransitEncryption']]
        """
        Determines whether to use encryption for Amazon EFS data in transit between the Amazon ECS host and the Amazon EFS server. Transit encryption must be turned on if Amazon EFS IAM authorization is used. If this parameter is omitted, the default value of ``DISABLED`` is used. For more information, see [Encrypting data in transit](https://docs.aws.amazon.com/efs/latest/ug/encryption-in-transit.html) in the *Amazon Elastic File System User Guide*.
        """
        transit_encryption_port: NotRequired[pulumi.Input[_builtins.int]]
        """
        The port to use when sending encrypted data between the Amazon ECS host and the Amazon EFS server. If you do not specify a transit encryption port, it will use the port selection strategy that the Amazon EFS mount helper uses. For more information, see [EFS mount helper](https://docs.aws.amazon.com/efs/latest/ug/efs-mount-helper.html) in the *Amazon Elastic File System User Guide*.
        """
elif False:
    TaskDefinitionEfsVolumeConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionEfsVolumeConfigurationArgs:
    def __init__(__self__, *,
                 filesystem_id: pulumi.Input[_builtins.str],
                 authorization_config: Optional[pulumi.Input['TaskDefinitionAuthorizationConfigArgs']] = None,
                 root_directory: Optional[pulumi.Input[_builtins.str]] = None,
                 transit_encryption: Optional[pulumi.Input['TaskDefinitionEfsVolumeConfigurationTransitEncryption']] = None,
                 transit_encryption_port: Optional[pulumi.Input[_builtins.int]] = None):
        """
        This parameter is specified when you're using an Amazon Elastic File System file system for task storage. For more information, see [Amazon EFS volumes](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/efs-volumes.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.str] filesystem_id: The Amazon EFS file system ID to use.
        :param pulumi.Input['TaskDefinitionAuthorizationConfigArgs'] authorization_config: The authorization configuration details for the Amazon EFS file system.
        :param pulumi.Input[_builtins.str] root_directory: The directory within the Amazon EFS file system to mount as the root directory inside the host. If this parameter is omitted, the root of the Amazon EFS volume will be used. Specifying ``/`` will have the same effect as omitting this parameter.
                 If an EFS access point is specified in the ``authorizationConfig``, the root directory parameter must either be omitted or set to ``/`` which will enforce the path set on the EFS access point.
        :param pulumi.Input['TaskDefinitionEfsVolumeConfigurationTransitEncryption'] transit_encryption: Determines whether to use encryption for Amazon EFS data in transit between the Amazon ECS host and the Amazon EFS server. Transit encryption must be turned on if Amazon EFS IAM authorization is used. If this parameter is omitted, the default value of ``DISABLED`` is used. For more information, see [Encrypting data in transit](https://docs.aws.amazon.com/efs/latest/ug/encryption-in-transit.html) in the *Amazon Elastic File System User Guide*.
        :param pulumi.Input[_builtins.int] transit_encryption_port: The port to use when sending encrypted data between the Amazon ECS host and the Amazon EFS server. If you do not specify a transit encryption port, it will use the port selection strategy that the Amazon EFS mount helper uses. For more information, see [EFS mount helper](https://docs.aws.amazon.com/efs/latest/ug/efs-mount-helper.html) in the *Amazon Elastic File System User Guide*.
        """
        pulumi.set(__self__, "filesystem_id", filesystem_id)
        if authorization_config is not None:
            pulumi.set(__self__, "authorization_config", authorization_config)
        if root_directory is not None:
            pulumi.set(__self__, "root_directory", root_directory)
        if transit_encryption is not None:
            pulumi.set(__self__, "transit_encryption", transit_encryption)
        if transit_encryption_port is not None:
            pulumi.set(__self__, "transit_encryption_port", transit_encryption_port)

    @_builtins.property
    @pulumi.getter(name="filesystemId")
    def filesystem_id(self) -> pulumi.Input[_builtins.str]:
        """
        The Amazon EFS file system ID to use.
        """
        return pulumi.get(self, "filesystem_id")

    @filesystem_id.setter
    def filesystem_id(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "filesystem_id", value)

    @_builtins.property
    @pulumi.getter(name="authorizationConfig")
    def authorization_config(self) -> Optional[pulumi.Input['TaskDefinitionAuthorizationConfigArgs']]:
        """
        The authorization configuration details for the Amazon EFS file system.
        """
        return pulumi.get(self, "authorization_config")

    @authorization_config.setter
    def authorization_config(self, value: Optional[pulumi.Input['TaskDefinitionAuthorizationConfigArgs']]):
        pulumi.set(self, "authorization_config", value)

    @_builtins.property
    @pulumi.getter(name="rootDirectory")
    def root_directory(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The directory within the Amazon EFS file system to mount as the root directory inside the host. If this parameter is omitted, the root of the Amazon EFS volume will be used. Specifying ``/`` will have the same effect as omitting this parameter.
          If an EFS access point is specified in the ``authorizationConfig``, the root directory parameter must either be omitted or set to ``/`` which will enforce the path set on the EFS access point.
        """
        return pulumi.get(self, "root_directory")

    @root_directory.setter
    def root_directory(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "root_directory", value)

    @_builtins.property
    @pulumi.getter(name="transitEncryption")
    def transit_encryption(self) -> Optional[pulumi.Input['TaskDefinitionEfsVolumeConfigurationTransitEncryption']]:
        """
        Determines whether to use encryption for Amazon EFS data in transit between the Amazon ECS host and the Amazon EFS server. Transit encryption must be turned on if Amazon EFS IAM authorization is used. If this parameter is omitted, the default value of ``DISABLED`` is used. For more information, see [Encrypting data in transit](https://docs.aws.amazon.com/efs/latest/ug/encryption-in-transit.html) in the *Amazon Elastic File System User Guide*.
        """
        return pulumi.get(self, "transit_encryption")

    @transit_encryption.setter
    def transit_encryption(self, value: Optional[pulumi.Input['TaskDefinitionEfsVolumeConfigurationTransitEncryption']]):
        pulumi.set(self, "transit_encryption", value)

    @_builtins.property
    @pulumi.getter(name="transitEncryptionPort")
    def transit_encryption_port(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The port to use when sending encrypted data between the Amazon ECS host and the Amazon EFS server. If you do not specify a transit encryption port, it will use the port selection strategy that the Amazon EFS mount helper uses. For more information, see [EFS mount helper](https://docs.aws.amazon.com/efs/latest/ug/efs-mount-helper.html) in the *Amazon Elastic File System User Guide*.
        """
        return pulumi.get(self, "transit_encryption_port")

    @transit_encryption_port.setter
    def transit_encryption_port(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "transit_encryption_port", value)


if not MYPY:
    class TaskDefinitionEnvironmentFileArgsDict(TypedDict):
        """
        A list of files containing the environment variables to pass to a container. You can specify up to ten environment files. The file must have a ``.env`` file extension. Each line in an environment file should contain an environment variable in ``VARIABLE=VALUE`` format. Lines beginning with ``#`` are treated as comments and are ignored.
         If there are environment variables specified using the ``environment`` parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they're processed from the top down. We recommend that you use unique variable names. For more information, see [Use a file to pass environment variables to a container](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/use-environment-file.html) in the *Amazon Elastic Container Service Developer Guide*.
         Environment variable files are objects in Amazon S3 and all Amazon S3 security considerations apply. 
         You must use the following platforms for the Fargate launch type:
          +  Linux platform version ``1.4.0`` or later.
          +  Windows platform version ``1.0.0`` or later.
          
         Consider the following when using the Fargate launch type:
          +  The file is handled like a native Docker env-file.
          +  There is no support for shell escape handling.
          +  The container entry point interperts the ``VARIABLE`` values.
        """
        type: NotRequired[pulumi.Input[_builtins.str]]
        """
        The file type to use. Environment files are objects in Amazon S3. The only supported value is ``s3``.
        """
        value: NotRequired[pulumi.Input[_builtins.str]]
        """
        The Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.
        """
elif False:
    TaskDefinitionEnvironmentFileArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionEnvironmentFileArgs:
    def __init__(__self__, *,
                 type: Optional[pulumi.Input[_builtins.str]] = None,
                 value: Optional[pulumi.Input[_builtins.str]] = None):
        """
        A list of files containing the environment variables to pass to a container. You can specify up to ten environment files. The file must have a ``.env`` file extension. Each line in an environment file should contain an environment variable in ``VARIABLE=VALUE`` format. Lines beginning with ``#`` are treated as comments and are ignored.
         If there are environment variables specified using the ``environment`` parameter in a container definition, they take precedence over the variables contained within an environment file. If multiple environment files are specified that contain the same variable, they're processed from the top down. We recommend that you use unique variable names. For more information, see [Use a file to pass environment variables to a container](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/use-environment-file.html) in the *Amazon Elastic Container Service Developer Guide*.
         Environment variable files are objects in Amazon S3 and all Amazon S3 security considerations apply. 
         You must use the following platforms for the Fargate launch type:
          +  Linux platform version ``1.4.0`` or later.
          +  Windows platform version ``1.0.0`` or later.
          
         Consider the following when using the Fargate launch type:
          +  The file is handled like a native Docker env-file.
          +  There is no support for shell escape handling.
          +  The container entry point interperts the ``VARIABLE`` values.
        :param pulumi.Input[_builtins.str] type: The file type to use. Environment files are objects in Amazon S3. The only supported value is ``s3``.
        :param pulumi.Input[_builtins.str] value: The Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.
        """
        if type is not None:
            pulumi.set(__self__, "type", type)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def type(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The file type to use. Environment files are objects in Amazon S3. The only supported value is ``s3``.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "type", value)

    @_builtins.property
    @pulumi.getter
    def value(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The Amazon Resource Name (ARN) of the Amazon S3 object containing the environment variable file.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "value", value)


if not MYPY:
    class TaskDefinitionEphemeralStorageArgsDict(TypedDict):
        """
        The amount of ephemeral storage to allocate for the task. This parameter is used to expand the total amount of ephemeral storage available, beyond the default amount, for tasks hosted on FARGATElong. For more information, see [Using data volumes in tasks](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_data_volumes.html) in the *Amazon ECS Developer Guide;*.
          For tasks using the Fargate launch type, the task requires the following platforms:
          +  Linux platform version ``1.4.0`` or later.
          +  Windows platform version ``1.0.0`` or later.
        """
        size_in_gi_b: NotRequired[pulumi.Input[_builtins.int]]
        """
        The total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is ``21`` GiB and the maximum supported value is ``200`` GiB.
        """
elif False:
    TaskDefinitionEphemeralStorageArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionEphemeralStorageArgs:
    def __init__(__self__, *,
                 size_in_gi_b: Optional[pulumi.Input[_builtins.int]] = None):
        """
        The amount of ephemeral storage to allocate for the task. This parameter is used to expand the total amount of ephemeral storage available, beyond the default amount, for tasks hosted on FARGATElong. For more information, see [Using data volumes in tasks](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_data_volumes.html) in the *Amazon ECS Developer Guide;*.
          For tasks using the Fargate launch type, the task requires the following platforms:
          +  Linux platform version ``1.4.0`` or later.
          +  Windows platform version ``1.0.0`` or later.
        :param pulumi.Input[_builtins.int] size_in_gi_b: The total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is ``21`` GiB and the maximum supported value is ``200`` GiB.
        """
        if size_in_gi_b is not None:
            pulumi.set(__self__, "size_in_gi_b", size_in_gi_b)

    @_builtins.property
    @pulumi.getter(name="sizeInGiB")
    def size_in_gi_b(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The total amount, in GiB, of ephemeral storage to set for the task. The minimum supported value is ``21`` GiB and the maximum supported value is ``200`` GiB.
        """
        return pulumi.get(self, "size_in_gi_b")

    @size_in_gi_b.setter
    def size_in_gi_b(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "size_in_gi_b", value)


if not MYPY:
    class TaskDefinitionFSxAuthorizationConfigArgsDict(TypedDict):
        """
        The authorization configuration details for Amazon FSx for Windows File Server file system. See [FSxWindowsFileServerVolumeConfiguration](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_FSxWindowsFileServerVolumeConfiguration.html) in the *Amazon ECS API Reference*.
         For more information and the input format, see [Amazon FSx for Windows File Server Volumes](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/wfsx-volumes.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        credentials_parameter: pulumi.Input[_builtins.str]
        """
        The authorization credential option to use. The authorization credential options can be provided using either the Amazon Resource Name (ARN) of an ASMlong secret or SSM Parameter Store parameter. The ARN refers to the stored credentials.
        """
        domain: pulumi.Input[_builtins.str]
        """
        A fully qualified domain name hosted by an [](https://docs.aws.amazon.com/directoryservice/latest/admin-guide/directory_microsoft_ad.html) Managed Microsoft AD (Active Directory) or self-hosted AD on Amazon EC2.
        """
elif False:
    TaskDefinitionFSxAuthorizationConfigArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionFSxAuthorizationConfigArgs:
    def __init__(__self__, *,
                 credentials_parameter: pulumi.Input[_builtins.str],
                 domain: pulumi.Input[_builtins.str]):
        """
        The authorization configuration details for Amazon FSx for Windows File Server file system. See [FSxWindowsFileServerVolumeConfiguration](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_FSxWindowsFileServerVolumeConfiguration.html) in the *Amazon ECS API Reference*.
         For more information and the input format, see [Amazon FSx for Windows File Server Volumes](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/wfsx-volumes.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.str] credentials_parameter: The authorization credential option to use. The authorization credential options can be provided using either the Amazon Resource Name (ARN) of an ASMlong secret or SSM Parameter Store parameter. The ARN refers to the stored credentials.
        :param pulumi.Input[_builtins.str] domain: A fully qualified domain name hosted by an [](https://docs.aws.amazon.com/directoryservice/latest/admin-guide/directory_microsoft_ad.html) Managed Microsoft AD (Active Directory) or self-hosted AD on Amazon EC2.
        """
        pulumi.set(__self__, "credentials_parameter", credentials_parameter)
        pulumi.set(__self__, "domain", domain)

    @_builtins.property
    @pulumi.getter(name="credentialsParameter")
    def credentials_parameter(self) -> pulumi.Input[_builtins.str]:
        """
        The authorization credential option to use. The authorization credential options can be provided using either the Amazon Resource Name (ARN) of an ASMlong secret or SSM Parameter Store parameter. The ARN refers to the stored credentials.
        """
        return pulumi.get(self, "credentials_parameter")

    @credentials_parameter.setter
    def credentials_parameter(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "credentials_parameter", value)

    @_builtins.property
    @pulumi.getter
    def domain(self) -> pulumi.Input[_builtins.str]:
        """
        A fully qualified domain name hosted by an [](https://docs.aws.amazon.com/directoryservice/latest/admin-guide/directory_microsoft_ad.html) Managed Microsoft AD (Active Directory) or self-hosted AD on Amazon EC2.
        """
        return pulumi.get(self, "domain")

    @domain.setter
    def domain(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "domain", value)


if not MYPY:
    class TaskDefinitionFSxWindowsFileServerVolumeConfigurationArgsDict(TypedDict):
        """
        This parameter is specified when you're using [Amazon FSx for Windows File Server](https://docs.aws.amazon.com/fsx/latest/WindowsGuide/what-is.html) file system for task storage.
         For more information and the input format, see [Amazon FSx for Windows File Server volumes](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/wfsx-volumes.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        file_system_id: pulumi.Input[_builtins.str]
        """
        The Amazon FSx for Windows File Server file system ID to use.
        """
        root_directory: pulumi.Input[_builtins.str]
        """
        The directory within the Amazon FSx for Windows File Server file system to mount as the root directory inside the host.
        """
        authorization_config: NotRequired[pulumi.Input['TaskDefinitionFSxAuthorizationConfigArgsDict']]
        """
        The authorization configuration details for the Amazon FSx for Windows File Server file system.
        """
elif False:
    TaskDefinitionFSxWindowsFileServerVolumeConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionFSxWindowsFileServerVolumeConfigurationArgs:
    def __init__(__self__, *,
                 file_system_id: pulumi.Input[_builtins.str],
                 root_directory: pulumi.Input[_builtins.str],
                 authorization_config: Optional[pulumi.Input['TaskDefinitionFSxAuthorizationConfigArgs']] = None):
        """
        This parameter is specified when you're using [Amazon FSx for Windows File Server](https://docs.aws.amazon.com/fsx/latest/WindowsGuide/what-is.html) file system for task storage.
         For more information and the input format, see [Amazon FSx for Windows File Server volumes](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/wfsx-volumes.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.str] file_system_id: The Amazon FSx for Windows File Server file system ID to use.
        :param pulumi.Input[_builtins.str] root_directory: The directory within the Amazon FSx for Windows File Server file system to mount as the root directory inside the host.
        :param pulumi.Input['TaskDefinitionFSxAuthorizationConfigArgs'] authorization_config: The authorization configuration details for the Amazon FSx for Windows File Server file system.
        """
        pulumi.set(__self__, "file_system_id", file_system_id)
        pulumi.set(__self__, "root_directory", root_directory)
        if authorization_config is not None:
            pulumi.set(__self__, "authorization_config", authorization_config)

    @_builtins.property
    @pulumi.getter(name="fileSystemId")
    def file_system_id(self) -> pulumi.Input[_builtins.str]:
        """
        The Amazon FSx for Windows File Server file system ID to use.
        """
        return pulumi.get(self, "file_system_id")

    @file_system_id.setter
    def file_system_id(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "file_system_id", value)

    @_builtins.property
    @pulumi.getter(name="rootDirectory")
    def root_directory(self) -> pulumi.Input[_builtins.str]:
        """
        The directory within the Amazon FSx for Windows File Server file system to mount as the root directory inside the host.
        """
        return pulumi.get(self, "root_directory")

    @root_directory.setter
    def root_directory(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "root_directory", value)

    @_builtins.property
    @pulumi.getter(name="authorizationConfig")
    def authorization_config(self) -> Optional[pulumi.Input['TaskDefinitionFSxAuthorizationConfigArgs']]:
        """
        The authorization configuration details for the Amazon FSx for Windows File Server file system.
        """
        return pulumi.get(self, "authorization_config")

    @authorization_config.setter
    def authorization_config(self, value: Optional[pulumi.Input['TaskDefinitionFSxAuthorizationConfigArgs']]):
        pulumi.set(self, "authorization_config", value)


if not MYPY:
    class TaskDefinitionFirelensConfigurationArgsDict(TypedDict):
        """
        The FireLens configuration for the container. This is used to specify and configure a log router for container logs. For more information, see [Custom log routing](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_firelens.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        options: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]
        """
        The options to use when configuring the log router. This field is optional and can be used to add additional metadata, such as the task, task definition, cluster, and container instance details to the log event.
          If specified, valid option keys are:
          +  ``enable-ecs-log-metadata``, which can be ``true`` or ``false``
          +  ``config-file-type``, which can be ``s3`` or ``file``
          +  ``config-file-value``, which is either an S3 ARN or a file path
        """
        type: NotRequired[pulumi.Input[_builtins.str]]
        """
        The log router to use. The valid values are ``fluentd`` or ``fluentbit``.
        """
elif False:
    TaskDefinitionFirelensConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionFirelensConfigurationArgs:
    def __init__(__self__, *,
                 options: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]] = None,
                 type: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The FireLens configuration for the container. This is used to specify and configure a log router for container logs. For more information, see [Custom log routing](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_firelens.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]] options: The options to use when configuring the log router. This field is optional and can be used to add additional metadata, such as the task, task definition, cluster, and container instance details to the log event.
                 If specified, valid option keys are:
                 +  ``enable-ecs-log-metadata``, which can be ``true`` or ``false``
                 +  ``config-file-type``, which can be ``s3`` or ``file``
                 +  ``config-file-value``, which is either an S3 ARN or a file path
        :param pulumi.Input[_builtins.str] type: The log router to use. The valid values are ``fluentd`` or ``fluentbit``.
        """
        if options is not None:
            pulumi.set(__self__, "options", options)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter
    def options(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]:
        """
        The options to use when configuring the log router. This field is optional and can be used to add additional metadata, such as the task, task definition, cluster, and container instance details to the log event.
          If specified, valid option keys are:
          +  ``enable-ecs-log-metadata``, which can be ``true`` or ``false``
          +  ``config-file-type``, which can be ``s3`` or ``file``
          +  ``config-file-value``, which is either an S3 ARN or a file path
        """
        return pulumi.get(self, "options")

    @options.setter
    def options(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "options", value)

    @_builtins.property
    @pulumi.getter
    def type(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The log router to use. The valid values are ``fluentd`` or ``fluentbit``.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "type", value)


if not MYPY:
    class TaskDefinitionHealthCheckArgsDict(TypedDict):
        """
        The ``HealthCheck`` property specifies an object representing a container health check. Health check parameters that are specified in a container definition override any Docker health checks that exist in the container image (such as those specified in a parent image or from the image's Dockerfile). This configuration maps to the ``HEALTHCHECK`` parameter of docker run.
          The Amazon ECS container agent only monitors and reports on the health checks specified in the task definition. Amazon ECS does not monitor Docker health checks that are embedded in a container image and not specified in the container definition. Health check parameters that are specified in a container definition override any Docker health checks that exist in the container image.
          If a task is run manually, and not as part of a service, the task will continue its lifecycle regardless of its health status. For tasks that are part of a service, if the task reports as unhealthy then the task will be stopped and the service scheduler will replace it.
         The following are notes about container health check support:
          +  Container health checks require version 1.17.0 or greater of the Amazon ECS container agent. For more information, see [Updating the Amazon ECS Container Agent](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-update.html).
          +  Container health checks are supported for Fargate tasks if you are using platform version 1.1.0 or greater. For more information, see [Platform Versions](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html).
          +  Container health checks are not supported for tasks that are part of a service that is configured to use a Classic Load Balancer.
        """
        command: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        A string array representing the command that the container runs to determine if it is healthy. The string array must start with ``CMD`` to run the command arguments directly, or ``CMD-SHELL`` to run the command with the container's default shell. 
          When you use the AWS Management Console JSON panel, the CLIlong, or the APIs, enclose the list of commands in double quotes and brackets.
          ``[ "CMD-SHELL", "curl -f http://localhost/ || exit 1" ]`` 
         You don't include the double quotes and brackets when you use the AWS Management Console.
          ``CMD-SHELL, curl -f http://localhost/ || exit 1`` 
         An exit code of 0 indicates success, and non-zero exit code indicates failure. For more information, see ``HealthCheck`` in the docker container create command.
        """
        interval: NotRequired[pulumi.Input[_builtins.int]]
        """
        The time period in seconds between each health check execution. You may specify between 5 and 300 seconds. The default value is 30 seconds. This value applies only when you specify a ``command``.
        """
        retries: NotRequired[pulumi.Input[_builtins.int]]
        """
        The number of times to retry a failed health check before the container is considered unhealthy. You may specify between 1 and 10 retries. The default value is 3. This value applies only when you specify a ``command``.
        """
        start_period: NotRequired[pulumi.Input[_builtins.int]]
        """
        The optional grace period to provide containers time to bootstrap before failed health checks count towards the maximum number of retries. You can specify between 0 and 300 seconds. By default, the ``startPeriod`` is off. This value applies only when you specify a ``command``. 
          If a health check succeeds within the ``startPeriod``, then the container is considered healthy and any subsequent failures count toward the maximum number of retries.
        """
        timeout: NotRequired[pulumi.Input[_builtins.int]]
        """
        The time period in seconds to wait for a health check to succeed before it is considered a failure. You may specify between 2 and 60 seconds. The default value is 5. This value applies only when you specify a ``command``.
        """
elif False:
    TaskDefinitionHealthCheckArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionHealthCheckArgs:
    def __init__(__self__, *,
                 command: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 interval: Optional[pulumi.Input[_builtins.int]] = None,
                 retries: Optional[pulumi.Input[_builtins.int]] = None,
                 start_period: Optional[pulumi.Input[_builtins.int]] = None,
                 timeout: Optional[pulumi.Input[_builtins.int]] = None):
        """
        The ``HealthCheck`` property specifies an object representing a container health check. Health check parameters that are specified in a container definition override any Docker health checks that exist in the container image (such as those specified in a parent image or from the image's Dockerfile). This configuration maps to the ``HEALTHCHECK`` parameter of docker run.
          The Amazon ECS container agent only monitors and reports on the health checks specified in the task definition. Amazon ECS does not monitor Docker health checks that are embedded in a container image and not specified in the container definition. Health check parameters that are specified in a container definition override any Docker health checks that exist in the container image.
          If a task is run manually, and not as part of a service, the task will continue its lifecycle regardless of its health status. For tasks that are part of a service, if the task reports as unhealthy then the task will be stopped and the service scheduler will replace it.
         The following are notes about container health check support:
          +  Container health checks require version 1.17.0 or greater of the Amazon ECS container agent. For more information, see [Updating the Amazon ECS Container Agent](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-update.html).
          +  Container health checks are supported for Fargate tasks if you are using platform version 1.1.0 or greater. For more information, see [Platform Versions](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html).
          +  Container health checks are not supported for tasks that are part of a service that is configured to use a Classic Load Balancer.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] command: A string array representing the command that the container runs to determine if it is healthy. The string array must start with ``CMD`` to run the command arguments directly, or ``CMD-SHELL`` to run the command with the container's default shell. 
                 When you use the AWS Management Console JSON panel, the CLIlong, or the APIs, enclose the list of commands in double quotes and brackets.
                 ``[ "CMD-SHELL", "curl -f http://localhost/ || exit 1" ]`` 
                You don't include the double quotes and brackets when you use the AWS Management Console.
                 ``CMD-SHELL, curl -f http://localhost/ || exit 1`` 
                An exit code of 0 indicates success, and non-zero exit code indicates failure. For more information, see ``HealthCheck`` in the docker container create command.
        :param pulumi.Input[_builtins.int] interval: The time period in seconds between each health check execution. You may specify between 5 and 300 seconds. The default value is 30 seconds. This value applies only when you specify a ``command``.
        :param pulumi.Input[_builtins.int] retries: The number of times to retry a failed health check before the container is considered unhealthy. You may specify between 1 and 10 retries. The default value is 3. This value applies only when you specify a ``command``.
        :param pulumi.Input[_builtins.int] start_period: The optional grace period to provide containers time to bootstrap before failed health checks count towards the maximum number of retries. You can specify between 0 and 300 seconds. By default, the ``startPeriod`` is off. This value applies only when you specify a ``command``. 
                 If a health check succeeds within the ``startPeriod``, then the container is considered healthy and any subsequent failures count toward the maximum number of retries.
        :param pulumi.Input[_builtins.int] timeout: The time period in seconds to wait for a health check to succeed before it is considered a failure. You may specify between 2 and 60 seconds. The default value is 5. This value applies only when you specify a ``command``.
        """
        if command is not None:
            pulumi.set(__self__, "command", command)
        if interval is not None:
            pulumi.set(__self__, "interval", interval)
        if retries is not None:
            pulumi.set(__self__, "retries", retries)
        if start_period is not None:
            pulumi.set(__self__, "start_period", start_period)
        if timeout is not None:
            pulumi.set(__self__, "timeout", timeout)

    @_builtins.property
    @pulumi.getter
    def command(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        A string array representing the command that the container runs to determine if it is healthy. The string array must start with ``CMD`` to run the command arguments directly, or ``CMD-SHELL`` to run the command with the container's default shell. 
          When you use the AWS Management Console JSON panel, the CLIlong, or the APIs, enclose the list of commands in double quotes and brackets.
          ``[ "CMD-SHELL", "curl -f http://localhost/ || exit 1" ]`` 
         You don't include the double quotes and brackets when you use the AWS Management Console.
          ``CMD-SHELL, curl -f http://localhost/ || exit 1`` 
         An exit code of 0 indicates success, and non-zero exit code indicates failure. For more information, see ``HealthCheck`` in the docker container create command.
        """
        return pulumi.get(self, "command")

    @command.setter
    def command(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "command", value)

    @_builtins.property
    @pulumi.getter
    def interval(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The time period in seconds between each health check execution. You may specify between 5 and 300 seconds. The default value is 30 seconds. This value applies only when you specify a ``command``.
        """
        return pulumi.get(self, "interval")

    @interval.setter
    def interval(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "interval", value)

    @_builtins.property
    @pulumi.getter
    def retries(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The number of times to retry a failed health check before the container is considered unhealthy. You may specify between 1 and 10 retries. The default value is 3. This value applies only when you specify a ``command``.
        """
        return pulumi.get(self, "retries")

    @retries.setter
    def retries(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "retries", value)

    @_builtins.property
    @pulumi.getter(name="startPeriod")
    def start_period(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The optional grace period to provide containers time to bootstrap before failed health checks count towards the maximum number of retries. You can specify between 0 and 300 seconds. By default, the ``startPeriod`` is off. This value applies only when you specify a ``command``. 
          If a health check succeeds within the ``startPeriod``, then the container is considered healthy and any subsequent failures count toward the maximum number of retries.
        """
        return pulumi.get(self, "start_period")

    @start_period.setter
    def start_period(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "start_period", value)

    @_builtins.property
    @pulumi.getter
    def timeout(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The time period in seconds to wait for a health check to succeed before it is considered a failure. You may specify between 2 and 60 seconds. The default value is 5. This value applies only when you specify a ``command``.
        """
        return pulumi.get(self, "timeout")

    @timeout.setter
    def timeout(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "timeout", value)


if not MYPY:
    class TaskDefinitionHostEntryArgsDict(TypedDict):
        """
        The ``HostEntry`` property specifies a hostname and an IP address that are added to the ``/etc/hosts`` file of a container through the ``extraHosts`` parameter of its ``ContainerDefinition`` resource.
        """
        hostname: NotRequired[pulumi.Input[_builtins.str]]
        """
        The hostname to use in the ``/etc/hosts`` entry.
        """
        ip_address: NotRequired[pulumi.Input[_builtins.str]]
        """
        The IP address to use in the ``/etc/hosts`` entry.
        """
elif False:
    TaskDefinitionHostEntryArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionHostEntryArgs:
    def __init__(__self__, *,
                 hostname: Optional[pulumi.Input[_builtins.str]] = None,
                 ip_address: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The ``HostEntry`` property specifies a hostname and an IP address that are added to the ``/etc/hosts`` file of a container through the ``extraHosts`` parameter of its ``ContainerDefinition`` resource.
        :param pulumi.Input[_builtins.str] hostname: The hostname to use in the ``/etc/hosts`` entry.
        :param pulumi.Input[_builtins.str] ip_address: The IP address to use in the ``/etc/hosts`` entry.
        """
        if hostname is not None:
            pulumi.set(__self__, "hostname", hostname)
        if ip_address is not None:
            pulumi.set(__self__, "ip_address", ip_address)

    @_builtins.property
    @pulumi.getter
    def hostname(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The hostname to use in the ``/etc/hosts`` entry.
        """
        return pulumi.get(self, "hostname")

    @hostname.setter
    def hostname(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "hostname", value)

    @_builtins.property
    @pulumi.getter(name="ipAddress")
    def ip_address(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The IP address to use in the ``/etc/hosts`` entry.
        """
        return pulumi.get(self, "ip_address")

    @ip_address.setter
    def ip_address(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "ip_address", value)


if not MYPY:
    class TaskDefinitionHostVolumePropertiesArgsDict(TypedDict):
        """
        The ``HostVolumeProperties`` property specifies details on a container instance bind mount host volume.
        """
        source_path: NotRequired[pulumi.Input[_builtins.str]]
        """
        When the ``host`` parameter is used, specify a ``sourcePath`` to declare the path on the host container instance that's presented to the container. If this parameter is empty, then the Docker daemon has assigned a host path for you. If the ``host`` parameter contains a ``sourcePath`` file location, then the data volume persists at the specified location on the host container instance until you delete it manually. If the ``sourcePath`` value doesn't exist on the host container instance, the Docker daemon creates it. If the location does exist, the contents of the source path folder are exported.
         If you're using the Fargate launch type, the ``sourcePath`` parameter is not supported.
        """
elif False:
    TaskDefinitionHostVolumePropertiesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionHostVolumePropertiesArgs:
    def __init__(__self__, *,
                 source_path: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The ``HostVolumeProperties`` property specifies details on a container instance bind mount host volume.
        :param pulumi.Input[_builtins.str] source_path: When the ``host`` parameter is used, specify a ``sourcePath`` to declare the path on the host container instance that's presented to the container. If this parameter is empty, then the Docker daemon has assigned a host path for you. If the ``host`` parameter contains a ``sourcePath`` file location, then the data volume persists at the specified location on the host container instance until you delete it manually. If the ``sourcePath`` value doesn't exist on the host container instance, the Docker daemon creates it. If the location does exist, the contents of the source path folder are exported.
                If you're using the Fargate launch type, the ``sourcePath`` parameter is not supported.
        """
        if source_path is not None:
            pulumi.set(__self__, "source_path", source_path)

    @_builtins.property
    @pulumi.getter(name="sourcePath")
    def source_path(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        When the ``host`` parameter is used, specify a ``sourcePath`` to declare the path on the host container instance that's presented to the container. If this parameter is empty, then the Docker daemon has assigned a host path for you. If the ``host`` parameter contains a ``sourcePath`` file location, then the data volume persists at the specified location on the host container instance until you delete it manually. If the ``sourcePath`` value doesn't exist on the host container instance, the Docker daemon creates it. If the location does exist, the contents of the source path folder are exported.
         If you're using the Fargate launch type, the ``sourcePath`` parameter is not supported.
        """
        return pulumi.get(self, "source_path")

    @source_path.setter
    def source_path(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "source_path", value)


if not MYPY:
    class TaskDefinitionInferenceAcceleratorArgsDict(TypedDict):
        device_name: NotRequired[pulumi.Input[_builtins.str]]
        device_type: NotRequired[pulumi.Input[_builtins.str]]
elif False:
    TaskDefinitionInferenceAcceleratorArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionInferenceAcceleratorArgs:
    def __init__(__self__, *,
                 device_name: Optional[pulumi.Input[_builtins.str]] = None,
                 device_type: Optional[pulumi.Input[_builtins.str]] = None):
        if device_name is not None:
            pulumi.set(__self__, "device_name", device_name)
        if device_type is not None:
            pulumi.set(__self__, "device_type", device_type)

    @_builtins.property
    @pulumi.getter(name="deviceName")
    def device_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        return pulumi.get(self, "device_name")

    @device_name.setter
    def device_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "device_name", value)

    @_builtins.property
    @pulumi.getter(name="deviceType")
    def device_type(self) -> Optional[pulumi.Input[_builtins.str]]:
        return pulumi.get(self, "device_type")

    @device_type.setter
    def device_type(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "device_type", value)


if not MYPY:
    class TaskDefinitionKernelCapabilitiesArgsDict(TypedDict):
        """
        The Linux capabilities to add or remove from the default Docker configuration for a container defined in the task definition. For more detailed information about these Linux capabilities, see the [capabilities(7)](https://docs.aws.amazon.com/http://man7.org/linux/man-pages/man7/capabilities.7.html) Linux manual page.
         The following describes how Docker processes the Linux capabilities specified in the ``add`` and ``drop`` request parameters. For information about the latest behavior, see [Docker Compose: order of cap_drop and cap_add](https://docs.aws.amazon.com/https://forums.docker.com/t/docker-compose-order-of-cap-drop-and-cap-add/97136/1) in the Docker Community Forum.
          +  When the container is a privleged container, the container capabilities are all of the default Docker capabilities. The capabilities specified in the ``add`` request parameter, and the ``drop`` request parameter are ignored.
          +  When the ``add`` request parameter is set to ALL, the container capabilities are all of the default Docker capabilities, excluding those specified in the ``drop`` request parameter.
          +  When the ``drop`` request parameter is set to ALL, the container capabilities are the capabilities specified in the ``add`` request parameter.
          +  When the ``add`` request parameter and the ``drop`` request parameter are both empty, the capabilities the container capabilities are all of the default Docker capabilities.
          +  The default is to first drop the capabilities specified in the ``drop`` request parameter, and then add the capabilities specified in the ``add`` request parameter.
        """
        add: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The Linux capabilities for the container that have been added to the default configuration provided by Docker. This parameter maps to ``CapAdd`` in the docker container create command and the ``--cap-add`` option to docker run.
          Tasks launched on FARGATElong only support adding the ``SYS_PTRACE`` kernel capability.
          Valid values: ``"ALL" | "AUDIT_CONTROL" | "AUDIT_WRITE" | "BLOCK_SUSPEND" | "CHOWN" | "DAC_OVERRIDE" | "DAC_READ_SEARCH" | "FOWNER" | "FSETID" | "IPC_LOCK" | "IPC_OWNER" | "KILL" | "LEASE" | "LINUX_IMMUTABLE" | "MAC_ADMIN" | "MAC_OVERRIDE" | "MKNOD" | "NET_ADMIN" | "NET_BIND_SERVICE" | "NET_BROADCAST" | "NET_RAW" | "SETFCAP" | "SETGID" | "SETPCAP" | "SETUID" | "SYS_ADMIN" | "SYS_BOOT" | "SYS_CHROOT" | "SYS_MODULE" | "SYS_NICE" | "SYS_PACCT" | "SYS_PTRACE" | "SYS_RAWIO" | "SYS_RESOURCE" | "SYS_TIME" | "SYS_TTY_CONFIG" | "SYSLOG" | "WAKE_ALARM"``
        """
        drop: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The Linux capabilities for the container that have been removed from the default configuration provided by Docker. This parameter maps to ``CapDrop`` in the docker container create command and the ``--cap-drop`` option to docker run.
         Valid values: ``"ALL" | "AUDIT_CONTROL" | "AUDIT_WRITE" | "BLOCK_SUSPEND" | "CHOWN" | "DAC_OVERRIDE" | "DAC_READ_SEARCH" | "FOWNER" | "FSETID" | "IPC_LOCK" | "IPC_OWNER" | "KILL" | "LEASE" | "LINUX_IMMUTABLE" | "MAC_ADMIN" | "MAC_OVERRIDE" | "MKNOD" | "NET_ADMIN" | "NET_BIND_SERVICE" | "NET_BROADCAST" | "NET_RAW" | "SETFCAP" | "SETGID" | "SETPCAP" | "SETUID" | "SYS_ADMIN" | "SYS_BOOT" | "SYS_CHROOT" | "SYS_MODULE" | "SYS_NICE" | "SYS_PACCT" | "SYS_PTRACE" | "SYS_RAWIO" | "SYS_RESOURCE" | "SYS_TIME" | "SYS_TTY_CONFIG" | "SYSLOG" | "WAKE_ALARM"``
        """
elif False:
    TaskDefinitionKernelCapabilitiesArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionKernelCapabilitiesArgs:
    def __init__(__self__, *,
                 add: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 drop: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None):
        """
        The Linux capabilities to add or remove from the default Docker configuration for a container defined in the task definition. For more detailed information about these Linux capabilities, see the [capabilities(7)](https://docs.aws.amazon.com/http://man7.org/linux/man-pages/man7/capabilities.7.html) Linux manual page.
         The following describes how Docker processes the Linux capabilities specified in the ``add`` and ``drop`` request parameters. For information about the latest behavior, see [Docker Compose: order of cap_drop and cap_add](https://docs.aws.amazon.com/https://forums.docker.com/t/docker-compose-order-of-cap-drop-and-cap-add/97136/1) in the Docker Community Forum.
          +  When the container is a privleged container, the container capabilities are all of the default Docker capabilities. The capabilities specified in the ``add`` request parameter, and the ``drop`` request parameter are ignored.
          +  When the ``add`` request parameter is set to ALL, the container capabilities are all of the default Docker capabilities, excluding those specified in the ``drop`` request parameter.
          +  When the ``drop`` request parameter is set to ALL, the container capabilities are the capabilities specified in the ``add`` request parameter.
          +  When the ``add`` request parameter and the ``drop`` request parameter are both empty, the capabilities the container capabilities are all of the default Docker capabilities.
          +  The default is to first drop the capabilities specified in the ``drop`` request parameter, and then add the capabilities specified in the ``add`` request parameter.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] add: The Linux capabilities for the container that have been added to the default configuration provided by Docker. This parameter maps to ``CapAdd`` in the docker container create command and the ``--cap-add`` option to docker run.
                 Tasks launched on FARGATElong only support adding the ``SYS_PTRACE`` kernel capability.
                 Valid values: ``"ALL" | "AUDIT_CONTROL" | "AUDIT_WRITE" | "BLOCK_SUSPEND" | "CHOWN" | "DAC_OVERRIDE" | "DAC_READ_SEARCH" | "FOWNER" | "FSETID" | "IPC_LOCK" | "IPC_OWNER" | "KILL" | "LEASE" | "LINUX_IMMUTABLE" | "MAC_ADMIN" | "MAC_OVERRIDE" | "MKNOD" | "NET_ADMIN" | "NET_BIND_SERVICE" | "NET_BROADCAST" | "NET_RAW" | "SETFCAP" | "SETGID" | "SETPCAP" | "SETUID" | "SYS_ADMIN" | "SYS_BOOT" | "SYS_CHROOT" | "SYS_MODULE" | "SYS_NICE" | "SYS_PACCT" | "SYS_PTRACE" | "SYS_RAWIO" | "SYS_RESOURCE" | "SYS_TIME" | "SYS_TTY_CONFIG" | "SYSLOG" | "WAKE_ALARM"``
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] drop: The Linux capabilities for the container that have been removed from the default configuration provided by Docker. This parameter maps to ``CapDrop`` in the docker container create command and the ``--cap-drop`` option to docker run.
                Valid values: ``"ALL" | "AUDIT_CONTROL" | "AUDIT_WRITE" | "BLOCK_SUSPEND" | "CHOWN" | "DAC_OVERRIDE" | "DAC_READ_SEARCH" | "FOWNER" | "FSETID" | "IPC_LOCK" | "IPC_OWNER" | "KILL" | "LEASE" | "LINUX_IMMUTABLE" | "MAC_ADMIN" | "MAC_OVERRIDE" | "MKNOD" | "NET_ADMIN" | "NET_BIND_SERVICE" | "NET_BROADCAST" | "NET_RAW" | "SETFCAP" | "SETGID" | "SETPCAP" | "SETUID" | "SYS_ADMIN" | "SYS_BOOT" | "SYS_CHROOT" | "SYS_MODULE" | "SYS_NICE" | "SYS_PACCT" | "SYS_PTRACE" | "SYS_RAWIO" | "SYS_RESOURCE" | "SYS_TIME" | "SYS_TTY_CONFIG" | "SYSLOG" | "WAKE_ALARM"``
        """
        if add is not None:
            pulumi.set(__self__, "add", add)
        if drop is not None:
            pulumi.set(__self__, "drop", drop)

    @_builtins.property
    @pulumi.getter
    def add(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The Linux capabilities for the container that have been added to the default configuration provided by Docker. This parameter maps to ``CapAdd`` in the docker container create command and the ``--cap-add`` option to docker run.
          Tasks launched on FARGATElong only support adding the ``SYS_PTRACE`` kernel capability.
          Valid values: ``"ALL" | "AUDIT_CONTROL" | "AUDIT_WRITE" | "BLOCK_SUSPEND" | "CHOWN" | "DAC_OVERRIDE" | "DAC_READ_SEARCH" | "FOWNER" | "FSETID" | "IPC_LOCK" | "IPC_OWNER" | "KILL" | "LEASE" | "LINUX_IMMUTABLE" | "MAC_ADMIN" | "MAC_OVERRIDE" | "MKNOD" | "NET_ADMIN" | "NET_BIND_SERVICE" | "NET_BROADCAST" | "NET_RAW" | "SETFCAP" | "SETGID" | "SETPCAP" | "SETUID" | "SYS_ADMIN" | "SYS_BOOT" | "SYS_CHROOT" | "SYS_MODULE" | "SYS_NICE" | "SYS_PACCT" | "SYS_PTRACE" | "SYS_RAWIO" | "SYS_RESOURCE" | "SYS_TIME" | "SYS_TTY_CONFIG" | "SYSLOG" | "WAKE_ALARM"``
        """
        return pulumi.get(self, "add")

    @add.setter
    def add(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "add", value)

    @_builtins.property
    @pulumi.getter
    def drop(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The Linux capabilities for the container that have been removed from the default configuration provided by Docker. This parameter maps to ``CapDrop`` in the docker container create command and the ``--cap-drop`` option to docker run.
         Valid values: ``"ALL" | "AUDIT_CONTROL" | "AUDIT_WRITE" | "BLOCK_SUSPEND" | "CHOWN" | "DAC_OVERRIDE" | "DAC_READ_SEARCH" | "FOWNER" | "FSETID" | "IPC_LOCK" | "IPC_OWNER" | "KILL" | "LEASE" | "LINUX_IMMUTABLE" | "MAC_ADMIN" | "MAC_OVERRIDE" | "MKNOD" | "NET_ADMIN" | "NET_BIND_SERVICE" | "NET_BROADCAST" | "NET_RAW" | "SETFCAP" | "SETGID" | "SETPCAP" | "SETUID" | "SYS_ADMIN" | "SYS_BOOT" | "SYS_CHROOT" | "SYS_MODULE" | "SYS_NICE" | "SYS_PACCT" | "SYS_PTRACE" | "SYS_RAWIO" | "SYS_RESOURCE" | "SYS_TIME" | "SYS_TTY_CONFIG" | "SYSLOG" | "WAKE_ALARM"``
        """
        return pulumi.get(self, "drop")

    @drop.setter
    def drop(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "drop", value)


if not MYPY:
    class TaskDefinitionKeyValuePairArgsDict(TypedDict):
        """
        A key-value pair object.
        """
        name: NotRequired[pulumi.Input[_builtins.str]]
        """
        The name of the key-value pair. For environment variables, this is the name of the environment variable.
        """
        value: NotRequired[pulumi.Input[_builtins.str]]
        """
        The value of the key-value pair. For environment variables, this is the value of the environment variable.
        """
elif False:
    TaskDefinitionKeyValuePairArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionKeyValuePairArgs:
    def __init__(__self__, *,
                 name: Optional[pulumi.Input[_builtins.str]] = None,
                 value: Optional[pulumi.Input[_builtins.str]] = None):
        """
        A key-value pair object.
        :param pulumi.Input[_builtins.str] name: The name of the key-value pair. For environment variables, this is the name of the environment variable.
        :param pulumi.Input[_builtins.str] value: The value of the key-value pair. For environment variables, this is the value of the environment variable.
        """
        if name is not None:
            pulumi.set(__self__, "name", name)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The name of the key-value pair. For environment variables, this is the name of the environment variable.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "name", value)

    @_builtins.property
    @pulumi.getter
    def value(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The value of the key-value pair. For environment variables, this is the value of the environment variable.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "value", value)


if not MYPY:
    class TaskDefinitionLinuxParametersArgsDict(TypedDict):
        """
        The Linux-specific options that are applied to the container, such as Linux [KernelCapabilities](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_KernelCapabilities.html).
        """
        capabilities: NotRequired[pulumi.Input['TaskDefinitionKernelCapabilitiesArgsDict']]
        """
        The Linux capabilities for the container that are added to or dropped from the default configuration provided by Docker.
          For tasks that use the Fargate launch type, ``capabilities`` is supported for all platform versions but the ``add`` parameter is only supported if using platform version 1.4.0 or later.
        """
        devices: NotRequired[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionDeviceArgsDict']]]]
        """
        Any host devices to expose to the container. This parameter maps to ``Devices`` in the docker container create command and the ``--device`` option to docker run.
          If you're using tasks that use the Fargate launch type, the ``devices`` parameter isn't supported.
        """
        init_process_enabled: NotRequired[pulumi.Input[_builtins.bool]]
        """
        Run an ``init`` process inside the container that forwards signals and reaps processes. This parameter maps to the ``--init`` option to docker run. This parameter requires version 1.25 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
        """
        max_swap: NotRequired[pulumi.Input[_builtins.int]]
        """
        The total amount of swap memory (in MiB) a container can use. This parameter will be translated to the ``--memory-swap`` option to docker run where the value would be the sum of the container memory plus the ``maxSwap`` value.
         If a ``maxSwap`` value of ``0`` is specified, the container will not use swap. Accepted values are ``0`` or any positive integer. If the ``maxSwap`` parameter is omitted, the container will use the swap configuration for the container instance it is running on. A ``maxSwap`` value must be set for the ``swappiness`` parameter to be used.
          If you're using tasks that use the Fargate launch type, the ``maxSwap`` parameter isn't supported.
         If you're using tasks on Amazon Linux 2023 the ``swappiness`` parameter isn't supported.
        """
        shared_memory_size: NotRequired[pulumi.Input[_builtins.int]]
        """
        The value for the size (in MiB) of the ``/dev/shm`` volume. This parameter maps to the ``--shm-size`` option to docker run.
          If you are using tasks that use the Fargate launch type, the ``sharedMemorySize`` parameter is not supported.
        """
        swappiness: NotRequired[pulumi.Input[_builtins.int]]
        """
        This allows you to tune a container's memory swappiness behavior. A ``swappiness`` value of ``0`` will cause swapping to not happen unless absolutely necessary. A ``swappiness`` value of ``100`` will cause pages to be swapped very aggressively. Accepted values are whole numbers between ``0`` and ``100``. If the ``swappiness`` parameter is not specified, a default value of ``60`` is used. If a value is not specified for ``maxSwap`` then this parameter is ignored. This parameter maps to the ``--memory-swappiness`` option to docker run.
          If you're using tasks that use the Fargate launch type, the ``swappiness`` parameter isn't supported.
         If you're using tasks on Amazon Linux 2023 the ``swappiness`` parameter isn't supported.
        """
        tmpfs: NotRequired[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionTmpfsArgsDict']]]]
        """
        The container path, mount options, and size (in MiB) of the tmpfs mount. This parameter maps to the ``--tmpfs`` option to docker run.
          If you're using tasks that use the Fargate launch type, the ``tmpfs`` parameter isn't supported.
        """
elif False:
    TaskDefinitionLinuxParametersArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionLinuxParametersArgs:
    def __init__(__self__, *,
                 capabilities: Optional[pulumi.Input['TaskDefinitionKernelCapabilitiesArgs']] = None,
                 devices: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionDeviceArgs']]]] = None,
                 init_process_enabled: Optional[pulumi.Input[_builtins.bool]] = None,
                 max_swap: Optional[pulumi.Input[_builtins.int]] = None,
                 shared_memory_size: Optional[pulumi.Input[_builtins.int]] = None,
                 swappiness: Optional[pulumi.Input[_builtins.int]] = None,
                 tmpfs: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionTmpfsArgs']]]] = None):
        """
        The Linux-specific options that are applied to the container, such as Linux [KernelCapabilities](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_KernelCapabilities.html).
        :param pulumi.Input['TaskDefinitionKernelCapabilitiesArgs'] capabilities: The Linux capabilities for the container that are added to or dropped from the default configuration provided by Docker.
                 For tasks that use the Fargate launch type, ``capabilities`` is supported for all platform versions but the ``add`` parameter is only supported if using platform version 1.4.0 or later.
        :param pulumi.Input[Sequence[pulumi.Input['TaskDefinitionDeviceArgs']]] devices: Any host devices to expose to the container. This parameter maps to ``Devices`` in the docker container create command and the ``--device`` option to docker run.
                 If you're using tasks that use the Fargate launch type, the ``devices`` parameter isn't supported.
        :param pulumi.Input[_builtins.bool] init_process_enabled: Run an ``init`` process inside the container that forwards signals and reaps processes. This parameter maps to the ``--init`` option to docker run. This parameter requires version 1.25 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
        :param pulumi.Input[_builtins.int] max_swap: The total amount of swap memory (in MiB) a container can use. This parameter will be translated to the ``--memory-swap`` option to docker run where the value would be the sum of the container memory plus the ``maxSwap`` value.
                If a ``maxSwap`` value of ``0`` is specified, the container will not use swap. Accepted values are ``0`` or any positive integer. If the ``maxSwap`` parameter is omitted, the container will use the swap configuration for the container instance it is running on. A ``maxSwap`` value must be set for the ``swappiness`` parameter to be used.
                 If you're using tasks that use the Fargate launch type, the ``maxSwap`` parameter isn't supported.
                If you're using tasks on Amazon Linux 2023 the ``swappiness`` parameter isn't supported.
        :param pulumi.Input[_builtins.int] shared_memory_size: The value for the size (in MiB) of the ``/dev/shm`` volume. This parameter maps to the ``--shm-size`` option to docker run.
                 If you are using tasks that use the Fargate launch type, the ``sharedMemorySize`` parameter is not supported.
        :param pulumi.Input[_builtins.int] swappiness: This allows you to tune a container's memory swappiness behavior. A ``swappiness`` value of ``0`` will cause swapping to not happen unless absolutely necessary. A ``swappiness`` value of ``100`` will cause pages to be swapped very aggressively. Accepted values are whole numbers between ``0`` and ``100``. If the ``swappiness`` parameter is not specified, a default value of ``60`` is used. If a value is not specified for ``maxSwap`` then this parameter is ignored. This parameter maps to the ``--memory-swappiness`` option to docker run.
                 If you're using tasks that use the Fargate launch type, the ``swappiness`` parameter isn't supported.
                If you're using tasks on Amazon Linux 2023 the ``swappiness`` parameter isn't supported.
        :param pulumi.Input[Sequence[pulumi.Input['TaskDefinitionTmpfsArgs']]] tmpfs: The container path, mount options, and size (in MiB) of the tmpfs mount. This parameter maps to the ``--tmpfs`` option to docker run.
                 If you're using tasks that use the Fargate launch type, the ``tmpfs`` parameter isn't supported.
        """
        if capabilities is not None:
            pulumi.set(__self__, "capabilities", capabilities)
        if devices is not None:
            pulumi.set(__self__, "devices", devices)
        if init_process_enabled is not None:
            pulumi.set(__self__, "init_process_enabled", init_process_enabled)
        if max_swap is not None:
            pulumi.set(__self__, "max_swap", max_swap)
        if shared_memory_size is not None:
            pulumi.set(__self__, "shared_memory_size", shared_memory_size)
        if swappiness is not None:
            pulumi.set(__self__, "swappiness", swappiness)
        if tmpfs is not None:
            pulumi.set(__self__, "tmpfs", tmpfs)

    @_builtins.property
    @pulumi.getter
    def capabilities(self) -> Optional[pulumi.Input['TaskDefinitionKernelCapabilitiesArgs']]:
        """
        The Linux capabilities for the container that are added to or dropped from the default configuration provided by Docker.
          For tasks that use the Fargate launch type, ``capabilities`` is supported for all platform versions but the ``add`` parameter is only supported if using platform version 1.4.0 or later.
        """
        return pulumi.get(self, "capabilities")

    @capabilities.setter
    def capabilities(self, value: Optional[pulumi.Input['TaskDefinitionKernelCapabilitiesArgs']]):
        pulumi.set(self, "capabilities", value)

    @_builtins.property
    @pulumi.getter
    def devices(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionDeviceArgs']]]]:
        """
        Any host devices to expose to the container. This parameter maps to ``Devices`` in the docker container create command and the ``--device`` option to docker run.
          If you're using tasks that use the Fargate launch type, the ``devices`` parameter isn't supported.
        """
        return pulumi.get(self, "devices")

    @devices.setter
    def devices(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionDeviceArgs']]]]):
        pulumi.set(self, "devices", value)

    @_builtins.property
    @pulumi.getter(name="initProcessEnabled")
    def init_process_enabled(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Run an ``init`` process inside the container that forwards signals and reaps processes. This parameter maps to the ``--init`` option to docker run. This parameter requires version 1.25 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
        """
        return pulumi.get(self, "init_process_enabled")

    @init_process_enabled.setter
    def init_process_enabled(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "init_process_enabled", value)

    @_builtins.property
    @pulumi.getter(name="maxSwap")
    def max_swap(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The total amount of swap memory (in MiB) a container can use. This parameter will be translated to the ``--memory-swap`` option to docker run where the value would be the sum of the container memory plus the ``maxSwap`` value.
         If a ``maxSwap`` value of ``0`` is specified, the container will not use swap. Accepted values are ``0`` or any positive integer. If the ``maxSwap`` parameter is omitted, the container will use the swap configuration for the container instance it is running on. A ``maxSwap`` value must be set for the ``swappiness`` parameter to be used.
          If you're using tasks that use the Fargate launch type, the ``maxSwap`` parameter isn't supported.
         If you're using tasks on Amazon Linux 2023 the ``swappiness`` parameter isn't supported.
        """
        return pulumi.get(self, "max_swap")

    @max_swap.setter
    def max_swap(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "max_swap", value)

    @_builtins.property
    @pulumi.getter(name="sharedMemorySize")
    def shared_memory_size(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The value for the size (in MiB) of the ``/dev/shm`` volume. This parameter maps to the ``--shm-size`` option to docker run.
          If you are using tasks that use the Fargate launch type, the ``sharedMemorySize`` parameter is not supported.
        """
        return pulumi.get(self, "shared_memory_size")

    @shared_memory_size.setter
    def shared_memory_size(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "shared_memory_size", value)

    @_builtins.property
    @pulumi.getter
    def swappiness(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        This allows you to tune a container's memory swappiness behavior. A ``swappiness`` value of ``0`` will cause swapping to not happen unless absolutely necessary. A ``swappiness`` value of ``100`` will cause pages to be swapped very aggressively. Accepted values are whole numbers between ``0`` and ``100``. If the ``swappiness`` parameter is not specified, a default value of ``60`` is used. If a value is not specified for ``maxSwap`` then this parameter is ignored. This parameter maps to the ``--memory-swappiness`` option to docker run.
          If you're using tasks that use the Fargate launch type, the ``swappiness`` parameter isn't supported.
         If you're using tasks on Amazon Linux 2023 the ``swappiness`` parameter isn't supported.
        """
        return pulumi.get(self, "swappiness")

    @swappiness.setter
    def swappiness(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "swappiness", value)

    @_builtins.property
    @pulumi.getter
    def tmpfs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionTmpfsArgs']]]]:
        """
        The container path, mount options, and size (in MiB) of the tmpfs mount. This parameter maps to the ``--tmpfs`` option to docker run.
          If you're using tasks that use the Fargate launch type, the ``tmpfs`` parameter isn't supported.
        """
        return pulumi.get(self, "tmpfs")

    @tmpfs.setter
    def tmpfs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionTmpfsArgs']]]]):
        pulumi.set(self, "tmpfs", value)


if not MYPY:
    class TaskDefinitionLogConfigurationArgsDict(TypedDict):
        """
        The ``LogConfiguration`` property specifies log configuration options to send to a custom log driver for the container.
        """
        log_driver: pulumi.Input[_builtins.str]
        """
        The log driver to use for the container.
         For tasks on FARGATElong, the supported log drivers are ``awslogs``, ``splunk``, and ``awsfirelens``.
         For tasks hosted on Amazon EC2 instances, the supported log drivers are ``awslogs``, ``fluentd``, ``gelf``, ``json-file``, ``journald``, ``syslog``, ``splunk``, and ``awsfirelens``.
         For more information about using the ``awslogs`` log driver, see [Send Amazon ECS logs to CloudWatch](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_awslogs.html) in the *Amazon Elastic Container Service Developer Guide*.
         For more information about using the ``awsfirelens`` log driver, see [Send Amazon ECS logs to an service or Partner](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_firelens.html).
          If you have a custom driver that isn't listed, you can fork the Amazon ECS container agent project that's [available on GitHub](https://docs.aws.amazon.com/https://github.com/aws/amazon-ecs-agent) and customize it to work with that driver. We encourage you to submit pull requests for changes that you would like to have included. However, we don't currently provide support for running modified copies of this software.
        """
        options: NotRequired[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]
        """
        The configuration options to send to the log driver.
         The options you can specify depend on the log driver. Some of the options you can specify when you use the ``awslogs`` log driver to route logs to Amazon CloudWatch include the following:
          + awslogs-create-group Required: No Specify whether you want the log group to be created automatically. If this option isn't specified, it defaults to false. Your IAM policy must include the logs:CreateLogGroup permission before you attempt to use awslogs-create-group. + awslogs-region Required: Yes Specify the Region that the awslogs log driver is to send your Docker logs to. You can choose to send all of your logs from clusters in different Regions to a single region in CloudWatch Logs. This is so that they're all visible in one location. Otherwise, you can separate them by Region for more granularity. Make sure that the specified log group exists in the Region that you specify with this option. + awslogs-group Required: Yes Make sure to specify a log group that the awslogs log driver sends its log streams to. + awslogs-stream-prefix Required: Yes, when using Fargate.Optional when using EC2. Use the awslogs-stream-prefix option to associate a log stream with the specified prefix, the container name, and the ID of the Amazon ECS task that the container belongs to. If you specify a prefix with this option, then the log stream takes the format prefix-name/container-name/ecs-task-id. If you don't specify a prefix with this option, then the log stream is named after the container ID that's assigned by the Docker daemon on the container instance. Because it's difficult to trace logs back to the container that sent them with just the Docker container ID (which is only available on the container instance), we recommend that you specify a prefix with this option. For Amazon ECS services, you can use the service name as the prefix. Doing so, you can trace log streams to the service that the container belongs to, the name of the container that sent them, and the ID of the task that the container belongs to. You must specify a stream-prefix for your logs to have your logs appear in the Log pane when using the Amazon ECS console. + awslogs-datetime-format Required: No This option defines a multiline start pattern in Python strftime format. A log message consists of a line that matches the pattern and any following lines that dont match the pattern. The matched line is the delimiter between log messages. One example of a use case for using this format is for parsing output such as a stack dump, which might otherwise be logged in multiple entries. The correct pattern allows it to be captured in a single entry. For more information, see awslogs-datetime-format. You cannot configure both the awslogs-datetime-format and awslogs-multiline-pattern options. Multiline logging performs regular expression parsing and matching of all log messages. This might have a negative impact on logging performance. + awslogs-multiline-pattern Required: No This option defines a multiline start pattern that uses a regular expression. A log message consists of a line that matches the pattern and any following lines that dont match the pattern. The matched line is the delimiter between log messages. For more information, see awslogs-multiline-pattern. This option is ignored if awslogs-datetime-format is also configured. You cannot configure both the awslogs-datetime-format and awslogs-multiline-pattern options. Multiline logging performs regular expression parsing and matching of all log messages. This might have a negative impact on logging performance. 
         The following options apply to all supported log drivers.
          + mode Required: No Valid values: non-blocking | blocking This option defines the delivery mode of log messages from the container to the log driver specified using logDriver. The delivery mode you choose affects application availability when the flow of logs from container is interrupted. If you use the blocking mode and the flow of logs is interrupted, calls from container code to write to the stdout and stderr streams will block. The logging thread of the application will block as a result. This may cause the application to become unresponsive and lead to container healthcheck failure. If you use the non-blocking mode, the container's logs are instead stored in an in-memory intermediate buffer configured with the max-buffer-size option. This prevents the application from becoming unresponsive when logs cannot be sent. We recommend using this mode if you want to ensure service availability and are okay with some log loss. For more information, see Preventing log loss with non-blocking mode in the awslogs container log driver. You can set a default mode for all containers in a specific Region by using the defaultLogDriverMode account setting. If you don't specify the mode option or configure the account setting, Amazon ECS will default to the non-blocking mode. For more information about the account setting, see Default log driver mode in the Amazon Elastic Container Service Developer Guide. On June 25, 2025, Amazon ECS changed the default log driver mode from blocking to non-blocking to prioritize task availability over logging. To continue using the blocking mode after this change, do one of the following: Set the mode option in your container definition's logConfiguration as blocking. Set the defaultLogDriverMode account setting to blocking. + max-buffer-size Required: No Default value: 10m When non-blocking mode is used, the max-buffer-size log option controls the size of the buffer that's used for intermediate message storage. Make sure to specify an adequate buffer size based on your application. When the buffer fills up, further logs cannot be stored. Logs that cannot be stored are lost. 
         To route logs using the ``splunk`` log router, you need to specify a ``splunk-token`` and a ``splunk-url``.
         When you use the ``awsfirelens`` log router to route logs to an AWS Service or AWS Partner Network destination for log storage and analytics, you can set the ``log-driver-buffer-limit`` option to limit the number of events that are buffered in memory, before being sent to the log router container. It can help to resolve potential log loss issue because high throughput might result in memory running out for the buffer inside of Docker.
         Other options you can specify when using ``awsfirelens`` to route logs depend on the destination. When you export logs to Amazon Data Firehose, you can specify the AWS Region with ``region`` and a name for the log stream with ``delivery_stream``.
         When you export logs to Amazon Kinesis Data Streams, you can specify an AWS Region with ``region`` and a data stream name with ``stream``.
          When you export logs to Amazon OpenSearch Service, you can specify options like ``Name``, ``Host`` (OpenSearch Service endpoint without protocol), ``Port``, ``Index``, ``Type``, ``Aws_auth``, ``Aws_region``, ``Suppress_Type_Name``, and ``tls``. For more information, see [Under the hood: FireLens for Amazon ECS Tasks](https://docs.aws.amazon.com/containers/under-the-hood-firelens-for-amazon-ecs-tasks/).
         When you export logs to Amazon S3, you can specify the bucket using the ``bucket`` option. You can also specify ``region``, ``total_file_size``, ``upload_timeout``, and ``use_put_object`` as options.
         This parameter requires version 1.19 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
        """
        secret_options: NotRequired[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionSecretArgsDict']]]]
        """
        The secrets to pass to the log configuration. For more information, see [Specifying sensitive data](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
elif False:
    TaskDefinitionLogConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionLogConfigurationArgs:
    def __init__(__self__, *,
                 log_driver: pulumi.Input[_builtins.str],
                 options: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]] = None,
                 secret_options: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionSecretArgs']]]] = None):
        """
        The ``LogConfiguration`` property specifies log configuration options to send to a custom log driver for the container.
        :param pulumi.Input[_builtins.str] log_driver: The log driver to use for the container.
                For tasks on FARGATElong, the supported log drivers are ``awslogs``, ``splunk``, and ``awsfirelens``.
                For tasks hosted on Amazon EC2 instances, the supported log drivers are ``awslogs``, ``fluentd``, ``gelf``, ``json-file``, ``journald``, ``syslog``, ``splunk``, and ``awsfirelens``.
                For more information about using the ``awslogs`` log driver, see [Send Amazon ECS logs to CloudWatch](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_awslogs.html) in the *Amazon Elastic Container Service Developer Guide*.
                For more information about using the ``awsfirelens`` log driver, see [Send Amazon ECS logs to an service or Partner](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_firelens.html).
                 If you have a custom driver that isn't listed, you can fork the Amazon ECS container agent project that's [available on GitHub](https://docs.aws.amazon.com/https://github.com/aws/amazon-ecs-agent) and customize it to work with that driver. We encourage you to submit pull requests for changes that you would like to have included. However, we don't currently provide support for running modified copies of this software.
        :param pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]] options: The configuration options to send to the log driver.
                The options you can specify depend on the log driver. Some of the options you can specify when you use the ``awslogs`` log driver to route logs to Amazon CloudWatch include the following:
                 + awslogs-create-group Required: No Specify whether you want the log group to be created automatically. If this option isn't specified, it defaults to false. Your IAM policy must include the logs:CreateLogGroup permission before you attempt to use awslogs-create-group. + awslogs-region Required: Yes Specify the Region that the awslogs log driver is to send your Docker logs to. You can choose to send all of your logs from clusters in different Regions to a single region in CloudWatch Logs. This is so that they're all visible in one location. Otherwise, you can separate them by Region for more granularity. Make sure that the specified log group exists in the Region that you specify with this option. + awslogs-group Required: Yes Make sure to specify a log group that the awslogs log driver sends its log streams to. + awslogs-stream-prefix Required: Yes, when using Fargate.Optional when using EC2. Use the awslogs-stream-prefix option to associate a log stream with the specified prefix, the container name, and the ID of the Amazon ECS task that the container belongs to. If you specify a prefix with this option, then the log stream takes the format prefix-name/container-name/ecs-task-id. If you don't specify a prefix with this option, then the log stream is named after the container ID that's assigned by the Docker daemon on the container instance. Because it's difficult to trace logs back to the container that sent them with just the Docker container ID (which is only available on the container instance), we recommend that you specify a prefix with this option. For Amazon ECS services, you can use the service name as the prefix. Doing so, you can trace log streams to the service that the container belongs to, the name of the container that sent them, and the ID of the task that the container belongs to. You must specify a stream-prefix for your logs to have your logs appear in the Log pane when using the Amazon ECS console. + awslogs-datetime-format Required: No This option defines a multiline start pattern in Python strftime format. A log message consists of a line that matches the pattern and any following lines that dont match the pattern. The matched line is the delimiter between log messages. One example of a use case for using this format is for parsing output such as a stack dump, which might otherwise be logged in multiple entries. The correct pattern allows it to be captured in a single entry. For more information, see awslogs-datetime-format. You cannot configure both the awslogs-datetime-format and awslogs-multiline-pattern options. Multiline logging performs regular expression parsing and matching of all log messages. This might have a negative impact on logging performance. + awslogs-multiline-pattern Required: No This option defines a multiline start pattern that uses a regular expression. A log message consists of a line that matches the pattern and any following lines that dont match the pattern. The matched line is the delimiter between log messages. For more information, see awslogs-multiline-pattern. This option is ignored if awslogs-datetime-format is also configured. You cannot configure both the awslogs-datetime-format and awslogs-multiline-pattern options. Multiline logging performs regular expression parsing and matching of all log messages. This might have a negative impact on logging performance. 
                The following options apply to all supported log drivers.
                 + mode Required: No Valid values: non-blocking | blocking This option defines the delivery mode of log messages from the container to the log driver specified using logDriver. The delivery mode you choose affects application availability when the flow of logs from container is interrupted. If you use the blocking mode and the flow of logs is interrupted, calls from container code to write to the stdout and stderr streams will block. The logging thread of the application will block as a result. This may cause the application to become unresponsive and lead to container healthcheck failure. If you use the non-blocking mode, the container's logs are instead stored in an in-memory intermediate buffer configured with the max-buffer-size option. This prevents the application from becoming unresponsive when logs cannot be sent. We recommend using this mode if you want to ensure service availability and are okay with some log loss. For more information, see Preventing log loss with non-blocking mode in the awslogs container log driver. You can set a default mode for all containers in a specific Region by using the defaultLogDriverMode account setting. If you don't specify the mode option or configure the account setting, Amazon ECS will default to the non-blocking mode. For more information about the account setting, see Default log driver mode in the Amazon Elastic Container Service Developer Guide. On June 25, 2025, Amazon ECS changed the default log driver mode from blocking to non-blocking to prioritize task availability over logging. To continue using the blocking mode after this change, do one of the following: Set the mode option in your container definition's logConfiguration as blocking. Set the defaultLogDriverMode account setting to blocking. + max-buffer-size Required: No Default value: 10m When non-blocking mode is used, the max-buffer-size log option controls the size of the buffer that's used for intermediate message storage. Make sure to specify an adequate buffer size based on your application. When the buffer fills up, further logs cannot be stored. Logs that cannot be stored are lost. 
                To route logs using the ``splunk`` log router, you need to specify a ``splunk-token`` and a ``splunk-url``.
                When you use the ``awsfirelens`` log router to route logs to an AWS Service or AWS Partner Network destination for log storage and analytics, you can set the ``log-driver-buffer-limit`` option to limit the number of events that are buffered in memory, before being sent to the log router container. It can help to resolve potential log loss issue because high throughput might result in memory running out for the buffer inside of Docker.
                Other options you can specify when using ``awsfirelens`` to route logs depend on the destination. When you export logs to Amazon Data Firehose, you can specify the AWS Region with ``region`` and a name for the log stream with ``delivery_stream``.
                When you export logs to Amazon Kinesis Data Streams, you can specify an AWS Region with ``region`` and a data stream name with ``stream``.
                 When you export logs to Amazon OpenSearch Service, you can specify options like ``Name``, ``Host`` (OpenSearch Service endpoint without protocol), ``Port``, ``Index``, ``Type``, ``Aws_auth``, ``Aws_region``, ``Suppress_Type_Name``, and ``tls``. For more information, see [Under the hood: FireLens for Amazon ECS Tasks](https://docs.aws.amazon.com/containers/under-the-hood-firelens-for-amazon-ecs-tasks/).
                When you export logs to Amazon S3, you can specify the bucket using the ``bucket`` option. You can also specify ``region``, ``total_file_size``, ``upload_timeout``, and ``use_put_object`` as options.
                This parameter requires version 1.19 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
        :param pulumi.Input[Sequence[pulumi.Input['TaskDefinitionSecretArgs']]] secret_options: The secrets to pass to the log configuration. For more information, see [Specifying sensitive data](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        pulumi.set(__self__, "log_driver", log_driver)
        if options is not None:
            pulumi.set(__self__, "options", options)
        if secret_options is not None:
            pulumi.set(__self__, "secret_options", secret_options)

    @_builtins.property
    @pulumi.getter(name="logDriver")
    def log_driver(self) -> pulumi.Input[_builtins.str]:
        """
        The log driver to use for the container.
         For tasks on FARGATElong, the supported log drivers are ``awslogs``, ``splunk``, and ``awsfirelens``.
         For tasks hosted on Amazon EC2 instances, the supported log drivers are ``awslogs``, ``fluentd``, ``gelf``, ``json-file``, ``journald``, ``syslog``, ``splunk``, and ``awsfirelens``.
         For more information about using the ``awslogs`` log driver, see [Send Amazon ECS logs to CloudWatch](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_awslogs.html) in the *Amazon Elastic Container Service Developer Guide*.
         For more information about using the ``awsfirelens`` log driver, see [Send Amazon ECS logs to an service or Partner](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_firelens.html).
          If you have a custom driver that isn't listed, you can fork the Amazon ECS container agent project that's [available on GitHub](https://docs.aws.amazon.com/https://github.com/aws/amazon-ecs-agent) and customize it to work with that driver. We encourage you to submit pull requests for changes that you would like to have included. However, we don't currently provide support for running modified copies of this software.
        """
        return pulumi.get(self, "log_driver")

    @log_driver.setter
    def log_driver(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "log_driver", value)

    @_builtins.property
    @pulumi.getter
    def options(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]:
        """
        The configuration options to send to the log driver.
         The options you can specify depend on the log driver. Some of the options you can specify when you use the ``awslogs`` log driver to route logs to Amazon CloudWatch include the following:
          + awslogs-create-group Required: No Specify whether you want the log group to be created automatically. If this option isn't specified, it defaults to false. Your IAM policy must include the logs:CreateLogGroup permission before you attempt to use awslogs-create-group. + awslogs-region Required: Yes Specify the Region that the awslogs log driver is to send your Docker logs to. You can choose to send all of your logs from clusters in different Regions to a single region in CloudWatch Logs. This is so that they're all visible in one location. Otherwise, you can separate them by Region for more granularity. Make sure that the specified log group exists in the Region that you specify with this option. + awslogs-group Required: Yes Make sure to specify a log group that the awslogs log driver sends its log streams to. + awslogs-stream-prefix Required: Yes, when using Fargate.Optional when using EC2. Use the awslogs-stream-prefix option to associate a log stream with the specified prefix, the container name, and the ID of the Amazon ECS task that the container belongs to. If you specify a prefix with this option, then the log stream takes the format prefix-name/container-name/ecs-task-id. If you don't specify a prefix with this option, then the log stream is named after the container ID that's assigned by the Docker daemon on the container instance. Because it's difficult to trace logs back to the container that sent them with just the Docker container ID (which is only available on the container instance), we recommend that you specify a prefix with this option. For Amazon ECS services, you can use the service name as the prefix. Doing so, you can trace log streams to the service that the container belongs to, the name of the container that sent them, and the ID of the task that the container belongs to. You must specify a stream-prefix for your logs to have your logs appear in the Log pane when using the Amazon ECS console. + awslogs-datetime-format Required: No This option defines a multiline start pattern in Python strftime format. A log message consists of a line that matches the pattern and any following lines that dont match the pattern. The matched line is the delimiter between log messages. One example of a use case for using this format is for parsing output such as a stack dump, which might otherwise be logged in multiple entries. The correct pattern allows it to be captured in a single entry. For more information, see awslogs-datetime-format. You cannot configure both the awslogs-datetime-format and awslogs-multiline-pattern options. Multiline logging performs regular expression parsing and matching of all log messages. This might have a negative impact on logging performance. + awslogs-multiline-pattern Required: No This option defines a multiline start pattern that uses a regular expression. A log message consists of a line that matches the pattern and any following lines that dont match the pattern. The matched line is the delimiter between log messages. For more information, see awslogs-multiline-pattern. This option is ignored if awslogs-datetime-format is also configured. You cannot configure both the awslogs-datetime-format and awslogs-multiline-pattern options. Multiline logging performs regular expression parsing and matching of all log messages. This might have a negative impact on logging performance. 
         The following options apply to all supported log drivers.
          + mode Required: No Valid values: non-blocking | blocking This option defines the delivery mode of log messages from the container to the log driver specified using logDriver. The delivery mode you choose affects application availability when the flow of logs from container is interrupted. If you use the blocking mode and the flow of logs is interrupted, calls from container code to write to the stdout and stderr streams will block. The logging thread of the application will block as a result. This may cause the application to become unresponsive and lead to container healthcheck failure. If you use the non-blocking mode, the container's logs are instead stored in an in-memory intermediate buffer configured with the max-buffer-size option. This prevents the application from becoming unresponsive when logs cannot be sent. We recommend using this mode if you want to ensure service availability and are okay with some log loss. For more information, see Preventing log loss with non-blocking mode in the awslogs container log driver. You can set a default mode for all containers in a specific Region by using the defaultLogDriverMode account setting. If you don't specify the mode option or configure the account setting, Amazon ECS will default to the non-blocking mode. For more information about the account setting, see Default log driver mode in the Amazon Elastic Container Service Developer Guide. On June 25, 2025, Amazon ECS changed the default log driver mode from blocking to non-blocking to prioritize task availability over logging. To continue using the blocking mode after this change, do one of the following: Set the mode option in your container definition's logConfiguration as blocking. Set the defaultLogDriverMode account setting to blocking. + max-buffer-size Required: No Default value: 10m When non-blocking mode is used, the max-buffer-size log option controls the size of the buffer that's used for intermediate message storage. Make sure to specify an adequate buffer size based on your application. When the buffer fills up, further logs cannot be stored. Logs that cannot be stored are lost. 
         To route logs using the ``splunk`` log router, you need to specify a ``splunk-token`` and a ``splunk-url``.
         When you use the ``awsfirelens`` log router to route logs to an AWS Service or AWS Partner Network destination for log storage and analytics, you can set the ``log-driver-buffer-limit`` option to limit the number of events that are buffered in memory, before being sent to the log router container. It can help to resolve potential log loss issue because high throughput might result in memory running out for the buffer inside of Docker.
         Other options you can specify when using ``awsfirelens`` to route logs depend on the destination. When you export logs to Amazon Data Firehose, you can specify the AWS Region with ``region`` and a name for the log stream with ``delivery_stream``.
         When you export logs to Amazon Kinesis Data Streams, you can specify an AWS Region with ``region`` and a data stream name with ``stream``.
          When you export logs to Amazon OpenSearch Service, you can specify options like ``Name``, ``Host`` (OpenSearch Service endpoint without protocol), ``Port``, ``Index``, ``Type``, ``Aws_auth``, ``Aws_region``, ``Suppress_Type_Name``, and ``tls``. For more information, see [Under the hood: FireLens for Amazon ECS Tasks](https://docs.aws.amazon.com/containers/under-the-hood-firelens-for-amazon-ecs-tasks/).
         When you export logs to Amazon S3, you can specify the bucket using the ``bucket`` option. You can also specify ``region``, ``total_file_size``, ``upload_timeout``, and ``use_put_object`` as options.
         This parameter requires version 1.19 of the Docker Remote API or greater on your container instance. To check the Docker Remote API version on your container instance, log in to your container instance and run the following command: ``sudo docker version --format '{{.Server.APIVersion}}'``
        """
        return pulumi.get(self, "options")

    @options.setter
    def options(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "options", value)

    @_builtins.property
    @pulumi.getter(name="secretOptions")
    def secret_options(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionSecretArgs']]]]:
        """
        The secrets to pass to the log configuration. For more information, see [Specifying sensitive data](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        return pulumi.get(self, "secret_options")

    @secret_options.setter
    def secret_options(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionSecretArgs']]]]):
        pulumi.set(self, "secret_options", value)


if not MYPY:
    class TaskDefinitionMountPointArgsDict(TypedDict):
        """
        The details for a volume mount point that's used in a container definition.
        """
        container_path: NotRequired[pulumi.Input[_builtins.str]]
        """
        The path on the container to mount the host volume at.
        """
        read_only: NotRequired[pulumi.Input[_builtins.bool]]
        """
        If this value is ``true``, the container has read-only access to the volume. If this value is ``false``, then the container can write to the volume. The default value is ``false``.
        """
        source_volume: NotRequired[pulumi.Input[_builtins.str]]
        """
        The name of the volume to mount. Must be a volume name referenced in the ``name`` parameter of task definition ``volume``.
        """
elif False:
    TaskDefinitionMountPointArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionMountPointArgs:
    def __init__(__self__, *,
                 container_path: Optional[pulumi.Input[_builtins.str]] = None,
                 read_only: Optional[pulumi.Input[_builtins.bool]] = None,
                 source_volume: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The details for a volume mount point that's used in a container definition.
        :param pulumi.Input[_builtins.str] container_path: The path on the container to mount the host volume at.
        :param pulumi.Input[_builtins.bool] read_only: If this value is ``true``, the container has read-only access to the volume. If this value is ``false``, then the container can write to the volume. The default value is ``false``.
        :param pulumi.Input[_builtins.str] source_volume: The name of the volume to mount. Must be a volume name referenced in the ``name`` parameter of task definition ``volume``.
        """
        if container_path is not None:
            pulumi.set(__self__, "container_path", container_path)
        if read_only is not None:
            pulumi.set(__self__, "read_only", read_only)
        if source_volume is not None:
            pulumi.set(__self__, "source_volume", source_volume)

    @_builtins.property
    @pulumi.getter(name="containerPath")
    def container_path(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The path on the container to mount the host volume at.
        """
        return pulumi.get(self, "container_path")

    @container_path.setter
    def container_path(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "container_path", value)

    @_builtins.property
    @pulumi.getter(name="readOnly")
    def read_only(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        If this value is ``true``, the container has read-only access to the volume. If this value is ``false``, then the container can write to the volume. The default value is ``false``.
        """
        return pulumi.get(self, "read_only")

    @read_only.setter
    def read_only(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "read_only", value)

    @_builtins.property
    @pulumi.getter(name="sourceVolume")
    def source_volume(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The name of the volume to mount. Must be a volume name referenced in the ``name`` parameter of task definition ``volume``.
        """
        return pulumi.get(self, "source_volume")

    @source_volume.setter
    def source_volume(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "source_volume", value)


if not MYPY:
    class TaskDefinitionPlacementConstraintArgsDict(TypedDict):
        """
        The constraint on task placement in the task definition. For more information, see [Task placement constraints](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-placement-constraints.html) in the *Amazon Elastic Container Service Developer Guide*.
          Task placement constraints aren't supported for tasks run on FARGATElong.
        """
        type: pulumi.Input[_builtins.str]
        """
        The type of constraint. The ``MemberOf`` constraint restricts selection to be from a group of valid candidates.
        """
        expression: NotRequired[pulumi.Input[_builtins.str]]
        """
        A cluster query language expression to apply to the constraint. For more information, see [Cluster query language](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-query-language.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
elif False:
    TaskDefinitionPlacementConstraintArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionPlacementConstraintArgs:
    def __init__(__self__, *,
                 type: pulumi.Input[_builtins.str],
                 expression: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The constraint on task placement in the task definition. For more information, see [Task placement constraints](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-placement-constraints.html) in the *Amazon Elastic Container Service Developer Guide*.
          Task placement constraints aren't supported for tasks run on FARGATElong.
        :param pulumi.Input[_builtins.str] type: The type of constraint. The ``MemberOf`` constraint restricts selection to be from a group of valid candidates.
        :param pulumi.Input[_builtins.str] expression: A cluster query language expression to apply to the constraint. For more information, see [Cluster query language](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-query-language.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        pulumi.set(__self__, "type", type)
        if expression is not None:
            pulumi.set(__self__, "expression", expression)

    @_builtins.property
    @pulumi.getter
    def type(self) -> pulumi.Input[_builtins.str]:
        """
        The type of constraint. The ``MemberOf`` constraint restricts selection to be from a group of valid candidates.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "type", value)

    @_builtins.property
    @pulumi.getter
    def expression(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        A cluster query language expression to apply to the constraint. For more information, see [Cluster query language](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-query-language.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        return pulumi.get(self, "expression")

    @expression.setter
    def expression(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "expression", value)


if not MYPY:
    class TaskDefinitionPortMappingArgsDict(TypedDict):
        """
        The ``PortMapping`` property specifies a port mapping. Port mappings allow containers to access ports on the host container instance to send or receive traffic. Port mappings are specified as part of the container definition.
         If you are using containers in a task with the ``awsvpc`` or ``host`` network mode, exposed ports should be specified using ``containerPort``. The ``hostPort`` can be left blank or it must be the same value as the ``containerPort``.
         After a task reaches the ``RUNNING`` status, manual and automatic host and container port assignments are visible in the ``networkBindings`` section of [DescribeTasks](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DescribeTasks.html) API responses.
        """
        app_protocol: NotRequired[pulumi.Input['TaskDefinitionPortMappingAppProtocol']]
        """
        The application protocol that's used for the port mapping. This parameter only applies to Service Connect. We recommend that you set this parameter to be consistent with the protocol that your application uses. If you set this parameter, Amazon ECS adds protocol-specific connection handling to the Service Connect proxy. If you set this parameter, Amazon ECS adds protocol-specific telemetry in the Amazon ECS console and CloudWatch.
         If you don't set a value for this parameter, then TCP is used. However, Amazon ECS doesn't add protocol-specific telemetry for TCP.
         ``appProtocol`` is immutable in a Service Connect service. Updating this field requires a service deletion and redeployment.
         Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        container_port: NotRequired[pulumi.Input[_builtins.int]]
        """
        The port number on the container that's bound to the user-specified or automatically assigned host port.
         If you use containers in a task with the ``awsvpc`` or ``host`` network mode, specify the exposed ports using ``containerPort``.
         If you use containers in a task with the ``bridge`` network mode and you specify a container port and not a host port, your container automatically receives a host port in the ephemeral port range. For more information, see ``hostPort``. Port mappings that are automatically assigned in this way do not count toward the 100 reserved ports limit of a container instance.
        """
        container_port_range: NotRequired[pulumi.Input[_builtins.str]]
        """
        The port number range on the container that's bound to the dynamically mapped host port range. 
         The following rules apply when you specify a ``containerPortRange``:
          +  You must use either the ``bridge`` network mode or the ``awsvpc`` network mode.
          +  This parameter is available for both the EC2 and FARGATElong launch types.
          +  This parameter is available for both the Linux and Windows operating systems.
          +  The container instance must have at least version 1.67.0 of the container agent and at least version 1.67.0-1 of the ``ecs-init`` package 
          +  You can specify a maximum of 100 port ranges per container.
          +  You do not specify a ``hostPortRange``. The value of the ``hostPortRange`` is set as follows:
          +  For containers in a task with the ``awsvpc`` network mode, the ``hostPortRange`` is set to the same value as the ``containerPortRange``. This is a static mapping strategy.
          +  For containers in a task with the ``bridge`` network mode, the Amazon ECS agent finds open host ports from the default ephemeral range and passes it to docker to bind them to the container ports.
          
          +  The ``containerPortRange`` valid values are between 1 and 65535.
          +  A port can only be included in one port mapping per container.
          +  You cannot specify overlapping port ranges.
          +  The first port in the range must be less than last port in the range.
          +  Docker recommends that you turn off the docker-proxy in the Docker daemon config file when you have a large number of ports.
         For more information, see [Issue #11185](https://docs.aws.amazon.com/https://github.com/moby/moby/issues/11185) on the Github website.
         For information about how to turn off the docker-proxy in the Docker daemon config file, see [Docker daemon](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/bootstrap_container_instance.html#bootstrap_docker_daemon) in the *Amazon ECS Developer Guide*.
          
         You can call [DescribeTasks](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DescribeTasks.html) to view the ``hostPortRange`` which are the host ports that are bound to the container ports.
        """
        host_port: NotRequired[pulumi.Input[_builtins.int]]
        """
        The port number on the container instance to reserve for your container.
         If you specify a ``containerPortRange``, leave this field empty and the value of the ``hostPort`` is set as follows:
          +  For containers in a task with the ``awsvpc`` network mode, the ``hostPort`` is set to the same value as the ``containerPort``. This is a static mapping strategy.
          +  For containers in a task with the ``bridge`` network mode, the Amazon ECS agent finds open ports on the host and automatically binds them to the container ports. This is a dynamic mapping strategy.
          
         If you use containers in a task with the ``awsvpc`` or ``host`` network mode, the ``hostPort`` can either be left blank or set to the same value as the ``containerPort``.
         If you use containers in a task with the ``bridge`` network mode, you can specify a non-reserved host port for your container port mapping, or you can omit the ``hostPort`` (or set it to ``0``) while specifying a ``containerPort`` and your container automatically receives a port in the ephemeral port range for your container instance operating system and Docker version.
         The default ephemeral port range for Docker version 1.6.0 and later is listed on the instance under ``/proc/sys/net/ipv4/ip_local_port_range``. If this kernel parameter is unavailable, the default ephemeral port range from 49153 through 65535 (Linux) or 49152 through 65535 (Windows) is used. Do not attempt to specify a host port in the ephemeral port range as these are reserved for automatic assignment. In general, ports below 32768 are outside of the ephemeral port range.
         The default reserved ports are 22 for SSH, the Docker ports 2375 and 2376, and the Amazon ECS container agent ports 51678-51680. Any host port that was previously specified in a running task is also reserved while the task is running. That is, after a task stops, the host port is released. The current reserved ports are displayed in the ``remainingResources`` of [DescribeContainerInstances](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DescribeContainerInstances.html) output. A container instance can have up to 100 reserved ports at a time. This number includes the default reserved ports. Automatically assigned ports aren't included in the 100 reserved ports quota.
        """
        name: NotRequired[pulumi.Input[_builtins.str]]
        """
        The name that's used for the port mapping. This parameter is the name that you use in the ``serviceConnectConfiguration`` and the ``vpcLatticeConfigurations`` of a service. The name can include up to 64 characters. The characters can include lowercase letters, numbers, underscores (_), and hyphens (-). The name can't start with a hyphen.
        """
        protocol: NotRequired[pulumi.Input[_builtins.str]]
        """
        The protocol used for the port mapping. Valid values are ``tcp`` and ``udp``. The default is ``tcp``. ``protocol`` is immutable in a Service Connect service. Updating this field requires a service deletion and redeployment.
        """
elif False:
    TaskDefinitionPortMappingArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionPortMappingArgs:
    def __init__(__self__, *,
                 app_protocol: Optional[pulumi.Input['TaskDefinitionPortMappingAppProtocol']] = None,
                 container_port: Optional[pulumi.Input[_builtins.int]] = None,
                 container_port_range: Optional[pulumi.Input[_builtins.str]] = None,
                 host_port: Optional[pulumi.Input[_builtins.int]] = None,
                 name: Optional[pulumi.Input[_builtins.str]] = None,
                 protocol: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The ``PortMapping`` property specifies a port mapping. Port mappings allow containers to access ports on the host container instance to send or receive traffic. Port mappings are specified as part of the container definition.
         If you are using containers in a task with the ``awsvpc`` or ``host`` network mode, exposed ports should be specified using ``containerPort``. The ``hostPort`` can be left blank or it must be the same value as the ``containerPort``.
         After a task reaches the ``RUNNING`` status, manual and automatic host and container port assignments are visible in the ``networkBindings`` section of [DescribeTasks](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DescribeTasks.html) API responses.
        :param pulumi.Input['TaskDefinitionPortMappingAppProtocol'] app_protocol: The application protocol that's used for the port mapping. This parameter only applies to Service Connect. We recommend that you set this parameter to be consistent with the protocol that your application uses. If you set this parameter, Amazon ECS adds protocol-specific connection handling to the Service Connect proxy. If you set this parameter, Amazon ECS adds protocol-specific telemetry in the Amazon ECS console and CloudWatch.
                If you don't set a value for this parameter, then TCP is used. However, Amazon ECS doesn't add protocol-specific telemetry for TCP.
                ``appProtocol`` is immutable in a Service Connect service. Updating this field requires a service deletion and redeployment.
                Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.int] container_port: The port number on the container that's bound to the user-specified or automatically assigned host port.
                If you use containers in a task with the ``awsvpc`` or ``host`` network mode, specify the exposed ports using ``containerPort``.
                If you use containers in a task with the ``bridge`` network mode and you specify a container port and not a host port, your container automatically receives a host port in the ephemeral port range. For more information, see ``hostPort``. Port mappings that are automatically assigned in this way do not count toward the 100 reserved ports limit of a container instance.
        :param pulumi.Input[_builtins.str] container_port_range: The port number range on the container that's bound to the dynamically mapped host port range. 
                The following rules apply when you specify a ``containerPortRange``:
                 +  You must use either the ``bridge`` network mode or the ``awsvpc`` network mode.
                 +  This parameter is available for both the EC2 and FARGATElong launch types.
                 +  This parameter is available for both the Linux and Windows operating systems.
                 +  The container instance must have at least version 1.67.0 of the container agent and at least version 1.67.0-1 of the ``ecs-init`` package 
                 +  You can specify a maximum of 100 port ranges per container.
                 +  You do not specify a ``hostPortRange``. The value of the ``hostPortRange`` is set as follows:
                 +  For containers in a task with the ``awsvpc`` network mode, the ``hostPortRange`` is set to the same value as the ``containerPortRange``. This is a static mapping strategy.
                 +  For containers in a task with the ``bridge`` network mode, the Amazon ECS agent finds open host ports from the default ephemeral range and passes it to docker to bind them to the container ports.
                 
                 +  The ``containerPortRange`` valid values are between 1 and 65535.
                 +  A port can only be included in one port mapping per container.
                 +  You cannot specify overlapping port ranges.
                 +  The first port in the range must be less than last port in the range.
                 +  Docker recommends that you turn off the docker-proxy in the Docker daemon config file when you have a large number of ports.
                For more information, see [Issue #11185](https://docs.aws.amazon.com/https://github.com/moby/moby/issues/11185) on the Github website.
                For information about how to turn off the docker-proxy in the Docker daemon config file, see [Docker daemon](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/bootstrap_container_instance.html#bootstrap_docker_daemon) in the *Amazon ECS Developer Guide*.
                 
                You can call [DescribeTasks](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DescribeTasks.html) to view the ``hostPortRange`` which are the host ports that are bound to the container ports.
        :param pulumi.Input[_builtins.int] host_port: The port number on the container instance to reserve for your container.
                If you specify a ``containerPortRange``, leave this field empty and the value of the ``hostPort`` is set as follows:
                 +  For containers in a task with the ``awsvpc`` network mode, the ``hostPort`` is set to the same value as the ``containerPort``. This is a static mapping strategy.
                 +  For containers in a task with the ``bridge`` network mode, the Amazon ECS agent finds open ports on the host and automatically binds them to the container ports. This is a dynamic mapping strategy.
                 
                If you use containers in a task with the ``awsvpc`` or ``host`` network mode, the ``hostPort`` can either be left blank or set to the same value as the ``containerPort``.
                If you use containers in a task with the ``bridge`` network mode, you can specify a non-reserved host port for your container port mapping, or you can omit the ``hostPort`` (or set it to ``0``) while specifying a ``containerPort`` and your container automatically receives a port in the ephemeral port range for your container instance operating system and Docker version.
                The default ephemeral port range for Docker version 1.6.0 and later is listed on the instance under ``/proc/sys/net/ipv4/ip_local_port_range``. If this kernel parameter is unavailable, the default ephemeral port range from 49153 through 65535 (Linux) or 49152 through 65535 (Windows) is used. Do not attempt to specify a host port in the ephemeral port range as these are reserved for automatic assignment. In general, ports below 32768 are outside of the ephemeral port range.
                The default reserved ports are 22 for SSH, the Docker ports 2375 and 2376, and the Amazon ECS container agent ports 51678-51680. Any host port that was previously specified in a running task is also reserved while the task is running. That is, after a task stops, the host port is released. The current reserved ports are displayed in the ``remainingResources`` of [DescribeContainerInstances](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DescribeContainerInstances.html) output. A container instance can have up to 100 reserved ports at a time. This number includes the default reserved ports. Automatically assigned ports aren't included in the 100 reserved ports quota.
        :param pulumi.Input[_builtins.str] name: The name that's used for the port mapping. This parameter is the name that you use in the ``serviceConnectConfiguration`` and the ``vpcLatticeConfigurations`` of a service. The name can include up to 64 characters. The characters can include lowercase letters, numbers, underscores (_), and hyphens (-). The name can't start with a hyphen.
        :param pulumi.Input[_builtins.str] protocol: The protocol used for the port mapping. Valid values are ``tcp`` and ``udp``. The default is ``tcp``. ``protocol`` is immutable in a Service Connect service. Updating this field requires a service deletion and redeployment.
        """
        if app_protocol is not None:
            pulumi.set(__self__, "app_protocol", app_protocol)
        if container_port is not None:
            pulumi.set(__self__, "container_port", container_port)
        if container_port_range is not None:
            pulumi.set(__self__, "container_port_range", container_port_range)
        if host_port is not None:
            pulumi.set(__self__, "host_port", host_port)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if protocol is not None:
            pulumi.set(__self__, "protocol", protocol)

    @_builtins.property
    @pulumi.getter(name="appProtocol")
    def app_protocol(self) -> Optional[pulumi.Input['TaskDefinitionPortMappingAppProtocol']]:
        """
        The application protocol that's used for the port mapping. This parameter only applies to Service Connect. We recommend that you set this parameter to be consistent with the protocol that your application uses. If you set this parameter, Amazon ECS adds protocol-specific connection handling to the Service Connect proxy. If you set this parameter, Amazon ECS adds protocol-specific telemetry in the Amazon ECS console and CloudWatch.
         If you don't set a value for this parameter, then TCP is used. However, Amazon ECS doesn't add protocol-specific telemetry for TCP.
         ``appProtocol`` is immutable in a Service Connect service. Updating this field requires a service deletion and redeployment.
         Tasks that run in a namespace can use short names to connect to services in the namespace. Tasks can connect to services across all of the clusters in the namespace. Tasks connect through a managed proxy container that collects logs and metrics for increased visibility. Only the tasks that Amazon ECS services create are supported with Service Connect. For more information, see [Service Connect](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-connect.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        return pulumi.get(self, "app_protocol")

    @app_protocol.setter
    def app_protocol(self, value: Optional[pulumi.Input['TaskDefinitionPortMappingAppProtocol']]):
        pulumi.set(self, "app_protocol", value)

    @_builtins.property
    @pulumi.getter(name="containerPort")
    def container_port(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The port number on the container that's bound to the user-specified or automatically assigned host port.
         If you use containers in a task with the ``awsvpc`` or ``host`` network mode, specify the exposed ports using ``containerPort``.
         If you use containers in a task with the ``bridge`` network mode and you specify a container port and not a host port, your container automatically receives a host port in the ephemeral port range. For more information, see ``hostPort``. Port mappings that are automatically assigned in this way do not count toward the 100 reserved ports limit of a container instance.
        """
        return pulumi.get(self, "container_port")

    @container_port.setter
    def container_port(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "container_port", value)

    @_builtins.property
    @pulumi.getter(name="containerPortRange")
    def container_port_range(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The port number range on the container that's bound to the dynamically mapped host port range. 
         The following rules apply when you specify a ``containerPortRange``:
          +  You must use either the ``bridge`` network mode or the ``awsvpc`` network mode.
          +  This parameter is available for both the EC2 and FARGATElong launch types.
          +  This parameter is available for both the Linux and Windows operating systems.
          +  The container instance must have at least version 1.67.0 of the container agent and at least version 1.67.0-1 of the ``ecs-init`` package 
          +  You can specify a maximum of 100 port ranges per container.
          +  You do not specify a ``hostPortRange``. The value of the ``hostPortRange`` is set as follows:
          +  For containers in a task with the ``awsvpc`` network mode, the ``hostPortRange`` is set to the same value as the ``containerPortRange``. This is a static mapping strategy.
          +  For containers in a task with the ``bridge`` network mode, the Amazon ECS agent finds open host ports from the default ephemeral range and passes it to docker to bind them to the container ports.
          
          +  The ``containerPortRange`` valid values are between 1 and 65535.
          +  A port can only be included in one port mapping per container.
          +  You cannot specify overlapping port ranges.
          +  The first port in the range must be less than last port in the range.
          +  Docker recommends that you turn off the docker-proxy in the Docker daemon config file when you have a large number of ports.
         For more information, see [Issue #11185](https://docs.aws.amazon.com/https://github.com/moby/moby/issues/11185) on the Github website.
         For information about how to turn off the docker-proxy in the Docker daemon config file, see [Docker daemon](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/bootstrap_container_instance.html#bootstrap_docker_daemon) in the *Amazon ECS Developer Guide*.
          
         You can call [DescribeTasks](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DescribeTasks.html) to view the ``hostPortRange`` which are the host ports that are bound to the container ports.
        """
        return pulumi.get(self, "container_port_range")

    @container_port_range.setter
    def container_port_range(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "container_port_range", value)

    @_builtins.property
    @pulumi.getter(name="hostPort")
    def host_port(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The port number on the container instance to reserve for your container.
         If you specify a ``containerPortRange``, leave this field empty and the value of the ``hostPort`` is set as follows:
          +  For containers in a task with the ``awsvpc`` network mode, the ``hostPort`` is set to the same value as the ``containerPort``. This is a static mapping strategy.
          +  For containers in a task with the ``bridge`` network mode, the Amazon ECS agent finds open ports on the host and automatically binds them to the container ports. This is a dynamic mapping strategy.
          
         If you use containers in a task with the ``awsvpc`` or ``host`` network mode, the ``hostPort`` can either be left blank or set to the same value as the ``containerPort``.
         If you use containers in a task with the ``bridge`` network mode, you can specify a non-reserved host port for your container port mapping, or you can omit the ``hostPort`` (or set it to ``0``) while specifying a ``containerPort`` and your container automatically receives a port in the ephemeral port range for your container instance operating system and Docker version.
         The default ephemeral port range for Docker version 1.6.0 and later is listed on the instance under ``/proc/sys/net/ipv4/ip_local_port_range``. If this kernel parameter is unavailable, the default ephemeral port range from 49153 through 65535 (Linux) or 49152 through 65535 (Windows) is used. Do not attempt to specify a host port in the ephemeral port range as these are reserved for automatic assignment. In general, ports below 32768 are outside of the ephemeral port range.
         The default reserved ports are 22 for SSH, the Docker ports 2375 and 2376, and the Amazon ECS container agent ports 51678-51680. Any host port that was previously specified in a running task is also reserved while the task is running. That is, after a task stops, the host port is released. The current reserved ports are displayed in the ``remainingResources`` of [DescribeContainerInstances](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DescribeContainerInstances.html) output. A container instance can have up to 100 reserved ports at a time. This number includes the default reserved ports. Automatically assigned ports aren't included in the 100 reserved ports quota.
        """
        return pulumi.get(self, "host_port")

    @host_port.setter
    def host_port(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "host_port", value)

    @_builtins.property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The name that's used for the port mapping. This parameter is the name that you use in the ``serviceConnectConfiguration`` and the ``vpcLatticeConfigurations`` of a service. The name can include up to 64 characters. The characters can include lowercase letters, numbers, underscores (_), and hyphens (-). The name can't start with a hyphen.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "name", value)

    @_builtins.property
    @pulumi.getter
    def protocol(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The protocol used for the port mapping. Valid values are ``tcp`` and ``udp``. The default is ``tcp``. ``protocol`` is immutable in a Service Connect service. Updating this field requires a service deletion and redeployment.
        """
        return pulumi.get(self, "protocol")

    @protocol.setter
    def protocol(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "protocol", value)


if not MYPY:
    class TaskDefinitionProxyConfigurationArgsDict(TypedDict):
        """
        The configuration details for the App Mesh proxy.
         For tasks that use the EC2 launch type, the container instances require at least version 1.26.0 of the container agent and at least version 1.26.0-1 of the ``ecs-init`` package to use a proxy configuration. If your container instances are launched from the Amazon ECS optimized AMI version ``20190301`` or later, then they contain the required versions of the container agent and ``ecs-init``. For more information, see [Amazon ECS-optimized Linux AMI](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html)
        """
        container_name: pulumi.Input[_builtins.str]
        """
        The name of the container that will serve as the App Mesh proxy.
        """
        proxy_configuration_properties: NotRequired[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionKeyValuePairArgsDict']]]]
        """
        The set of network configuration parameters to provide the Container Network Interface (CNI) plugin, specified as key-value pairs.
          +  ``IgnoredUID`` - (Required) The user ID (UID) of the proxy container as defined by the ``user`` parameter in a container definition. This is used to ensure the proxy ignores its own traffic. If ``IgnoredGID`` is specified, this field can be empty.
          +  ``IgnoredGID`` - (Required) The group ID (GID) of the proxy container as defined by the ``user`` parameter in a container definition. This is used to ensure the proxy ignores its own traffic. If ``IgnoredUID`` is specified, this field can be empty.
          +  ``AppPorts`` - (Required) The list of ports that the application uses. Network traffic to these ports is forwarded to the ``ProxyIngressPort`` and ``ProxyEgressPort``.
          +  ``ProxyIngressPort`` - (Required) Specifies the port that incoming traffic to the ``AppPorts`` is directed to.
          +  ``ProxyEgressPort`` - (Required) Specifies the port that outgoing traffic from the ``AppPorts`` is directed to.
          +  ``EgressIgnoredPorts`` - (Required) The egress traffic going to the specified ports is ignored and not redirected to the ``ProxyEgressPort``. It can be an empty list.
          +  ``EgressIgnoredIPs`` - (Required) The egress traffic going to the specified IP addresses is ignored and not redirected to the ``ProxyEgressPort``. It can be an empty list.
        """
        type: NotRequired[pulumi.Input[_builtins.str]]
        """
        The proxy type. The only supported value is ``APPMESH``.
        """
elif False:
    TaskDefinitionProxyConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionProxyConfigurationArgs:
    def __init__(__self__, *,
                 container_name: pulumi.Input[_builtins.str],
                 proxy_configuration_properties: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionKeyValuePairArgs']]]] = None,
                 type: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The configuration details for the App Mesh proxy.
         For tasks that use the EC2 launch type, the container instances require at least version 1.26.0 of the container agent and at least version 1.26.0-1 of the ``ecs-init`` package to use a proxy configuration. If your container instances are launched from the Amazon ECS optimized AMI version ``20190301`` or later, then they contain the required versions of the container agent and ``ecs-init``. For more information, see [Amazon ECS-optimized Linux AMI](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html)
        :param pulumi.Input[_builtins.str] container_name: The name of the container that will serve as the App Mesh proxy.
        :param pulumi.Input[Sequence[pulumi.Input['TaskDefinitionKeyValuePairArgs']]] proxy_configuration_properties: The set of network configuration parameters to provide the Container Network Interface (CNI) plugin, specified as key-value pairs.
                 +  ``IgnoredUID`` - (Required) The user ID (UID) of the proxy container as defined by the ``user`` parameter in a container definition. This is used to ensure the proxy ignores its own traffic. If ``IgnoredGID`` is specified, this field can be empty.
                 +  ``IgnoredGID`` - (Required) The group ID (GID) of the proxy container as defined by the ``user`` parameter in a container definition. This is used to ensure the proxy ignores its own traffic. If ``IgnoredUID`` is specified, this field can be empty.
                 +  ``AppPorts`` - (Required) The list of ports that the application uses. Network traffic to these ports is forwarded to the ``ProxyIngressPort`` and ``ProxyEgressPort``.
                 +  ``ProxyIngressPort`` - (Required) Specifies the port that incoming traffic to the ``AppPorts`` is directed to.
                 +  ``ProxyEgressPort`` - (Required) Specifies the port that outgoing traffic from the ``AppPorts`` is directed to.
                 +  ``EgressIgnoredPorts`` - (Required) The egress traffic going to the specified ports is ignored and not redirected to the ``ProxyEgressPort``. It can be an empty list.
                 +  ``EgressIgnoredIPs`` - (Required) The egress traffic going to the specified IP addresses is ignored and not redirected to the ``ProxyEgressPort``. It can be an empty list.
        :param pulumi.Input[_builtins.str] type: The proxy type. The only supported value is ``APPMESH``.
        """
        pulumi.set(__self__, "container_name", container_name)
        if proxy_configuration_properties is not None:
            pulumi.set(__self__, "proxy_configuration_properties", proxy_configuration_properties)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter(name="containerName")
    def container_name(self) -> pulumi.Input[_builtins.str]:
        """
        The name of the container that will serve as the App Mesh proxy.
        """
        return pulumi.get(self, "container_name")

    @container_name.setter
    def container_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "container_name", value)

    @_builtins.property
    @pulumi.getter(name="proxyConfigurationProperties")
    def proxy_configuration_properties(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionKeyValuePairArgs']]]]:
        """
        The set of network configuration parameters to provide the Container Network Interface (CNI) plugin, specified as key-value pairs.
          +  ``IgnoredUID`` - (Required) The user ID (UID) of the proxy container as defined by the ``user`` parameter in a container definition. This is used to ensure the proxy ignores its own traffic. If ``IgnoredGID`` is specified, this field can be empty.
          +  ``IgnoredGID`` - (Required) The group ID (GID) of the proxy container as defined by the ``user`` parameter in a container definition. This is used to ensure the proxy ignores its own traffic. If ``IgnoredUID`` is specified, this field can be empty.
          +  ``AppPorts`` - (Required) The list of ports that the application uses. Network traffic to these ports is forwarded to the ``ProxyIngressPort`` and ``ProxyEgressPort``.
          +  ``ProxyIngressPort`` - (Required) Specifies the port that incoming traffic to the ``AppPorts`` is directed to.
          +  ``ProxyEgressPort`` - (Required) Specifies the port that outgoing traffic from the ``AppPorts`` is directed to.
          +  ``EgressIgnoredPorts`` - (Required) The egress traffic going to the specified ports is ignored and not redirected to the ``ProxyEgressPort``. It can be an empty list.
          +  ``EgressIgnoredIPs`` - (Required) The egress traffic going to the specified IP addresses is ignored and not redirected to the ``ProxyEgressPort``. It can be an empty list.
        """
        return pulumi.get(self, "proxy_configuration_properties")

    @proxy_configuration_properties.setter
    def proxy_configuration_properties(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['TaskDefinitionKeyValuePairArgs']]]]):
        pulumi.set(self, "proxy_configuration_properties", value)

    @_builtins.property
    @pulumi.getter
    def type(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The proxy type. The only supported value is ``APPMESH``.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "type", value)


if not MYPY:
    class TaskDefinitionRepositoryCredentialsArgsDict(TypedDict):
        """
        The repository credentials for private registry authentication.
        """
        credentials_parameter: NotRequired[pulumi.Input[_builtins.str]]
        """
        The Amazon Resource Name (ARN) of the secret containing the private repository credentials.
          When you use the Amazon ECS API, CLI, or AWS SDK, if the secret exists in the same Region as the task that you're launching then you can use either the full ARN or the name of the secret. When you use the AWS Management Console, you must specify the full ARN of the secret.
        """
elif False:
    TaskDefinitionRepositoryCredentialsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionRepositoryCredentialsArgs:
    def __init__(__self__, *,
                 credentials_parameter: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The repository credentials for private registry authentication.
        :param pulumi.Input[_builtins.str] credentials_parameter: The Amazon Resource Name (ARN) of the secret containing the private repository credentials.
                 When you use the Amazon ECS API, CLI, or AWS SDK, if the secret exists in the same Region as the task that you're launching then you can use either the full ARN or the name of the secret. When you use the AWS Management Console, you must specify the full ARN of the secret.
        """
        if credentials_parameter is not None:
            pulumi.set(__self__, "credentials_parameter", credentials_parameter)

    @_builtins.property
    @pulumi.getter(name="credentialsParameter")
    def credentials_parameter(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The Amazon Resource Name (ARN) of the secret containing the private repository credentials.
          When you use the Amazon ECS API, CLI, or AWS SDK, if the secret exists in the same Region as the task that you're launching then you can use either the full ARN or the name of the secret. When you use the AWS Management Console, you must specify the full ARN of the secret.
        """
        return pulumi.get(self, "credentials_parameter")

    @credentials_parameter.setter
    def credentials_parameter(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "credentials_parameter", value)


if not MYPY:
    class TaskDefinitionResourceRequirementArgsDict(TypedDict):
        """
        The type and amount of a resource to assign to a container. The supported resource types are GPUs and Elastic Inference accelerators. For more information, see [Working with GPUs on Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-gpu.html) or [Working with Amazon Elastic Inference on Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-inference.html) in the *Amazon Elastic Container Service Developer Guide*
        """
        type: pulumi.Input[_builtins.str]
        """
        The type of resource to assign to a container.
        """
        value: pulumi.Input[_builtins.str]
        """
        The value for the specified resource type.
         When the type is ``GPU``, the value is the number of physical ``GPUs`` the Amazon ECS container agent reserves for the container. The number of GPUs that's reserved for all containers in a task can't exceed the number of available GPUs on the container instance that the task is launched on.
         When the type is ``InferenceAccelerator``, the ``value`` matches the ``deviceName`` for an [InferenceAccelerator](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_InferenceAccelerator.html) specified in a task definition.
        """
elif False:
    TaskDefinitionResourceRequirementArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionResourceRequirementArgs:
    def __init__(__self__, *,
                 type: pulumi.Input[_builtins.str],
                 value: pulumi.Input[_builtins.str]):
        """
        The type and amount of a resource to assign to a container. The supported resource types are GPUs and Elastic Inference accelerators. For more information, see [Working with GPUs on Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-gpu.html) or [Working with Amazon Elastic Inference on Amazon ECS](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-inference.html) in the *Amazon Elastic Container Service Developer Guide*
        :param pulumi.Input[_builtins.str] type: The type of resource to assign to a container.
        :param pulumi.Input[_builtins.str] value: The value for the specified resource type.
                When the type is ``GPU``, the value is the number of physical ``GPUs`` the Amazon ECS container agent reserves for the container. The number of GPUs that's reserved for all containers in a task can't exceed the number of available GPUs on the container instance that the task is launched on.
                When the type is ``InferenceAccelerator``, the ``value`` matches the ``deviceName`` for an [InferenceAccelerator](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_InferenceAccelerator.html) specified in a task definition.
        """
        pulumi.set(__self__, "type", type)
        pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def type(self) -> pulumi.Input[_builtins.str]:
        """
        The type of resource to assign to a container.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "type", value)

    @_builtins.property
    @pulumi.getter
    def value(self) -> pulumi.Input[_builtins.str]:
        """
        The value for the specified resource type.
         When the type is ``GPU``, the value is the number of physical ``GPUs`` the Amazon ECS container agent reserves for the container. The number of GPUs that's reserved for all containers in a task can't exceed the number of available GPUs on the container instance that the task is launched on.
         When the type is ``InferenceAccelerator``, the ``value`` matches the ``deviceName`` for an [InferenceAccelerator](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_InferenceAccelerator.html) specified in a task definition.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "value", value)


if not MYPY:
    class TaskDefinitionRestartPolicyArgsDict(TypedDict):
        """
        You can enable a restart policy for each container defined in your task definition, to overcome transient failures faster and maintain task availability. When you enable a restart policy for a container, Amazon ECS can restart the container if it exits, without needing to replace the task. For more information, see [Restart individual containers in Amazon ECS tasks with container restart policies](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/container-restart-policy.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        enabled: NotRequired[pulumi.Input[_builtins.bool]]
        """
        Specifies whether a restart policy is enabled for the container.
        """
        ignored_exit_codes: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.int]]]]
        """
        A list of exit codes that Amazon ECS will ignore and not attempt a restart on. You can specify a maximum of 50 container exit codes. By default, Amazon ECS does not ignore any exit codes.
        """
        restart_attempt_period: NotRequired[pulumi.Input[_builtins.int]]
        """
        A period of time (in seconds) that the container must run for before a restart can be attempted. A container can be restarted only once every ``restartAttemptPeriod`` seconds. If a container isn't able to run for this time period and exits early, it will not be restarted. You can set a minimum ``restartAttemptPeriod`` of 60 seconds and a maximum ``restartAttemptPeriod`` of 1800 seconds. By default, a container must run for 300 seconds before it can be restarted.
        """
elif False:
    TaskDefinitionRestartPolicyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionRestartPolicyArgs:
    def __init__(__self__, *,
                 enabled: Optional[pulumi.Input[_builtins.bool]] = None,
                 ignored_exit_codes: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.int]]]] = None,
                 restart_attempt_period: Optional[pulumi.Input[_builtins.int]] = None):
        """
        You can enable a restart policy for each container defined in your task definition, to overcome transient failures faster and maintain task availability. When you enable a restart policy for a container, Amazon ECS can restart the container if it exits, without needing to replace the task. For more information, see [Restart individual containers in Amazon ECS tasks with container restart policies](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/container-restart-policy.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.bool] enabled: Specifies whether a restart policy is enabled for the container.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.int]]] ignored_exit_codes: A list of exit codes that Amazon ECS will ignore and not attempt a restart on. You can specify a maximum of 50 container exit codes. By default, Amazon ECS does not ignore any exit codes.
        :param pulumi.Input[_builtins.int] restart_attempt_period: A period of time (in seconds) that the container must run for before a restart can be attempted. A container can be restarted only once every ``restartAttemptPeriod`` seconds. If a container isn't able to run for this time period and exits early, it will not be restarted. You can set a minimum ``restartAttemptPeriod`` of 60 seconds and a maximum ``restartAttemptPeriod`` of 1800 seconds. By default, a container must run for 300 seconds before it can be restarted.
        """
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if ignored_exit_codes is not None:
            pulumi.set(__self__, "ignored_exit_codes", ignored_exit_codes)
        if restart_attempt_period is not None:
            pulumi.set(__self__, "restart_attempt_period", restart_attempt_period)

    @_builtins.property
    @pulumi.getter
    def enabled(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Specifies whether a restart policy is enabled for the container.
        """
        return pulumi.get(self, "enabled")

    @enabled.setter
    def enabled(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "enabled", value)

    @_builtins.property
    @pulumi.getter(name="ignoredExitCodes")
    def ignored_exit_codes(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.int]]]]:
        """
        A list of exit codes that Amazon ECS will ignore and not attempt a restart on. You can specify a maximum of 50 container exit codes. By default, Amazon ECS does not ignore any exit codes.
        """
        return pulumi.get(self, "ignored_exit_codes")

    @ignored_exit_codes.setter
    def ignored_exit_codes(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.int]]]]):
        pulumi.set(self, "ignored_exit_codes", value)

    @_builtins.property
    @pulumi.getter(name="restartAttemptPeriod")
    def restart_attempt_period(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        A period of time (in seconds) that the container must run for before a restart can be attempted. A container can be restarted only once every ``restartAttemptPeriod`` seconds. If a container isn't able to run for this time period and exits early, it will not be restarted. You can set a minimum ``restartAttemptPeriod`` of 60 seconds and a maximum ``restartAttemptPeriod`` of 1800 seconds. By default, a container must run for 300 seconds before it can be restarted.
        """
        return pulumi.get(self, "restart_attempt_period")

    @restart_attempt_period.setter
    def restart_attempt_period(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "restart_attempt_period", value)


if not MYPY:
    class TaskDefinitionRuntimePlatformArgsDict(TypedDict):
        """
        Information about the platform for the Amazon ECS service or task.
         For more information about ``RuntimePlatform``, see [RuntimePlatform](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#runtime-platform) in the *Amazon Elastic Container Service Developer Guide*.
        """
        cpu_architecture: NotRequired[pulumi.Input[_builtins.str]]
        """
        The CPU architecture.
         You can run your Linux tasks on an ARM-based platform by setting the value to ``ARM64``. This option is available for tasks that run on Linux Amazon EC2 instance, Amazon ECS Managed Instances, or Linux containers on Fargate.
        """
        operating_system_family: NotRequired[pulumi.Input[_builtins.str]]
        """
        The operating system.
        """
elif False:
    TaskDefinitionRuntimePlatformArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionRuntimePlatformArgs:
    def __init__(__self__, *,
                 cpu_architecture: Optional[pulumi.Input[_builtins.str]] = None,
                 operating_system_family: Optional[pulumi.Input[_builtins.str]] = None):
        """
        Information about the platform for the Amazon ECS service or task.
         For more information about ``RuntimePlatform``, see [RuntimePlatform](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#runtime-platform) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.str] cpu_architecture: The CPU architecture.
                You can run your Linux tasks on an ARM-based platform by setting the value to ``ARM64``. This option is available for tasks that run on Linux Amazon EC2 instance, Amazon ECS Managed Instances, or Linux containers on Fargate.
        :param pulumi.Input[_builtins.str] operating_system_family: The operating system.
        """
        if cpu_architecture is not None:
            pulumi.set(__self__, "cpu_architecture", cpu_architecture)
        if operating_system_family is not None:
            pulumi.set(__self__, "operating_system_family", operating_system_family)

    @_builtins.property
    @pulumi.getter(name="cpuArchitecture")
    def cpu_architecture(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The CPU architecture.
         You can run your Linux tasks on an ARM-based platform by setting the value to ``ARM64``. This option is available for tasks that run on Linux Amazon EC2 instance, Amazon ECS Managed Instances, or Linux containers on Fargate.
        """
        return pulumi.get(self, "cpu_architecture")

    @cpu_architecture.setter
    def cpu_architecture(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "cpu_architecture", value)

    @_builtins.property
    @pulumi.getter(name="operatingSystemFamily")
    def operating_system_family(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The operating system.
        """
        return pulumi.get(self, "operating_system_family")

    @operating_system_family.setter
    def operating_system_family(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "operating_system_family", value)


if not MYPY:
    class TaskDefinitionSecretArgsDict(TypedDict):
        """
        An object representing the secret to expose to your container. Secrets can be exposed to a container in the following ways:
          +  To inject sensitive data into your containers as environment variables, use the ``secrets`` container definition parameter.
          +  To reference sensitive information in the log configuration of a container, use the ``secretOptions`` container definition parameter.
          
         For more information, see [Specifying sensitive data](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data.html) in the *Amazon Elastic Container Service Developer Guide*.
        """
        name: pulumi.Input[_builtins.str]
        """
        The name of the secret.
        """
        value_from: pulumi.Input[_builtins.str]
        """
        The secret to expose to the container. The supported values are either the full ARN of the ASMlong secret or the full ARN of the parameter in the SSM Parameter Store.
         For information about the require IAMlong permissions, see [Required IAM permissions for Amazon ECS secrets](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data-secrets.html#secrets-iam) (for Secrets Manager) or [Required IAM permissions for Amazon ECS secrets](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data-parameters.html) (for Systems Manager Parameter store) in the *Amazon Elastic Container Service Developer Guide*.
          If the SSM Parameter Store parameter exists in the same Region as the task you're launching, then you can use either the full ARN or name of the parameter. If the parameter exists in a different Region, then the full ARN must be specified.
        """
elif False:
    TaskDefinitionSecretArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionSecretArgs:
    def __init__(__self__, *,
                 name: pulumi.Input[_builtins.str],
                 value_from: pulumi.Input[_builtins.str]):
        """
        An object representing the secret to expose to your container. Secrets can be exposed to a container in the following ways:
          +  To inject sensitive data into your containers as environment variables, use the ``secrets`` container definition parameter.
          +  To reference sensitive information in the log configuration of a container, use the ``secretOptions`` container definition parameter.
          
         For more information, see [Specifying sensitive data](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data.html) in the *Amazon Elastic Container Service Developer Guide*.
        :param pulumi.Input[_builtins.str] name: The name of the secret.
        :param pulumi.Input[_builtins.str] value_from: The secret to expose to the container. The supported values are either the full ARN of the ASMlong secret or the full ARN of the parameter in the SSM Parameter Store.
                For information about the require IAMlong permissions, see [Required IAM permissions for Amazon ECS secrets](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data-secrets.html#secrets-iam) (for Secrets Manager) or [Required IAM permissions for Amazon ECS secrets](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data-parameters.html) (for Systems Manager Parameter store) in the *Amazon Elastic Container Service Developer Guide*.
                 If the SSM Parameter Store parameter exists in the same Region as the task you're launching, then you can use either the full ARN or name of the parameter. If the parameter exists in a different Region, then the full ARN must be specified.
        """
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "value_from", value_from)

    @_builtins.property
    @pulumi.getter
    def name(self) -> pulumi.Input[_builtins.str]:
        """
        The name of the secret.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "name", value)

    @_builtins.property
    @pulumi.getter(name="valueFrom")
    def value_from(self) -> pulumi.Input[_builtins.str]:
        """
        The secret to expose to the container. The supported values are either the full ARN of the ASMlong secret or the full ARN of the parameter in the SSM Parameter Store.
         For information about the require IAMlong permissions, see [Required IAM permissions for Amazon ECS secrets](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data-secrets.html#secrets-iam) (for Secrets Manager) or [Required IAM permissions for Amazon ECS secrets](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data-parameters.html) (for Systems Manager Parameter store) in the *Amazon Elastic Container Service Developer Guide*.
          If the SSM Parameter Store parameter exists in the same Region as the task you're launching, then you can use either the full ARN or name of the parameter. If the parameter exists in a different Region, then the full ARN must be specified.
        """
        return pulumi.get(self, "value_from")

    @value_from.setter
    def value_from(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "value_from", value)


if not MYPY:
    class TaskDefinitionSystemControlArgsDict(TypedDict):
        """
        A list of namespaced kernel parameters to set in the container. This parameter maps to ``Sysctls`` in the docker container create command and the ``--sysctl`` option to docker run. For example, you can configure ``net.ipv4.tcp_keepalive_time`` setting to maintain longer lived connections.
         We don't recommend that you specify network-related ``systemControls`` parameters for multiple containers in a single task that also uses either the ``awsvpc`` or ``host`` network mode. Doing this has the following disadvantages:
          +  For tasks that use the ``awsvpc`` network mode including Fargate, if you set ``systemControls`` for any container, it applies to all containers in the task. If you set different ``systemControls`` for multiple containers in a single task, the container that's started last determines which ``systemControls`` take effect.
          +  For tasks that use the ``host`` network mode, the network namespace ``systemControls`` aren't supported.
          
         If you're setting an IPC resource namespace to use for the containers in the task, the following conditions apply to your system controls. For more information, see [IPC mode](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#task_definition_ipcmode).
          +  For tasks that use the ``host`` IPC mode, IPC namespace ``systemControls`` aren't supported.
          +  For tasks that use the ``task`` IPC mode, IPC namespace ``systemControls`` values apply to all containers within a task.
          
          This parameter is not supported for Windows containers.
           This parameter is only supported for tasks that are hosted on FARGATElong if the tasks are using platform version ``1.4.0`` or later (Linux). This isn't supported for Windows containers on Fargate.
        """
        namespace: NotRequired[pulumi.Input[_builtins.str]]
        """
        The namespaced kernel parameter to set a ``value`` for.
        """
        value: NotRequired[pulumi.Input[_builtins.str]]
        """
        The namespaced kernel parameter to set a ``value`` for.
         Valid IPC namespace values: ``"kernel.msgmax" | "kernel.msgmnb" | "kernel.msgmni" | "kernel.sem" | "kernel.shmall" | "kernel.shmmax" | "kernel.shmmni" | "kernel.shm_rmid_forced"``, and ``Sysctls`` that start with ``"fs.mqueue.*"``
         Valid network namespace values: ``Sysctls`` that start with ``"net.*"``. Only namespaced ``Sysctls`` that exist within the container starting with "net.* are accepted.
         All of these values are supported by Fargate.
        """
elif False:
    TaskDefinitionSystemControlArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionSystemControlArgs:
    def __init__(__self__, *,
                 namespace: Optional[pulumi.Input[_builtins.str]] = None,
                 value: Optional[pulumi.Input[_builtins.str]] = None):
        """
        A list of namespaced kernel parameters to set in the container. This parameter maps to ``Sysctls`` in the docker container create command and the ``--sysctl`` option to docker run. For example, you can configure ``net.ipv4.tcp_keepalive_time`` setting to maintain longer lived connections.
         We don't recommend that you specify network-related ``systemControls`` parameters for multiple containers in a single task that also uses either the ``awsvpc`` or ``host`` network mode. Doing this has the following disadvantages:
          +  For tasks that use the ``awsvpc`` network mode including Fargate, if you set ``systemControls`` for any container, it applies to all containers in the task. If you set different ``systemControls`` for multiple containers in a single task, the container that's started last determines which ``systemControls`` take effect.
          +  For tasks that use the ``host`` network mode, the network namespace ``systemControls`` aren't supported.
          
         If you're setting an IPC resource namespace to use for the containers in the task, the following conditions apply to your system controls. For more information, see [IPC mode](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#task_definition_ipcmode).
          +  For tasks that use the ``host`` IPC mode, IPC namespace ``systemControls`` aren't supported.
          +  For tasks that use the ``task`` IPC mode, IPC namespace ``systemControls`` values apply to all containers within a task.
          
          This parameter is not supported for Windows containers.
           This parameter is only supported for tasks that are hosted on FARGATElong if the tasks are using platform version ``1.4.0`` or later (Linux). This isn't supported for Windows containers on Fargate.
        :param pulumi.Input[_builtins.str] namespace: The namespaced kernel parameter to set a ``value`` for.
        :param pulumi.Input[_builtins.str] value: The namespaced kernel parameter to set a ``value`` for.
                Valid IPC namespace values: ``"kernel.msgmax" | "kernel.msgmnb" | "kernel.msgmni" | "kernel.sem" | "kernel.shmall" | "kernel.shmmax" | "kernel.shmmni" | "kernel.shm_rmid_forced"``, and ``Sysctls`` that start with ``"fs.mqueue.*"``
                Valid network namespace values: ``Sysctls`` that start with ``"net.*"``. Only namespaced ``Sysctls`` that exist within the container starting with "net.* are accepted.
                All of these values are supported by Fargate.
        """
        if namespace is not None:
            pulumi.set(__self__, "namespace", namespace)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def namespace(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The namespaced kernel parameter to set a ``value`` for.
        """
        return pulumi.get(self, "namespace")

    @namespace.setter
    def namespace(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "namespace", value)

    @_builtins.property
    @pulumi.getter
    def value(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The namespaced kernel parameter to set a ``value`` for.
         Valid IPC namespace values: ``"kernel.msgmax" | "kernel.msgmnb" | "kernel.msgmni" | "kernel.sem" | "kernel.shmall" | "kernel.shmmax" | "kernel.shmmni" | "kernel.shm_rmid_forced"``, and ``Sysctls`` that start with ``"fs.mqueue.*"``
         Valid network namespace values: ``Sysctls`` that start with ``"net.*"``. Only namespaced ``Sysctls`` that exist within the container starting with "net.* are accepted.
         All of these values are supported by Fargate.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "value", value)


if not MYPY:
    class TaskDefinitionTmpfsArgsDict(TypedDict):
        """
        The container path, mount options, and size of the tmpfs mount.
        """
        size: pulumi.Input[_builtins.int]
        """
        The maximum size (in MiB) of the tmpfs volume.
        """
        container_path: NotRequired[pulumi.Input[_builtins.str]]
        """
        The absolute file path where the tmpfs volume is to be mounted.
        """
        mount_options: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The list of tmpfs volume mount options.
         Valid values: ``"defaults" | "ro" | "rw" | "suid" | "nosuid" | "dev" | "nodev" | "exec" | "noexec" | "sync" | "async" | "dirsync" | "remount" | "mand" | "nomand" | "atime" | "noatime" | "diratime" | "nodiratime" | "bind" | "rbind" | "unbindable" | "runbindable" | "private" | "rprivate" | "shared" | "rshared" | "slave" | "rslave" | "relatime" | "norelatime" | "strictatime" | "nostrictatime" | "mode" | "uid" | "gid" | "nr_inodes" | "nr_blocks" | "mpol"``
        """
elif False:
    TaskDefinitionTmpfsArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionTmpfsArgs:
    def __init__(__self__, *,
                 size: pulumi.Input[_builtins.int],
                 container_path: Optional[pulumi.Input[_builtins.str]] = None,
                 mount_options: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None):
        """
        The container path, mount options, and size of the tmpfs mount.
        :param pulumi.Input[_builtins.int] size: The maximum size (in MiB) of the tmpfs volume.
        :param pulumi.Input[_builtins.str] container_path: The absolute file path where the tmpfs volume is to be mounted.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] mount_options: The list of tmpfs volume mount options.
                Valid values: ``"defaults" | "ro" | "rw" | "suid" | "nosuid" | "dev" | "nodev" | "exec" | "noexec" | "sync" | "async" | "dirsync" | "remount" | "mand" | "nomand" | "atime" | "noatime" | "diratime" | "nodiratime" | "bind" | "rbind" | "unbindable" | "runbindable" | "private" | "rprivate" | "shared" | "rshared" | "slave" | "rslave" | "relatime" | "norelatime" | "strictatime" | "nostrictatime" | "mode" | "uid" | "gid" | "nr_inodes" | "nr_blocks" | "mpol"``
        """
        pulumi.set(__self__, "size", size)
        if container_path is not None:
            pulumi.set(__self__, "container_path", container_path)
        if mount_options is not None:
            pulumi.set(__self__, "mount_options", mount_options)

    @_builtins.property
    @pulumi.getter
    def size(self) -> pulumi.Input[_builtins.int]:
        """
        The maximum size (in MiB) of the tmpfs volume.
        """
        return pulumi.get(self, "size")

    @size.setter
    def size(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "size", value)

    @_builtins.property
    @pulumi.getter(name="containerPath")
    def container_path(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The absolute file path where the tmpfs volume is to be mounted.
        """
        return pulumi.get(self, "container_path")

    @container_path.setter
    def container_path(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "container_path", value)

    @_builtins.property
    @pulumi.getter(name="mountOptions")
    def mount_options(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The list of tmpfs volume mount options.
         Valid values: ``"defaults" | "ro" | "rw" | "suid" | "nosuid" | "dev" | "nodev" | "exec" | "noexec" | "sync" | "async" | "dirsync" | "remount" | "mand" | "nomand" | "atime" | "noatime" | "diratime" | "nodiratime" | "bind" | "rbind" | "unbindable" | "runbindable" | "private" | "rprivate" | "shared" | "rshared" | "slave" | "rslave" | "relatime" | "norelatime" | "strictatime" | "nostrictatime" | "mode" | "uid" | "gid" | "nr_inodes" | "nr_blocks" | "mpol"``
        """
        return pulumi.get(self, "mount_options")

    @mount_options.setter
    def mount_options(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "mount_options", value)


if not MYPY:
    class TaskDefinitionUlimitArgsDict(TypedDict):
        """
        The ``ulimit`` settings to pass to the container.
         Amazon ECS tasks hosted on FARGATElong use the default resource limit values set by the operating system with the exception of the ``nofile`` resource limit parameter which FARGATElong overrides. The ``nofile`` resource limit sets a restriction on the number of open files that a container can use. The default ``nofile`` soft limit is ``65535`` and the default hard limit is ``65535``.
         You can specify the ``ulimit`` settings for a container in a task definition.
        """
        hard_limit: pulumi.Input[_builtins.int]
        """
        The hard limit for the ``ulimit`` type. The value can be specified in bytes, seconds, or as a count, depending on the ``type`` of the ``ulimit``.
        """
        name: pulumi.Input[_builtins.str]
        """
        The ``type`` of the ``ulimit``.
        """
        soft_limit: pulumi.Input[_builtins.int]
        """
        The soft limit for the ``ulimit`` type. The value can be specified in bytes, seconds, or as a count, depending on the ``type`` of the ``ulimit``.
        """
elif False:
    TaskDefinitionUlimitArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionUlimitArgs:
    def __init__(__self__, *,
                 hard_limit: pulumi.Input[_builtins.int],
                 name: pulumi.Input[_builtins.str],
                 soft_limit: pulumi.Input[_builtins.int]):
        """
        The ``ulimit`` settings to pass to the container.
         Amazon ECS tasks hosted on FARGATElong use the default resource limit values set by the operating system with the exception of the ``nofile`` resource limit parameter which FARGATElong overrides. The ``nofile`` resource limit sets a restriction on the number of open files that a container can use. The default ``nofile`` soft limit is ``65535`` and the default hard limit is ``65535``.
         You can specify the ``ulimit`` settings for a container in a task definition.
        :param pulumi.Input[_builtins.int] hard_limit: The hard limit for the ``ulimit`` type. The value can be specified in bytes, seconds, or as a count, depending on the ``type`` of the ``ulimit``.
        :param pulumi.Input[_builtins.str] name: The ``type`` of the ``ulimit``.
        :param pulumi.Input[_builtins.int] soft_limit: The soft limit for the ``ulimit`` type. The value can be specified in bytes, seconds, or as a count, depending on the ``type`` of the ``ulimit``.
        """
        pulumi.set(__self__, "hard_limit", hard_limit)
        pulumi.set(__self__, "name", name)
        pulumi.set(__self__, "soft_limit", soft_limit)

    @_builtins.property
    @pulumi.getter(name="hardLimit")
    def hard_limit(self) -> pulumi.Input[_builtins.int]:
        """
        The hard limit for the ``ulimit`` type. The value can be specified in bytes, seconds, or as a count, depending on the ``type`` of the ``ulimit``.
        """
        return pulumi.get(self, "hard_limit")

    @hard_limit.setter
    def hard_limit(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "hard_limit", value)

    @_builtins.property
    @pulumi.getter
    def name(self) -> pulumi.Input[_builtins.str]:
        """
        The ``type`` of the ``ulimit``.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "name", value)

    @_builtins.property
    @pulumi.getter(name="softLimit")
    def soft_limit(self) -> pulumi.Input[_builtins.int]:
        """
        The soft limit for the ``ulimit`` type. The value can be specified in bytes, seconds, or as a count, depending on the ``type`` of the ``ulimit``.
        """
        return pulumi.get(self, "soft_limit")

    @soft_limit.setter
    def soft_limit(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "soft_limit", value)


if not MYPY:
    class TaskDefinitionVolumeFromArgsDict(TypedDict):
        """
        Details on a data volume from another container in the same task definition.
        """
        read_only: NotRequired[pulumi.Input[_builtins.bool]]
        """
        If this value is ``true``, the container has read-only access to the volume. If this value is ``false``, then the container can write to the volume. The default value is ``false``.
        """
        source_container: NotRequired[pulumi.Input[_builtins.str]]
        """
        The name of another container within the same task definition to mount volumes from.
        """
elif False:
    TaskDefinitionVolumeFromArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionVolumeFromArgs:
    def __init__(__self__, *,
                 read_only: Optional[pulumi.Input[_builtins.bool]] = None,
                 source_container: Optional[pulumi.Input[_builtins.str]] = None):
        """
        Details on a data volume from another container in the same task definition.
        :param pulumi.Input[_builtins.bool] read_only: If this value is ``true``, the container has read-only access to the volume. If this value is ``false``, then the container can write to the volume. The default value is ``false``.
        :param pulumi.Input[_builtins.str] source_container: The name of another container within the same task definition to mount volumes from.
        """
        if read_only is not None:
            pulumi.set(__self__, "read_only", read_only)
        if source_container is not None:
            pulumi.set(__self__, "source_container", source_container)

    @_builtins.property
    @pulumi.getter(name="readOnly")
    def read_only(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        If this value is ``true``, the container has read-only access to the volume. If this value is ``false``, then the container can write to the volume. The default value is ``false``.
        """
        return pulumi.get(self, "read_only")

    @read_only.setter
    def read_only(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "read_only", value)

    @_builtins.property
    @pulumi.getter(name="sourceContainer")
    def source_container(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The name of another container within the same task definition to mount volumes from.
        """
        return pulumi.get(self, "source_container")

    @source_container.setter
    def source_container(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "source_container", value)


if not MYPY:
    class TaskDefinitionVolumeArgsDict(TypedDict):
        """
        The data volume configuration for tasks launched using this task definition. Specifying a volume configuration in a task definition is optional. The volume configuration may contain multiple volumes but only one volume configured at launch is supported. Each volume defined in the volume configuration may only specify a ``name`` and one of either ``configuredAtLaunch``, ``dockerVolumeConfiguration``, ``efsVolumeConfiguration``, ``fsxWindowsFileServerVolumeConfiguration``, or ``host``. If an empty volume configuration is specified, by default Amazon ECS uses a host volume. For more information, see [Using data volumes in tasks](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_data_volumes.html).
        """
        configured_at_launch: NotRequired[pulumi.Input[_builtins.bool]]
        """
        Indicates whether the volume should be configured at launch time. This is used to create Amazon EBS volumes for standalone tasks or tasks created as part of a service. Each task definition revision may only have one volume configured at launch in the volume configuration.
         To configure a volume at launch time, use this task definition revision and specify a ``volumeConfigurations`` object when calling the ``CreateService``, ``UpdateService``, ``RunTask`` or ``StartTask`` APIs.
        """
        docker_volume_configuration: NotRequired[pulumi.Input['TaskDefinitionDockerVolumeConfigurationArgsDict']]
        """
        This parameter is specified when you use Docker volumes.
         Windows containers only support the use of the ``local`` driver. To use bind mounts, specify the ``host`` parameter instead.
          Docker volumes aren't supported by tasks run on FARGATElong.
        """
        efs_volume_configuration: NotRequired[pulumi.Input['TaskDefinitionEfsVolumeConfigurationArgsDict']]
        """
        This parameter is specified when you use an Amazon Elastic File System file system for task storage.
        """
        f_sx_windows_file_server_volume_configuration: NotRequired[pulumi.Input['TaskDefinitionFSxWindowsFileServerVolumeConfigurationArgsDict']]
        """
        This parameter is specified when you use Amazon FSx for Windows File Server file system for task storage.
        """
        host: NotRequired[pulumi.Input['TaskDefinitionHostVolumePropertiesArgsDict']]
        """
        This parameter is specified when you use bind mount host volumes. The contents of the ``host`` parameter determine whether your bind mount host volume persists on the host container instance and where it's stored. If the ``host`` parameter is empty, then the Docker daemon assigns a host path for your data volume. However, the data isn't guaranteed to persist after the containers that are associated with it stop running.
         Windows containers can mount whole directories on the same drive as ``$env:ProgramData``. Windows containers can't mount directories on a different drive, and mount point can't be across drives. For example, you can mount ``C:\\my\\path:C:\\my\\path`` and ``D:\\:D:\\``, but not ``D:\\my\\path:C:\\my\\path`` or ``D:\\:C:\\my\\path``.
        """
        name: NotRequired[pulumi.Input[_builtins.str]]
        """
        The name of the volume. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed.
         When using a volume configured at launch, the ``name`` is required and must also be specified as the volume name in the ``ServiceVolumeConfiguration`` or ``TaskVolumeConfiguration`` parameter when creating your service or standalone task.
         For all other types of volumes, this name is referenced in the ``sourceVolume`` parameter of the ``mountPoints`` object in the container definition.
         When a volume is using the ``efsVolumeConfiguration``, the name is required.
        """
elif False:
    TaskDefinitionVolumeArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskDefinitionVolumeArgs:
    def __init__(__self__, *,
                 configured_at_launch: Optional[pulumi.Input[_builtins.bool]] = None,
                 docker_volume_configuration: Optional[pulumi.Input['TaskDefinitionDockerVolumeConfigurationArgs']] = None,
                 efs_volume_configuration: Optional[pulumi.Input['TaskDefinitionEfsVolumeConfigurationArgs']] = None,
                 f_sx_windows_file_server_volume_configuration: Optional[pulumi.Input['TaskDefinitionFSxWindowsFileServerVolumeConfigurationArgs']] = None,
                 host: Optional[pulumi.Input['TaskDefinitionHostVolumePropertiesArgs']] = None,
                 name: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The data volume configuration for tasks launched using this task definition. Specifying a volume configuration in a task definition is optional. The volume configuration may contain multiple volumes but only one volume configured at launch is supported. Each volume defined in the volume configuration may only specify a ``name`` and one of either ``configuredAtLaunch``, ``dockerVolumeConfiguration``, ``efsVolumeConfiguration``, ``fsxWindowsFileServerVolumeConfiguration``, or ``host``. If an empty volume configuration is specified, by default Amazon ECS uses a host volume. For more information, see [Using data volumes in tasks](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_data_volumes.html).
        :param pulumi.Input[_builtins.bool] configured_at_launch: Indicates whether the volume should be configured at launch time. This is used to create Amazon EBS volumes for standalone tasks or tasks created as part of a service. Each task definition revision may only have one volume configured at launch in the volume configuration.
                To configure a volume at launch time, use this task definition revision and specify a ``volumeConfigurations`` object when calling the ``CreateService``, ``UpdateService``, ``RunTask`` or ``StartTask`` APIs.
        :param pulumi.Input['TaskDefinitionDockerVolumeConfigurationArgs'] docker_volume_configuration: This parameter is specified when you use Docker volumes.
                Windows containers only support the use of the ``local`` driver. To use bind mounts, specify the ``host`` parameter instead.
                 Docker volumes aren't supported by tasks run on FARGATElong.
        :param pulumi.Input['TaskDefinitionEfsVolumeConfigurationArgs'] efs_volume_configuration: This parameter is specified when you use an Amazon Elastic File System file system for task storage.
        :param pulumi.Input['TaskDefinitionFSxWindowsFileServerVolumeConfigurationArgs'] f_sx_windows_file_server_volume_configuration: This parameter is specified when you use Amazon FSx for Windows File Server file system for task storage.
        :param pulumi.Input['TaskDefinitionHostVolumePropertiesArgs'] host: This parameter is specified when you use bind mount host volumes. The contents of the ``host`` parameter determine whether your bind mount host volume persists on the host container instance and where it's stored. If the ``host`` parameter is empty, then the Docker daemon assigns a host path for your data volume. However, the data isn't guaranteed to persist after the containers that are associated with it stop running.
                Windows containers can mount whole directories on the same drive as ``$env:ProgramData``. Windows containers can't mount directories on a different drive, and mount point can't be across drives. For example, you can mount ``C:\\my\\path:C:\\my\\path`` and ``D:\\:D:\\``, but not ``D:\\my\\path:C:\\my\\path`` or ``D:\\:C:\\my\\path``.
        :param pulumi.Input[_builtins.str] name: The name of the volume. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed.
                When using a volume configured at launch, the ``name`` is required and must also be specified as the volume name in the ``ServiceVolumeConfiguration`` or ``TaskVolumeConfiguration`` parameter when creating your service or standalone task.
                For all other types of volumes, this name is referenced in the ``sourceVolume`` parameter of the ``mountPoints`` object in the container definition.
                When a volume is using the ``efsVolumeConfiguration``, the name is required.
        """
        if configured_at_launch is not None:
            pulumi.set(__self__, "configured_at_launch", configured_at_launch)
        if docker_volume_configuration is not None:
            pulumi.set(__self__, "docker_volume_configuration", docker_volume_configuration)
        if efs_volume_configuration is not None:
            pulumi.set(__self__, "efs_volume_configuration", efs_volume_configuration)
        if f_sx_windows_file_server_volume_configuration is not None:
            pulumi.set(__self__, "f_sx_windows_file_server_volume_configuration", f_sx_windows_file_server_volume_configuration)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if name is not None:
            pulumi.set(__self__, "name", name)

    @_builtins.property
    @pulumi.getter(name="configuredAtLaunch")
    def configured_at_launch(self) -> Optional[pulumi.Input[_builtins.bool]]:
        """
        Indicates whether the volume should be configured at launch time. This is used to create Amazon EBS volumes for standalone tasks or tasks created as part of a service. Each task definition revision may only have one volume configured at launch in the volume configuration.
         To configure a volume at launch time, use this task definition revision and specify a ``volumeConfigurations`` object when calling the ``CreateService``, ``UpdateService``, ``RunTask`` or ``StartTask`` APIs.
        """
        return pulumi.get(self, "configured_at_launch")

    @configured_at_launch.setter
    def configured_at_launch(self, value: Optional[pulumi.Input[_builtins.bool]]):
        pulumi.set(self, "configured_at_launch", value)

    @_builtins.property
    @pulumi.getter(name="dockerVolumeConfiguration")
    def docker_volume_configuration(self) -> Optional[pulumi.Input['TaskDefinitionDockerVolumeConfigurationArgs']]:
        """
        This parameter is specified when you use Docker volumes.
         Windows containers only support the use of the ``local`` driver. To use bind mounts, specify the ``host`` parameter instead.
          Docker volumes aren't supported by tasks run on FARGATElong.
        """
        return pulumi.get(self, "docker_volume_configuration")

    @docker_volume_configuration.setter
    def docker_volume_configuration(self, value: Optional[pulumi.Input['TaskDefinitionDockerVolumeConfigurationArgs']]):
        pulumi.set(self, "docker_volume_configuration", value)

    @_builtins.property
    @pulumi.getter(name="efsVolumeConfiguration")
    def efs_volume_configuration(self) -> Optional[pulumi.Input['TaskDefinitionEfsVolumeConfigurationArgs']]:
        """
        This parameter is specified when you use an Amazon Elastic File System file system for task storage.
        """
        return pulumi.get(self, "efs_volume_configuration")

    @efs_volume_configuration.setter
    def efs_volume_configuration(self, value: Optional[pulumi.Input['TaskDefinitionEfsVolumeConfigurationArgs']]):
        pulumi.set(self, "efs_volume_configuration", value)

    @_builtins.property
    @pulumi.getter(name="fSxWindowsFileServerVolumeConfiguration")
    def f_sx_windows_file_server_volume_configuration(self) -> Optional[pulumi.Input['TaskDefinitionFSxWindowsFileServerVolumeConfigurationArgs']]:
        """
        This parameter is specified when you use Amazon FSx for Windows File Server file system for task storage.
        """
        return pulumi.get(self, "f_sx_windows_file_server_volume_configuration")

    @f_sx_windows_file_server_volume_configuration.setter
    def f_sx_windows_file_server_volume_configuration(self, value: Optional[pulumi.Input['TaskDefinitionFSxWindowsFileServerVolumeConfigurationArgs']]):
        pulumi.set(self, "f_sx_windows_file_server_volume_configuration", value)

    @_builtins.property
    @pulumi.getter
    def host(self) -> Optional[pulumi.Input['TaskDefinitionHostVolumePropertiesArgs']]:
        """
        This parameter is specified when you use bind mount host volumes. The contents of the ``host`` parameter determine whether your bind mount host volume persists on the host container instance and where it's stored. If the ``host`` parameter is empty, then the Docker daemon assigns a host path for your data volume. However, the data isn't guaranteed to persist after the containers that are associated with it stop running.
         Windows containers can mount whole directories on the same drive as ``$env:ProgramData``. Windows containers can't mount directories on a different drive, and mount point can't be across drives. For example, you can mount ``C:\\my\\path:C:\\my\\path`` and ``D:\\:D:\\``, but not ``D:\\my\\path:C:\\my\\path`` or ``D:\\:C:\\my\\path``.
        """
        return pulumi.get(self, "host")

    @host.setter
    def host(self, value: Optional[pulumi.Input['TaskDefinitionHostVolumePropertiesArgs']]):
        pulumi.set(self, "host", value)

    @_builtins.property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The name of the volume. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed.
         When using a volume configured at launch, the ``name`` is required and must also be specified as the volume name in the ``ServiceVolumeConfiguration`` or ``TaskVolumeConfiguration`` parameter when creating your service or standalone task.
         For all other types of volumes, this name is referenced in the ``sourceVolume`` parameter of the ``mountPoints`` object in the container definition.
         When a volume is using the ``efsVolumeConfiguration``, the name is required.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "name", value)


if not MYPY:
    class TaskSetAwsVpcConfigurationArgsDict(TypedDict):
        """
        The VPC subnets and security groups associated with a task. All specified subnets and security groups must be from the same VPC.
        """
        subnets: pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]
        """
        The subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration.
        """
        assign_public_ip: NotRequired[pulumi.Input['TaskSetAwsVpcConfigurationAssignPublicIp']]
        """
        Whether the task's elastic network interface receives a public IP address. The default value is DISABLED.
        """
        security_groups: NotRequired[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]
        """
        The security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration.
        """
elif False:
    TaskSetAwsVpcConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskSetAwsVpcConfigurationArgs:
    def __init__(__self__, *,
                 subnets: pulumi.Input[Sequence[pulumi.Input[_builtins.str]]],
                 assign_public_ip: Optional[pulumi.Input['TaskSetAwsVpcConfigurationAssignPublicIp']] = None,
                 security_groups: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None):
        """
        The VPC subnets and security groups associated with a task. All specified subnets and security groups must be from the same VPC.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] subnets: The subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration.
        :param pulumi.Input['TaskSetAwsVpcConfigurationAssignPublicIp'] assign_public_ip: Whether the task's elastic network interface receives a public IP address. The default value is DISABLED.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] security_groups: The security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration.
        """
        pulumi.set(__self__, "subnets", subnets)
        if assign_public_ip is not None:
            pulumi.set(__self__, "assign_public_ip", assign_public_ip)
        if security_groups is not None:
            pulumi.set(__self__, "security_groups", security_groups)

    @_builtins.property
    @pulumi.getter
    def subnets(self) -> pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]:
        """
        The subnets associated with the task or service. There is a limit of 16 subnets that can be specified per AwsVpcConfiguration.
        """
        return pulumi.get(self, "subnets")

    @subnets.setter
    def subnets(self, value: pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]):
        pulumi.set(self, "subnets", value)

    @_builtins.property
    @pulumi.getter(name="assignPublicIp")
    def assign_public_ip(self) -> Optional[pulumi.Input['TaskSetAwsVpcConfigurationAssignPublicIp']]:
        """
        Whether the task's elastic network interface receives a public IP address. The default value is DISABLED.
        """
        return pulumi.get(self, "assign_public_ip")

    @assign_public_ip.setter
    def assign_public_ip(self, value: Optional[pulumi.Input['TaskSetAwsVpcConfigurationAssignPublicIp']]):
        pulumi.set(self, "assign_public_ip", value)

    @_builtins.property
    @pulumi.getter(name="securityGroups")
    def security_groups(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        The security groups associated with the task or service. If you do not specify a security group, the default security group for the VPC is used. There is a limit of 5 security groups that can be specified per AwsVpcConfiguration.
        """
        return pulumi.get(self, "security_groups")

    @security_groups.setter
    def security_groups(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "security_groups", value)


if not MYPY:
    class TaskSetCapacityProviderStrategyItemArgsDict(TypedDict):
        base: NotRequired[pulumi.Input[_builtins.int]]
        """
        The *base* value designates how many tasks, at a minimum, to run on the specified capacity provider for each service. Only one capacity provider in a capacity provider strategy can have a *base* defined. If no value is specified, the default value of `0` is used.

        Base value characteristics:

        - Only one capacity provider in a strategy can have a base defined
        - The default value is `0` if not specified
        - The valid range is 0 to 100,000
        - Base requirements are satisfied first before weight distribution
        """
        capacity_provider: NotRequired[pulumi.Input[_builtins.str]]
        """
        The short name of the capacity provider. This can be either an AWS managed capacity provider ( `FARGATE` or `FARGATE_SPOT` ) or the name of a custom capacity provider that you created.
        """
        weight: NotRequired[pulumi.Input[_builtins.int]]
        """
        The *weight* value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The `weight` value is taken into consideration after the `base` value, if defined, is satisfied.

        If no `weight` value is specified, the default value of `0` is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of `0` can't be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of `0` , any `RunTask` or `CreateService` actions using the capacity provider strategy will fail.

        Weight value characteristics:

        - Weight is considered after the base value is satisfied
        - The default value is `0` if not specified
        - The valid range is 0 to 1,000
        - At least one capacity provider must have a weight greater than zero
        - Capacity providers with weight of `0` cannot place tasks

        Task distribution logic:

        - Base satisfaction: The minimum number of tasks specified by the base value are placed on that capacity provider
        - Weight distribution: After base requirements are met, additional tasks are distributed according to weight ratios

        Examples:

        Equal Distribution: Two capacity providers both with weight `1` will split tasks evenly after base requirements are met.

        Weighted Distribution: If capacityProviderA has weight `1` and capacityProviderB has weight `4` , then for every 1 task on A, 4 tasks will run on B.
        """
elif False:
    TaskSetCapacityProviderStrategyItemArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskSetCapacityProviderStrategyItemArgs:
    def __init__(__self__, *,
                 base: Optional[pulumi.Input[_builtins.int]] = None,
                 capacity_provider: Optional[pulumi.Input[_builtins.str]] = None,
                 weight: Optional[pulumi.Input[_builtins.int]] = None):
        """
        :param pulumi.Input[_builtins.int] base: The *base* value designates how many tasks, at a minimum, to run on the specified capacity provider for each service. Only one capacity provider in a capacity provider strategy can have a *base* defined. If no value is specified, the default value of `0` is used.
               
               Base value characteristics:
               
               - Only one capacity provider in a strategy can have a base defined
               - The default value is `0` if not specified
               - The valid range is 0 to 100,000
               - Base requirements are satisfied first before weight distribution
        :param pulumi.Input[_builtins.str] capacity_provider: The short name of the capacity provider. This can be either an AWS managed capacity provider ( `FARGATE` or `FARGATE_SPOT` ) or the name of a custom capacity provider that you created.
        :param pulumi.Input[_builtins.int] weight: The *weight* value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The `weight` value is taken into consideration after the `base` value, if defined, is satisfied.
               
               If no `weight` value is specified, the default value of `0` is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of `0` can't be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of `0` , any `RunTask` or `CreateService` actions using the capacity provider strategy will fail.
               
               Weight value characteristics:
               
               - Weight is considered after the base value is satisfied
               - The default value is `0` if not specified
               - The valid range is 0 to 1,000
               - At least one capacity provider must have a weight greater than zero
               - Capacity providers with weight of `0` cannot place tasks
               
               Task distribution logic:
               
               - Base satisfaction: The minimum number of tasks specified by the base value are placed on that capacity provider
               - Weight distribution: After base requirements are met, additional tasks are distributed according to weight ratios
               
               Examples:
               
               Equal Distribution: Two capacity providers both with weight `1` will split tasks evenly after base requirements are met.
               
               Weighted Distribution: If capacityProviderA has weight `1` and capacityProviderB has weight `4` , then for every 1 task on A, 4 tasks will run on B.
        """
        if base is not None:
            pulumi.set(__self__, "base", base)
        if capacity_provider is not None:
            pulumi.set(__self__, "capacity_provider", capacity_provider)
        if weight is not None:
            pulumi.set(__self__, "weight", weight)

    @_builtins.property
    @pulumi.getter
    def base(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The *base* value designates how many tasks, at a minimum, to run on the specified capacity provider for each service. Only one capacity provider in a capacity provider strategy can have a *base* defined. If no value is specified, the default value of `0` is used.

        Base value characteristics:

        - Only one capacity provider in a strategy can have a base defined
        - The default value is `0` if not specified
        - The valid range is 0 to 100,000
        - Base requirements are satisfied first before weight distribution
        """
        return pulumi.get(self, "base")

    @base.setter
    def base(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "base", value)

    @_builtins.property
    @pulumi.getter(name="capacityProvider")
    def capacity_provider(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The short name of the capacity provider. This can be either an AWS managed capacity provider ( `FARGATE` or `FARGATE_SPOT` ) or the name of a custom capacity provider that you created.
        """
        return pulumi.get(self, "capacity_provider")

    @capacity_provider.setter
    def capacity_provider(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "capacity_provider", value)

    @_builtins.property
    @pulumi.getter
    def weight(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The *weight* value designates the relative percentage of the total number of tasks launched that should use the specified capacity provider. The `weight` value is taken into consideration after the `base` value, if defined, is satisfied.

        If no `weight` value is specified, the default value of `0` is used. When multiple capacity providers are specified within a capacity provider strategy, at least one of the capacity providers must have a weight value greater than zero and any capacity providers with a weight of `0` can't be used to place tasks. If you specify multiple capacity providers in a strategy that all have a weight of `0` , any `RunTask` or `CreateService` actions using the capacity provider strategy will fail.

        Weight value characteristics:

        - Weight is considered after the base value is satisfied
        - The default value is `0` if not specified
        - The valid range is 0 to 1,000
        - At least one capacity provider must have a weight greater than zero
        - Capacity providers with weight of `0` cannot place tasks

        Task distribution logic:

        - Base satisfaction: The minimum number of tasks specified by the base value are placed on that capacity provider
        - Weight distribution: After base requirements are met, additional tasks are distributed according to weight ratios

        Examples:

        Equal Distribution: Two capacity providers both with weight `1` will split tasks evenly after base requirements are met.

        Weighted Distribution: If capacityProviderA has weight `1` and capacityProviderB has weight `4` , then for every 1 task on A, 4 tasks will run on B.
        """
        return pulumi.get(self, "weight")

    @weight.setter
    def weight(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "weight", value)


if not MYPY:
    class TaskSetLoadBalancerArgsDict(TypedDict):
        """
        A load balancer object representing the load balancer to use with the task set. The supported load balancer types are either an Application Load Balancer or a Network Load Balancer. 
        """
        container_name: NotRequired[pulumi.Input[_builtins.str]]
        """
        The name of the container (as it appears in a container definition) to associate with the load balancer.
        """
        container_port: NotRequired[pulumi.Input[_builtins.int]]
        """
        The port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.
        """
        target_group_arn: NotRequired[pulumi.Input[_builtins.str]]
        """
        The full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set. A target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer this should be omitted. For services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html in the Amazon Elastic Container Service Developer Guide. For services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-bluegreen.html in the Amazon Elastic Container Service Developer Guide. If your service's task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance, when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.
        """
elif False:
    TaskSetLoadBalancerArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskSetLoadBalancerArgs:
    def __init__(__self__, *,
                 container_name: Optional[pulumi.Input[_builtins.str]] = None,
                 container_port: Optional[pulumi.Input[_builtins.int]] = None,
                 target_group_arn: Optional[pulumi.Input[_builtins.str]] = None):
        """
        A load balancer object representing the load balancer to use with the task set. The supported load balancer types are either an Application Load Balancer or a Network Load Balancer. 
        :param pulumi.Input[_builtins.str] container_name: The name of the container (as it appears in a container definition) to associate with the load balancer.
        :param pulumi.Input[_builtins.int] container_port: The port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.
        :param pulumi.Input[_builtins.str] target_group_arn: The full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set. A target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer this should be omitted. For services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html in the Amazon Elastic Container Service Developer Guide. For services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-bluegreen.html in the Amazon Elastic Container Service Developer Guide. If your service's task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance, when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.
        """
        if container_name is not None:
            pulumi.set(__self__, "container_name", container_name)
        if container_port is not None:
            pulumi.set(__self__, "container_port", container_port)
        if target_group_arn is not None:
            pulumi.set(__self__, "target_group_arn", target_group_arn)

    @_builtins.property
    @pulumi.getter(name="containerName")
    def container_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The name of the container (as it appears in a container definition) to associate with the load balancer.
        """
        return pulumi.get(self, "container_name")

    @container_name.setter
    def container_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "container_name", value)

    @_builtins.property
    @pulumi.getter(name="containerPort")
    def container_port(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The port on the container to associate with the load balancer. This port must correspond to a containerPort in the task definition the tasks in the service are using. For tasks that use the EC2 launch type, the container instance they are launched on must allow ingress traffic on the hostPort of the port mapping.
        """
        return pulumi.get(self, "container_port")

    @container_port.setter
    def container_port(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "container_port", value)

    @_builtins.property
    @pulumi.getter(name="targetGroupArn")
    def target_group_arn(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The full Amazon Resource Name (ARN) of the Elastic Load Balancing target group or groups associated with a service or task set. A target group ARN is only specified when using an Application Load Balancer or Network Load Balancer. If you are using a Classic Load Balancer this should be omitted. For services using the ECS deployment controller, you can specify one or multiple target groups. For more information, see https://docs.aws.amazon.com/AmazonECS/latest/developerguide/register-multiple-targetgroups.html in the Amazon Elastic Container Service Developer Guide. For services using the CODE_DEPLOY deployment controller, you are required to define two target groups for the load balancer. For more information, see https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-bluegreen.html in the Amazon Elastic Container Service Developer Guide. If your service's task definition uses the awsvpc network mode (which is required for the Fargate launch type), you must choose ip as the target type, not instance, when creating your target groups because tasks that use the awsvpc network mode are associated with an elastic network interface, not an Amazon EC2 instance.
        """
        return pulumi.get(self, "target_group_arn")

    @target_group_arn.setter
    def target_group_arn(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "target_group_arn", value)


if not MYPY:
    class TaskSetNetworkConfigurationArgsDict(TypedDict):
        """
        An object representing the network configuration for a task or service.
        """
        aws_vpc_configuration: NotRequired[pulumi.Input['TaskSetAwsVpcConfigurationArgsDict']]
        """
        The VPC subnets and security groups that are associated with a task.

        > All specified subnets and security groups must be from the same VPC.
        """
elif False:
    TaskSetNetworkConfigurationArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskSetNetworkConfigurationArgs:
    def __init__(__self__, *,
                 aws_vpc_configuration: Optional[pulumi.Input['TaskSetAwsVpcConfigurationArgs']] = None):
        """
        An object representing the network configuration for a task or service.
        :param pulumi.Input['TaskSetAwsVpcConfigurationArgs'] aws_vpc_configuration: The VPC subnets and security groups that are associated with a task.
               
               > All specified subnets and security groups must be from the same VPC.
        """
        if aws_vpc_configuration is not None:
            pulumi.set(__self__, "aws_vpc_configuration", aws_vpc_configuration)

    @_builtins.property
    @pulumi.getter(name="awsVpcConfiguration")
    def aws_vpc_configuration(self) -> Optional[pulumi.Input['TaskSetAwsVpcConfigurationArgs']]:
        """
        The VPC subnets and security groups that are associated with a task.

        > All specified subnets and security groups must be from the same VPC.
        """
        return pulumi.get(self, "aws_vpc_configuration")

    @aws_vpc_configuration.setter
    def aws_vpc_configuration(self, value: Optional[pulumi.Input['TaskSetAwsVpcConfigurationArgs']]):
        pulumi.set(self, "aws_vpc_configuration", value)


if not MYPY:
    class TaskSetScaleArgsDict(TypedDict):
        unit: NotRequired[pulumi.Input['TaskSetScaleUnit']]
        """
        The unit of measure for the scale value.
        """
        value: NotRequired[pulumi.Input[_builtins.float]]
        """
        The value, specified as a percent total of a service's desiredCount, to scale the task set. Accepted values are numbers between 0 and 100.
        """
elif False:
    TaskSetScaleArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskSetScaleArgs:
    def __init__(__self__, *,
                 unit: Optional[pulumi.Input['TaskSetScaleUnit']] = None,
                 value: Optional[pulumi.Input[_builtins.float]] = None):
        """
        :param pulumi.Input['TaskSetScaleUnit'] unit: The unit of measure for the scale value.
        :param pulumi.Input[_builtins.float] value: The value, specified as a percent total of a service's desiredCount, to scale the task set. Accepted values are numbers between 0 and 100.
        """
        if unit is not None:
            pulumi.set(__self__, "unit", unit)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @_builtins.property
    @pulumi.getter
    def unit(self) -> Optional[pulumi.Input['TaskSetScaleUnit']]:
        """
        The unit of measure for the scale value.
        """
        return pulumi.get(self, "unit")

    @unit.setter
    def unit(self, value: Optional[pulumi.Input['TaskSetScaleUnit']]):
        pulumi.set(self, "unit", value)

    @_builtins.property
    @pulumi.getter
    def value(self) -> Optional[pulumi.Input[_builtins.float]]:
        """
        The value, specified as a percent total of a service's desiredCount, to scale the task set. Accepted values are numbers between 0 and 100.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: Optional[pulumi.Input[_builtins.float]]):
        pulumi.set(self, "value", value)


if not MYPY:
    class TaskSetServiceRegistryArgsDict(TypedDict):
        container_name: NotRequired[pulumi.Input[_builtins.str]]
        """
        The container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.
        """
        container_port: NotRequired[pulumi.Input[_builtins.int]]
        """
        The port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.
        """
        port: NotRequired[pulumi.Input[_builtins.int]]
        """
        The port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.
        """
        registry_arn: NotRequired[pulumi.Input[_builtins.str]]
        """
        The Amazon Resource Name (ARN) of the service registry. The currently supported service registry is AWS Cloud Map. For more information, see https://docs.aws.amazon.com/cloud-map/latest/api/API_CreateService.html
        """
elif False:
    TaskSetServiceRegistryArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class TaskSetServiceRegistryArgs:
    def __init__(__self__, *,
                 container_name: Optional[pulumi.Input[_builtins.str]] = None,
                 container_port: Optional[pulumi.Input[_builtins.int]] = None,
                 port: Optional[pulumi.Input[_builtins.int]] = None,
                 registry_arn: Optional[pulumi.Input[_builtins.str]] = None):
        """
        :param pulumi.Input[_builtins.str] container_name: The container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.
        :param pulumi.Input[_builtins.int] container_port: The port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.
        :param pulumi.Input[_builtins.int] port: The port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.
        :param pulumi.Input[_builtins.str] registry_arn: The Amazon Resource Name (ARN) of the service registry. The currently supported service registry is AWS Cloud Map. For more information, see https://docs.aws.amazon.com/cloud-map/latest/api/API_CreateService.html
        """
        if container_name is not None:
            pulumi.set(__self__, "container_name", container_name)
        if container_port is not None:
            pulumi.set(__self__, "container_port", container_port)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if registry_arn is not None:
            pulumi.set(__self__, "registry_arn", registry_arn)

    @_builtins.property
    @pulumi.getter(name="containerName")
    def container_name(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The container name value, already specified in the task definition, to be used for your service discovery service. If the task definition that your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition that your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.
        """
        return pulumi.get(self, "container_name")

    @container_name.setter
    def container_name(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "container_name", value)

    @_builtins.property
    @pulumi.getter(name="containerPort")
    def container_port(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The port value, already specified in the task definition, to be used for your service discovery service. If the task definition your service task specifies uses the bridge or host network mode, you must specify a containerName and containerPort combination from the task definition. If the task definition your service task specifies uses the awsvpc network mode and a type SRV DNS record is used, you must specify either a containerName and containerPort combination or a port value, but not both.
        """
        return pulumi.get(self, "container_port")

    @container_port.setter
    def container_port(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "container_port", value)

    @_builtins.property
    @pulumi.getter
    def port(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        The port value used if your service discovery service specified an SRV record. This field may be used if both the awsvpc network mode and SRV records are used.
        """
        return pulumi.get(self, "port")

    @port.setter
    def port(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "port", value)

    @_builtins.property
    @pulumi.getter(name="registryArn")
    def registry_arn(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        The Amazon Resource Name (ARN) of the service registry. The currently supported service registry is AWS Cloud Map. For more information, see https://docs.aws.amazon.com/cloud-map/latest/api/API_CreateService.html
        """
        return pulumi.get(self, "registry_arn")

    @registry_arn.setter
    def registry_arn(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "registry_arn", value)


