// *** WARNING: this file was generated by the Pulumi SDK Generator. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.AwsNative.LookoutEquipment
{
    /// <summary>
    /// Resource schema for LookoutEquipment InferenceScheduler.
    /// </summary>
    [Obsolete(@"InferenceScheduler is not yet supported by AWS Native, so its creation will currently fail. Please use the classic AWS provider, if possible.")]
    [AwsNativeResourceType("aws-native:lookoutequipment:InferenceScheduler")]
    public partial class InferenceScheduler : Pulumi.CustomResource
    {
        /// <summary>
        /// A period of time (in minutes) by which inference on the data is delayed after the data starts.
        /// </summary>
        [Output("dataDelayOffsetInMinutes")]
        public Output<int?> DataDelayOffsetInMinutes { get; private set; } = null!;

        /// <summary>
        /// Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location.
        /// </summary>
        [Output("dataInputConfiguration")]
        public Output<Outputs.DataInputConfigurationProperties> DataInputConfiguration { get; private set; } = null!;

        /// <summary>
        /// Specifies configuration information for the output results for the inference scheduler, including the S3 location for the output.
        /// </summary>
        [Output("dataOutputConfiguration")]
        public Output<Outputs.DataOutputConfigurationProperties> DataOutputConfiguration { get; private set; } = null!;

        /// <summary>
        /// How often data is uploaded to the source S3 bucket for the input data.
        /// </summary>
        [Output("dataUploadFrequency")]
        public Output<Pulumi.AwsNative.LookoutEquipment.InferenceSchedulerDataUploadFrequency> DataUploadFrequency { get; private set; } = null!;

        /// <summary>
        /// The Amazon Resource Name (ARN) of the inference scheduler being created.
        /// </summary>
        [Output("inferenceSchedulerArn")]
        public Output<string> InferenceSchedulerArn { get; private set; } = null!;

        /// <summary>
        /// The name of the inference scheduler being created.
        /// </summary>
        [Output("inferenceSchedulerName")]
        public Output<string?> InferenceSchedulerName { get; private set; } = null!;

        /// <summary>
        /// The name of the previously trained ML model being used to create the inference scheduler.
        /// </summary>
        [Output("modelName")]
        public Output<string> ModelName { get; private set; } = null!;

        /// <summary>
        /// The Amazon Resource Name (ARN) of a role with permission to access the data source being used for the inference.
        /// </summary>
        [Output("roleArn")]
        public Output<string> RoleArn { get; private set; } = null!;

        /// <summary>
        /// Provides the identifier of the AWS KMS customer master key (CMK) used to encrypt inference scheduler data by Amazon Lookout for Equipment.
        /// </summary>
        [Output("serverSideKmsKeyId")]
        public Output<string?> ServerSideKmsKeyId { get; private set; } = null!;

        /// <summary>
        /// Any tags associated with the inference scheduler.
        /// </summary>
        [Output("tags")]
        public Output<ImmutableArray<Outputs.InferenceSchedulerTag>> Tags { get; private set; } = null!;


        /// <summary>
        /// Create a InferenceScheduler resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public InferenceScheduler(string name, InferenceSchedulerArgs args, CustomResourceOptions? options = null)
            : base("aws-native:lookoutequipment:InferenceScheduler", name, args ?? new InferenceSchedulerArgs(), MakeResourceOptions(options, ""))
        {
        }

        private InferenceScheduler(string name, Input<string> id, CustomResourceOptions? options = null)
            : base("aws-native:lookoutequipment:InferenceScheduler", name, null, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing InferenceScheduler resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static InferenceScheduler Get(string name, Input<string> id, CustomResourceOptions? options = null)
        {
            return new InferenceScheduler(name, id, options);
        }
    }

    public sealed class InferenceSchedulerArgs : Pulumi.ResourceArgs
    {
        /// <summary>
        /// A period of time (in minutes) by which inference on the data is delayed after the data starts.
        /// </summary>
        [Input("dataDelayOffsetInMinutes")]
        public Input<int>? DataDelayOffsetInMinutes { get; set; }

        /// <summary>
        /// Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location.
        /// </summary>
        [Input("dataInputConfiguration", required: true)]
        public Input<Inputs.DataInputConfigurationPropertiesArgs> DataInputConfiguration { get; set; } = null!;

        /// <summary>
        /// Specifies configuration information for the output results for the inference scheduler, including the S3 location for the output.
        /// </summary>
        [Input("dataOutputConfiguration", required: true)]
        public Input<Inputs.DataOutputConfigurationPropertiesArgs> DataOutputConfiguration { get; set; } = null!;

        /// <summary>
        /// How often data is uploaded to the source S3 bucket for the input data.
        /// </summary>
        [Input("dataUploadFrequency", required: true)]
        public Input<Pulumi.AwsNative.LookoutEquipment.InferenceSchedulerDataUploadFrequency> DataUploadFrequency { get; set; } = null!;

        /// <summary>
        /// The name of the inference scheduler being created.
        /// </summary>
        [Input("inferenceSchedulerName")]
        public Input<string>? InferenceSchedulerName { get; set; }

        /// <summary>
        /// The name of the previously trained ML model being used to create the inference scheduler.
        /// </summary>
        [Input("modelName", required: true)]
        public Input<string> ModelName { get; set; } = null!;

        /// <summary>
        /// The Amazon Resource Name (ARN) of a role with permission to access the data source being used for the inference.
        /// </summary>
        [Input("roleArn", required: true)]
        public Input<string> RoleArn { get; set; } = null!;

        /// <summary>
        /// Provides the identifier of the AWS KMS customer master key (CMK) used to encrypt inference scheduler data by Amazon Lookout for Equipment.
        /// </summary>
        [Input("serverSideKmsKeyId")]
        public Input<string>? ServerSideKmsKeyId { get; set; }

        [Input("tags")]
        private InputList<Inputs.InferenceSchedulerTagArgs>? _tags;

        /// <summary>
        /// Any tags associated with the inference scheduler.
        /// </summary>
        public InputList<Inputs.InferenceSchedulerTagArgs> Tags
        {
            get => _tags ?? (_tags = new InputList<Inputs.InferenceSchedulerTagArgs>());
            set => _tags = value;
        }

        public InferenceSchedulerArgs()
        {
        }
    }
}
