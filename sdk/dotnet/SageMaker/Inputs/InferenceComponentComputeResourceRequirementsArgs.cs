// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.AwsNative.SageMaker.Inputs
{

    public sealed class InferenceComponentComputeResourceRequirementsArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// The maximum MB of memory to allocate to run a model that you assign to an inference component.
        /// </summary>
        [Input("maxMemoryRequiredInMb")]
        public Input<int>? MaxMemoryRequiredInMb { get; set; }

        /// <summary>
        /// The minimum MB of memory to allocate to run a model that you assign to an inference component.
        /// </summary>
        [Input("minMemoryRequiredInMb")]
        public Input<int>? MinMemoryRequiredInMb { get; set; }

        /// <summary>
        /// The number of accelerators to allocate to run a model that you assign to an inference component. Accelerators include GPUs and AWS Inferentia.
        /// </summary>
        [Input("numberOfAcceleratorDevicesRequired")]
        public Input<double>? NumberOfAcceleratorDevicesRequired { get; set; }

        /// <summary>
        /// The number of CPU cores to allocate to run a model that you assign to an inference component.
        /// </summary>
        [Input("numberOfCpuCoresRequired")]
        public Input<double>? NumberOfCpuCoresRequired { get; set; }

        public InferenceComponentComputeResourceRequirementsArgs()
        {
        }
        public static new InferenceComponentComputeResourceRequirementsArgs Empty => new InferenceComponentComputeResourceRequirementsArgs();
    }
}
