// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.AwsNative.Bedrock.Inputs
{

    /// <summary>
    /// Topic config in topic policy.
    /// </summary>
    public sealed class GuardrailTopicConfigArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Definition of topic in topic policy
        /// </summary>
        [Input("definition", required: true)]
        public Input<string> Definition { get; set; } = null!;

        [Input("examples")]
        private InputList<string>? _examples;

        /// <summary>
        /// List of text examples
        /// </summary>
        public InputList<string> Examples
        {
            get => _examples ?? (_examples = new InputList<string>());
            set => _examples = value;
        }

        /// <summary>
        /// Specifies the action to take when harmful content is detected in the input. Supported values include:
        /// 
        /// - `BLOCK` – Block the content and replace it with blocked messaging.
        /// - `NONE` – Take no action but return detection information in the trace response.
        /// </summary>
        [Input("inputAction")]
        public Input<Pulumi.AwsNative.Bedrock.GuardrailTopicAction>? InputAction { get; set; }

        /// <summary>
        /// Specifies whether to enable guardrail evaluation on the input. When disabled, you aren't charged for the evaluation. The evaluation doesn't appear in the response.
        /// </summary>
        [Input("inputEnabled")]
        public Input<bool>? InputEnabled { get; set; }

        /// <summary>
        /// Name of topic in topic policy
        /// </summary>
        [Input("name", required: true)]
        public Input<string> Name { get; set; } = null!;

        /// <summary>
        /// Specifies the action to take when harmful content is detected in the output. Supported values include:
        /// 
        /// - `BLOCK` – Block the content and replace it with blocked messaging.
        /// - `NONE` – Take no action but return detection information in the trace response.
        /// </summary>
        [Input("outputAction")]
        public Input<Pulumi.AwsNative.Bedrock.GuardrailTopicAction>? OutputAction { get; set; }

        /// <summary>
        /// Specifies whether to enable guardrail evaluation on the output. When disabled, you aren't charged for the evaluation. The evaluation doesn't appear in the response.
        /// </summary>
        [Input("outputEnabled")]
        public Input<bool>? OutputEnabled { get; set; }

        /// <summary>
        /// Specifies to deny the topic.
        /// </summary>
        [Input("type", required: true)]
        public Input<Pulumi.AwsNative.Bedrock.GuardrailTopicType> Type { get; set; } = null!;

        public GuardrailTopicConfigArgs()
        {
        }
        public static new GuardrailTopicConfigArgs Empty => new GuardrailTopicConfigArgs();
    }
}
