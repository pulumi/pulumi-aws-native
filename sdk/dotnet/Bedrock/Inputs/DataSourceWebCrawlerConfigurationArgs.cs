// *** WARNING: this file was generated by pulumi. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.AwsNative.Bedrock.Inputs
{

    /// <summary>
    /// Configuration for the web crawler.
    /// </summary>
    public sealed class DataSourceWebCrawlerConfigurationArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// The configuration of crawl limits for the web URLs.
        /// </summary>
        [Input("crawlerLimits")]
        public Input<Inputs.DataSourceWebCrawlerLimitsArgs>? CrawlerLimits { get; set; }

        [Input("exclusionFilters")]
        private InputList<string>? _exclusionFilters;

        /// <summary>
        /// A list of one or more exclusion regular expression patterns to exclude certain URLs. If you specify an inclusion and exclusion filter/pattern and both match a URL, the exclusion filter takes precedence and the web content of the URL isn’t crawled.
        /// </summary>
        public InputList<string> ExclusionFilters
        {
            get => _exclusionFilters ?? (_exclusionFilters = new InputList<string>());
            set => _exclusionFilters = value;
        }

        [Input("inclusionFilters")]
        private InputList<string>? _inclusionFilters;

        /// <summary>
        /// A list of one or more inclusion regular expression patterns to include certain URLs. If you specify an inclusion and exclusion filter/pattern and both match a URL, the exclusion filter takes precedence and the web content of the URL isn’t crawled.
        /// </summary>
        public InputList<string> InclusionFilters
        {
            get => _inclusionFilters ?? (_inclusionFilters = new InputList<string>());
            set => _inclusionFilters = value;
        }

        /// <summary>
        /// The scope of what is crawled for your URLs.
        /// 
        /// You can choose to crawl only web pages that belong to the same host or primary domain. For example, only web pages that contain the seed URL "https://docs.aws.amazon.com/bedrock/latest/userguide/" and no other domains. You can choose to include sub domains in addition to the host or primary domain. For example, web pages that contain "aws.amazon.com" can also include sub domain "docs.aws.amazon.com".
        /// </summary>
        [Input("scope")]
        public Input<Pulumi.AwsNative.Bedrock.DataSourceWebScopeType>? Scope { get; set; }

        /// <summary>
        /// The suffix that will be included in the user agent header.
        /// </summary>
        [Input("userAgent")]
        public Input<string>? UserAgent { get; set; }

        /// <summary>
        /// The full user agent header, including UUID and suffix.
        /// </summary>
        [Input("userAgentHeader")]
        public Input<string>? UserAgentHeader { get; set; }

        public DataSourceWebCrawlerConfigurationArgs()
        {
        }
        public static new DataSourceWebCrawlerConfigurationArgs Empty => new DataSourceWebCrawlerConfigurationArgs();
    }
}
