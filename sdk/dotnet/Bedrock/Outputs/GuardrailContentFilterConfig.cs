// *** WARNING: this file was generated by pulumi. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.AwsNative.Bedrock.Outputs
{

    /// <summary>
    /// Content filter config in content policy.
    /// </summary>
    [OutputType]
    public sealed class GuardrailContentFilterConfig
    {
        /// <summary>
        /// The strength of the content filter to apply to prompts. As you increase the filter strength, the likelihood of filtering harmful content increases and the probability of seeing harmful content in your application reduces.
        /// </summary>
        public readonly Pulumi.AwsNative.Bedrock.GuardrailFilterStrength InputStrength;
        /// <summary>
        /// The strength of the content filter to apply to model responses. As you increase the filter strength, the likelihood of filtering harmful content increases and the probability of seeing harmful content in your application reduces.
        /// </summary>
        public readonly Pulumi.AwsNative.Bedrock.GuardrailFilterStrength OutputStrength;
        /// <summary>
        /// The harmful category that the content filter is applied to.
        /// </summary>
        public readonly Pulumi.AwsNative.Bedrock.GuardrailContentFilterType Type;

        [OutputConstructor]
        private GuardrailContentFilterConfig(
            Pulumi.AwsNative.Bedrock.GuardrailFilterStrength inputStrength,

            Pulumi.AwsNative.Bedrock.GuardrailFilterStrength outputStrength,

            Pulumi.AwsNative.Bedrock.GuardrailContentFilterType type)
        {
            InputStrength = inputStrength;
            OutputStrength = outputStrength;
            Type = type;
        }
    }
}
