// *** WARNING: this file was generated by pulumi. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.AwsNative.Bedrock.Outputs
{

    /// <summary>
    /// Prompt variant
    /// </summary>
    [OutputType]
    public sealed class PromptVersionPromptVariant
    {
        /// <summary>
        /// Contains model-specific inference configurations that aren't in the `inferenceConfiguration` field. To see model-specific inference parameters, see [Inference request parameters and response fields for foundation models](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html) .
        /// </summary>
        public readonly Outputs.PromptVersionAdditionalModelRequestFields? AdditionalModelRequestFields;
        /// <summary>
        /// Specifies a generative AI resource with which to use the prompt.
        /// </summary>
        public readonly Outputs.PromptVersionPromptGenAiResourceProperties? GenAiResource;
        /// <summary>
        /// Contains inference configurations for the prompt variant.
        /// </summary>
        public readonly Outputs.PromptVersionPromptInferenceConfigurationProperties? InferenceConfiguration;
        /// <summary>
        /// ARN or Id of a Bedrock Foundational Model or Inference Profile, or the ARN of a imported model, or a provisioned throughput ARN for custom models.
        /// </summary>
        public readonly string? ModelId;
        /// <summary>
        /// Name for a variant.
        /// </summary>
        public readonly string Name;
        /// <summary>
        /// Contains configurations for the prompt template.
        /// </summary>
        public readonly Union<Outputs.PromptVersionPromptTemplateConfiguration0Properties, Outputs.PromptVersionPromptTemplateConfiguration1Properties> TemplateConfiguration;
        /// <summary>
        /// The type of prompt template to use.
        /// </summary>
        public readonly Pulumi.AwsNative.Bedrock.PromptVersionPromptTemplateType TemplateType;

        [OutputConstructor]
        private PromptVersionPromptVariant(
            Outputs.PromptVersionAdditionalModelRequestFields? additionalModelRequestFields,

            Outputs.PromptVersionPromptGenAiResourceProperties? genAiResource,

            Outputs.PromptVersionPromptInferenceConfigurationProperties? inferenceConfiguration,

            string? modelId,

            string name,

            Union<Outputs.PromptVersionPromptTemplateConfiguration0Properties, Outputs.PromptVersionPromptTemplateConfiguration1Properties> templateConfiguration,

            Pulumi.AwsNative.Bedrock.PromptVersionPromptTemplateType templateType)
        {
            AdditionalModelRequestFields = additionalModelRequestFields;
            GenAiResource = genAiResource;
            InferenceConfiguration = inferenceConfiguration;
            ModelId = modelId;
            Name = name;
            TemplateConfiguration = templateConfiguration;
            TemplateType = templateType;
        }
    }
}
